docName,pageContent,pageNumber
Attention is all you need - Cornell.pdf,"['attention', 'need', 'ashishvaswani∗', 'noamshazeer∗', 'nikiparmar∗', 'jakobuszkoreit∗', 'googlebrain', 'googlebrain', 'googleresearch', 'googleresearch', 'avaswani', 'google.com', 'noam', 'google.com', 'nikip', 'google.com', 'usz', 'google.com', '7', '1', '0', 'llionjones∗', 'aidann.gomez∗', '†', 'łukaszkaiser∗', '2', 'googleresearch', 'universityoftoronto', 'googlebrain', 'llion', 'google.com', 'aidan', 'cs.toronto.edu', 'lukaszkaiser', 'google.com', 'c', 'e', 'illiapolosukhin∗', '‡', '6', 'illia.polosukhin', 'gmail.com', ']', 'l', 'c', 'abstract', 'c', 'thedominantsequencetransductionmodelsarebasedoncomplexrecurrentor', '[', 'convolutionalneuralnetworksthatincludeanencoderandadecoder', 'thebest', 'perform', 'model', 'also', 'connect', 'encoder', 'decoder', 'attention', '5', 'mechanism', 'propose', 'new', 'simple', 'network', 'architecture', 'transformer', 'v', 'basedsolelyonattentionmechanisms', 'dispensingwithrecurrenceandconvolutions', '2', '6', 'entirely', 'experiment', 'two', 'machine', 'translation', 'task', 'show', 'model', '7', 'besuperiorinqualitywhilebeingmoreparallelizableandrequiringsigniﬁcantly', '3', 'less', 'time', 'train', 'model', 'achieve', '28.4', 'bleu', 'wmt', '2014', 'english-', '0', 'to-german', 'translation', 'task', 'improve', 'exist', 'best', 'result', 'include', 'ensembles', 'byover2bleu.onthewmt2014english-to-frenchtranslationtask', '6', '0', 'ourmodelestablishesanewsingle-modelstate-of-the-artbleuscoreof41.8after', '7', 'trainingfor3.5daysoneightgpus', 'asmallfractionofthetrainingcostsofthe', '1', 'bestmodelsfromtheliterature', 'weshowthatthetransformergeneralizeswellto', 'othertasksbyapplyingitsuccessfullytoenglishconstituencyparsingbothwith', 'v', 'largeandlimitedtrainingdata', 'x', 'r', '1', 'introduction', 'recurrentneuralnetworks', 'longshort-termmemory', '[', '13', ']', 'andgatedrecurrent', '[', '7', ']', 'neuralnetworks', 'inparticular', 'havebeenﬁrmlyestablishedasstateoftheartapproachesinsequencemodelingand', '∗equalcontribution.listingorderisrandom.jakobproposedreplacingrnnswithself-attentionandstarted', 'theefforttoevaluatethisidea.ashish', 'withillia', 'designedandimplementedtheﬁrsttransformermodelsand', 'hasbeencruciallyinvolvedineveryaspectofthiswork.noamproposedscaleddot-productattention', 'multi-head', 'attentionandtheparameter-freepositionrepresentationandbecametheotherpersoninvolvedinnearlyevery', 'detail.nikidesigned', 'implement', 'tunedandevaluatedcountlessmodelvariantsinouroriginalcodebaseand', 'tensor2tensor.llionalsoexperimentedwithnovelmodelvariants', 'wasresponsibleforourinitialcodebase', 'efﬁcientinferenceandvisualizations.lukaszandaidanspentcountlesslongdaysdesigningvariouspartsofand', 'implementingtensor2tensor', 'replacingourearliercodebase', 'greatlyimprovingresultsandmassivelyaccelerating', 'ourresearch', '†workperformedwhileatgooglebrain', '‡workperformedwhileatgoogleresearch', '31stconferenceonneuralinformationprocessingsystems', 'nips2017', 'longbeach', 'ca', 'usa']",1
Attention is all you need - Cornell.pdf,"['transductionproblemssuchaslanguagemodelingandmachinetranslation', '[', '35,2,5', ']', 'numerous', 'effortshavesincecontinuedtopushtheboundariesofrecurrentlanguagemodelsandencoder-decoder', 'architectures', '[', '38,24,15', ']', 'recurrentmodelstypicallyfactorcomputationalongthesymbolpositionsoftheinputandoutput', 'sequence', 'aligningthepositionstostepsincomputationtime', 'theygenerateasequenceofhidden', 'statesh', 'asafunctionoftheprevioushiddenstateh', 'andtheinputforpositiont', 'thisinherently', 't−1', 'sequentialnatureprecludesparallelizationwithintrainingexamples', 'whichbecomescriticalatlonger', 'sequencelengths', 'asmemoryconstraintslimitbatchingacrossexamples', 'recentworkhasachieved', 'signiﬁcantimprovementsincomputationalefﬁciencythroughfactorizationtricks', '[', '21', ']', 'andconditional', 'computation', '[', '32', ']', 'whilealsoimprovingmodelperformanceincaseofthelatter', 'thefundamental', 'constraintofsequentialcomputation', 'however', 'remain', 'attentionmechanismshavebecomeanintegralpartofcompellingsequencemodelingandtransduc-', 'tionmodelsinvarioustasks', 'allowingmodelingofdependencieswithoutregardtotheirdistancein', 'theinputoroutputsequences', '[', '2,19', ']', 'inallbutafewcases', '[', '27', ']', 'however', 'suchattentionmechanisms', 'areusedinconjunctionwitharecurrentnetwork', 'inthisworkweproposethetransformer', 'amodelarchitectureeschewingrecurrenceandinstead', 'relyingentirelyonanattentionmechanismtodrawglobaldependenciesbetweeninputandoutput', 'thetransformerallowsforsigniﬁcantlymoreparallelizationandcanreachanewstateoftheartin', 'translationqualityafterbeingtrainedforaslittleastwelvehoursoneightp100gpus', '2', 'background', 'thegoalofreducingsequentialcomputationalsoformsthefoundationoftheextendedneuralgpu', '[', '16', ']', 'bytenet', '[', '18', ']', 'andconvs2s', '[', '9', ']', 'allofwhichuseconvolutionalneuralnetworksasbasicbuilding', 'block', 'computinghiddenrepresentationsinparallelforallinputandoutputpositions.inthesemodels', 'thenumberofoperationsrequiredtorelatesignalsfromtwoarbitraryinputoroutputpositionsgrows', 'inthedistancebetweenpositions', 'linearlyforconvs2sandlogarithmicallyforbytenet', 'thismakes', 'difﬁcult', 'learn', 'dependencies', 'distant', 'position', '[', '12', ']', 'transformer', 'reducedtoaconstantnumberofoperations', 'albeitatthecostofreducedeffectiveresolutiondue', 'average', 'attention-weighted', 'position', 'effect', 'counteract', 'multi-head', 'attention', 'describedinsection3.2', 'self-attention', 'sometimescalledintra-attentionisanattentionmechanismrelatingdifferentpositions', 'ofasinglesequenceinordertocomputearepresentationofthesequence', 'self-attentionhasbeen', 'usedsuccessfullyinavarietyoftasksincludingreadingcomprehension', 'abstractivesummarization', 'textualentailmentandlearningtask-independentsentencerepresentations', '[', '4,27,28,22', ']', 'end-to-endmemorynetworksarebasedonarecurrentattentionmechanisminsteadofsequence-', 'alignedrecurrenceandhavebeenshowntoperformwellonsimple-languagequestionansweringand', 'languagemodelingtasks', '[', '34', ']', 'best', 'knowledge', 'however', 'transformer', 'ﬁrst', 'transduction', 'model', 'rely', 'entirelyonself-attentiontocomputerepresentationsofitsinputandoutputwithoutusingsequence-', 'alignedrnnsorconvolution', 'inthefollowingsections', 'wewilldescribethetransformer', 'motivate', 'self-attentionanddiscussitsadvantagesovermodelssuchas', '[', '17,18', ']', '[', '9', ']', '3', 'modelarchitecture', 'mostcompetitiveneuralsequencetransductionmodelshaveanencoder-decoderstructure', '[', '5,2,35', ']', 'encoder', 'map', 'input', 'sequence', 'symbol', 'representations', 'x', '...', 'x', 'sequence', '1', 'n', 'continuous', 'representations', 'z', '=', 'z', '...', 'z', 'give', 'z', 'decoder', 'generate', 'output', '1', 'n', 'sequence', '...', 'ofsymbolsoneelementatatime', 'ateachstepthemodelisauto-regressive', '1', '[', '10', ']', 'consumingthepreviouslygeneratedsymbolsasadditionalinputwhengeneratingthenext', 'thetransformerfollowsthisoverallarchitectureusingstackedself-attentionandpoint-wise', 'fully', 'connectedlayersforboththeencoderanddecoder', 'shownintheleftandrighthalvesoffigure1', 'respectively', '2']",2
Attention is all you need - Cornell.pdf,"['figure1', 'thetransformer-modelarchitecture', '3.1', 'encoderanddecoderstacks', 'encoder', 'encoder', 'compose', 'stack', 'n', '=', '6', 'identical', 'layer', 'layer', 'two', 'sub-layers', 'theﬁrstisamulti-headself-attentionmechanism', 'andthesecondisasimple', 'position-', 'wisefullyconnectedfeed-forwardnetwork', 'weemployaresidualconnection', '[', '11', ']', 'aroundeachof', 'two', 'sub-layers', 'follow', 'layer', 'normalization', '[', '1', ']', 'output', 'sub-layer', 'layernorm', 'x+sublayer', 'x', 'wheresublayer', 'x', 'isthefunctionimplementedbythesub-layer', 'tofacilitatetheseresidualconnections', 'allsub-layersinthemodel', 'aswellastheembedding', 'layer', 'produceoutputsofdimensiond', '=512', 'model', 'decoder', 'thedecoderisalsocomposedofastackofn', '=6identicallayers', 'inadditiontothetwo', 'sub-layersineachencoderlayer', 'thedecoderinsertsathirdsub-layer', 'whichperformsmulti-head', 'attentionovertheoutputoftheencoderstack', 'similartotheencoder', 'weemployresidualconnections', 'aroundeachofthesub-layers', 'followedbylayernormalization', 'wealsomodifytheself-attention', 'sub-layer', 'decoder', 'stack', 'prevent', 'position', 'attend', 'subsequent', 'position', 'mask', 'combinedwithfactthattheoutputembeddingsareoffsetbyoneposition', 'ensuresthatthe', 'predictionsforpositionicandependonlyontheknownoutputsatpositionslessthani', '3.2', 'attention', 'anattentionfunctioncanbedescribedasmappingaqueryandasetofkey-valuepairstoanoutput', 'wherethequery', 'key', 'value', 'andoutputareallvectors', 'theoutputiscomputedasaweightedsum', 'ofthevalues', 'wheretheweightassignedtoeachvalueiscomputedbyacompatibilityfunctionofthe', 'querywiththecorrespondingkey', '3']",3
Attention is all you need - Cornell.pdf,"['scaleddot-productattention', 'multi-headattention', 'figure', '2', 'leave', 'scale', 'dot-product', 'attention', 'right', 'multi-head', 'attention', 'consist', 'several', 'attentionlayersrunninginparallel', '3.2.1', 'scaleddot-productattention', 'wecallourparticularattention', ""''"", 'scaleddot-productattention', ""''"", 'figure2', 'theinputconsistsof', 'queriesandkeysofdimensiondk', 'a√ndvaluesofdimensiondv', 'wecomputethedotproductsofthe', 'querywithallkeys', 'divideeachby', 'andapplyasoftmaxfunctiontoobtaintheweightsonthe', 'k', 'value', 'inpractice', 'wecomputetheattentionfunctiononasetofqueriessimultaneously', 'packedtogether', 'intoamatrixq', 'thekeysandvaluesarealsopackedtogetherintomatricesk', 'andv', 'wecompute', 'thematrixofoutputsas', 'qkt', 'attention', 'q', 'k', 'v', '=softmax', '√', 'v', '1', 'k', 'thetwomostcommonlyusedattentionfunctionsareadditiveattention', '[', '2', ']', 'anddot-product', 'multi-', 'plicative', 'attention', 'dot-productattentionisidenticaltoouralgorithm', 'exceptforthescalingfactor', '√1', 'additiveattentioncomputesthecompatibilityfunctionusingafeed-forwardnetworkwith', 'dk', 'asinglehiddenlayer', 'whilethetwoaresimilarintheoreticalcomplexity', 'dot-productattentionis', 'muchfasterandmorespace-efﬁcientinpractice', 'sinceitcanbeimplementedusinghighlyoptimized', 'matrixmultiplicationcode', 'whileforsmallvaluesofd', 'thetwomechanismsperformsimilarly', 'additiveattentionoutperforms', 'k', 'dotproductattentionwithoutscalingforlargervaluesofd', '[', '3', ']', 'wesuspectthatforlargevaluesof', 'k', 'thedotproductsgrowlargeinmagnitude', 'pushingthesoftmaxfunctionintoregionswhereithas', 'k', 'extremelysmallgradients4', 'tocounteractthiseffect', 'wescalethedotproductsby', '√1', 'dk', '3.2.2', 'multi-headattention', 'insteadofperformingasingleattentionfunctionwithd', '-dimensionalkeys', 'valuesandqueries', 'model', 'wefounditbeneﬁcialtolinearlyprojectthequeries', 'keysandvalueshtimeswithdifferent', 'learn', 'linearprojectionstod', 'andd', 'dimension', 'respectively', 'oneachoftheseprojectedversionsof', 'k', 'k', 'v', 'query', 'keysandvalueswethenperformtheattentionfunctioninparallel', 'yieldingd', '-dimensional', 'v', 'output', 'value', 'concatenate', 'project', 'result', 'ﬁnal', 'value', 'depictedinfigure2', '4toillustratewhythedotproductsgetlarge', 'assumethatthecomponentsofqandkareindependentrandom', 'variableswithmean0andvariance1.thentheirdotproduct', 'q·k=', 'cid:80', 'dk', 'q', 'k', 'hasmean0andvarianced', 'i=1', 'k', '4']",4
Attention is all you need - Cornell.pdf,"['multi-headattentionallowsthemodeltojointlyattendtoinformationfromdifferentrepresentation', 'subspacesatdifferentpositions', 'withasingleattentionhead', 'averaginginhibitsthis', 'multihead', 'q', 'k', 'v', '=concat', 'head', '...', 'head', 'wo', '1', 'h', 'wherehead', '=attention', 'qwq', 'kwk', 'vwv', 'wheretheprojectionsareparametermatriceswq', '∈rdmodel×dk', 'wk', '∈rdmodel×dk', 'wv', '∈rdmodel×dv', 'andwo', '∈rhdv×dmodel', 'work', 'employ', 'h', '=', '8', 'parallel', 'attention', 'layer', 'head', 'use', '=d', '=d', '/h=64', 'duetothereduceddimensionofeachhead', 'thetotalcomputationalcost', 'k', 'v', 'model', 'issimilartothatofsingle-headattentionwithfulldimensionality', '3.2.3', 'applicationsofattentioninourmodel', 'thetransformerusesmulti-headattentioninthreedifferentways', '•', ""''"", 'encoder-decoderattention', ""''"", 'layer', 'thequeriescomefromthepreviousdecoderlayer', 'andthememorykeysandvaluescomefromtheoutputoftheencoder', 'thisallowsevery', 'positioninthedecodertoattendoverallpositionsintheinputsequence', 'thismimicsthe', 'typical', 'encoder-decoder', 'attention', 'mechanisms', 'sequence-to-sequence', 'model', '[', '38,2,9', ']', '•', 'theencodercontainsself-attentionlayers', 'inaself-attentionlayerallofthekeys', 'value', 'andqueriescomefromthesameplace', 'inthiscase', 'theoutputofthepreviouslayerinthe', 'encoder', 'eachpositionintheencodercanattendtoallpositionsinthepreviouslayerofthe', 'encoder', '•', 'similarly', 'self-attentionlayersinthedecoderalloweachpositioninthedecodertoattendto', 'allpositionsinthedecoderuptoandincludingthatposition', 'weneedtopreventleftward', 'informationﬂowinthedecodertopreservetheauto-regressiveproperty', 'weimplementthis', 'insideofscaleddot-productattentionbymaskingout', 'settingto−∞', 'allvaluesintheinput', 'ofthesoftmaxwhichcorrespondtoillegalconnections', 'seefigure2', '3.3', 'position-wisefeed-forwardnetworks', 'inadditiontoattentionsub-layers', 'eachofthelayersinourencoderanddecodercontainsafully', 'connectedfeed-forwardnetwork', 'whichisappliedtoeachpositionseparatelyandidentically', 'consistsoftwolineartransformationswithareluactivationinbetween', 'ffn', 'x', '=max', '0', 'xw', '+b', 'w', '+b', '2', '1', '1', '2', '2', 'whilethelineartransformationsarethesameacrossdifferentpositions', 'theyusedifferentparameters', 'layer', 'layer', 'another', 'way', 'describe', 'two', 'convolutions', 'kernel', 'size', '1', 'dimensionality', 'input', 'output', '=', '512', 'inner-layer', 'dimensionality', 'model', '=2048', 'ff', '3.4', 'embeddingsandsoftmax', 'similarlytoothersequencetransductionmodels', 'weuselearnedembeddingstoconverttheinput', 'tokensandoutputtokenstovectorsofdimensiond', 'wealsousetheusuallearnedlineartransfor-', 'model', 'mationandsoftmaxfunctiontoconvertthedecoderoutputtopredictednext-tokenprobabilities', 'ourmodel', 'wesharethesameweightmatrixbetweenthetwoembeddinglayersandthepre-√softmax', 'lineartransformation', 'similarto', '[', '30', ']', 'intheembeddinglayers', 'wemultiplythoseweightsby', 'model', '3.5', 'positionalencoding', 'sinceourmodelcontainsnorecurrenceandnoconvolution', 'inorderforthemodeltomakeuseofthe', 'orderofthesequence', 'wemustinjectsomeinformationabouttherelativeorabsolutepositionofthe', '5']",5
Attention is all you need - Cornell.pdf,"['table1', 'maximumpathlengths', 'per-layercomplexityandminimumnumberofsequentialoperations', 'fordifferentlayertypes', 'nisthesequencelength', 'distherepresentationdimension', 'kisthekernel', 'sizeofconvolutionsandrthesizeoftheneighborhoodinrestrictedself-attention', 'layertype', 'complexityperlayer', 'sequential', 'maximumpathlength', 'operations', 'self-attention', 'n2·d', '1', '1', 'recurrent', 'n·d2', 'n', 'n', 'convolutional', 'k·n·d2', '1', 'log', 'n', 'k', 'self-attention', 'restrict', 'r·n·d', '1', 'n/r', 'tokensinthesequence', 'tothisend', 'weadd', ""''"", 'positionalencodings', ""''"", 'totheinputembeddingsatthe', 'bottomsoftheencoderanddecoderstacks', 'thepositionalencodingshavethesamedimensiond', 'model', 'astheembeddings', 'sothatthetwocanbesummed', 'therearemanychoicesofpositionalencodings', 'learnedandﬁxed', '[', '9', ']', 'inthiswork', 'weusesineandcosinefunctionsofdifferentfrequencies', 'pe', '=sin', 'pos/100002i/dmodel', 'pos,2i', 'pe', '=cos', 'pos/100002i/dmodel', 'pos,2i+1', 'whereposisthepositionandiisthedimension', 'thatis', 'eachdimensionofthepositionalencoding', 'correspondstoasinusoid', 'thewavelengthsformageometricprogressionfrom2πto10000·2π', 'chosethisfunctionbecausewehypothesizeditwouldallowthemodeltoeasilylearntoattendby', 'relativepositions', 'sinceforanyﬁxedoffsetk', 'pe', 'canberepresentedasalinearfunctionof', 'pos+k', 'pe', 'pos', 'wealsoexperimentedwithusinglearnedpositionalembeddings', '[', '9', ']', 'instead', 'andfoundthatthetwo', 'versionsproducednearlyidenticalresults', 'seetable3row', 'e', '.wechosethesinusoidalversion', 'becauseitmayallowthemodeltoextrapolatetosequencelengthslongerthantheonesencountered', 'duringtraining', '4', 'whyself-attention', 'section', 'compare', 'various', 'aspects', 'self-attention', 'layer', 'recurrent', 'convolu-', 'tionallayerscommonlyusedformappingonevariable-lengthsequenceofsymbolrepresentations', 'x', '...', 'x', 'another', 'sequence', 'equal', 'length', 'z', '...', 'z', 'x', 'z', '∈', 'rd', 'hide', '1', 'n', '1', 'n', 'layerinatypicalsequencetransductionencoderordecoder', 'motivatingouruseofself-attentionwe', 'considerthreedesiderata', 'oneisthetotalcomputationalcomplexityperlayer', 'anotheristheamountofcomputationthatcan', 'beparallelized', 'asmeasuredbytheminimumnumberofsequentialoperationsrequired', 'thethirdisthepathlengthbetweenlong-rangedependenciesinthenetwork', 'learninglong-range', 'dependenciesisakeychallengeinmanysequencetransductiontasks', 'onekeyfactoraffectingthe', 'abilitytolearnsuchdependenciesisthelengthofthepathsforwardandbackwardsignalshaveto', 'traverseinthenetwork', 'theshorterthesepathsbetweenanycombinationofpositionsintheinput', 'andoutputsequences', 'theeasieritistolearnlong-rangedependencies', '[', '12', ']', 'hencewealsocompare', 'themaximumpathlengthbetweenanytwoinputandoutputpositionsinnetworkscomposedofthe', 'differentlayertypes', 'asnotedintable1', 'aself-attentionlayerconnectsallpositionswithaconstantnumberofsequentially', 'execute', 'operations', 'whereas', 'recurrent', 'layer', 'require', 'n', 'sequential', 'operations', 'term', 'computationalcomplexity', 'self-attentionlayersarefasterthanrecurrentlayerswhenthesequence', 'length', 'n', 'smaller', 'representation', 'dimensionality', 'often', 'case', 'sentencerepresentationsusedbystate-of-the-artmodelsinmachinetranslations', 'suchasword-piece', '[', '38', ']', 'andbyte-pair', '[', '31', ']', 'representations', 'toimprovecomputationalperformancefortasksinvolving', 'verylongsequences', 'self-attentioncouldberestrictedtoconsideringonlyaneighborhoodofsizerin', '6']",6
Attention is all you need - Cornell.pdf,"['theinputsequencecenteredaroundtherespectiveoutputposition', 'thiswouldincreasethemaximum', 'pathlengthtoo', 'n/r', 'weplantoinvestigatethisapproachfurtherinfuturework', 'asingleconvolutionallayerwithkernelwidthk', '<', 'ndoesnotconnectallpairsofinputandoutput', 'position', 'doingsorequiresastackofo', 'n/k', 'convolutionallayersinthecaseofcontiguouskernels', 'oro', 'log', 'n', 'inthecaseofdilatedconvolutions', '[', '18', ']', 'increasingthelengthofthelongestpaths', 'k', 'betweenanytwopositionsinthenetwork', 'convolutionallayersaregenerallymoreexpensivethan', 'recurrent', 'layer', 'factor', 'k.', 'separable', 'convolutions', '[', '6', ']', 'however', 'decrease', 'complexity', 'considerably', 'k·n·d+n·d2', 'evenwithk', '=', 'n', 'however', 'thecomplexityofaseparable', 'convolutionisequaltothecombinationofaself-attentionlayerandapoint-wisefeed-forwardlayer', 'theapproachwetakeinourmodel', 'assidebeneﬁt', 'self-attentioncouldyieldmoreinterpretablemodels.weinspectattentiondistributions', 'fromourmodelsandpresentanddiscussexamplesintheappendix', 'notonlydoindividualattention', 'headsclearlylearntoperformdifferenttasks', 'manyappeartoexhibitbehaviorrelatedtothesyntactic', 'andsemanticstructureofthesentences', '5', 'train', 'thissectiondescribesthetrainingregimeforourmodels', '5.1', 'trainingdataandbatching', 'train', 'standard', 'wmt', '2014', 'english-german', 'dataset', 'consist', '4.5', 'million', 'sentencepairs', 'sentenceswereencodedusingbyte-pairencoding', '[', '3', ']', 'whichhasasharedsource-', 'targetvocabularyofabout37000tokens', 'forenglish-french', 'weusedthesigniﬁcantlylargerwmt', '2014english-frenchdatasetconsistingof36msentencesandsplittokensintoa32000word-piece', 'vocabulary', '[', '38', ']', '.sentencepairswerebatchedtogetherbyapproximatesequencelength.eachtraining', 'batchcontainedasetofsentencepairscontainingapproximately25000sourcetokensand25000', 'targettokens', '5.2', 'hardwareandschedule', 'wetrainedourmodelsononemachinewith8nvidiap100gpus', 'forourbasemodelsusing', 'thehyperparametersdescribedthroughoutthepaper', 'eachtrainingsteptookabout0.4seconds', 'trainedthebasemodelsforatotalof100,000stepsor12hours', 'forourbigmodels', 'describedonthe', 'bottomlineoftable3', 'steptimewas1.0seconds', 'thebigmodelsweretrainedfor300,000steps', '3.5days', '5.3', 'optimizer', 'weusedtheadamoptimizer', '[', '20', ']', 'withβ', '=0.9', 'β', '=0.98and', 'cid:15', '=10−9', 'wevariedthelearning', '1', '2', 'rateoverthecourseoftraining', 'accordingtotheformula', 'lrate=d−0.5', '·min', 'step_num−0.5', 'step_num·warmup_steps−1.5', '3', 'model', 'thiscorrespondstoincreasingthelearningratelinearlyfortheﬁrstwarmup_stepstrainingsteps', 'anddecreasingitthereafterproportionallytotheinversesquarerootofthestepnumber', 'weused', 'warmup_steps=4000', '5.4', 'regularization', 'weemploythreetypesofregularizationduringtraining', 'residualdropout', 'weapplydropout', '[', '33', ']', 'totheoutputofeachsub-layer', 'beforeitisaddedtothe', 'sub-layerinputandnormalized', 'inaddition', 'weapplydropouttothesumsoftheembeddingsandthe', 'positionalencodingsinboththeencoderanddecoderstacks', 'forthebasemodel', 'weusearateof', 'p', '=0.1', 'drop', '7']",7
Attention is all you need - Cornell.pdf,"['table2', 'thetransformerachievesbetterbleuscoresthanpreviousstate-of-the-artmodelsonthe', 'english-to-germanandenglish-to-frenchnewstest2014testsatafractionofthetrainingcost', 'bleu', 'trainingcost', 'flop', 'model', 'en-de', 'en-fr', 'en-de', 'en-fr', 'bytenet', '[', '18', ']', '23.75', 'deep-att+posunk', '[', '39', ']', '39.2', '1.0·1020', 'gnmt+rl', '[', '38', ']', '24.6', '39.92', '2.3·1019', '1.4·1020', 'convs2s', '[', '9', ']', '25.16', '40.46', '9.6·1018', '1.5·1020', 'moe', '[', '32', ']', '26.03', '40.56', '2.0·1019', '1.2·1020', 'deep-att+posunkensemble', '[', '39', ']', '40.4', '8.0·1020', 'gnmt+rlensemble', '[', '38', ']', '26.30', '41.16', '1.8·1020', '1.1·1021', 'convs2sensemble', '[', '9', ']', '26.36', '41.29', '7.7·1019', '1.2·1021', 'transformer', 'basemodel', '27.3', '38.1', '3.3·1018', 'transformer', 'big', '28.4', '41.8', '2.3·1019', 'labelsmoothing', 'duringtraining', 'weemployedlabelsmoothingofvalue', 'cid:15', '=', '0.1', '[', '36', ']', 'ls', 'hurtsperplexity', 'asthemodellearnstobemoreunsure', 'butimprovesaccuracyandbleuscore', '6', 'result', '6.1', 'machinetranslation', 'onthewmt2014english-to-germantranslationtask', 'thebigtransformermodel', 'transformer', 'big', 'intable2', 'outperformsthebestpreviouslyreportedmodels', 'includingensembles', 'bymorethan2.0', 'bleu', 'establishinganewstate-of-the-artbleuscoreof28.4', 'theconﬁgurationofthismodelis', 'listedinthebottomlineoftable3', 'trainingtook3.5dayson8p100gpus', 'evenourbasemodel', 'surpassesallpreviouslypublishedmodelsandensembles', 'atafractionofthetrainingcostofanyof', 'thecompetitivemodels', 'onthewmt2014english-to-frenchtranslationtask', 'ourbigmodelachievesableuscoreof41.0', 'outperformingallofthepreviouslypublishedsinglemodels', 'atlessthan1/4thetrainingcostofthe', 'previousstate-of-the-artmodel', 'thetransformer', 'big', 'modeltrainedforenglish-to-frenchused', 'dropoutratep', '=0.1', 'insteadof0.3', 'drop', 'forthebasemodels', 'weusedasinglemodelobtainedbyaveragingthelast5checkpoints', 'werewrittenat10-minuteintervals', 'forthebigmodels', 'weaveragedthelast20checkpoints', 'usedbeamsearchwithabeamsizeof4andlengthpenaltyα', '=', '0.6', '[', '38', ']', 'thesehyperparameters', 'werechosenafterexperimentationonthedevelopmentset', 'wesetthemaximumoutputlengthduring', 'inferencetoinputlength+50', 'butterminateearlywhenpossible', '[', '38', ']', 'table2summarizesourresultsandcomparesourtranslationqualityandtrainingcoststoothermodel', 'architecturesfromtheliterature', 'weestimatethenumberofﬂoatingpointoperationsusedtotraina', 'modelbymultiplyingthetrainingtime', 'thenumberofgpusused', 'andanestimateofthesustained', 'single-precisionﬂoating-pointcapacityofeachgpu5', '6.2', 'modelvariations', 'toevaluatetheimportanceofdifferentcomponentsofthetransformer', 'wevariedourbasemodel', 'indifferentways', 'measuringthechangeinperformanceonenglish-to-germantranslationonthe', 'developmentset', 'newstest2013', 'weusedbeamsearchasdescribedintheprevioussection', 'butno', 'checkpointaveraging', 'wepresenttheseresultsintable3', 'intable3rows', 'wevarythenumberofattentionheadsandtheattentionkeyandvaluedimensions', 'keep', 'amount', 'computation', 'constant', 'describe', 'section', '3.2.2', 'single-head', 'attentionis0.9bleuworsethanthebestsetting', 'qualityalsodropsoffwithtoomanyheads', '5weusedvaluesof2.8,3.7,6.0and9.5tflopsfork80', 'k40', 'm40andp100', 'respectively', '8']",8
Attention is all you need - Cornell.pdf,"['table3', 'variationsonthetransformerarchitecture', 'unlistedvaluesareidenticaltothoseofthebase', 'model', 'allmetricsareontheenglish-to-germantranslationdevelopmentset', 'newstest2013', 'list', 'perplexitiesareper-wordpiece', 'accordingtoourbyte-pairencoding', 'andshouldnotbecomparedto', 'per-wordperplexities', 'train', 'ppl', 'bleu', 'params', 'n', 'h', 'p', 'cid:15', 'model', 'ff', 'k', 'v', 'drop', 'ls', 'step', 'dev', 'dev', '×106', 'base', '6', '512', '2048', '8', '64', '64', '0.1', '0.1', '100k', '4.92', '25.8', '65', '1', '512', '512', '5.29', '24.9', '4', '128', '128', '5.00', '25.5', '16', '32', '32', '4.91', '25.8', '32', '16', '16', '5.01', '25.4', '16', '5.16', '25.1', '58', 'b', '32', '5.01', '25.4', '60', '2', '6.11', '23.7', '36', '4', '5.19', '25.3', '50', '8', '4.88', '25.5', '80', 'c', '256', '32', '32', '5.75', '24.5', '28', '1024', '128', '128', '4.66', '26.0', '168', '1024', '5.12', '25.4', '53', '4096', '4.75', '26.2', '90', '0.0', '5.77', '24.6', '0.2', '4.95', '25.5', '0.0', '4.67', '25.3', '0.2', '5.47', '25.7', 'e', 'positionalembeddinginsteadofsinusoids', '4.92', '25.7', 'big', '6', '1024', '4096', '16', '0.3', '300k', '4.33', '26.4', '213', 'table4', 'thetransformergeneralizeswelltoenglishconstituencyparsing', 'resultsareonsection23', 'ofwsj', 'parser', 'train', 'wsj23f1', 'vinyals', '&', 'kaiserelal', '2014', '[', '37', ']', 'wsjonly', 'discriminative', '88.3', 'petrovetal', '2006', '[', '29', ']', 'wsjonly', 'discriminative', '90.4', 'zhuetal', '2013', '[', '40', ']', 'wsjonly', 'discriminative', '90.4', 'dyeretal', '[', '8', ']', 'wsjonly', 'discriminative', '91.7', 'transformer', '4layers', 'wsjonly', 'discriminative', '91.3', 'zhuetal', '2013', '[', '40', ']', 'semi-supervised', '91.3', 'huang', '&', 'harper', '2009', '[', '14', ']', 'semi-supervised', '91.3', 'mccloskyetal', '2006', '[', '26', ']', 'semi-supervised', '92.1', 'vinyals', '&', 'kaiserelal', '2014', '[', '37', ']', 'semi-supervised', '92.1', 'transformer', '4layers', 'semi-supervised', '92.7', 'luongetal', '[', '23', ']', 'multi-task', '93.0', 'dyeretal', '[', '8', ']', 'generative', '93.3', 'intable3rows', 'b', 'weobservethatreducingtheattentionkeysized', 'hurtsmodelquality', 'k', 'suggest', 'determine', 'compatibility', 'easy', 'sophisticate', 'compatibility', 'functionthandotproductmaybebeneﬁcial', 'wefurtherobserveinrows', 'c', 'asexpected', 'biggermodelsarebetter', 'anddropoutisveryhelpfulinavoidingover-ﬁtting.inrow', 'e', 'wereplaceour', 'sinusoidalpositionalencodingwithlearnedpositionalembeddings', '[', '9', ']', 'andobservenearlyidentical', 'resultstothebasemodel', '6.3', 'englishconstituencyparsing', 'toevaluateifthetransformercangeneralizetoothertasksweperformedexperimentsonenglish', 'constituencyparsing', 'thistaskpresentsspeciﬁcchallenges', 'theoutputissubjecttostrongstructural', '9']",9
Attention is all you need - Cornell.pdf,"['constraints', 'signiﬁcantly', 'longer', 'input', 'furthermore', 'rnn', 'sequence-to-sequence', 'modelshavenotbeenabletoattainstate-of-the-artresultsinsmall-dataregimes', '[', '37', ']', 'wetraineda4-layertransformerwithd', '=1024onthewallstreetjournal', 'wsj', 'portionofthe', 'model', 'penntreebank', '[', '25', ']', 'about40ktrainingsentences', 'wealsotraineditinasemi-supervisedsetting', 'usingthelargerhigh-conﬁdenceandberkleyparsercorporafromwithapproximately17msentences', '[', '37', ']', 'weusedavocabularyof16ktokensforthewsjonlysettingandavocabularyof32ktokens', 'forthesemi-supervisedsetting', 'weperformedonlyasmallnumberofexperimentstoselectthedropout', 'bothattentionandresidual', 'section5.4', 'learningratesandbeamsizeonthesection22developmentset', 'allotherparameters', 'remain', 'unchanged', 'english-to-german', 'base', 'translation', 'model', 'inference', 'increasedthemaximumoutputlengthtoinputlength+300', 'weusedabeamsizeof21andα=0.3', 'forbothwsjonlyandthesemi-supervisedsetting', 'result', 'table', '4', 'show', 'despite', 'lack', 'task-speciﬁc', 'tune', 'model', 'perform', 'sur-', 'prisinglywell', 'yieldingbetterresultsthanallpreviouslyreportedmodelswiththeexceptionofthe', 'recurrentneuralnetworkgrammar', '[', '8', ']', 'incontrasttornnsequence-to-sequencemodels', '[', '37', ']', 'thetransformeroutperformstheberkeley-', 'parser', '[', '29', ']', 'evenwhentrainingonlyonthewsjtrainingsetof40ksentences', '7', 'conclusion', 'inthiswork', 'wepresentedthetransformer', 'theﬁrstsequencetransductionmodelbasedentirelyon', 'attention', 'replacingtherecurrentlayersmostcommonlyusedinencoder-decoderarchitectureswith', 'multi-headedself-attention', 'translation', 'task', 'transformer', 'train', 'signiﬁcantly', 'faster', 'architectures', 'base', 'recurrent', 'convolutional', 'layer', 'wmt', '2014', 'english-to-german', 'wmt', '2014', 'english-to-frenchtranslationtasks', 'weachieveanewstateoftheart', 'intheformertaskourbest', 'modeloutperformsevenallpreviouslyreportedensembles', 'weareexcitedaboutthefutureofattention-basedmodelsandplantoapplythemtoothertasks', 'plantoextendthetransformertoproblemsinvolvinginputandoutputmodalitiesotherthantextand', 'toinvestigatelocal', 'restrictedattentionmechanismstoefﬁcientlyhandlelargeinputsandoutputs', 'suchasimages', 'audioandvideo', 'makinggenerationlesssequentialisanotherresearchgoalsofours', 'code', 'use', 'train', 'evaluate', 'model', 'available', 'https', '//github.com/', 'tensorflow/tensor2tensor', 'acknowledgements', 'wearegratefulto', 'nalkalchbrennerand', 'stephangouwsfor', 'theirfruitful', 'comment', 'correctionsandinspiration', 'reference', '[', '1', ']', 'jimmyleiba', 'jamieryankiros', 'andgeoffreyehinton', 'layernormalization', 'arxivpreprint', 'arxiv:1607.06450,2016', '[', '2', ']', 'dzmitrybahdanau', 'kyunghyuncho', 'andyoshuabengio', 'neuralmachinetranslationbyjointly', 'learningtoalignandtranslate', 'corr', 'abs/1409.0473,2014', '[', '3', ']', 'dennybritz', 'annagoldie', 'minh-thangluong', 'andquocv.le', 'massiveexplorationofneural', 'machinetranslationarchitectures', 'corr', 'abs/1703.03906,2017', '[', '4', ']', 'jianpengcheng', 'lidong', 'andmirellalapata', 'longshort-termmemory-networksformachine', 'read', 'arxivpreprintarxiv:1601.06733,2016', '[', '5', ']', 'kyunghyuncho', 'bartvanmerrienboer', 'caglargulcehre', 'fethibougares', 'holgerschwenk', 'andyoshuabengio', 'learningphraserepresentationsusingrnnencoder-decoderforstatistical', 'machinetranslation', 'corr', 'abs/1406.1078,2014', '[', '6', ']', 'francois', 'chollet', 'xception', 'deep', 'learn', 'depthwise', 'separable', 'convolutions', 'arxiv', 'preprintarxiv:1610.02357,2016', '10']",10
Attention is all you need - Cornell.pdf,"['[', '7', ']', 'junyoungchung', 'çaglargülçehre', 'kyunghyuncho', 'andyoshuabengio', 'empiricalevaluation', 'ofgatedrecurrentneuralnetworksonsequencemodeling', 'corr', 'abs/1412.3555,2014', '[', '8', ']', 'chris', 'dyer', 'adhiguna', 'kuncoro', 'miguel', 'ballesteros', 'noah', 'a.', 'smith', 'recurrent', 'neural', 'networkgrammars', 'inproc.ofnaacl,2016', '[', '9', ']', 'jonasgehring', 'michaelauli', 'davidgrangier', 'denisyarats', 'andyannn.dauphin', 'convolu-', 'tionalsequencetosequencelearning', 'arxivpreprintarxiv:1705.03122v2,2017', '[', '10', ']', 'alex', 'grave', 'generate', 'sequence', 'recurrent', 'neural', 'network', 'arxiv', 'preprint', 'arxiv:1308.0850,2013', '[', '11', ']', 'kaiming', 'xiangyu', 'zhang', 'shaoqing', 'ren', 'jian', 'sun', 'deep', 'residual', 'learn', 'im-', 'age', 'recognition', 'proceed', 'ieee', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'pages770–778,2016', '[', '12', ']', 'sepphochreiter', 'yoshuabengio', 'paolofrasconi', 'andjürgenschmidhuber', 'gradientﬂowin', 'recurrentnets', 'thedifﬁcultyoflearninglong-termdependencies,2001', '[', '13', ']', 'sepp', 'hochreiter', 'jürgen', 'schmidhuber', 'long', 'short-term', 'memory', 'neural', 'computation', '9', '8', ':1735–1780,1997', '[', '14', ']', 'zhongqianghuangandmaryharper', 'self-trainingpcfggrammarswithlatentannotations', 'acrosslanguages', 'inproceedingsofthe2009conferenceonempiricalmethodsinnatural', 'languageprocessing', 'pages832–841.acl', 'august2009', '[', '15', ']', 'rafaljozefowicz', 'oriolvinyals', 'mikeschuster', 'noamshazeer', 'andyonghuiwu', 'explore', 'thelimitsoflanguagemodeling', 'arxivpreprintarxiv:1602.02410,2016', '[', '16', ']', 'łukaszkaiserandsamybengio', 'canactivememoryreplaceattention', '?', 'inadvancesinneural', 'informationprocessingsystems', 'nip', ',2016', '[', '17', ']', 'łukaszkaiserandilyasutskever', 'neuralgpuslearnalgorithms', 'ininternationalconference', 'onlearningrepresentations', 'iclr', ',2016', '[', '18', ']', 'nalkalchbrenner', 'lasseespeholt', 'karensimonyan', 'aaronvandenoord', 'alexgraves', 'andko-', 'raykavukcuoglu.neuralmachinetranslationinlineartime.arxivpreprintarxiv:1610.10099v2', '[', '19', ']', 'yoonkim', 'carldenton', 'luonghoang', 'andalexanderm.rush', 'structuredattentionnetworks', 'ininternationalconferenceonlearningrepresentations,2017', '[', '20', ']', 'diederikkingmaandjimmyba', 'adam', 'amethodforstochasticoptimization', 'iniclr,2015', '[', '21', ']', 'oleksiikuchaievandborisginsburg', 'factorizationtricksforlstmnetworks', 'arxivpreprint', 'arxiv:1703.10722,2017', '[', '22', ']', 'zhouhan', 'lin', 'minwei', 'feng', 'cicero', 'nogueira', 'do', 'santos', 'mo', 'yu', 'bing', 'xiang', 'bowen', 'zhou', 'yoshua', 'bengio', 'structure', 'self-attentive', 'sentence', 'embed', 'arxiv', 'preprint', 'arxiv:1703.03130,2017', '[', '23', ']', 'minh-thangluong', 'quocv.le', 'ilyasutskever', 'oriolvinyals', 'andlukaszkaiser', 'multi-task', 'sequencetosequencelearning', 'arxivpreprintarxiv:1511.06114,2015', '[', '24', ']', 'minh-thangluong', 'hieupham', 'andchristopherdmanning', 'effectiveapproachestoattention-', 'basedneuralmachinetranslation', 'arxivpreprintarxiv:1508.04025,2015', '[', '25', ']', 'mitchellpmarcus', 'maryannmarcinkiewicz', 'andbeatricesantorini.buildingalargeannotated', 'corpusofenglish', 'thepenntreebank', 'computationallinguistics,19', '2', ':313–330,1993', '[', '26', ']', 'davidmcclosky', 'eugenecharniak', 'andmarkjohnson', 'effectiveself-trainingforparsing', 'proceedingsofthehumanlanguagetechnologyconferenceofthenaacl', 'mainconference', 'pages152–159.acl', 'june2006', '11']",11
Attention is all you need - Cornell.pdf,"['[', '27', ']', 'ankurparikh', 'oscartäckström', 'dipanjandas', 'andjakobuszkoreit', 'adecomposableattention', 'model', 'inempiricalmethodsinnaturallanguageprocessing,2016', '[', '28', ']', 'romainpaulus', 'caimingxiong', 'andrichardsocher', 'adeepreinforcedmodelforabstractive', 'summarization', 'arxivpreprintarxiv:1705.04304,2017', '[', '29', ']', 'slav', 'petrov', 'leon', 'barrett', 'romain', 'thibaux', 'dan', 'klein', 'learn', 'accurate', 'compact', 'interpretable', 'tree', 'annotation', 'proceed', '21st', 'international', 'conference', 'computationallinguisticsand44thannualmeetingoftheacl', 'pages433–440.acl', 'july', '2006', '[', '30', ']', 'oﬁrpressandliorwolf', 'usingtheoutputembeddingtoimprovelanguagemodels', 'arxiv', 'preprintarxiv:1608.05859,2016', '[', '31', ']', 'ricosennrich', 'barryhaddow', 'andalexandrabirch', 'neuralmachinetranslationofrarewords', 'withsubwordunits', 'arxivpreprintarxiv:1508.07909,2015', '[', '32', ']', 'noamshazeer', 'azaliamirhoseini', 'krzysztofmaziarz', 'andydavis', 'quocle', 'geoffreyhinton', 'andjeffdean', 'outrageouslylargeneuralnetworks', 'thesparsely-gatedmixture-of-experts', 'layer', 'arxivpreprintarxiv:1701.06538,2017', '[', '33', ']', 'nitishsrivastava', 'geoffreyehinton', 'alexkrizhevsky', 'ilyasutskever', 'andruslansalakhutdi-', 'nov', 'dropout', 'asimplewaytopreventneuralnetworksfromoverﬁtting', 'journalofmachine', 'learningresearch,15', '1', ':1929–1958,2014', '[', '34', ']', 'sainbayar', 'sukhbaatar', 'arthur', 'szlam', 'jason', 'weston', 'rob', 'fergus', 'end-to-end', 'memory', 'network', 'inc.cortes', 'n.d.lawrence', 'd.d.lee', 'm.sugiyama', 'andr.garnett', 'editors', 'advancesinneuralinformationprocessingsystems28', 'pages2440–2448.curranassociates', 'inc.,2015', '[', '35', ']', 'ilyasutskever', 'oriolvinyals', 'andquocvvle', 'sequencetosequencelearningwithneural', 'network', 'inadvancesinneuralinformationprocessingsystems', 'pages3104–3112,2014', '[', '36', ']', 'christianszegedy', 'vincentvanhoucke', 'sergeyioffe', 'jonathonshlens', 'andzbigniewwojna', 'rethinkingtheinceptionarchitectureforcomputervision', 'corr', 'abs/1512.00567,2015', '[', '37', ']', 'vinyals', '&', 'kaiser', 'koo', 'petrov', 'sutskever', 'andhinton', 'grammarasaforeignlanguage', 'advancesinneuralinformationprocessingsystems,2015', '[', '38', ']', 'yonghui', 'wu', 'mike', 'schuster', 'zhifeng', 'chen', 'quoc', 'v', 'le', 'mohammad', 'norouzi', 'wolfgang', 'macherey', 'maximkrikun', 'yuancao', 'qingao', 'klausmacherey', 'etal', 'google', '’', 'sneuralmachine', 'translationsystem', 'bridgingthegapbetweenhumanandmachinetranslation', 'arxivpreprint', 'arxiv:1609.08144,2016', '[', '39', ']', 'jie', 'zhou', 'ying', 'cao', 'xuguang', 'wang', 'peng', 'li', 'wei', 'xu', 'deep', 'recurrent', 'model', 'fast-forwardconnectionsforneuralmachinetranslation', 'corr', 'abs/1606.04199,2016', '[', '40', ']', 'muhua', 'zhu', 'yue', 'zhang', 'wenliang', 'chen', 'min', 'zhang', 'jingbo', 'zhu', 'fast', 'accurate', 'shift-reduceconstituentparsing', 'inproceedingsofthe51stannualmeetingoftheacl', 'volume', '1', 'longpapers', 'pages434–443.acl', 'august2013', '12']",12
Attention is all you need - Cornell.pdf,"['input-input', 'layer5', 'attentionvisualizations', 'nt', 'n', 'spirit', 'majority', 'american', 'governme', 'pass', 'new', 'laws', 'since', '2009', 'make', 'registratio', 'vote', 'process', 'difficult', '<', 'eos', '>', '<', 'pad', '>', '<', 'pad', '>', '<', 'pad', '>', '<', 'pad', '>', '<', 'pad', '>', '<', 'pad', '>', 'spirit', 'majority', 'american', 'ernments', 'pass', 'new', 'laws', 'since', '2009', 'make', 'gistration', 'vote', 'process', 'difficult', '<', 'eos', '>', '<', 'pad', '>', '<', 'pad', '>', '<', 'pad', '>', '<', 'pad', '>', '<', 'pad', '>', '<', 'pad', '>', 'v', 'e', 'r', 'g', 'figure', '3', 'example', 'attention', 'mechanism', 'follow', 'long-distance', 'dependencies', 'encoderself-attentioninlayer5of6', 'manyoftheattentionheadsattendtoadistantdependencyof', 'theverb', '‘', 'make', '’', 'completingthephrase', '‘', 'make', '...', 'moredifﬁcult', '’', 'attentionshereshownonlyfor', 'theword', '‘', 'make', '’', 'differentcolorsrepresentdifferentheads', 'bestviewedincolor', '13']",13
Attention is all you need - Cornell.pdf,"['input-input', 'layer5', 'n', 'law', 'never', 'perfect', 'applicati', 'miss', 'opinion', '<', 'eos', '>', '<', 'pad', '>', 'inthepulawtwill-inevernpbeuperfectt', 'lbutaitsyplicationershould5be', 'miss', 'opinion', '<', 'eos', '>', '<', 'pad', '>', 'p', 'n', 'law', 'never', 'perfect', 'applicati', 'miss', 'opinion', '<', 'eos', '>', '<', 'pad', '>', 'law', 'never', 'perfect', 'plication', 'miss', 'opinion', '<', 'eos', '>', '<', 'pad', '>', 'p', 'figure4', 'twoattentionheads', 'alsoinlayer5of6', 'apparentlyinvolvedinanaphoraresolution', 'top', 'fullattentionsforhead5', 'bottom', 'isolatedattentionsfromjusttheword', '‘', '’', 'forattentionheads5', 'and6', 'notethattheattentionsareverysharpforthisword', '14']",14
Attention is all you need - Cornell.pdf,"['input-input', 'layer5', 'n', 'law', 'never', 'perfect', 'applicati', 'miss', 'opinion', '<', 'eos', '>', '<', 'pad', '>', 'inthepulawtwill-inevernpbeuperfectt', 'lbutaitsyeplicationrshould5be', 'miss', 'opinion', '<', 'eos', '>', '<', 'pad', '>', 'p', 'n', 'law', 'never', 'perfect', 'applicati', 'miss', 'opinion', '<', 'eos', '>', '<', 'pad', '>', 'law', 'never', 'perfect', 'plication', 'miss', 'opinion', '<', 'eos', '>', '<', 'pad', '>', 'p', 'figure5', 'manyoftheattentionheadsexhibitbehaviourthatseemsrelatedtothestructureofthe', 'sentence', 'wegivetwosuchexamplesabove', 'fromtwodifferentheadsfromtheencoderself-attention', 'atlayer5of6', 'theheadsclearlylearnedtoperformdifferenttasks', '15']",15
Opportunities and Risks of Foundational Models - Stanford.pdf,"['opportunities', 'risk', 'foundation', 'model', 'rishibommasani', 'drewa.hudson', 'ehsanadeli', 'russaltman', 'simranarora', '1', '2', 'sydneyvonarx', 'michaels.bernstein', 'jeannettebohg', 'antoinebosselut', 'emmabrunskill', '0', 'erikbrynjolfsson', 'shyamalbuch', 'dallascard', 'rodrigocastellon', 'niladrichatterji', '2', 'anniechen', 'kathleencreel', 'jaredquincydavis', 'dorottyademszky', 'chrisdonahue', 'g', 'moussadoumbouya', 'esindurmus', 'stefanoermon', 'johnetchemendy', 'kawinethayarajh', 'u', 'lifei-fei', 'chelseafinn', 'trevorgale', 'laurengillespie', 'karangoel', 'noahgoodman', 'shelbygrossman', 'neelguha', 'tatsunorihashimoto', 'peterhenderson', 'johnhewitt', 'daniele.ho', 'jennyhong', 'kylehsu', 'jinghuang', 'thomasicard', 'saahiljain', '8', '1', 'danjurafsky', 'pratyushakalluri', 'siddharthkaramcheti', 'geoffkeeling', 'fereshtekhani', 'omarkhattab', 'pangweikoh', 'markkrass', 'ranjaykrishna', 'rohithkuditipudi', ']', 'ananyakumar', 'faisalladhak', 'minalee', 'tonylee', 'jureleskovec', 'isabellelevent', 'g', 'xianglisali', 'xuechenli', 'tengyuma', 'alimalik', 'christopherd.manning', 'l', 'suvirmirchandani', 'ericmitchell', 'zanelemunyikwa', 'surajnair', 'avanikanarayan', 'deepaknarayanan', 'bennewman', 'allennie', 'juancarlosniebles', 'hamednilforoshan', 'c', 'juliannyarko', 'girayogut', 'laurelorr', 'isabelpapadimitriou', 'joonsungpark', 'chrispiech', '[', 'evaportelance', 'christopherpotts', 'aditiraghunathan', 'robreich', 'hongyuren', '2', 'friedarong', 'yusufroohani', 'camiloruiz', 'jackryan', 'christopherré', 'dorsasadigh', 'v', 'shiorisagawa', 'keshavsanthanam', 'andyshih', 'krishnansrinivasan', 'alextamkin', '8', 'rohantaori', 'arminw.thomas', 'floriantramèr', 'rosee.wang', 'williamwang', 'bohanwu', '5', '2', 'jiajunwu', 'yuhuaiwu', 'sangmichaelxie', 'michihiroyasunaga', 'jiaxuanyou', 'mateizaharia', '7', 'michaelzhang', 'tianyizhang', 'xikunzhang', 'yuhuizhang', 'luciazheng', 'kaitlynzhou', '0', 'percyliang', '1', '8', '0', 'centerforresearchonfoundationmodels', 'crfm', '1', 'stanfordinstituteforhuman-centeredartificialintelligence', 'hai', '2', 'stanforduniversity', 'v', 'ai', 'undergo', 'paradigm', 'shift', 'rise', 'model', 'e.g.', 'bert', 'dall-e', 'gpt-3', 'x', 'trainedonbroaddataatscaleandareadaptabletoawiderangeofdownstreamtasks.wecallthese', 'r', 'modelsfoundationmodelstounderscoretheircriticallycentralyetincompletecharacter.thisreport', 'providesathoroughaccountoftheopportunitiesandrisksoffoundationmodels', 'rangingfromtheir', 'capabilities', 'e.g.', 'language', 'vision', 'robotics', 'reason', 'humaninteraction', 'andtechnicalprinciples', 'e.g.', 'model', 'architectures', 'train', 'procedures', 'data', 'systems', 'security', 'evaluation', 'theory', 'applications', 'e.g.', 'law', 'healthcare', 'education', 'andsocietalimpact', 'e.g.', 'inequity', 'misuse', 'economic', 'andenvironmentalimpact', 'legalandethicalconsiderations', '.thoughfoundationmodelsarebased', 'standard', 'deep', 'learn', 'transfer', 'learn', 'scale', 'result', 'new', 'emergent', 'capabilities', 'andtheireffectivenessacrosssomanytasksincentivizeshomogenization.homogenizationprovides', 'powerfulleveragebutdemandscaution', 'asthedefectsofthefoundationmodelareinheritedbyallthe', 'adaptedmodelsdownstream.despitetheimpendingwidespreaddeploymentoffoundationmodels', 'wecurrentlylackaclearunderstandingofhowtheywork', 'whentheyfail', 'andwhattheyareeven', 'capableofduetotheiremergentproperties.totacklethesequestions', 'webelievemuchofthecritical', 'researchonfoundationmodelswillrequiredeepinterdisciplinarycollaborationcommensuratewith', 'theirfundamentallysociotechnicalnature', '1correspondingauthor', 'pliang', 'cs.stanford.edu', 'equalcontribution', '1']",1
Opportunities and Risks of Foundational Models - Stanford.pdf,"['2', 'centerforresearchonfoundationmodels', 'crfm', 'content', 'content', '2', '1', 'introduction', '3', '1.1', 'emergenceandhomogenization', '3', '1.2', 'socialimpactandthefoundationmodelsecosystem', '7', '1.3', 'thefutureoffoundationmodels', '9', '1.4', 'overviewofthisreport', '12', '2', 'capabilities', '21', '2.1', 'language', '22', '2.2', 'vision', '28', '2.3', 'robotics', '34', '2.4', 'reasoningandsearch', '40', '2.5', 'interaction', '44', '2.6', 'philosophyofunderstanding', '48', '3', 'applications', '53', '3.1', 'healthcareandbiomedicine', '54', '3.2', 'law', '59', '3.3', 'education', '67', '4', 'technology', '73', '4.1', 'model', '74', '4.2', 'train', '81', '4.3', 'adaptation', '85', '4.4', 'evaluation', '91', '4.5', 'systems', '97', '4.6', 'data', '101', '4.7', 'securityandprivacy', '105', '4.8', 'robustnesstodistributionshifts', '108', '4.9', 'aisafetyandalignment', '113', '4.10', 'theory', '117', '4.11', 'interpretability', '122', '5', 'society', '128', '5.1', 'inequityandfairness', '129', '5.2', 'misuse', '135', '5.3', 'environment', '139', '5.4', 'legality', '145', '5.5', 'economics', '148', '5.6', 'ethicsofscale', '151', '6', 'conclusion', '160', 'acknowledgments', '160', 'reference', '160']",2
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '3', '1', 'introduction', 'report', 'investigate', 'emerge', 'paradigm', 'build', 'artificial', 'intelligence', 'ai', 'systems', 'basedonageneralclassofmodelswhichwetermfoundationmodels.2afoundationmodelisany', 'modelthatistrainedonbroaddataatscaleandcanbeadapted', 'e.g.', 'fine-tune', 'toawiderangeof', 'downstreamtasks', 'currentexamplesincludebert', '[', 'devlinetal.2019', ']', 'gpt-3', '[', 'brownetal.2020', ']', 'andclip', '[', 'radfordetal.2021', ']', '.fromatechnologicalpointofview', 'foundationmodelsarenot', 'new—theyarebasedondeepneuralnetworksandself-supervisedlearning', 'bothofwhichhave', 'existedfordecades.however', 'thesheerscaleandscopeoffoundationmodelsoverthelastfewyears', 'havestretchedourimaginationofwhatispossible', 'forexample', 'gpt-3has175billionparameters', 'andcanbeadaptedvianaturallanguagepromptstodoapassablejobonawiderangeoftasks', 'despitenotbeingtrainedexplicitlytodomanyofthosetasks', '[', 'brownetal.2020', ']', '.atthesametime', 'existingfoundationmodelshavethepotentialtoaccentuateharms', 'andtheircharacteristicsarein', 'generalpoorlyunderstood.giventheirimpendingwidespreaddeployment', 'theyhavebecomea', 'topicofintensescrutiny', '[', 'benderetal.2021', ']', '1.1', 'emergenceandhomogenization', 'thesignificanceoffoundationmodelscanbesummarizedwithtwowords', 'emergence', 'andho-', 'mogenization.emergencemeansthatthebehaviorofasystemisimplicitlyinducedratherthan', 'explicitlyconstructed', 'itisboththesourceofscientificexcitementandanxietyaboutunanticipated', 'consequences.homogenizationindicatestheconsolidationofmethodologiesforbuildingmachine', 'learningsystemsacrossawiderangeofapplications', 'itprovidesstrongleveragetowardsmany', 'tasksbutalsocreatessinglepointsoffailure.tobetterappreciateemergenceandhomogenization', 'letusreflectontheirriseinairesearchoverthelast30years', 'fig.1', 'thestoryofaihasbeenoneofincreasingemergenceandhomogenization.withtheintroductionof', 'machinelearning', 'ataskisperformedemerges', 'isinferredautomatically', 'fromexamples', 'withdeep', 'learn', 'thehigh-levelfeaturesusedforpredictionemerge', 'andwithfoundationmodels', 'evenadvanced', 'functionalitiessuchasin-contextlearningemerge.atthesametime', 'machinelearninghomogenizeslearning', 'algorithms', 'e.g.', 'logisticregression', 'deeplearninghomogenizesmodelarchitectures', 'e.g.', 'convolutional', 'neuralnetworks', 'andfoundationmodelshomogenizesthemodelitself', 'e.g.', 'gpt-3', 'machinelearning', 'mostaisystemstodayarepoweredbymachinelearning', 'wherepredictive', 'modelsaretrainedonhistoricaldataandusedtomakefuturepredictions.theriseofmachine', 'learningwithinaistartedinthe1990s', 'representingamarkedshiftfromthewayaisystemswere', 'builtpreviously', 'ratherthanspecifyinghow', 'tosolveatask', 'alearningalgorithmwouldinduce', 'itbasedondata—i.e.', 'thehow', 'emergesfromthedynamicsoflearning.machinelearningalso', '2wechosethetermfoundationmodelstocapturetheunfinishedyetimportantstatusofthesemodels—see§1.1.1', 'name', 'forfurtherdiscussionofthename']",3
Opportunities and Risks of Foundational Models - Stanford.pdf,"['4', 'centerforresearchonfoundationmodels', 'crfm', 'representedasteptowardshomogenization', 'awiderangeofapplicationscouldnowbepowered', 'byasinglegenericlearningalgorithmsuchaslogisticregression', 'despitetheubiquityofmachinelearningwithinai', 'semanticallycomplextasksinnaturallan-', 'guageprocessing', 'nlp', 'andcomputervisionsuchasquestionansweringorobjectrecognition', 'wheretheinputsaresentencesorimages', 'stillrequireddomainexpertstoperform', '“', 'featureen-', 'gineering', '”', '—thatis', 'writingdomain-specificlogictoconvertrawdataintohigher-levelfeatures', 'e.g.', 'sift', '[', 'lowe1999', ']', 'incomputervision', 'thatweremoresuitableforpopularmachinelearning', 'methods', 'deeplearning', 'around2010', 'arevivalofdeepneuralnetworksunderthemonikerofdeeplearning', '[', 'lecunetal.2015', ']', 'startedgainingtractioninthefieldofmachinelearning.deeplearningwas', 'fueledbylargerdatasets', 'morecomputation', 'notably', 'theavailabilityofgpus', 'andgreateraudacity', 'deepneuralnetworkswouldbetrainedontherawinputs', 'e.g.', 'pixels', 'andhigher-levelfeatures', 'wouldemergethroughtraining.thisledtomassiveperformancegainsonstandardbenchmarks', 'forexample', 'intheseminalworkofalexnet', '[', 'krizhevskyetal.2012', ']', 'ontheimagenetdataset', '[', 'dengetal.2009', ']', '.deeplearningalsoreflectedafurthershifttowardshomogenization', 'ratherthan', 'havingbespokefeatureengineeringpipelinesforeachapplication', 'thesamedeepneuralnetwork', 'architecturecouldbeusedformanyapplications', 'foundationmodels', 'foundationmodelshavetakenshapemoststronglyinnlp', 'sowefocusour', 'storythereforthemoment.bytheendof2018', 'thefieldofnlpwasabouttoundergoanother', 'seismic', 'change', 'mark', 'begin', 'era', 'foundation', 'model', 'technical', 'level', 'foundationmodelsareenabledbytransferlearning', '[', 'thrun1998', ']', 'andscale.theideaoftransfer', 'learningistotakethe', '“', 'knowledge', '”', 'learnedfromonetask', 'e.g.', 'objectrecognitioninimages', 'applyittoanothertask', 'e.g.', 'activityrecognitioninvideos', '.withindeeplearning', 'pretrainingis', 'thedominantapproachtotransferlearning', 'amodelistrainedonasurrogatetask', 'oftenjustasa', 'meanstoanend', 'andthenadaptedtothedownstreamtaskofinterestviafine-tuning', 'transfer', 'learn', 'make', 'foundation', 'model', 'possible', 'scale', 'make', 'powerful.scalerequiredthreeingredients', 'improvementsincomputerhardware—e.g.', 'gpu', 'throughput', 'memory', 'increase', '10×', 'last', 'four', 'years', '§4.5', 'systems', 'ii', 'development', 'transformer', 'model', 'architecture', '[', 'vaswani', 'et', 'al', ']', 'leverage', 'parallelismofthehardwaretotrainmuchmoreexpressivemodelsthanbefore', '§4.1', 'model', 'iii', 'theavailabilityofmuchmoretrainingdata', 'theimportanceoftheavailabilityofdataandtheabilitytoharnessitcannotbeunderestimated', 'transfer', 'learningwith', 'annotateddatasets', 'hasbeencommon', 'practiceforat', 'leasta', 'decade', 'example', 'pretrainingontheimagenetdataset', '[', 'dengetal.2009', ']', 'forimageclassificationinthe', 'computervisioncommunity.however', 'thenon-trivialcostofannotationimposesapracticallimit', 'onthebenefitsofpretraining', 'inself-supervisedlearningontheotherhand', 'thepretrainingtaskisderivedautomaticallyfrom', 'unannotateddata.3forexample', 'themaskedlanguagemodelingtaskusedtotrainbert', '[', 'devlin', 'etal.2019', ']', 'istopredictamissingwordinasentencegivenitssurroundingcontext', 'e.g.', 'ilike', 'sprout', '.self-supervisedtasksarenotonlymorescalable', 'onlydependingonunlabeled', 'data', 'buttheyaredesignedtoforcethemodeltopredictpartsoftheinputs', 'makingthemricher', 'andpotentiallymoreusefulthanmodelstrainedonamorelimitedlabelspace', 'therehadbeenconsiderableprogressinself-supervisedlearningdatingbacktowordembeddings', '[', 'turianetal.2010', 'mikolovetal.2013', 'penningtonetal.2014', ']', 'whichassociatedeachwordwitha', '3interestingly', 'self-supervisedlearningwasdominantintheearlydaysofdeeplearning', '[', 'hintonetal.2006', ']', 'butwasfor', 'adecadelargelyovertakenbypuresupervisedlearningaslabeleddatasetsbecamelarger']",4
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '5', 'context-independentvector', 'providedthebasisforawiderangeofnlpmodels.shortlythereafter', 'self-supervisedlearningbasedonautoregressivelanguagemodeling', 'predictthenextwordgiven', 'thepreviouswords', '[', 'daiandle2015', ']', 'becamepopular.thisproducedmodelsthatrepresented', 'wordsincontext', 'suchasgpt', '[', 'radfordetal.2018', ']', 'elmo', '[', 'petersetal.2018', ']', 'andulmfit', '[', 'howard', 'andruder2018', ']', '.4', 'thenextwaveofdevelopmentsinself-supervisedlearning—bert', '[', 'devlinetal.2019', ']', 'gpt-2', '[', 'radfordetal.2019', ']', 'roberta', '[', 'liuetal.2019', ']', 't5', '[', 'raffeletal.2019', ']', 'bart', '[', 'lewisetal.2020a', ']', '—', 'quickly', 'follow', 'embrace', 'transformer', 'architecture', 'incorporate', 'powerful', 'deep', 'bidirectionalencodersofsentences', 'andscalinguptolargermodelsanddatasets', 'whileonecanviewthislastwaveoftechnicaldevelopmentspurelythroughthelensofself-', 'supervisedlearning', 'therewasasociologicalinflectionpointaroundtheintroductionofbert', 'before2019', 'self-supervisedlearningwithlanguagemodelswasessentiallyasubareainnlp', 'progressedinparalleltootherdevelopmentsinnlp.after2019', 'self-supervisedlearningwith', 'languagemodelsbecamemoreofasubstrateofnlp', 'asusingberthasbecomethenorm.the', 'acceptancethatasinglemodelcouldbeusefulforsuchawiderangeoftasksmarksthebeginning', 'oftheeraoffoundationmodels', 'foundationmodelshaveledtoanunprecedentedlevelofhomogenization', 'almostallstate-of-', 'the-artnlpmodelsarenowadaptedfromoneofafewfoundationmodels', 'suchasbert', 'roberta', 'bart', 't5', 'etc.whilethishomogenizationproducesextremelyhighleverage', 'anyimprovementsin', 'thefoundationmodelscanleadtoimmediatebenefitsacrossallofnlp', 'itisalsoaliability', 'allai', 'systemsmightinheritthesameproblematicbiasesofafewfoundationmodels', '[', 'bolukbasietal', 'caliskanetal.2017', 'abidetal.2021', 'interalia', ']', '—see§5.1', 'fairness', '§5.6', 'ethicsforfurther', 'discussion', 'wearealsobeginningtoseeahomogenizationacrossresearchcommunities.forexample', 'similar', 'transformer-based', 'sequence', 'model', 'approach', 'apply', 'text', '[', 'devlin', 'et', 'al', '2019', 'radfordetal.2019', 'raffeletal.2019', ']', 'image', '[', 'dosovitskiyetal.2020', 'chenetal.2020d', ']', 'speech', '[', 'liu', 'etal.2020d', ']', 'tabulardata', '[', 'yinetal.2020', ']', 'proteinsequences', '[', 'rivesetal.2021', ']', 'organicmolecules', '[', 'rothchildetal.2021', ']', 'andreinforcementlearning', '[', 'chenetal.2021b', 'janneretal.2021', ']', '.these', 'examplespointtoapossiblefuturewherewehaveaunifiedsetoftoolsfordevelopingfoundation', 'modelsacrossawiderangeofmodalities', '[', 'tamkinetal.2021a', ']', 'besidesthehomogenizationofapproaches', 'wealsoseethehomogenizationofactualmodels', 'acrossresearchcommunitiesintheformofmultimodalmodels—e.g.', 'foundationmodelstrained', 'onlanguageandvisiondata', '[', 'luoetal.2020', 'kimetal.2021a', 'choetal.2021', 'rameshetal.2021', 'radfordetal.2021', ']', '.dataisnaturallymultimodalinsomedomains—e.g.', 'medicalimages', 'structure', 'data', 'clinicaltextinhealthcare', '§3.1', 'healthcare', '.thus', 'multimodalfoundationmodelsarea', 'naturalwayoffusingalltherelevantinformationaboutadomain', 'andadaptingtotasksthatalso', 'spanmultiplemodes', 'figure2', 'foundationmodelshavealsoledtosurprisingemergencewhichresultsfromscale.forexample', 'gpt-3', '[', 'brownetal.2020', ']', 'with175billionparameterscomparedtogpt-2', '’', 's1.5billion', 'permit', 'in-contextlearning', 'inwhichthelanguagemodelcanbeadaptedtoadownstreamtasksimplyby', 'providingitwithaprompt', 'anaturallanguagedescriptionofthetask', 'anemergentpropertythat', 'wasneitherspecificallytrainedfornoranticipatedtoarise', 'homogenizationandemergenceinteractinapotentiallyunsettlingway.homogenizationcould', 'potentiallyprovideenormousgainsformanydomainswheretask-specificdataisquitelimited—see', '4theprescientworkofcollobertandweston', '[', '2008', ']', 'isrelated', 'theytrainedonascalabletaskakintomaskedlanguage', 'modelingjointlywithdownstreamtasks', 'ratherthanproducingasinglefoundationmodelthatcanbeadaptedafterthefact', 'todownstreamtasks']",5
Opportunities and Risks of Foundational Models - Stanford.pdf,"['6', 'centerforresearchonfoundationmodels', 'crfm', 'fig.2', 'afoundationmodelcancentralizetheinformationfromallthedatafromvariousmodalities.this', 'onemodelcanthenbeadaptedtoawiderangeofdownstreamtasks', 'theopportunitiespresentedinseveralsuchdomains', 'e.g.', '§3.1', 'healthcare', '§3.2', 'law', '§3.3', 'edu-', 'cation', 'ontheotherhand', 'anyflawsinthemodelareblindlyinheritedbyalladaptedmodels', '§5.1', 'fairness', '§5.6', 'ethics', '.sincethepoweroffoundationmodelscomesfromtheiremergent', 'qualitiesratherthantheirexplicitconstruction', 'existingfoundationmodelsarehardtounderstand', '§4.4', 'evaluation', '§4.10', 'theory', '§4.11', 'interpretability', 'unexpected', 'failure', 'modes', '§4.7', 'security', '§4.8', 'robustness', '.sinceemergencegeneratessubstantialuncertaintyover', 'thecapabilitiesandflawsoffoundationmodels', 'aggressivehomogenizationthroughthesemodelsis', 'riskybusiness.deriskingisthecentralchallengeinthefurtherdevelopmentoffoundationmodels', 'fromanethical', '§5.6', 'ethics', 'andaisafety', '§4.9', 'ai-safety', 'perspective', '1.1.1', 'name', 'weintroducethetermfoundationmodels', 'tofillavoidindescribingtheparadigmshiftweare', 'witness', 'webrieflyrecountsomeofourreasoningforthisdecision.existingterms', 'e.g.', 'pretrained', 'model', 'self-supervisedmodel', 'partiallycapturethetechnicaldimensionofthesemodels', 'butfailto', 'capturethesignificanceoftheparadigmshiftinanaccessiblemannerforthosebeyondmachine', 'learning.languagemodelistoonarrow', 'aswedescribe', 'thescopeoffoundationmodelsgoeswell', 'beyondlanguage.wealsoconsideredtermssuchasgeneral-purposemodelandmulti-purposemodel', 'thatcapturetheimportantaspectthatthesemodelscanservemultipledownstreamtasks', 'butboth', 'failtocapturetheirunfinishedcharacterandtheneedforadaptation.termssuchastask-agnostic', 'model', 'would', 'capture', 'manner', 'train', 'fail', 'capture', 'significant', 'implication', 'downstreamapplications']",6
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '7', 'fig.3', 'beforereasoningaboutthesocialimpactoffoundationmodels', 'itisimportanttounderstandthat', 'theyarepartofabroaderecosystemthatstretchesfromdatacreationtodeployment.atbothends', 'highlighttheroleofpeopleastheultimatesourceofdataintotrainingofafoundationmodel', 'butalsoasthe', 'downstreamrecipientsofanybenefitsandharms.thoughtfuldatacurationandadaptationshouldbepart', 'oftheresponsibledevelopmentofanyaisystem.finally', 'notethatthedeploymentofadaptedfoundation', 'modelsisadecisionseparatefromtheirconstruction', 'whichcouldbeforresearch', 'wechosethenewtermfoundationmodelstoidentifythemodelsandtheemergingparadigmthat', 'arethesubjectofthisreport.inparticular', 'theword', '“', 'foundation', '”', 'specifiestherolethesemodels', 'play', 'afoundationmodelisitselfincompletebutservesasthecommonbasisfromwhichmany', 'task-specificmodelsarebuiltviaadaptation.wealsochosetheterm', '“', 'foundation', ""''"", 'toconnotethe', 'significanceofarchitecturalstability', 'safety', 'andsecurity', 'poorly-constructedfoundationsarea', 'recipefordisasterandwell-executedfoundationsareareliablebedrockforfutureapplications.at', 'present', 'weemphasizethatwedonotfullyunderstandthenatureorqualityofthefoundationthat', 'foundationmodelsprovide', 'wecannotcharacterizewhetherthefoundationistrustworthyornot', 'thus', 'thisisacriticalproblemforresearchers', 'foundationmodelproviders', 'applicationdevelopers', 'whorelyonfoundationmodels', 'policymakers', 'andsocietyatlargetoaddress', '1.2', 'socialimpactandthefoundationmodelsecosystem', 'foundationmodelsarescientificallyinterestingduetotheirimpressiveperformanceandcapabilities', 'butwhatmakesthemcriticaltostudyisthefactthattheyarequicklybeingintegratedintoreal-', 'worlddeploymentsofaisystemswithfar-reachingconsequencesonpeople.forexample', 'google', 'search', 'whichboasts4billionusers', 'nowdependsonfoundationmodelslikebert', '[', 'devlinetal', '2019', ']', 'asoneofitssignals.5', 'wemustthuspauseandask', 'whatisthenatureofthissocialimpact', '?', 'inthisreport', 'weaddress', 'manyaspectsofthisquestion', 'thepotentialexacerbationofsocialinequities', '§5.1', 'fairness', 'economicimpactduetoincreasedcapabilities', '§5.5', 'economics', 'theenvironmentalimpactdueto', 'increasedcomputationdemands', '§5.3', 'environment', 'potentialconcernsofamplifyingdisinfor-', 'mation', '§5.2', 'misuse', 'legalramificationsduetopowerfulgenerativecapabilities', '§5.4', 'legality', 'ethicalissuesresultingfromhomogenization', 'andthebroaderpoliticaleconomyinwhichfounda-', 'tionmodelsaredevelopedanddeployed', '§5.6', 'ethics', '.giventheproteannatureoffoundation', '5https', '//blog.google/products/search/search-language-understanding-bert/']",7
Opportunities and Risks of Foundational Models - Stanford.pdf,"['8', 'centerforresearchonfoundationmodels', 'crfm', 'modelsandtheirunmappedcapabilities', 'howcanweresponsiblyanticipateandaddresstheethical', 'andsocietalconsiderationstheyraise', '?', 'arecurringthemeisthatitiseasiertoreasonaboutthe', 'socialimpactofspecificsystemsdeployedtospecificusersthanitistoreasonaboutthesocial', 'impactoffoundationmodels', 'whichcouldbeadaptedtoanynumberofunforeseendownstream', 'systems', 'beforeattemptingtoanswerthesequestions', 'weneedtolaysomegroundwork.first', 'letus', 'distinguishbetweenresearchonfoundationmodelsanddeployment', 'offoundationmodels.mostof', 'whatispubliclyknownisfoundationmodelsresearch—throughacademicpapers', 'demonstrations', 'andprogressonleaderboards.whiletheproductionofknowledgecanplayavitalroleinshaping', 'thefuture', 'thedirectsocialimpactisthroughtheactualdeploymentofthesemodels', 'whichis', 'governedbyproprietarypracticesonoftenprivatedata.sometimesthedeploymentisthrough', 'newproducts—e.g.', 'github', '’', 'scopilot6basedonopenai', '’', 'scodexmodel', '[', 'chenetal.2021e', ']', 'often', 'itisthroughupgradestoexistingproducts', 'e.g.', 'googlesearchusingbert', '.researchmodels', 'areoftennotextensivelytestedandmighthaveunknownfailuremodes', 'warninglabelsshould', 'beplacedonresearchmodelsthatarenotfittodeploy.ontheotherhand', 'deployedfoundation', 'modelsthatactuallyaffectpeople', '’', 'slivesshouldbesubjecttomuchmorerigoroustestingand', 'audit', 'tofurtherunderstandtheresearchanddeploymentoffoundationmodels', 'wemustzoomout', 'andconsiderthefullecosystemthatthesefoundationmodelsinhabit', 'fromdatacreationtoactual', 'deployment.itisimportanttonotethatthefoundationmodelisonlyonecomponent', 'thoughan', 'increasinglyimportantcomponent', 'ofanaisystem.simplifying', 'wecanthinkabouttheecosystem', 'ofafoundationmodelintermsofsequenceofstages', 'extendingthetrainingandadaptationstages', 'frombefore.7appropriately', 'aswe', '’', 'reinterestedinsocialimpact', 'peopleoccupybothendsofthe', 'pipeline.thisecosystemviewallowsustoseethatdifferentquestionsaboutfoundationmodels', 'e.g.', 'whetherafoundationmodelisethical', 'shouldactuallybeansweredwithrespecttodifferent', 'stag', '1', 'datacreation', 'datacreationisfundamentallyahuman-centricprocess', 'alldataiscreated', 'bypeopleandmostdataisatleastimplicitlyaboutpeople.sometimesdataiscreatedby', 'peopleforotherpeopleintheformofemails', 'article', 'photos', 'etc.', 'andsometimesitisa', 'measurementofpeople', 'e.g.', 'genomicdata', 'orameasurementoftheenvironmentpeople', 'livein', 'e.g.', 'satelliteimages', '.itisimportanttonotethatalldatahasanownerandiscreated', 'withapurpose', 'wherethatpurposemayormaynotincludetrainingafoundationmodel', '2', 'datacuration', 'dataisthencuratedintodatasets.thereisnosinglenaturaldistribution', 'ofdata', 'eventhemostpermissiveinternetcrawlrequiressomeselectionandpost-filtering', 'ensuringdatarelevanceandqualitywhilerespectinglegalandethicalconstraintsiscritical', 'butchallenging.whilethisisrecognizedinindustry', 'itisunderappreciatedinairesearch', '§4.6', 'data', '3', 'train', 'trainingfoundationmodelsonthesecurateddatasets8isthecelebratedcenterpiece', 'inairesearch', 'thoughitisonlyoneofmanystages', '4', 'adaptation', 'inthecontextofmachinelearningresearch', 'adaptationisaboutcreatinganew', 'modelbasedonthefoundationmodelthatperformssometask', 'e.g.', 'documentsummarization', 'deployment', 'adaptation', 'create', 'system', 'require', 'potentially', 'many', 'differentmodules', 'customrules', 'e.g.', 'restrictionsontheoutputspace', 'orclassifiers', 'e.g.', 'toxicityclassification', 'andcombinationwithothercomplementarysignals', 'e.g.', 'aquestion', '6https', '//copilot.github.com/', '7inpractice', 'theendofthepipelineisfollowedbymonitoring', 'andfeedbackisusedtoreadjustthepreviousstages', '8afoundationmodel', 'e.g.', 'codex', 'canalsobetrainedwithanothermodel', 'e.g.', 'gpt-3', 'asastartingpoint']",8
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '9', 'answeringmodel', '’', 'sgeneratedanswerswouldbevalidatedagainstrelevantdocuments', '.for', 'example', 'problematic', 'model', 'capable', 'generate', 'toxic', 'content', 'might', 'tolerable', 'appropriateprecautionsaretakendownstream.theextraapplication-specificlogiciscrucial', 'formitigatingharms', '5', 'deployment', 'thedirectsocialimpactofanaisystemoccurswhenitisdeployedtopeople', 'thoughwewouldnotwanttodeploypotentiallyharmfulfoundationmodelstrainedon', 'questionable', 'data', 'might', 'still', 'value', 'permit', 'research', 'advance', 'scientificunderstanding', 'thoughonemuststillexercisecaution.moregenerally', 'itisstandard', 'practiceinlarge-scaledeploymentstoconductgradualreleases', 'wheredeploymenthappens', 'toanincreasingfractionofusers', 'thiscanpartiallymitigateanypotentialharms', 'whilethisreportisaboutfoundationmodels', 'itisimportanttonotethatmanyoftheimpactscome', 'fromdecisionsmadeinotherstagesinthepipeline', 'andthoughtfulmonitoringandinterventionis', 'neededateverystage.whilelargeorganizationsmightowntheentirepipeline', 'eachstagecould', 'beperformedbyadifferentorganization', 'e.g.', 'acompanywhichspecializesincreatingcustom', 'foundationmodelsforvariousdomainsthatapplication-developerscanuse', 'thinkecosystem', 'actmodel', 'whilethesocialimpactdependsonthewholeecosystem', 'itisstill', 'importanttobeabletoreasonaboutthesocialimplicationsofafoundationmodel', 'giventhatmany', 'researchers', '’', 'andpractitioners', '’', 'purviewisrestrictedtothetrainingstage.thisisdifficultbecause', 'foundationmodelsareunfinishedintermediateobjectsthatcanbeadaptedtomanydownstream', 'applications', 'sometimesbyanentirelydifferententityforunforeseenpurposes.whatweneed', 'aretwothings', 'surrogatemetricsforarepresentativesetofpotentialdownstreamevaluation', '§4.4', 'evaluation', 'ii', 'commitment', 'document', 'metrics', '[', 'mitchell', 'et', 'al', '2019', ']', 'similartodatasheetsformaterialssuchasmetalsandplastics', 'whichcanbeadaptedtomany', 'downstreamusecases', 'characterizingthepotentialdownstreamsocialimpactoffoundationmodelsischallengingand', 'demandsadeepunderstandingofboththetechnologicalecosystemandofsociety.onecannot', 'fullyassesstheharms', '§5.1', 'fairness', 'ofafoundationmodelwithoutrecognizinghowitwillbe', 'deploy', 'andonecannotjustdefineautomaticmetricswithoutconsideringtherichsocialand', 'historicalcontext', '1.3', 'thefutureoffoundationmodels', 'foundationmodelshavedemonstratedrawpotential', 'butwearestillintheearlydays.despitetheir', 'deploymentintotherealworld', 'thesemodelsareverymuchresearchprototypesthatarepoorly', 'understood.eventheprofessionalnorms—whatrobertmertoncallstheethosofscience', '[', 'merton', '1979', ']', '—aroundfoundationmodelsareunderdeveloped.forexample', 'thereislackofagreementon', 'basicquestionssuchaswhenmodelsare', '“', 'safe', '”', 'toreleaseorhowthecommunityshouldreactin', 'responsetomethodologicalmisconduct.giventhatthefutureoffoundationmodelsisthusfilled', 'withuncertainty', 'abigquestionis', 'whowilldeterminethisfuture', '?', 'disciplinarydiversity', 'thetechnologybehindfoundationmodelsisbasedondecadesofresearch', 'inmachinelearning', 'optimization', 'nlp', 'computervision', 'andotherfields.thesetechnicalcontri-', 'butionshavecomefrombothacademiaandindustrialresearchlabs.however', 'researchonbuilding', 'foundationmodelsthemselveshasoccurredalmostexclusivelyinindustry—bigtechcompanies', 'suchasgoogle', 'facebook', 'microsoft', 'orhuawei', 'orstartupssuchasopenaiorai21labs', 'though', 'ai2isanotableexception', '[', 'petersetal.2018', 'zellersetal.2019b', ']', 'thefuriouspaceoftechnologicalprogressandtheentrenchmentduetocentralizationraise', 'powerful', 'concern', 'demand', 'attention', 'humanists', 'social', 'scientists', 'addition']",9
Opportunities and Risks of Foundational Models - Stanford.pdf,"['10', 'centerforresearchonfoundationmodels', 'crfm', 'technologists.weshouldnotrelyonpost-hocauditsofethicalandsocialconsequences', 'conduct', 'onlyafterthetechnicalarchitectureanddeploymentdecisionshavebeenmade.weinsteadneed', 'toinfusesocialconsiderationsandethicaldesigndeeplyintothetechnologicaldevelopmentof', 'foundation', 'model', 'surround', 'ecosystem', 'start', 'academic', 'institutions', 'unique', 'host', 'widest', 'set', 'discipline', 'one', 'roof', 'thus', 'bring', 'together', 'computerscientists', 'socialscientists', 'economists', 'ethicists', 'legalscholars', 'etc.giventheimportance', 'ofdisciplinarydiversityinunderstandingandsolvingproblemsthatcombinetechnical', 'ethical', 'legal', 'social', 'andpoliticaldimensions', '[', 'hongandpage2004', 'solomon2006', 'steeletal.2018', ']', 'thereforeseeacademiaasplayingacrucialroleindevelopingfoundationmodelsinsuchawayto', 'promotetheirsocialbenefitandmitigatetheirsocialharms', 'aswellasdeterminingthecontexts', 'underwhichactionsineachofthestagesoftheecosystem', '§1.2', 'ecosystem', 'rangingfromdata', 'curationtodeploymentshouldbestrictlyprohibited', 'incentives', 'thepolitical', 'economy', 'inwhichfoundations', 'modelsare', 'design', 'develop', 'deploy', 'provide', 'inevitable', 'incentive', 'structure', 'decision-making', 'every', 'stage', 'peopleandinstitutionsrespondtoincentivesisanelementarylessonofeconomics.market-driven', 'commercialincentivescanalignwellwithsocialbenefit', 'makingfoundationmodelsmoreaccurate', 'reliable', 'safe', 'andefficientwhilesearchingforawidevarietyofpotentialusecasescanproducea', 'greatdealofsocialutility.however', 'commercialincentivescanalsoleadtomarketfailuresand', 'underinvestmentindomainswhereshareholdersareunabletocapturethevalueofinnovation', 'pharmaceutical', 'industry', 'little', 'incentive', 'devote', 'significant', 'resources', 'researchanddevelopmentofmalariatreatments', 'becausepoorpeoplecannotaffordmedications,9', 'thetechindustryhaslittleincentivetodevotesignificantresourcestotechnologiesdesignedfor', 'improvingtheconditionofpoorandmarginalizedpeople', '[', 'reichetal.2021', ']', '.what', '’', 'smore', 'commercialincentivecanleadcompaniestoignoresocialexternalities', '[', 'acemoglu2021', 'reichetal', '2021', ']', 'suchasthetechnologicaldisplacementoflabor', 'thehealthofaninformationalecosystem', 'requiredfordemocracy', 'theenvironmentalcostofcomputingresources', 'andtheprofit-drivensale', 'oftechnologiestonon-democraticregimes.finally', 'thereislittleincentiveforanygivencompany', 'create', 'open', 'decentralize', 'ecosystem', 'develop', 'foundation', 'model', 'encourage', 'broadparticipation', 'incontrast', 'thelong-standinganddeeply-seatedresearchmissionofuniversitiesistheproduction', 'anddisseminationofknowledgeandcreationofglobalpublicgoods', '[', 'kerr2001', 'rhotenandcalhoun', '2011', 'nussbaum2010', ']', '.webelievethatacademiaisdistinctivelypositionedtoshapethedevelopment', 'offoundationmodelstoensurethatwecapturedirectionswithpotentiallylargesocialbenefitthat', 'mightnototherwisebeprioritizedbyindustry', 'lossinaccessibility', 'unfortunately', 'academiahasnotbeenabletoparticipateinthefullestway', 'possibleduetothelossinaccessibility.oneoftheoftenoverlookedeffectsofthedeeplearning', 'revolutionwastheincreaseinreproducibilityandopenscience', 'itincreasinglybecamethenorm', 'topubliclyreleasecodeanddatasets', 'andpackagessuchastensorflow', '[', 'abadietal.2016', ']', 'pytorch', '[', 'paszkeetal.2019', ']', 'madeitmucheasierforpeopletocollaborateandbuildoffofeach', '’', 'swork.initiativeslikethemlreproducibilitychallenge10aswellasreproducibilitychecklists', 'adoptedbymajorconferences', '[', 'pineauetal.2020', ']', 'alongsideplatformslikecodalabworksheets11', 'helpedadvancecommunitystandardsforreproducibility.thisresultedinasurgeintechnological', 'innovationandprogress', '9seehttps', '//www.gatesfoundation.org/about/our-role', '10https', '//paperswithcode.com/rc2020', '11https', '//worksheets.codalab.org/']",10
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '11', 'foundation', 'model', 'start', 'roll', 'back', 'positive', 'trend', 'model', 'e.g.', 'gpt-3', 'releasedatall', 'onlyapiaccesstoalimitedpoolofpeople', '.evendatasets', 'e.g.', 'forgpt-2', 'arenot', 'released.whiletrainedmodelsmaybeavailable', 'e.g.', 'bert', 'theactualtrainingoffoundation', 'modelsisunavailabletothevastmajorityofairesearchers', 'duetothemuchhighercomputational', 'costandthecomplexengineeringrequirements', 'meaningful', 'research', 'still', 'do', 'train', 'smaller', 'model', 'within', 'reach', 'academicbudget', 'andindeedthesurprisinglyregularitypredictedbyscalinglaws', '[', 'kaplanetal', '2020', ']', 'make', 'viable', 'strategy', 'case', 'differences', 'due', 'scale', 'quantitative', 'e.g.', 'accuracygoesup', '.however', 'duetotheemergentnatureofthesefoundationmodels', 'functionalitieslikein-contextlearninghaveonlybeendemonstratedinmodelsofsufficientsize', 'scaleisneededtoevenasktherightquestions', 'itisalsopossibletoproductivelystudypre-existingmodelsthathavebeenreleased', 'indeed', 'hasledtoalargesubcommunitywithinnlpforprobingthesemodels', '[', 'rogersetal.2020', 'man', 'etal.2020', ']', '.havingaccesstoexistingmodelscanbeusefulforpoweringdownstreamapplications', 'oridentifyingdefects', 'e.g.', 'bias', 'butthismightnotbeenoughforustodesignbetterarchitectures', 'ortrainingobjectivesforfoundationmodelsthatcanfixthesedefects', 'e.g.', 'mitigatethebias', '.itis', 'worthreflectingonhowmuchofnlpresearchtodayisbasedonbert', 'aparticular', 'andsomewhat', 'arbitrary', 'foundationmodel.giventheneedtoinfusesocialawarenessandethicaldesignintothe', 'constructionofthesemodels', 'itispossiblethatweneedtobuildfoundationmodelsthatlookquite', 'differentfromwhatexiststoday.thiswilldemandintenseexperimentationatscale', 'communityeffortssuchaseleutherai12andhuggingface', '’', 'sbigscienceproject13areattempting', 'totrainlargefoundationmodels', 'butthegapbetweentheprivatemodelsthatindustrycantrain', 'andtheonesthatareopentothecommunitywilllikelyremainlargeifnotgrow.further', 'today', 'startups', 'openai', 'anthropic', 'ai21labs', 'etc', 'aremuchmorewell-resourcedthanacademiaandcan', 'thereforestillaffordtotrainthelargestfoundationmodels', 'e.g.', 'openai', '’', 'sgpt-3', '.however', 'big', 'techcompaniesareonacompletelydifferentlevelintermsofresources', 'especiallyintermsofthe', 'infrastructure', 'users', 'anddatathatcomefromtheirmarketposition.thefundamentalcentralizing', 'natureoffoundationmodelsmeansthatthebarriertoentryfordevelopingthemwillcontinue', 'torise', 'sothatevenstartups', 'despitetheiragility', 'willfinditdifficulttocompete', 'atrendthatis', 'reflectedinthedevelopmentofsearchengines', '[', 'radinsky2015', ']', 'onewaytoclosetheresourcegapisforthegovernmenttoinvestinpublicinfrastructure.wecan', 'looktobigscienceprojectssuchasthehubblespacetelescopeandthelargehadroncollideras', 'inspiration', 'wheresubstantialinvestmentmadepossiblefundamentalscientificdiscoverieswhich', '’', 'thavebeenpossible.onecanimagineasimilarinfrastructureforcomputing', 'fromwhich', 'academicresearchonfoundationmodelswouldgreatlybenefit.intheus', 'thenascentnational', 'researchcloudinitiative14isastepinthisdirection', 'another', 'complementary', 'approach', 'rely', 'volunteer', 'compute', 'billionsofcomputingdevices', 'nod', 'canconnecttoacentralserverandcontributecomputation', 'thefolding', 'homeprojecthassuccessfullyimplementedthisapproachforsimulatingprotein', 'dynamics', '[', 'beberg', 'et', 'al', '2009', ']', 'recently', 'learn', 'home', 'project', 'attempt', 'harness', 'volunteercomputingfortrainingfoundationmodels', '[', 'ryabininandgusev2020', ']', '.thehighlatency', 'connectionsbetweennodesandthehighbandwidthrequirementsfortrainingfoundationmodels', 'makethisanopentechnicalchallenge', '12https', '//www.eleuther.ai/', '13https', '//bigscience.huggingface.co/', '14https', '//hai.stanford.edu/policy/national-research-cloud']",11
Opportunities and Risks of Foundational Models - Stanford.pdf,"['12', 'centerforresearchonfoundationmodels', 'crfm', 'summary', 'therearetremendouseconomicincentivestopushthecapabilitiesandscaleoffoun-', 'dation', 'model', 'anticipate', 'steady', 'technological', 'progress', 'come', 'years', 'suitabilityofatechnologyrelyinglargelyonemergentbehaviorforwidespreaddeploymentto', 'peopleisunclear.whatisclearthatweneedtobecautious', 'andthatnowisthetimetoestablish', 'theprofessionalnormsthatwillenabletheresponsibleresearchanddeploymentoffoundation', 'models.academiaandindustryneedtocollaborateonthis', 'industryultimatelymakesconcrete', 'decisionsabouthowfoundationmodelswillbedeployed', 'butweshouldalsoleanonacademia', 'withitsdisciplinarydiversityandnon-commercialincentivesaroundknowledgeproductionand', 'socialbenefit', 'toprovidedistinctiveguidanceonthedevelopmentanddeploymentoffoundation', 'modelsthatisbothtechnicallyandethicallygrounded', '1.4', 'overviewofthisreport', 'march', '2021', 'create', 'informal', 'community', 'stanford', 'university', 'students', 'faculty', 'andresearchersinterestedinsomeaspectoffoundationmodels.15', 'fromtheverybeginning', 'communityincludednotjustairesearchers', 'butthoseeagertoapplyfoundationmodelstotheir', 'domain', 'e.g.', 'healthcare', 'law', 'well', 'interest', 'societal', 'concern', 'e.g.', 'ethicsandeconomics', '.asdiscussionsprogressed', 'wenoticedthatthereweremanygapsin', 'mutualunderstanding—howthetechnologyworked', 'howindustrydevelopsfoundationmodels', 'howtothinkabouttheethicalconcerns', 'etc.', 'andexistingliteratureonlycoveredbitsandpieces', 'wewantedtothereforeprovideafullerpictureoffoundationmodels', 'identifyopportunitiesand', 'risk', 'andestablishaconstructivevisionforthefutureresponsibledevelopmentoffoundation', 'model', 'thewritingofthisreportwasanexperiment', 'wehadover100peoplefromdifferentbackgrounds', 'cometogethertowritesinglereportcoveringawiderangeofaspectsoffoundationmodels.alarge', 'partofthisreportisasurveyofexistingwork', 'butthroughmanydiscussions', 'wehaveunifieditin', 'onereporttohighlightalltheinterdisciplinaryconnections', 'structure', 'thereportisdividedinto26sections', 'eachdiscussingoneaspectoffoundationmodels', 'section', 'group', 'four', 'part', 'capabilities', '§2', 'capabilities', 'applications', '§3', 'ap-', 'plications', 'technology', '§4', 'technology', 'andsociety', '§5', 'society', 'althoughtherearemany', 'connectionsacrosssections.theseconnectionshighlightanintegratedapproachinwhichthe', 'technologiesandcapabilitiesaredevelopedinawaythatissensitivetorealsocietalconcerns', 'beinginspiredbyandgroundedoutinapplications', 'whilewehavesoughttocapturemostoftheimportanttopicssurroundingfoundationmodels', 'thisreportwillinevitablybeincomplete', 'especiallyasthefieldevolvesquickly.forexample', 'many', 'applications', 'e.g.', 'naturalsciences', 'music', 'finance', 'agriculture', 'arenotincluded', 'thoughtheyareas', 'likelytobeaffectedastheapplicationswehavechosentodiscuss.itwouldalsobeinterestingto', 'studyhowfoundationmodelsrelatetoresearchinneuroscience', 'cognitivescience', 'andpsychology', 'toexplainintelligenceandaideffortsincomputationalsocialsciencetounderstandsociety', 'authorcontributions', 'percylianginitiatedandconceptualizedtheframingandstructureof', 'theoverallreport.heandrishibommasaniworkedtogethertoleadthedecentralizedwriting', 'effortandprovidedguidanceonindividualsections.drewa.hudsoncreatedallthefiguresin', 'thereport', 'discussingtheirstructureandcontentwiththeauthorsofeachsection.eachofthe26', 'sectionsofthisreportwaswrittenbyasubsetofauthors', 'whosenamesarelistedatthebeginning', 'ofeachsection.therewere', 'however', 'manydiscussionsthatspannedmultiplesections', 'sothe', '15thiscommunityledtothefoundingofthecenterforresearchonfoundationmodels', 'crfm', 'anewinterdisciplinary', 'initiativeatthestanfordinstituteforhuman-centeredai', 'hai']",12
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '13', 'fig.4', 'thisreportisdividedintofourparts', 'capabilities', 'applications', 'technology', 'andsociety', 'whereeach', 'partcontainsasetofsections', 'andeachsectioncoversoneaspectoffoundationmodels', 'actualcontributionstoeachsectiongenerallycamefromabroaderset.finally', 'wenotethatnotall', 'theviewsexpressedinthisreportareheldbyalltheauthors']",13
Opportunities and Risks of Foundational Models - Stanford.pdf,"['14', 'centerforresearchonfoundationmodels', 'crfm', '1.4.1', 'overviewofcapabilities', 'foundationmodelspossessvariouscapabilitiesthatapplicationscandrawfrom.wehavechosento', 'discussfivepotentialcapabilities', 'theabilitytoprocessdifferentmodalities', 'e.g.', 'language', 'vision', 'affectthephysicalworld', 'robotics', 'toperformreasoning', 'andtointeractwithhumans', 'interaction', 'finally', 'weconcludewithaphilosophicaldiscussionofpotentiallimitsontheircapabilities', '§2.1', 'language', 'nlpasafieldhasblazedthetrailforfoundationmodels.whilethesemodels', 'dominatestandardbenchmarks', 'thereisacleargapbetweenthecapabilitiesthesemodelsacquire', 'currentlyandthosethatcharacterizelanguageasacomplexsystemforhumancommunicationand', 'thought.tounderstandthisrift', 'weemphasizethefullrangeoflinguisticvariation', 'e.g.', 'different', 'style', 'dialects', 'languages', 'whichposesanopportunityandchallengegivensomevariantsaredata-', 'limited.further', 'childlanguageacquisitionismoresampleefficientthanthetrainingoffoundation', 'model', 'weexaminehowsignalsbeyondtextandgroundingmayhelptobridgethisgap.bothof', 'thesecharacteristicsoflanguageprovidecleardirectionsforfuturefoundationmodelsresearch', '§2.2', 'vision', 'computervisionledtheadoptionofdeeplearninginai', '[', 'russakovskyetal.2015', ']', 'demonstratingthatpretrainingmodelsonlarge-scaleannotateddatasetscantransfertonumerous', 'downstreamsettings.now', 'pretrainingonweb-scalerawdatainsteadofcurateddatasets', 'foundation', 'modelsareontheriseincomputervision', '[', 'e.g.', 'radfordetal.2021', ']', '.thesemodelshaveshown', 'promise', 'result', 'standard', 'task', 'field', 'like', 'image', 'classification', 'object', 'detection', 'andtrainingonmultimodalandembodied', 'databeyondimagesmayenableprogressonsignificant', 'challenge', 'e.g.', '3d', 'geometric', 'physical', 'understand', 'commonsense', 'reason', 'also', 'discuss', 'key', 'challenge', 'model', 'e.g.', 'ability', 'scale', 'effectively', 'videos', 'andevaluation', 'e.g.', 'themeasurementofhigher-ordercapabilities', 'alongwiththeapplications', 'e.g.', 'ambientintelligenceforhealthcare', 'andsocietalconsiderations', 'e.g.', 'surveillance', 'thatwill', 'determinetheimpactoffoundationmodelsforcomputervisiongoingforward', '§2.3', 'robotics', 'alongstandinggoalofroboticsresearchistodevelop', '“', 'generalist', '”', 'robotscapable', 'ofperformingmyriadtasksacrossphysicallydiverseenvironments.unlikelanguageandvision', 'whichhaveledthewaywithfoundationmodelsbothduetotheabundanceofrawdatatotrain', 'thesemodelsonandtheavailabilityofvirtualapplicationstoapplythesemodelsto', 'roboticsfaces', 'fundamentalchallengesduetobeinganchoredtothephysicalworld.theprincipalchallengefor', 'roboticstoleveragefoundationmodelsisacquiringsufficientdataoftherightformthatisconducive', 'tolearning', 'weexplorehowplentifuldata', 'e.g.', 'genericvideosofhumans', 'amongstothers', 'isnotspecifictoparticularenvironmentsandacrossmodalities', 'e.g.', 'language', 'vision', 'mayhelp', 'tobridgethisgap.iffoundationmodelsworkwellinroboticcontexts', 'thisallowsfortheeasier', 'specificationandlearningoftasksbyroboticagents', 'usheringinnewapplications', 'e.g.', 'household', 'task', 'andheighteningtheimportanceofrobustnessandsafety', 'e.g.', 'formalsafetyevaluation', '§2.4', 'reasoningandsearch', 'reasoningandsearchproblemssuchastheoremprovingandpro-', 'gramsynthesishavebeenlong-standingchallengesinai.thecombinatorialsearchspacerenders', 'traditionalsearch-basedmethodsintractable.however', 'humansareknowntooperateintuitively', 'eveninthemostmathematicalofdomains', '[', 'lakoffandnúñez2000', ']', 'andindeedexistingwork', 'suchasalphagohavealreadyshownthatdeepneuralnetworkscanbeeffectiveinguidingthe', 'searchspace.buthumansalsotransferknowledgeacrosstasks', 'facilitatingmuchmoreefficient', 'adaptationandtheabilitytoreasonmoreabstractly.foundationmodelsofferthepossibilityof', 'closingthisgap', 'theirmulti-purposenaturealongwiththeirstronggenerativeandmultimodal', 'capabilitiesoffernewleverageforcontrollingthecombinatorialexplosioninherenttosearch']",14
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '15', '§2.5', 'interaction', 'foundationmodelsshowclearpotentialtotransformthedeveloperanduser', 'experienceforaisystems', 'foundationmodelslowerthedifficultythresholdforprototypingand', 'buildingaiapplicationsduetotheirsampleefficiencyinadaptation', 'andraisetheceilingfornovel', 'userinteractionduetotheirmultimodalandgenerativecapabilities.thisprovidesasynergywe', 'encouragegoingforward', 'developerscanprovideapplicationsthatbetterfittheuser', '’', 'sneedsand', 'value', 'whileintroducingfarmoredynamicformsofinteractionandopportunitiesforfeedback', '§2.6', 'philosophyofunderstanding', 'whatcouldafoundationmodelcometounderstandabout', 'thedataitistrainedon', '?', 'focusingonthecaseofnaturallanguage', 'weidentifydifferentpositions', 'onthenatureofunderstandingandexploretheirrelevanceforourcentralquestion.ourtentative', 'conclusionisthatskepticismaboutthecapacityoffuturefoundationmodelstounderstandnatural', 'languagemaybepremature', 'especiallywherethemodelsaretrainedonmulti-modaldata', '1.4.2', 'overviewofapplications', 'atpresent', 'foundationmodelresearchislargelyconfinedtocomputerscienceandai', 'withthe', 'impactoffoundationmodelsandtheapplicationstheysupportlargelybeingcenteredinthetech', 'industry.movingforward', 'foundationmodelspresentclearpotentialtotransformandextendthe', 'reachofaiacrossmanysectorsbeyondthetechindustry', 'suggestingamorepervasiveeffecton', 'people', '’', 'slives.whilethereisamultitudeofapplicationsanddomainstoconsider', 'wewehavechosen', 'threeapplications—', 'healthcare', 'law', 'andeducation—', 'becausetheyrepresentfoundationalpillarsof', 'oursociety.forfoundationmodelstosignificantlycontributetotheseapplicationdomains', 'model', 'willrequirespecificcapabilities', '§2', 'capabilities', 'aswellastechnicalinnovation', '§4', 'technology', 'toaccountfortheuniqueconsiderationsineachdomain.further', 'sincethesedomainsarecritical', 'tosocietalfunction', '§5', 'society', 'applyingfoundationmodelsinthesedomainsrequiresengaging', 'withdeeplysociotechnicalmatterssuchasthosethosepertainingtodata', '§4.6', 'data', 'privacy', '§4.7', 'security', 'interpretability', '§4.11', 'interpretability', 'fairness', '§5.1', 'fairness', 'andethics', '§5.6', 'ethics', '§3.1', 'healthcareandbiomedicine', 'healthcaretasks', 'e.g.', 'patientcareviadiseasetreatment', 'andbiomedicalresearch', 'e.g.', 'scientificdiscoveryofnewtherapies', 'requireexpertknowledgethat', 'islimitedandexpensive.foundationmodelspresentclearopportunitiesinthesedomainsdueto', 'theabundanceofdataacrossmanymodalities', 'e.g.', 'image', 'text', 'molecules', 'totrainfoundation', 'model', 'aswellasthevalueofimprovedsampleefficiencyinadaptationduetothecostofex-', 'perttimeandknowledge.further', 'foundationmodelsmayallowforimprovedinterfacedesign', '§2.5', 'interaction', 'forbothhealthcareprovidersandpatientstointeractwithaisystems', 'theirgenerativecapabilitiessuggestpotentialforopen-endedresearchproblemslikedrugdiscovery', 'simultaneously', 'theycomewithclearrisks', 'e.g.', 'exacerbatinghistoricalbiasesinmedicaldatasets', 'andtrials', '.toresponsiblyunlockthispotentialrequiresengagingdeeplywiththesociotechnical', 'mattersofdatasourcesandprivacyaswellasmodelinterpretabilityandexplainability', 'alongside', 'effectiveregulationoftheuseoffoundationmodelsforbothhealthcareandbiomedicine', '§3.2', 'law', 'legalapplicationsrequirethatattorneysreadandproducelongcoherentnarratives', 'thatincorporateshiftingcontextsanddecipherambiguouslegalstandards.foundationmodelsmay', 'providebenefitsinthisdomain', 'ampledataexistsintheformoflegaldocumentsandtheirgenerative', 'capabilitiesarewell-suitedtothemanygenerativetasksrequiredinlaw', 'butsignificantimprovements', 'arerequiredforfoundationmodelstobeabletoreliablyreasonovervarioussourcesofinformationto', 'generatetruthfullong-formdocuments.asisthecareinhealthcare', '§3.1', 'healthcare', 'thesample', 'efficiencyofadaptationforfoundationmodelsisofheightenedvaluegiventhecostsofexperttime', 'andknowledgeinthelegaldomain', 'whichmayallowforthere-allocationofexpertise', 'towards']",15
Opportunities and Risks of Foundational Models - Stanford.pdf,"['16', 'centerforresearchonfoundationmodels', 'crfm', 'pressingproblemsofjusticeandgovernmentservice.theresponsibledevelopmentoffoundation', 'modelsforlawwillrequirespecificconsiderationofprivacy', 'andhighlightscorelimitationsof', 'existingfoundationalmodelsthatwillrequirefundamentaladvanceswithrespecttoprovenance', 'fortheirbehaviorandguaranteesforthefactualityoftheirgeneration', '§3.3', 'education', 'educationisacomplexandsubtledomain', 'effectiveteachinginvolvesreasoning', 'aboutstudentcognitionandshouldreflectthelearninggoalsofstudents.thenatureoffoundation', 'modelspresentspromiseherethathasyettoberealizedinthesphereofaiforeducation', 'certainmanystreamsofdataineducationareindividuallytoolimitedtotrainfoundationmodels', 'ability', 'leverage', 'relevant', 'data', 'outside', 'domain', 'e.g.', 'internet', 'make', 'use', 'ofdataacrossmultiplemodalities', 'e.g.', 'textbooks', 'mathematicalformula', 'diagram', 'video-based', 'tutorials', 'jointlyoffershopeforfoundationmodelsthatarebroadlyapplicabletoeducationaltasks', 'iffoundationmodelsleadtoasignificantimprovementineducation-relevantcapabilities', 'isclearpotentialfornewapplicationsthatalignwiththeopen-endedgenerative', 'e.g.', 'problem', 'generation', 'andinteractive', 'e.g.', 'feedbacktoteachers', 'aspectsoffoundationmodels', 'thesample', 'efficientadaptationoffoundationmodelssuggestsgreaterabilityforadaptiveandpersonalized', 'learning.inthisevent', 'renewedconsiderationisrequiredofhallmarksofapplyingtechnologyto', 'education', 'e.g.', 'studentprivacy', 'alongwithcertainconcernsbecomingmorecritical', 'e.g.', 'inequity', 'inaccesstotechnologyineducation', 'technology-aidedplagiarism', '1.4.3', 'overviewoftechnology', 'nowwediscussthetechnologybehindbuildingbettermodelarchitectures', 'trainingandadaptation', 'procedures', 'andofcoursescalingupthesystems.onecrucialbutoftenoverlookedtopicisdata—', 'wheredoesitcomefromandwhatisitscomposition', '?', 'inaddition', 'wewantfoundationmodelsto', 'berobusttodistributionshiftsandsecureagainstattackers.finally', 'wewishtounderstandwhy', 'foundationmodelsworkfrombothamathematicalperspectiveaswellasanempiricalperspective', '§4.1', 'model', 'structural', 'properties', 'give', 'rise', 'foundation', 'model', '?', 'model', 'section', 'explore', 'underlie', 'architectures', 'behind', 'foundation', 'model', 'identify', '5', 'key', 'attributes.first', 'westartbydiscussingexpressivityofthecomputationalmodel—', 'tocaptureand', 'assimilatereal-worldinformation', 'andscalability', '—', 'toadeptlyhandlelargequantitiesofhigh-', 'dimensionaldata.thesepropertiesaresuccessfullyrealizedbyexistingarchitecturessuchasthe', 'transformernetwork', '[', 'vaswanietal.2017', ']', 'thatunderpinsmostfoundationmodelstodate.wethen', 'proceedtoattributesmaybeessentialforthenextgenerationofmodels', 'include', 'multimodallity—', 'toconsume', 'processandpotentiallyproducecontentfromdifferentsourcesanddomains', 'memory', 'capacity—', 'toeffectivelystoreandretrievetheacquiredknowledge', 'andfinally', 'compositionality', 'tofostersuccessfulgeneralizationtonovelsettingsandenvironments.webelievethatrealizingthe', 'fullpotentialenvisionedforfoundationmodelswillhingeonmodellingadvancestofulfillthese', 'desiderata', '§4.2', 'train', 'trainingobjectivesmathematicallyspecifyhowmodelsshouldlearnandacquire', 'capabilitiesfromtheirtrainingdata.thecurrentstatusquofortrainingfoundationmodelsinvolves', 'modality-specific', 'objectives', 'e.g.', 'mask', 'language', 'model', '[', 'devlin', 'et', 'al', '2019', ']', 'text', 'simclr', '[', 'chen', 'et', 'al', '2020c', ']', 'image', 'often', 'choose', 'heuristically', 'envision', 'future', 'train', 'objectives', 'foundation', 'model', 'reflect', 'two', 'change', 'principled', 'selection', 'derivedfromsystematicevidenceandevaluation', '§4.4', 'evaluation', 'anddomain-generality', 'provide', 'rich', 'scalable', 'unify', 'train', 'signal', 'across', 'data', 'source', 'modalities', 'also', 'discussimportantdesigntrade-offs', 'includinggenerativevsdiscriminativetraining', 'thechoice']",16
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '17', 'ofinputdatarepresentation', 'andthepotentialoffuturetrainingobjectivesthatinvolveexplicit', 'representationsofgoals', '§4.3', 'adaptation', 'foundationmodelsareintermediaryassets', 'theyareunfinishedandgenerally', 'shouldnotbeuseddirectly', 'insteadrequiringadaptationforspecificdownstreamtasks.thede', 'factoapproachforadaptationhasbeenfine-tuning', 'withrecentworksuggestingthatlightweight', 'fine-tuningalternativesandprompting-basedmethodsmayachievefavorableaccuracy-efficiency', 'tradeoffs.movingforward', 'weenvisionamoreexpansiveviewofadaptationthatgoesbeyond', 'justspecializingfoundationmodelstoperformthetaskofinterest', 'adaptationwillalleviatedefi-', 'cienciesofstand-alonefoundationmodels', 'e.g.', 'temporaladaptationtoreflectchangesovertime', 'intheworld', 'orintroduceconstraints', 'e.g.', 'gdprcompliancerelatingtotherighttobeforgotten', '§4.7', 'security', 'thisbroaderperspectiveonadaptationcoincideswithaneedfornewevaluation', 'protocols', '§4.4', 'evaluation', 'thatsystematicallyevaluateadaptationmethodswhilecontrollingfor', 'resources', 'e.g.', 'runtime', 'memory', 'andaccessrequirementsinvolvedinadaptation', '§4.4', 'evaluation', 'evaluationofferscontexttofoundationmodelsbyprovidingameanstotrack', 'progress', 'understand', 'model', 'document', 'capabilities', 'bias', 'foundation', 'model', 'challengetheabilityofstandardevaluationparadigmsinmachinelearningtoachievethesegoals', 'sincetheyareonestepremovedfromspecifictasks.toenvisionnewparadigmsinevaluation', 'thatsuitfoundationmodels', 'wediscuss', 'evaluatingfoundationmodelsdirectlytomeasuretheir', 'inherentcapabilitiesandinformhowfoundationmodelsaretrained', 'b', 'evaluatingtask-specific', 'model', 'control', 'adaptation', 'resources', 'access', 'c', 'broader', 'evaluation', 'design', 'providerichercontextbeyondmeasuresofaccuracy', 'e.g.', 'robustness', '§4.8', 'robustness', 'fairness', '§5.1', 'fairness', 'efficiency', '§4.5', 'systems', 'environmentalimpact', '§5.3', 'environment', '.reformof', 'evaluationpracticeswillallowforevaluationthatadequatelyservesboththediversegoalsand', 'stakeholdersinvolvedinthefoundationmodelparadigm', '§4.5', 'systems', 'whilethetrainingdata', '§4.6', 'data', 'determinesthetheoreticalinformationavail-', 'able', 'foundation', 'model', 'model', 'architectures', '§4.1', 'model', 'train', 'objectives', '§4.2', 'train', 'determinehowmuchofthisinformationcanbeextracted', 'computersystems', 'determinewhatispracticallyachievableforfoundationmodels.systemsareakeybottleneckfor', 'scalingintermsofdataandmodelsize', 'bothofwhichappeartoreliablytrackwithimprovements', 'incapabilities.toensurethatwecantrainthenextgenerationoffoundationmodelsefficiently', 'withrespecttotimeandcost', 'wewillrequiretheco-designofalgorithms', 'model', 'software', 'hardware.thisco-designisalreadystartingtohappentoinvariousforms', 'fromcarefullytuned', 'dnndesignstonewarchitecturessuchasretrieval-basedmodels.beyondtraining', 'weconsider', 'whatwillberequiredtodeployapplicationsontopoffoundationmodels', 'e.g.', 'efficientinference', '§4.6', 'data', 'dataisthelifebloodoffoundationmodels', 'thetrainingdataofthesemodelslargely', 'determineswhatthesecapabilitiesthesemodelscanacquire.thecentralityofdataisnotunique', 'tofoundationmodels', 'recentcallsfordata-centricai', '[', 'press2021', 'ré2021', ']', 'indicatethepervasive', 'importanceofmanaging', 'understand', 'anddocumentingdatausedtotrainmachinelearning', 'models.forfoundationmodelsspecifically', 'thecurrentmodusoperandiisfortrainingdatatobe', 'selectedusingunspecifiedorunclearprincipleswithagenerallackoftransparencyregardingthe', 'natureoftrainingdata.webelieveanalternativeapproachisneededtore-imaginethedataecosys-', 'temsurroundingfoundationmodels', 'wedrawuponworkondatavisualizationandmanagement', 'toproposeadatahubforfoundationmodels.wearticulatehowthisproposalrelatestomanyof', 'therelevantdata-centricconsiderationsforfoundationmodels', 'selection', 'curation', 'documentation', 'access', 'visualizationandinspection', 'qualityassessment', 'andlegalregulation']",17
Opportunities and Risks of Foundational Models - Stanford.pdf,"['18', 'centerforresearchonfoundationmodels', 'crfm', '§4.7', 'securityandprivacy', 'securityandprivacyforfoundationmodelsislargelyunchartedat', 'present', 'fundamentally', 'foundation', 'model', 'high-leverage', 'single', 'point', 'failure', 'make', 'themaprimetargetforattack', 'existingworkdemonstratesavarietyofsecurityvulnerabilities', 'e.g.', 'adversarialtriggerstogenerateundesirableoutputs', 'orprivacyrisks', 'e.g.', 'memorizationof', 'trainingdata', 'forthesemodels.further', 'thegeneralityoffoundationmodelscompoundsthese', 'concern', 'intensifyingtheriskforfunctioncreepordualuse', 'i.e.', 'useforunintendedpurposes', '.for', 'security', 'weviewfoundationmodelsasakintooperatingsystemsintraditionalsoftwaresystems', 'wediscussstepstowardssecurefoundationmodelswhich', 'ifachieved', 'wouldprovideastrong', 'abstractionlayertobuilduponforreliablemlapplications.forprivacy', 'byleveragingknowledge', 'transfer', 'public', 'data', 'foundation', 'model', 'may', 'enable', 'sample', 'efficient', 'adaptation', 'sensitive', 'data', 'distributions', 'i.e.', 'privacy-preserving', 'applications', 'may', 'incurless', 'degradation', 'accuracywhenbuiltusingfoundationmodels', '§4.8', 'robustnesstodistributionshifts', 'amajorlimitationofstandardmachinelearningisthat', 'itproducesmodelsthatarenotrobusttodistributionshifts', 'wherethetrainingdistributiondoes', 'notmatchthetestdistribution', 'forthedownstreamtask', '.existingworkshowsthatadaptinga', 'foundationmodeltrainedonabroadrangeofunlabeleddataimprovestherobustnessofadapted', 'modelsacrossawidevarietyofshifts.thisopensanewsetofpromisingdirectionsforimproving', 'trainingandadaptationoffoundationmodelsforrobustness.however', 'wedonotbelievethat', 'foundationmodelsareapanaceaforrobustness—challengessuchasextrapolationacrosstime', 'andspuriouscorrelationsarenotlikelytobefullyaddressed', '§4.9', 'aisafetyandalignment', 'ensuringfoundationmodelsarereliable', '§4.5', 'systems', 'robust', '§4.8', 'robustness', 'andinterpretable', '§4.11', 'interpretability', 'isincreasinglyimportantwhen', 'consideringthepotentialreal-worldapplicationsofthesemodels.inadditiontocriticalandimme-', 'diateconsiderations', 'wealsoconsidertherelationshipbetweenfoundationmodelsandlarger-scale', 'risk', 'hazard', 'harm', 'potential', 'increase', 'relevance', 'model', 'capabilities', 'continue', 'advance', 'example', 'consider', 'importance', 'align', 'foundation', 'model', 'suchthattheyarenotdeployedwithmisspecifiedgoalsorvalues.wealsodiscusstherelevance', 'forecast', 'emergent', 'behaviors', 'foundation', 'model', 'e.g.', 'ability', 'deceive', 'plan', 'strategically', 'whichmaycomplicateattemptstoadaptthemtoparticulartasks', 'andmayrequire', 'newapproachesforinterpretability', '§4.11', 'interpretability', 'orevaluation', '§4.4', 'evaluation', '§4.10', 'theory', 'learningtheoryprovidesabroadfoundationforthevarietyofcontextsencountered', 'apply', 'machine', 'learn', 'theory', 'offer', 'understand', 'principles', 'guarantee', 'complementempiricalfindings.atpresent', 'thestudyoffoundationmodelsislargelyempirical', 'thetheoryofstandardsupervisedlearning', 'whilerelativelymature', 'isinadequatetofullyexplain', 'foundationmodels.specifically', 'thediscrepancybetweenthetrainingphaseandtheadaptation', 'phasewithinthefoundationmodelregimepinpointstheinsufficiencyofexistingtheory', 'sincethese', 'phasescorrespondto', 'potentially', 'completelydifferenttasksanddatadistributions.nevertheless', 'weendeavorthatadvancesintheorytoaddressthisdiscrepancy', 'eveninsimple', 'limitedsettings', 'willprovideusefulinsights', '§4.11', 'interpretability', 'interpretability', 'provide', 'clarity', 'foundation', 'model', 'opacity', 'thedeepneuralnetworksthatunderpinfoundationmodels', 'alongsidetheexpectedubiquityof', 'foundationmodels', 'heightenstheneedtounderstandthesemodelsandtheircapabilities.inter-', 'pretabilitymethodsatpresentgenerallyaredesignedforinterpretingandexplainingthebehavior', 'oftask-specificmodels', 'thenatureoffoundationmodels', 'i.e.', 'thewidearrayoftasksthesemodels', 'arebeneficialforandtheunexpectedemergentpropertiestheyacquire', 'introducesnewchallenges', 'forinterpretabilityresearch.toframethediscussionofinterpretabilityforfoundationmodels']",18
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '19', 'proposetheonemodel-manymodelsparadigm', 'whichaimstodeterminetheextenttowhichtheone', 'model', 'thefoundationmodel', 'anditsmanymodels', 'itsadaptedderivatives', 'sharedecision-making', 'buildingblocks.inadditiontointerpretingthedecision-makingcomponentsinvolved', 'wefurther', 'discussexplainabilityinthecontextoffoundationmodels', 'e.g.', 'thevalidityofposthocexplanations', 'generatedbymodels', 'aswellasthemechanisms', 'thatdrivemodelbehavior', 'whichmayclarify', 'theextenttowhichunderstandingfoundationmodelscanextendtounderstandingtheiradapted', 'derivatives', '.giventhecriticalroleweascribeinterpretabilityinthestudyoffoundationmodels', 'weconcludewithanassessmentofthesocietalimpactofinterpretabilityandnon-interpretability', '1.4.4', 'overviewofsociety', 'webelievetherapiddevelopmentoffoundationmodels', 'adaptedanddeployedtovariousapplica-', 'tions', 'willhavewide-rangingconsequencesonthehealthofsocieties.whatmakesthesemodelsso', 'excitingandalsosotroublingistheirtaskagnosticity.societalimpactiseasier', 'butstillnon-trivial', 'tounderstandandreasonaboutwhenwetalkaboutspecificsystemsdeployedtousers', 'buthow', 'canwetakeintoaccountthesocietalimpactofallpossiblesystemsandusecaseswhendeveloping', 'foundationmodels', '?', '§5.1', 'inequityandfairness', 'inmanycontexts', 'machinelearninghasbeenshowntocontribute', 'andpotentiallyamplify', 'societalinequity.foundationmodelsmayextendthistrend', 'i.e.', 'fur-', 'theringtheunjusttreatmentofpeoplewhohavebeenhistoricallydiscriminatedagainst.however', 'understandingtherelationshipbetweeninequityandfoundationmodelsrequiresreckoningwith', 'theabstractionoffoundationmodels', 'foundationmodelsareintermediaryassetsthatareadapted', 'forapplicationsthatimpactusers.therefore', 'wedelineateintrinsicbiases', 'i.e.', 'propertiesinfounda-', 'tionmodelsthatportendharm', 'andextrinsicharms', 'i.e.', 'harmsarisinginthecontextofspecific', 'applicationsbuiltusingfoundationmodels.wetaxonomizevarioussources', 'e.g.', 'trainingdata', 'lack', 'ofdiversityamongfoundationmodeldevelopers', 'thebroadersociotechnicalcontext', 'thatgiverise', 'tothesebiasesandharms', 'emphasizingtheimportance', 'andtechnicaldifficulty', 'ofsourcetracingto', 'understandethicalandlegalresponsibility.wedonotviewunfairnessasinevitableinthefounda-', 'tionmodelparadigm', 'toaddressunfairoutcomesthatarisefromfoundationmodels', 'wedually', 'considerproactiveinterventions', 'e.g.', 'technicalmethodslikecounterfactualdataaugmentation', 'andreactiverecourse', 'e.g.', 'mechanismsforfeedbackpropagationandattributionofmoral/legal', 'responsibility', '§5.2', 'misuse', 'wedefinefoundationmodelmisuseastheuseoffoundationmodelsastheyare', 'technicallyintended', 'e.g.', 'togeneratelanguageorvideo', 'butwiththegoalofcausingsocietalharm', 'e.g.', 'togeneratedisinformation', 'todevelopdeepfakesforharassment', '.wearguethatadvancesin', 'foundationmodelswillresultinhigher-qualitymachine-generatedcontentthatwillbeeasierto', 'createandpersonalizeformisusepurposes.forexample', 'disinformationactorsmayusethemto', 'quicklygeneratecollectionsofarticlestargetedacrossdifferentdemographicgroups', 'e.g.', 'national-', 'ity', 'politicalparty', 'religion', 'etc', '.whilethesenewcapabilitiesmaylimitexistinghumandetection', 'methodsforharmfulcontent', 'e.g.', 'trackingsimilartextacrossdifferentsources', 'foundationmodels', 'maythemselvesprovidepromisingpotentialasautomatedmisusedetectors', '§5.3', 'environment', 'foundationmodelsarethebyproductsofcomputationallyexpensivetraining', 'regimes', 'withtheexistingtrajectoryfavoringevenmoreintensivemodels', 'theenergyrequiredfor', 'thistrainingcoincideswiththereleaseofmorecarbonintotheatmosphereandthedegradationof', 'theenvironment.atpresent', 'currentdiscussioncenterstheseenormoussingle-timetrainingcosts', 'andthepotentialtoamortizethesecostsacrossrepeateduse.weseektoclarifythesediscussions', 'byidentifyingassumptionsthatshapethecalculusofenvironmentalimpactforfoundationmodels']",19
Opportunities and Risks of Foundational Models - Stanford.pdf,"['20', 'centerforresearchonfoundationmodels', 'crfm', 'weenvisionthattheecosystemsurroundingfoundationmodelsrequiresamulti-faceted', 'approach', 'compute-efficient', 'model', 'hardware', 'energy', 'grids', 'may', 'mitigate', 'carbonburdenofthesemodels', 'b', 'environmentalcostshouldbeaclearfactorthatinformshow', 'foundationmodelsareevaluated', '§4.4', 'evaluation', 'suchthatfoundationmodelscanbemore', 'comprehensivelyjuxtaposedwithmoreenvironment-friendlybaselines', 'c', 'thecost-benefit', 'analysissurroundingenvironmentalimpactnecessitatesgreaterdocumentationandmeasurement', 'acrossthecommunity', '§5.4', 'legality', 'foundationmodelsrestontenuouslegalfootingsatpresent', 'howthelawbearson', 'boththedevelopmentanduseofthesemodelsislargelyunclear.legalandregulatoryframeworks', 'foundation', 'model', 'specifically', 'alongside', 'ai', 'technology', 'generally', 'neededtoinfluence', 'constrain', 'andevenfosterpracticesinresearch', 'development', 'anddeployment', 'centeringonthelegallandscapeoftheunitedstates', 'whereexistingconsiderationofalgorithmic', 'toolsremainsbroadlyuncertain', 'wehighlightthepertinentissuesofliabilityformodelpredictions', 'andprotectionsfrommodelbehavior.withrespecttobothissues', 'wedescribehowlegalstandards', 'willneedtobeadvancedtoaddressthesegiventheintermediarystatusoffoundationmodels', 'opposedtothatofuser-facingtask-specificmodels', '§5.5', 'economics', 'foundationmodelsarelikelytohavesubstantialeconomicimpactduetotheir', 'novelcapabilitiesandpotentialapplicationsinawidevarietyofindustriesandoccupations.we', 'considertheimplicationsofthedevelopmentanduseoffoundationmodelsforthefutureoftheus', 'andglobaleconomywithafocusonproductivity', 'wageinequality', 'andconcentrationofownership', '§5.6', 'ethics', 'scale', 'addition', 'run', 'risk', 'increase', 'inequity', 'discuss', '§5.1', 'fairness', 'thewidespreadadoptionoffoundationmodelsposesotherethical', 'politicaland', 'socialconcerns.wediscussethicalissuesrelatedtothescaleofapplicationoffoundationmodels', 'suchashomogenizationandtheconcentrationofpower', 'aswellasthenormsandreleasestrategies', 'appropriatetoaddressthem']",20
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '21', '2', 'capabilities', 'foundationmodelsacquirecapabilities', 'somethatsurprisinglyemergefromtheirlearningprocess', 'power', 'downstream', 'applications', '§3', 'applications', 'reason', 'capabilities', 'offoundationmodelsinfluencethediscussionofcreatingaisystemswithcertainfundamental', 'capabilities.specifically', 'wediscusslinguistic', '§2.1', 'language', 'andvisual', '§2.2', 'vision', 'capabilities', 'alongsidetheabilitytoaffectthephysicalworld', '§2.3', 'robotics', 'performreasoningandsearch', '§2.4', 'reason', 'andinteractwithhumans', '§2.5', 'interaction', '.inaddition', 'wediscusshowself-', 'supervision', 'thetechnicalapproachusedtolearnmostcurrentfoundationmodels', 'philosophically', 'relatestotheabilitytounderstand', '§2.6', 'philosophy']",21
Opportunities and Risks of Foundational Models - Stanford.pdf,"['22', 'centerforresearchonfoundationmodels', 'crfm', '2.1', 'language', 'author', 'isabelpapadimitriou', 'christopherd.manning', '2.1.1', 'thenatureofhumanlanguage', 'languageisthebasisofmosthumancommunicationandinteraction.however', 'itisnotjusta', 'meansforhumanstoachievesharedgoals', 'languageiscentraltohumanthought', 'tohowsocial', 'emotional', 'relations', 'form', 'identify', 'socially', 'personally', 'tohowhumansrecordknowledgeanddevelopsocietalintelligence.spokenorsignedlanguages', 'ariseineveryhumansociety', 'andthelanguagesoftheworldarebothincrediblydiverseinthe', 'waysthattheyexpressandstructuretheinformationtheyconvey', 'whilealsoexhibitingsurprising', 'concordanceintherichnessofwhatmakesalanguage', '[', 'comrie1989', ']', '.languagesareremarkably', 'complexyetefficientsystems', 'acquiredconsistentlybychildreninashortamountoftime', 'whichevolveandencompassthechangingneedsandconditionsoflinguisticcommunities.dueto', 'thiscentralityoflanguageinhumanactivities', 'languageunderstandingandgenerationisacritical', 'elementofresearchinartificialintelligence.naturallanguageprocessing', 'nlp', 'isthesubfieldof', 'artificialintelligenceconcernedwithlanguageand', 'togetherwiththerelatedfieldsofautomatic', 'speechrecognition', 'asr', 'andtext-to-speech', 'tts', 'hasthegoalofgivingcomputerstheabilityto', 'understandandgeneratehumanlanguageinmuchthesamewayhumanbeingscan', 'todatein2021', 'nlphasbeenthefieldmostprofoundlyaffectedbyfoundationmodels.thefirst', 'generationoffoundationmodelsshowcasedanimpressivevarietyoflinguisticabilities', 'aswellas', 'asurprisingamountofadaptabilitytoalargerangeoflinguisticsituations.sincetheintroduction', 'oftheearlyfoundationmodelselmo', '[', 'petersetal.2018', ']', 'andbert', '[', 'devlinetal.2019', ']', 'in2018', 'fieldofnlphasbecomelargelycenteredaroundusingandunderstandingfoundationmodels.the', 'fieldhasshiftedtousingfoundationmodelsastheprimarytool', 'movingtowardsmoregeneralized', 'languagelearningasacentralapproachandgoal.inthissection', 'wegoovertherecentsuccesses', 'offoundationmodelsinnlp', 'detailhowfoundationmodelshavechangedtheoverallprocessand', 'mentalityfortrainingmachinelearningmodelsforlanguage', 'anddiscusssomeofthetheoretical', 'andpracticalchallengesfacingfoundationmodelsastheyarebeingappliedtoabroadersetof', 'languagesandmorerealisticandcomplexlinguisticsituations', '2.1.2', 'impactoffoundationmodelsonnlp', 'foundationmodelshavehadahugeimpactonthefieldofnlp', 'andarenowcentraltomostnlp', 'systemsandresearch.onafirstlevel', 'manyfoundationmodelsareskilledlanguagegenerators', 'example', 'clarketal', '[', '2021', ']', 'demonstratethatnon-expertshavedifficultydistinguishingshort-form', 'englishtextthat', 'waswrittenbygpt-3fromthatwrittenbyhumans', 'however', 'thefeatureof', 'foundationmodelsthathasbeenmostimpactfulinnlpisnottheirrawgenerationabilitiesbut', 'theirsurprisinggeneralityandadaptability', 'asinglefoundationmodelcanbeadaptedindifferent', 'waysinordertosolvemanylinguistictasks', 'thefieldofnlphashistoricallyfocusedoncreatingandsolvingchallenginglinguistictasks', 'thevisionthatbuildingmodelsthatsolvethesetaskswillleadtocompetentlanguagesystemsfor', 'downstreamapplications.nlptasksincludeclassificationtasksforawholesentenceordocument', 'e.g.', 'sentiment', 'classification', 'like', 'predict', 'whether', 'movie', 'positive', 'negative', 'sequence', 'label', 'task', 'classify', 'word', 'phrase', 'sentence', 'document', 'e.g.', 'predictingifeachwordisaverboranoun', 'orwhichspansofwordsrefertoapersonor', 'organization', 'span', 'relation', 'classification', 'e.g.', 'relation', 'extraction', 'parse', 'like', 'whether', 'person', 'location', 'link', '“', 'current', 'residence', '”', 'relation', 'verb', 'noun', '“', 'subject-verb', '”', 'relation', 'andgenerationtasks', 'producingnewtextthatisconditionedstronglyon']",22
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '23', 'fig.5', 'thereareover6,000languagesintheworld', 'thoughestimatesvaryduetotheinherentuncertaintyof', 'whatconstitutesaseparatelanguage', '[', 'nordhoffandhammarström2011', ']', '.thismapshowsthelanguagesof', 'theworld', 'witheachdotrepresentingonelanguageandcolorindicatingthetop-levellanguagefamilyfor', 'eachlanguage.dataisfromglottolog', '[', 'hammarströmetal.2021', ']', '.welabelafewofthelanguagesonthe', 'mapasexamples.onlyatinypercentageoftheworld', '’', 'slanguagesarecurrentlyrepresentedinfoundation', 'model', 'aninput', 'e.g.', 'producingatranslationorsummaryofatext', 'recognizingorproducingspeech', 'respondinginaconversation', '[', 'jurafskyandmartin2009', ']', '.inthepast', 'nlptaskshaddistinctresearch', 'communitiesthatdevelopedtask-specificarchitectures', 'oftenbasedonpipelinesofdifferentmodels', 'eachperformingalinguisticsub-tasksuchastokensegmentation', 'syntacticparsing', 'orcoreference', 'resolution', 'bycontrast', 'thedominantmodernapproachforperformingeachtaskistouseasinglefoundation', 'modelandadaptitslightlyusingrelativelysmallamountsofannotateddataspecifictoeachtask', 'sentimentclassification', 'namedentitytagging', 'translation', 'summarization', 'tocreateanadapted', 'model', 'see§4.3', 'adaptationforadetailedviewofadaptation', '.thishasprovedtobeanextremely', 'successfulapproach', 'forthevastmajorityofthetasksdescribedabove', 'afoundationmodelthatis', 'slightlyadaptedforataskgreatlyoutperformspreviousmodelsorpipelinesofmodelsthatwere', 'builtspecificallytosolvethatonetask.totakejustoneexample', 'thebestsystemforanswering', 'open-endedsciencequestionsin2018', 'beforefoundationmodels', 'couldget73.1', '%', 'onthenyregents', '8thgradescienceexam.ayearlaterin2019', 'anadaptedfoundationmodelscored91.6', '%', '[', 'clark', 'etal.2019', ']', 'theemergenceoffoundationmodelsthatarelargelytrainedtogeneratelanguagehasconstituted', 'animportantshiftintheroleoflanguagegenerationinnlp.untilaround2018', 'theproblemof', 'generatinggeneral-purposelanguagewasconsideredverydifficultandessentiallyunapproachable', 'except', 'linguistic', 'sub-tasks', '[', 'paris', 'et', 'al', '2013', ']', 'instead', 'nlp', 'research', 'mostly', 'focus', 'linguistically', 'analyze', 'understand', 'text', 'possible', 'train', 'highly', 'coherentfoundationmodelswithasimplelanguagegenerationobjective', 'like', '“', 'predictthenext', 'wordinthissentence', '”', '.thesegenerativemodelsnowconstitutetheprimaryvehiclethroughwhich']",23
Opportunities and Risks of Foundational Models - Stanford.pdf,"['24', 'centerforresearchonfoundationmodels', 'crfm', 'machinelearningforlanguageisdone—includingtheanalysisandunderstandingtasksthatwere', 'onceconsideredprerequisitesforgeneration.thesuccessfulgenerationexhibitedbyfoundation', 'modelshasalsoledtoafloweringofresearchforlanguagegenerationtaskslikesummarization', 'anddialoguegeneration.theriseofthefoundationmodelparadigmhasbeguntoplayasimilar', 'roleinspokenlanguageaswellaswritten.modernautomaticspeechrecognition', 'asr', 'model', 'likewav2vec2.0aretrainedonlargedatasetsofspeechaudioalone', 'andthenadaptedonaudio', 'withassociatedtranscriptionsforthetaskofasr', '[', 'baevskietal.2020', ']', 'duetothechangesbroughtaboutbythefoundationmodelparadigm', 'thefocusofresearchand', 'practiceinnlphasshiftedfrommakingbespokearchitecturesfordifferenttaskstoexploring', 'howtobestleveragefoundationmodels.researchintoadaptationmethodshasblossomed', 'see', '§4.3', 'adaptationforadetailedlookatadaptation', 'andthesurprisingsuccessesoffoundation', 'modelshavealsocausedashiftinresearchinteresttowardsanalyzingandunderstandingfoundation', 'model', 'see§4.11', 'interpretabilityforinterpretabilityandanalysisoffoundationmodels', '2.1.3', 'languagevariationandmultilinguality', 'thoughfoundationmodelsaresurprisinglyversatilewiththelinguisticknowledgetheyobtainfrom', 'pretraining', 'therearelimitstothisadaptability', 'itisnotclearhowsuccessfullycurrentfoundation', 'model', 'handle', 'language', 'variation', 'language', 'vary', 'greatly', 'apart', 'fact', 'thousandsofdifferentlanguagesintheworld', 'languagevariesevenwithinonelanguageorwithin', 'onespeaker.topointoutafewexamples', 'informalconversationmanifestsdifferentlyfromwritten', 'language', 'thegrammaticalconstructionsthatpeoplereachforwhenspeakingtofriendsarevery', 'differentfromthoseusedwhenspeakingtosomeonewithauthority', 'andcommunitiesofspeakers', 'withinalanguageusedifferentdialects.socialandpoliticalfactorsareembeddedinhowlanguage', 'variationisviewedandvalued', 'andinhowmuchdifferentvarietiesarerepresentedinnlpresearch', 'seeforexampleblodgettando', '’', 'connor', '[', ']', 'onthefailuresofnlpforafricanamericanenglish', 'and§5.1', 'fairnessforadeeperdiscussiononinequitiesinfoundationmodels', '.duetotheirlarge', 'capacity', 'learn', 'linguistic', 'information', 'flexibly', 'adapt', 'knowledge', 'foundation', 'modelsholdpromiseforexpandingnlptoencompassmorelinguisticdiversity.itremainsanopen', 'researchquestiontounderstandwhetheritispossibletomakefoundationmodelsthatrobustlyand', 'equitablyrepresentlanguagewithbothitsmajorandsubtlevariations', 'givingequalweightand', 'acuitytowhatmakeseachlinguisticvarietydistinct', '[', 'researchposingandaddressingthisquestion', 'includespontietal.2019', 'bender2011', 'joshietal.2020', ']', 'followingthesuccessoffoundationmodelsinenglish', 'multilingualfoundationmodelshave', 'beenreleasedtoextendthatsuccesstonon-englishlanguages.formostoftheover6,000languages', 'intheworld', 'thetextdataavailableisnotenoughtotrainalarge-scalefoundationmodelwith', 'give', 'one', 'example', '65', 'million', 'speakers', 'fula', 'west', 'african', 'language', 'fewifanyresourcesavailablefornlpinfula', '[', 'ngueretal.2020', ']', '.multilingualfoundationmodels', 'address', 'jointly', 'train', 'multiple', 'languages', 'time', 'multilingual', 'foundationmodelstodate', 'mbert', 'mt5', 'xlm-r', 'areeachtrainedonaround100languages', '[', 'devlin', 'etal.2019', 'goyaletal.2021', 'xueetal.2020', ']', '.jointmultilingualtrainingreliesonthereasonable', 'assumptionthatthesharedstructuresandpatternsbetweenlanguagescanleadtosharingand', 'transferfromthehigh-resourcelanguagestothelow-resourceones', 'makingfoundationmodels', 'possible', 'languages', 'could', 'train', 'stand-alone', 'model', 'experiment', 'use', 'analyzingmultilingualfoundationmodelshaveshownthatthereisindeedasurprisingamount', 'oftransferbetweenandparallelencodingofthedifferentlanguagesinmultilingualfoundation', 'model', '[', 'wuanddredze2019', 'choenniandshutova2020', 'piresetal.2019', 'libovicky', 'etal.2019', 'chietal.2020', 'papadimitriouetal.2021', 'caoetal.2019', ']']",24
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '25', 'however', 'theextenttowhichthesemodelsarerobustlymultilingualisstillanopenquestion.it', 'remainsunclearhowmuchmodelstrainedonthisdatacanrepresentaspectsofotherlanguages', 'thataredrasticallydifferent', 'fromenglish', 'orif', 'theirapparentmultilingual', 'performancerelies', 'moreonassimilation', '[', 'lauscheretal.2020', 'virtanenetal.2019', 'artetxeetal.2020', ']', '.multilingual', 'modelsshowbetterperformanceinlanguagesthataresimilartothehighest-resourcelanguages', 'intheirtrainingdata', 'andithasbeenshownthatlanguagesinmultilingualmodelscompetefor', 'modelparameters', 'makingitunclearhowmuchvariationcanfitinasinglemodel', '[', 'wangetal', '2020d', ']', '.asalientissuestemsfromthedatathatweusetotrainmultilingualfoundationmodels', 'manymultilingualcorpora', 'englishdataisnotonlyordersofmagnitudemoreabundantthanthat', 'oflower-resourcelanguages', 'butitisoftencleaner', 'broader', 'andcontainsexamplesshowcasing', 'morelinguisticdepthandcomplexity', '[', 'caswelletal.2021', ']', 'seenekotoetal', '[', '2020', ']', 'onbuilding', 'participatoryandrobustmultilingualdatasets', '.however', 'theanswerdoesnotsimplylieincreating', 'morebalancedcorpora', 'therearesomanyaxesoflanguagevariationthatitwouldbeinfeasibleto', 'createacorpusthatisbalancedandrepresentativeinallregards.thefuture', 'versatility', 'andequity', 'offoundationmodelsalldependonrobustlyhandlinglanguagevariationdespiteunbalanceddata', '[', 'e.g.', 'orenetal.2019', ']', 'currentmultilingualfoundationmodelsintheirrawform', 'andnaiveunsupervisedmultilingual', 'trainingasamethod', 'maynotdeeplymodelthesubtletiesoflanguagesandlanguagevarietiesto', 'theirfullextent.nevertheless', 'theyremainusefulforsomemultilingualapplications', 'forexample', 'throughadaptingmultilingualmodelsforlow-resourcelanguagesnotintheiroriginaltrainingset', '[', 'wangetal.2020b', ']', '.theresearchcommunityshouldcriticallyexaminehowfoundationmodels', 'dealwithlanguagevariation', 'understandthelimitsoffoundationmodelsinbringingequityand', 'representationtonlp', 'andnotsettleonpromotingfoundationmodelsthateraselanguagevariation', 'andmostlyconformtothelinguisticmajorityintheirtrainingdata', '2.1.4', 'inspirationfromhumanlanguageacquisition', 'thoughfoundationmodelshaveconstitutedahugesourceofprogressincreatingnlpsystems', 'thatactmorelikehumans', 'therearestillsignificantwaysinwhichthelinguisticsystemthatthey', 'acquire', 'aswellasthelearningprocess', 'differfromhumanlanguage.understandingtheimplications', 'ofthisgapbetweenmachineandhumanlanguagelearningisanecessarypartofdevelopinga', 'researchcommunityinformedaboutthelinguisticlimitsandpossibilitiesoffoundationmodels', 'humanlanguageacquisitionisveryefficient', 'foundationmodelslikegpt-3aretrainedonaround', 'threetofourordersofmagnitudemorelanguagedatathanmosthumanswilleverhearorread', 'certainlymuchmorethanchildrenhavebeenexposedtobythetimetheyaremostlylinguistically', 'competent.onesalientdifferencebetweenfoundationmodelsandhumanlanguageacquisition', 'isthathumanlanguageisgroundedtotherealworld.forexamplebabiesandcaretakerspoint', 'toobjectsduringlanguagedevelopment', '[', 'colonnesietal.2010', ']', 'andbabieslearnthegrounded', 'meaningsofwordsthatrefertocommonobjectsbeforetheylearnalotoftheotheraspectsof', 'thelinguisticsystem', '[', 'bergelsonandswingley2012', ']', '.mostfoundationmodelsusedinnlp', 'onthe', 'otherhand', 'learnfromthedistributionalinformationofraw', 'ungroundedtext', 'incontrast', 'human', 'learners', 'zhang', 'et', 'al', '[', '2021', ']', 'show', 'roberta', 'model', 'express', 'abstract', 'syntactic', 'featuresbeforeusablemeaning.powerfulungroundedstatisticallearningisindeedalsopresent', 'inbabies', '[', 'saffranetal.1996', ']', 'soitisnodoubtanimportantfactorinacquisition.nevertheless', 'advancinggroundedlanguagelearningforfoundationmodelsremainsanimportantdirectionfor', 'approachinghumanacquisitionefficiency', '[', 'dupoux2018', 'tanandbansal2020', 'zellersetal.2021a', 'interalia', ']', 'see§2.2', 'visionand§2.3', 'roboticsforthemultimodalpotentialoffoundationmodels', 'and§2.6', 'philosophyforadiscussionofwhetherfoundationmodelscanunderstandlanguage', 'withoutgrounding', '.anotherimportantdirectionisexaminingtheinductivebiasesinfoundation']",25
Opportunities and Risks of Foundational Models - Stanford.pdf,"['26', 'centerforresearchonfoundationmodels', 'crfm', 'fig.6', 'languageacquisitionforhumansandfoundationmodels.whiletherearecertainlydifferentinductive', 'biasesbetweenthehumanbrainandfoundationmodels', 'thewaysthattheylearnlanguageisalsovery', 'different.mostsaliently', 'humansinteractwithaphysicalandsocialworldinwhichtheyhavevariedneeds', 'anddesires', 'whilefoundationmodelsmostlyobserveandmodeldataproducedbyothers', 'model', 'relate', 'inductive', 'bias', 'human', 'mind', 'specific', 'languagelearningandthosegeneraltohumancognition', '[', 'linzenandbaroni2021', ']', '.thoughthe', 'humanbrainmaybemorearchitecturallyspecializedforefficientlanguageacquisition', 'foundation', 'modelsarenotblank-slatelearners', '[', 'baroni2021', ']', 'andunderstandingandaligningtheselinguistic', 'inductivebiasesisanimportantfuturedirectionforresearchinfoundationmodels', 'asignificantfactorintheefficiencyoflanguageacquisitionisthefactthathumansacquirea', 'systematicandgeneralizablelanguagesystem.thoughtherearemanydifferingtheoriesaboutwhat', 'typesoftheoreticalabstractionsthehumanlanguagesystemmakes', '[', 'e.g.', 'comrie1989', 'chomsky', '2014', 'croft2001', 'jackendoff2011', ']', 'itisgenerallyagreedthathumanslearnlanguageinawaythat', 'allowsthemtoeasilyslotnewknowledgeintoexistingabstractions', 'andproductivelycreatenew', 'grammaticalsentences.forexample', 'aten-year-oldchildhasacquiredalotoftheabstractions', 'abouthowtheirlanguageworks', 'thoughtheactualwordsandconstructionsthattheyproduce', 'willchangedrasticallyoverthenexttenyears.foundationmodels', 'ontheotherhand', 'oftendonot', 'acquirethesystematicabstractionsthatweexpectfromhumans.forexample', 'whenafoundation', 'modelproducesalinguisticconstructionaccuratelyonetimethereisnoguaranteethatfuture', 'usesofthatconstructionwillbemostlyconsistent', 'especiallyafterasignificantdomainshiftin', 'thesubjectmatter', '[', 'examplesofworkexamininglimitationsoffoundationmodelsinsystematicity', 'includelakeandbaroni2018', 'kimandlinzen2020', 'bahdanauetal.2018', 'chaabounietal.2021', ']', 'nlpfacesthechallengeofdevelopingsomesortofsystematicityinacquisitionforfoundation', 'model', 'withoutregressingtosystemsthatrelytooheavilyonrigidlinguisticrules', 'languagelearningcontinuesforaspeaker', '’', 'swholelifetime', 'thegrammarofhumanlanguages', 'evolve', 'andhumansflexiblyadapttonovellinguisticsituations', '[', 'sankoff2018', ']', '.forexample', 'newtermsandconceptsariseinanadult', '’', 'slifetheycanusethemrelativelyeasilyingrammatical']",26
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '27', 'sentence', 'andhumansoftenadapttheirgrammaticalpatternstofitinwithdifferentsocialgroups', '[', 'rickfordetal.1994', ']', '.ontheotherhand', 'thelinguisticsystemoffoundationmodelsismostlyset', 'bythetrainingdata', 'andisrelativelystatic', '[', 'lazaridouetal.2021', 'khandelwaletal.2020', ']', '.though', 'adaptationmethodscanprimefoundationmodelsfordifferenttasks', 'see§4.3', 'adaptation', 'itstill', 'remainsunclearhowtochangethemorebasiclinguisticfoundationofafoundationmodelwithout', 'alargeamountoftraining.makingadaptablemodelsthatnaturallymirrorhuman-likelinguistic', 'accommodationandlanguageevolutionisanimportantresearchareaforthefutureoffoundation', 'model', 'foundation', 'model', 'drastically', 'change', 'research', 'practice', 'nlp', 'complexnlptasksthattheresearchcommunityfocusedonsolvingbeforefoundationmodels', 'arenowbestsolvedtoanalmost-humanlevelusingoneofafewpublicly-releasedfoundation', 'models.yet', 'thereremainsagapbetweenthisperformanceandtheimmediateandsafeusefulness', 'offoundationmodelsincomplexdownstreamsettings.foundationmodelshavealsogivenrise', 'tomanynewresearchdirectionsforthecommunity', 'understandinggenerationasafundamental', 'aspectoflanguage', 'studyinghowtobestuseandunderstandfoundationmodels', 'understandingthe', 'waysinwhichfoundationmodelsmayincreaseinequitiesinnlp', 'examiningwhetherfoundation', 'modelscansatisfactorilyencompasslinguisticvariationanddiversity', 'andfindingwaystodrawon', 'humanlanguagelearningdynamics']",27
Opportunities and Risks of Foundational Models - Stanford.pdf,"['28', 'centerforresearchonfoundationmodels', 'crfm', '2.2', 'vision', 'author', 'shyamalbuch', 'drewa.hudson', 'friedarong', 'alextamkin', 'xikunzhang', 'bohanwu', 'ehsan', 'adeli', 'stefanoermon', 'ranjaykrishna', 'juancarlosniebles', 'jiajunwu', 'lifei-fei', 'fig.7', 'byharnessingself-supervisionatscale', 'foundationmodelsforvisionhavethepotentialtodistillraw', 'multimodalsensoryinformationintovisualknowledge', 'whichmayeffectivelysupporttraditionalperception', 'tasksandpossiblyenablenewprogressonchallenginghigher-orderskillsliketemporalandcommonsense', 'reason', '§2.2.1', 'vision-capabilities', '.theseinputscancomefromadiverserangeofdatasourcesand', 'applicationdomains', 'suggestingpromiseforapplicationsinhealthcareandembodied', 'interactiveperception', 'settings', '§2.2.2', 'vision-challenges', '.imagecredits', '[', 'zamiretal.2018', 'haqueetal.2020', ']', 'visionunderliesoneoftheprimarymodesthroughwhichalivingorganismunderstandsits', 'environment.theabilitytoseeenablesthenear-constant', 'long-rangegatheringofdensesignals', 'capabilitysoimportantthatresearchershavehypothesizedthatthedevelopmentofeyesmillions', 'ofyearsagotriggereda', '“', 'cambrianexplosion', '”', 'inevolutionfromwhichsprungmanyofthelife', 'formsweknowtoday—amongthem', '[', 'parker2003', ']', '.foraskillexecutedeffortlesslyby', 'evensimplelivingcreatures', 'transferringthesameabilitiestomachineshasprovedremarkably', 'challenge', 'leadingcomputervisionandroboticsresearcherhansmoravecin1988toobserve', 'aparadox', 'inai', 'hardproblemsareeasyandeasyproblemsarehard', 'andamongthe', '“', 'easiest', '”', 'problemsofthemallisthevisualacuitywhichweuseeachdaytocontinuallyinterpretcomplex', 'scenesinamatterofmilliseconds', '[', 'moravec1988', 'thorpeetal.1996', 'fei-feietal.2007', ']', 'ontheotherendofthisformidablechallengeisthesubstantialscopeoftransformativeappli-', 'cationswhichcomputervisionholdsthekeyto', 'self-drivingcarsthatcanfreecommutersfrom', 'gridlock', '§2.3', 'robotics', 'life-savingaitoolsthatcanassistoverworkedspecialistsbydetecting', 'raremedicalevents', '§3.1', 'healthcare', 'next-generationtoolsformultimediacreationandediting', '§2.5', 'interaction', 'among', 'others', 'reflect', 'applications', 'settings', 'human', 'perceptionisfundamentaloffersasenseofthepotentialareaswherecomputervisioncanassist', 'andtransform']",28
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '29', 'thefieldofcomputervisionandthechallengeswedefinedrawinspirationinmanywaysfrom', 'humanperceptioncapabilities.severalclassicaltheories', '[', 'e.g.', 'biederman1972', 'mcclellandand', 'rumelhart1981', 'marr1982', ']', 'suggestedthathumansmayperceiverealworldscenesbycontextual-', 'izingpartsasalargerwhole', 'andpointedthewayforcomputervisiontechniquestoprogressively', 'modelthephysicalworldwithgrowinglevelsofabstractions', '[', 'lowe1992', 'girshicketal.2014', ']', 'gibson', '[', '1979', ']', 'suggest', 'human', 'vision', 'inherently', 'embody', 'interactive', 'ecological', 'environmentsmayplayakeyroleinitsdevelopment.theseideascontinuetomotivatetheongoing', 'developmentofcomputervisionsystems', 'iteratingtowardsacontextual', 'interactive', 'andembodied', 'perceptionoftheworld', 'context', 'computer', 'vision', 'foundation', 'model', 'translate', 'raw', 'perceptual', 'information', 'fromdiversesourcesandsensorsintovisualknowledgethatmaybeadaptedtoamultitudeof', 'downstreamsettings', 'figure7', '.toalargeextent', 'thiseffortisanaturalevolutionofthekeyideas', 'thathaveemergedfromthefieldoverthelastdecade.theintroductionofimagenet', '[', 'dengetal', '2009', ']', 'andtheadventofsupervisedpretrainingledtoadeeplearningparadigmshiftincomputer', 'vision.thistransitionmarkedanewera', 'wherewemovedbeyondtheclassicapproachesand', 'task-specificfeatureengineeringofearlierdays', '[', 'lowe2004', 'bayetal.2006', 'rostenanddrummond', '2006', ']', 'towardsmodelsthatcouldbetrainedonceoverlargeamountsofdata', 'andthenadapted', 'forabroadvarietyoftasks', 'suchasimagerecognition', 'objectdetection', 'andimagesegmentation', '[', 'krizhevskyetal.2012', 'szegedyetal.2015', 'heetal.2016a', 'simonyanandzisserman2015', ']', '.this', 'idearemainsatthecoreoffoundationmodels', 'thebridgetofoundationmodelscomesfromthelimitationsofthepreviousparadigm.traditional', 'supervisedtechniquesrelyonexpensiveandcarefully-collectedlabelsandannotations', 'limit', 'theirrobustness', 'generalizationandapplicability', 'incontrast', 'recentadvancesinself-supervised', 'learn', '[', 'chen', 'et', 'al', '2020c', 'et', 'al', '2020', ']', 'suggest', 'alternative', 'route', 'development', 'offoundationmodelsthatcouldmakeuseoflargequantitiesofrawdatatoattainacontextual', 'understandingofthevisualworld.relativetothebroaderaimsofthefield', 'thecurrentcapabilitiesof', 'visionfoundationmodelsarecurrentlyearly-stage', '§2.2.1', 'vision-capabilities', 'wehaveobserved', 'improvementsintraditionalcomputervisiontasks', 'particularlywithrespecttogeneralization', 'capability', '[', 'radfordetal.2021', 'rameshetal.2021', ']', 'andanticipatethatthenear-termprogress', 'continue', 'trend', 'however', 'longer-term', 'potential', 'foundation', 'model', 'reduce', 'dependence', 'explicit', 'annotations', 'may', 'lead', 'progress', 'essential', 'cognitive', 'skills', 'e.g.', 'commonsensereasoning', 'whichhaveprovendifficultinthecurrent', 'fully-supervisedparadigm', '[', 'zellersetal.2019a', 'martin-martin', 'etal.2021', ']', '.inturn', 'wediscussthepotentialimplicationsof', 'foundationmodelsfordownstreamapplications', 'andthecentralchallengesandfrontiersthatmust', 'beaddressedmovingforward', '§2.2.2', 'vision-challenges', '2.2.1', 'keycapabilitiesandapproaches', 'atahigh-level', 'computervisionisthecoresub-fieldofartificialintelligencethatexploreswaysto', 'endowmachineswiththecapacitytointerpretandunderstandthevisualworld.itencompassesa', 'multitudeoftasks', 'sub-domainsanddownstreamapplications', 'wherethecommunityhasmade', 'continualprogressoverthelastseveraldecades', '[', 'zamiretal.2018', ']', '.aselectionofexampletasks16', '1', 'semanticunderstandingtasks', 'whichaimtodiscoverthepropertiesandrelationsamongentities', 'withinvisualscenes', 'theseincludeimageclassification', 'objectdetection', 'semanticsegmentation', 'actionrecognition', 'andscenegraphgeneration', 'amongothers', '[', 'e.g.', 'krizhevskyetal.2012', 'heetal', '2016a', 'krishnaetal.2017', 'russakovskyetal.2015', 'krizhevskyetal.2009', 'kayetal.2017', 'linetal', '2014', ']', '2', 'geometric', 'motionand3dtasks', 'seekingtorepresentthegeometry', 'poseandstructure', '16this', 'ofcourse', 'isacoarseselection', 'pleaseseethecategoriesattheannualconferenceoncomputervisionandpattern', 'recognition', 'cvpr', 'foramorecomplete', 'butevolving', 'pictureofthetasksinthefield']",29
Opportunities and Risks of Foundational Models - Stanford.pdf,"['30', 'centerforresearchonfoundationmodels', 'crfm', 'ofstillormovingobjects', 'andincludetasksofdepthestimation', 'structure-from-motion', 'surface', 'normaldetection', 'curvaturelineandkeypointestimation', 'tonameafew', '[', 'e.g.', 'lainaetal.2016', 'agarwaletal.2011', 'wangetal.2015a', 'zamiretal.2018', 'ullman1979', ']', '3', 'multimodalintegration', 'task', 'combiningsemanticandgeometricunderstandingwithothermodalitiessuchasnatural', 'language', 'theseinclude', 'forinstance', 'visualquestionanswering', 'imagecaptioning', 'andinstruction', 'follow', '[', 'e.g.', 'antoletal.2015', 'chenetal.2015b', 'andersonetal.2018', 'goyaletal.2017b', 'hudson', 'andmanning2019b', 'johnsonetal.2017', 'luoetal.2020', 'akbarietal.2021', 'huangetal.2021c', 'tsimpoukellietal.2021', ']', '.wehighlightasubsetoftraditionalcoretasksinfigure7', 'thepredominantparadigmforaddressingthesetasks', 'drivenbytheemergenceofimagenet', '[', 'dengetal.2009', ']', 'duringtheearly2010s', 'tendstocenteraroundafamiliarcoreidea', 'first', 'pretrain', 'amodelonalargecollectionofcarefullyannotateddata', '[', 'russakovskyetal.2015', ']', 'withafully', 'supervisedtrainingtask', 'likeimageclassification.then', 'adaptthemodeldownstreamontask-', 'specificdatasetsanddomains', '[', 'linetal.2014', 'chenetal.2015b', 'antoletal.2015', ']', 'byfine-tuning', 'toreachstate-of-the-artperformance', '[', 'krizhevskyetal.2012', 'simonyanandzisserman2015', 'et', 'al', '2016a', 'xu', 'saenko', ']', 'notion', 'pretraining', 'follow', 'adaptation', 'persist', 'inthedefinitionsweconsidernowforfoundationmodels', '§1', 'introduction', '.thelimitations', 'ofthisfullysupervisedparadigmmotivatethetransitiontofoundationmodels', 'therelianceon', 'externalsupervisedannotationsconstrainstheupperboundcapabilityofpreviousapproachesto', 'capturethediversespectrumofvisualinputsinascalable', 'robustandgeneralizablemanner.recent', 'developments', 'domain', 'visual', 'synthesis', 'unsupervised', 'learn', 'offer', 'compel', 'alternative.gans', 'forinstance', 'learntogeneratevisualcontentofhighfidelity', 'realismanddiversity', 'byfeaturingtwocompetingnetworksofageneratorandadiscriminatorthatcansuperviseone', 'another', 'image', 'collections', 'alone', '[', 'e.g.', 'goodfellow', 'et', 'al', '2014', 'hudson', 'zitnick', '2021', ']', 'otherneuralmodelsinferthevisualpropertiesofobjectsandsceneswithoutexplicitlyannotated', 'supervision', 'byemployingvariationalauto-encoding', 'contrastivelearningorotherself-supervised', 'techniques', '[', 'e.g.', 'kingmaandwelling2014', 'chenetal.2020c', 'heetal.2020', ']', 'withfoundationmodels', 'thedevelopmentofsuchself-supervisiontechniqueshasenabledtrain-', 'ing', 'greater', 'scale', 'visual', 'data', '[', 'changpinyo', 'et', 'al', '2021', ']', 'term', 'scopeas', 'well', 'asitspotentialdiversity.accordingly', 'wehaveseenearlyindicatorsofprogressontraditional', 'visiontasksintermsofbothstandardaccuracymetricsandfew-shotgeneralization.forimage', 'classificationandobjectdetection', 'self-supervisedtechniqueshavereportedcompetitiveperfor-', 'mancetopriorfully-supervisedapproaches', '[', 'heetal.2019', 'chenetal.2020c', 'radfordetal.2021', 'hénaff', 'et', 'al', '2021', ']', 'without', 'explicit', 'annotations', 'train', 'greater', 'sample', 'efficiency', 'duringadaptation.forvisualsynthesis', 'notableexamplesincludedall-e', '[', 'rameshetal.2021', ']', 'andclip-guidedgeneration', '[', 'radfordetal.2021', 'galatoloetal.2021', ']', 'whereresearchersleverage', 'multimodallanguageandvisioninputtorendercompellingvisualscenes.intheshort-term', 'anticipatethatthecapabilitiesofthesefoundationmodelswillcontinuetoimprovealongthese', 'directions', 'astrainingobjectivesarerefined', '[', 'chenetal.2020a', 'hénaffetal.2021', 'selvaraju', 'etal', '2021', ']', 'andarchitecturesaredesignedtoincorporateadditionalmodalities', '[', 'jaegleetal.2021b', ']', 'notably', 'currentfoundationmodelsforcomputervisionarenascentrelativetotheirnlpcoun-', 'terparts', '§2.1', 'language', 'promisingearlyeffortsarestilllargelycenteredonrgbimageinputsand', 'asubsetofcoretraditionalvisiontasks.however', 'thefieldcontinuestoprogressonbroaderchal-', 'lengescenteredonembodiedandinteractiveperceptionsettings', 'criticalforfoundationmodelsfor', 'robotics', '§2.3', 'robotics', '.wenoteasubsetofthesehigher-ordergoalsinfigure7', 'includingphysical', 'sceneunderstanding', 'reasoningovervisualcommonsenseandtemporalevents', 'andperceptionfor', 'socialaffordances.eachofthesehavebeengoalsforfully-supervisedsystems', 'buthaveproven', 'challenginginpartduetothedifficultyofannotatingthesetasksatscale.forinstance', 'standard']",30
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '31', 'systemsforvisual-questionansweringstruggletoanswerquestionsthatrequirecommonsenseun-', 'derstanding', 'sincethesequestionsoftenrequireexternalknowledgebeyondwhatispresentinthe', 'pixelsalone', '[', 'zellersetal.2019a', ']', '.perceivinghumangazeandsocialaffordancesinarobustmanner', 'remain', 'ongoing', 'challenge', 'embody', 'vision', 'systems', 'interactive', 'agents', '[', 'martin-martin', 'etal.2021', ']', '.byreducingthedependenceonexplicitannotations', 'foundationmodelsmayenable', 'furtherprogresstowardsthesegoalsthanwaspreviouslyfeasible.relatedprogressinlanguage', 'foundationmodels', '§2.1', 'language', 'whichhavebeenabletocaptureadegreeofcommonsense', 'language', 'events', '[', 'brown', 'et', 'al', '2020', ']', 'also', 'suggest', 'potential', 'avenue', 'towards', 'achieve', 'similar', 'capability', 'multimodal', 'visual', 'input', 'exact', 'roadmap', 'achieve', 'thesecapabilitiesinfoundationmodelsremainsanopenproblem', 'acombinationofnewefficient', 'architectures', '§4.1', 'model', 'large-scaletraining', '§4.5', 'systems', 'self-supervisiontechniques', '§4.2', 'train', 'andfew-shotadaptationschemes', '§4.3', 'adaptation', 'mayopenthedoortowards', 'capabilitiesthathavebeendifficulttoreachsofar', '2.2.2', 'centralresearchchallenges', 'ourdiscussionofresearchchallengesismotivatedbythedownstreamapplicationdomainswhere', 'foundationmodelsmayfurthertheintegrationandimpactofvisionmodels.wehighlightafew', 'suchareas', '1', 'ambientintelligenceforhealthcareandhomeenvironments', 'buildinguponexisting', 'approachesforambientintelligenceinthesesettings', '[', 'haqueetal.2017', 'lyytinenandyoo2002', 'hongandlanday2004', ']', 'foundationmodelsmayofferthepotentialforbetterdetectionoffine-', 'grainedhumanactivitiesandmedicalevents', 'aswellasimprovedassistiveinteractionforclinicians', 'patients', 'andeverydayconsumers', 'seealso§3.1', 'healthcare', '2', 'mobileandconsumerapplications', 'foundationmodelswithstrongermultimodalgroundingmayenablemorecapableinteractivityof', 'servicesinmobilesettings', 'andfundamentalimprovementsingenerationcapabilityfromvisionand', 'languageinputscanbenefitcomputationalphotographyandcontenteditingapplications', '[', 'delbracio', 'etal.2021', 'rameshetal.2021', 'parketal.2019', ']', 'seealso§2.5', 'interaction', '3', 'embody', 'interactive', 'agents', 'perceptionmodelshavealreadyproveneffectiveasbothinputs', '[', 'sermanetetal.2018', ']', 'rewardfunctions', '[', 'chenetal.2021c', ']', 'inroboticssettings', 'foundationmodelstrainedonlargeand/or', 'simulatedcollectionsofegocentricvisualdata', '[', 'damenetal.2018', 'chenetal.2021d', ']', 'maypotentially', 'furtherthisprogressbycapturingawiderdistributionofvisualscenes', 'object', 'andactions', 'see', 'also§2.3', 'robotics', 'theextenttowhichfoundationmodelsmayfurtherimpacttheseapplicationsettingshingeson', 'thedegreetowhichthecapabilitiesoutlinedin§2.2.1', 'vision-capabilitiesarerealized.tobridge', 'thesignificantgapsbetweenpresent', 'short-term', 'andlong-termanticipatedcapabilities', 'wemust', 'addresscurrentlimitationsoffoundationmodelsforvision', 'includingtheirtrainingandevaluation', 'asubsetofcorrespondingkeychallenges', 'semanticsystematicityandperceptualrobustness', 'humanshavearemarkablecapacityfor', 'generalizingvisualunderstandingtounseencompositions', 'andreasoningaboutthephysicaland', 'geometric', 'properties', 'novel', 'object', 'scenes', '[', 'lake', 'et', 'al', ']', 'current', 'foundation', 'modelshaveshownpromisingcapabilityforimagesynthesisandearlyresultsforgeneralizationto', 'fine-grainedlanguageinputs', 'thesemodelsstillstruggletogeneralizetocompositionsofsimple', 'shapesandcolors', '[', 'rameshetal.2021', 'radfordetal.2021', 'rong2021', ']', '.generalizabilitygoesbeyond', 'semanticsaswell', 'visualscenesandobjectshaveanaturalregularitytotheirphysicaldynamics', 'geometric', 'properties', 'foundation', 'model', 'show', 'early', 'indications', 'understand', 'sceneandobjectgeometry', '[', 'rameshetal.2021', ']', '.further', 'earlyeffortstowardsphysicalsceneand', 'geometricunderstandinginperceptionmodelsmayprovideguidanceforongoingfoundationmodel', 'development', '[', 'yietal.2019', 'bakhtinetal.2019', 'lietal.2020b', ']', '.indeed', 'thecontinuedincorporation']",31
Opportunities and Risks of Foundational Models - Stanford.pdf,"['32', 'centerforresearchonfoundationmodels', 'crfm', 'ofmultiplemodalities', 'e.g.', 'audio', 'infoundationmodelsmayprovebeneficialtowardstheseaims', '[', 'zhangetal.2017', 'gaoetal.2020b', 'jaegleetal.2021a', ']', '.however', 'thespecifictechniquestoenable', 'generalizingtheinitialobservedcapabilitiesrobustlytoawiderangeofnaturalscenesandobjects', 'atthelevelofhumansremainsanopenresearchchallengeforfoundationmodels', 'computationalefficiencyanddynamicsmodeling', 'humansaresurprisinglyefficientatpro-', 'cessingthecontinuousvisualstreamofobjects', 'scenes', 'andeventsnecessarytosupportanun-', 'derstandingofeventdynamics', '[', 'zacksetal.2001', 'tverskyandzacks2013', ']', '.foundationmodelsin', 'language', '§2.1', 'language', 'haveshowninitialstepstowardsmodelinglonger-termcoherenceof', 'events', 'theanalogousabilitytocapturelong-rangetemporalcorrelationsandcausalcoherencein', 'visualinputwouldstandtobenefitdownstreamsettingslikerobotics', '[', 'daietal.2019', 'alyamkin', 'etal.2019', 'goeletal.2020b', 'fengetal.2019', '§2.3', 'robotics', ']', '.however', 'relativetowordtoken-level', 'inputsinlanguage', 'low-levelcomputervisioninputsareextremelyhigh-dimensional', 'asingle', '1080pframecontainsover2millionpixels.inthiscontext', 'modelingtherichereventdynamicsin', 'long-rangevideosequencesseemslikeadauntingendeavor', 'especiallywithadditionalmodalities', 'e.g.', 'speech', 'opticalflow', 'etc', 'andincreasingresolutions.understandably', 'anaïveapproachto', 'fullyprocessingeveryindividualpixelislikelyprohibitive.currentvisionmodels', '[', 'e.g.', 'radford', 'etal.2021', 'sunetal.2019a', 'tanandbansal2019', 'kimetal.2021a', ']', 'oftenaddressthisbyprocessing', 'embeddingsthatsummarizeimagepatchesorevengroupsofframesaltogether', 'butthishasthe', 'potentialdrawbackoflosingfine-graineddetails', '[', 'rameshetal.2021', ']', '.inadditiontoconsiderations', 'oftherawinputspace', 'foundationmodelsforvisionmayneedtorevisitthedesignoffundamental', 'architectureprimitives', '§4.1', 'model', 'forefficientandeffectivemodeling', 'alternativesto3d', 'convolutionsmaybetteraddressitscubiccomplexity', '[', 'fan', 'etal.2020', 'sitzmannetal.2019', ']', 'particle-basedrepresentationsmayprovemoreeffectiveformodelingphysicaldynamics', '[', 'bear', 'etal.2021', ']', '.further', 'deploymentofthesevisionmodelstodownstreamapplicationsettingswill', 'alsonecessitateadvancementsinsystemsdesign', '§4.5', 'systems', '.takentogether', 'thebottleneckof', 'efficientandeffectivemodelingforlarger-scale', 'dynamicvisioninputsremainsamulti-faceted', 'researchdirectionthatmustbeaddressedgoingforward', 'train', 'environments', 'andevaluation', 'equallycriticaltorealizingthepotentialoffounda-', 'tionmodelsarethesupportingelementsfortrainingandevaluatingthem.currentfoundation', 'modelsforvisionhavelargelyfocusedonasmallsubsetofmodalitiesshowninfigure7', 'e.g.', 'datasets', 'ofrgbimagesandtext', 'sincetheseareperhapsthemostreadilyaccessible', '[', 'changpinyoetal', '2021', 'radfordetal.2021', ']', '.thismotivatesthedevelopmentanduseofadditionallarge-scaletraining', 'datasetswhichcontainadiversecollectionofinputsacrossabroadspectrumofmodalities.while', 'additionalannotationsmaynotstrictlybenecessary', 'theinputqualityimpactsthelearningeffi-', 'ciencyofthemodels', 'techniquesthatleveragefoundationmodelsofothertypes', 'e.g.', 'language', 'helpimprovequalityareapromisingrouteforward', '[', 'zellersetal.2021b', ']', '.wealsowanttoconsider', 'settingsbeyondstaticdatasets', 'classicstudieshavesuggestedthatperceptualunderstandingin', 'humansislinkedtoitsembodimentandinteractive', 'ecologicalsettings', '[', 'gibson1979', ']', '.asstepping', 'stonestowardslonger-termcapabilitiesofembodimentandinteraction', '§2.3', 'robotics', 'ongoing', 'development', 'simulation', 'environments', 'capture', 'physical', 'visual', 'ecological', 'realism', 'withmultiplemodalitiesandviewpointsmayplayanimportantroleinprovidingscalableand', 'high-fidelityvisualinputsforthisgoal', '[', 'kolveetal.2017a', 'manolissavva', 'etal.2019', 'ganetal', '2020', 'shenetal.2021a', 'srivastavaetal.2021', ']', '.finally', 'thereisthequestionofmetrics', 'howdo', 'weevaluatethefaithfulnessofgenerativefoundationmodeloutputswithrespecttosemantics', '?', 'standardmetricslikefréchetinceptiondistance', 'sufferfromknownflaws', '[', 'bińkowskietal.2018', ']', 'suchissuesparallelonesinnaturallanguageprocessing', 'e.g.', 'metricslikebleudonotcorrelate', 'withcausaljudgementsfromhumans', '.havinghumanjudgementsaspartofevaluationmaybeone']",32
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '33', 'route', 'butincurssignificantcostandmaynotbeasscalable', '[', 'zhou', 'etal.2019', 'khashabietal.2021', ']', 'theoutstandingandopenchallengessurroundingthetraining', '§4.2', 'train', 'data', '§4.6', 'data', 'andevaluation', '§4.4', 'evaluation', 'settingsforvisionfoundationmodelsareindeedquitenuanced', 'andwillbeacentralareaofresearchgoingforward', 'concludingremarks', 'inthissection', 'weexploredfoundationmodelsinthecontextofcomputer', 'vision', 'fromidentifyingrootsinpreviouscomputervisionparadigms', 'tocontextualizingitscurrent', 'andanticipatedcapabilities', 'toproposingresearchdirectionsmovingforward.weconcludewitha', 'briefdiscussionofsomebroadersocietalimplicationsoffoundationmodelsforcomputervision', 'andtheircontinueddevelopment', 'seealso§5', 'society', '.theubiquityofcamerasinoursociety', 'meansthatadvancesincomputervisiontechniqueshavegreatpotentialfordisruptiveimpact', 'carriesacorrespondingburdenofresponsibilityforcarefulconsiderationofitsrisks.thereisa', 'well-documentedhistoryoflearnedbiasincomputervisionmodels', 'resultinginloweraccuracies', 'andcorrelatederrorsforunderrepresentedgroups', 'withconsequentlyinappropriateandpremature', 'deploymenttosomereal-worldsettings', '[', 'e.g.', 'buolamwiniandgebru2018', '§5.1', 'fairness', ']', '.many', 'ofthesameunderlyingissuescontinuetopersistincurrentfoundationmodels', '[', 'agarwaletal.2021', ']', 'asdatafromadditionalsensormodalities', 'e.g.', 'wearableorambientsensors', 'figure7', 'become', 'incorporatedinthesefoundationmodels', 'concernssurroundingprivacyandsurveillancebecome', 'paramount', 'see§5.6', 'ethics', '.furthermore', 'generateddeepfakeimagesandmisinformationpose', 'greaterrisksasthesemanticandgenerativecapabilityofvisionfoundationmodelscontinuesto', 'grow', '[', 'dolhanskyetal.2020', 'rameshetal.2021', '§5.2', 'misuse', ']', '.whiletheintriguingopenchallenges', 'andopportunitiesaheadforcomputervisionandfoundationmodelsaresignificant', 'address', 'theseandrelatedrisksconcurrentlyremainsessential']",33
Opportunities and Risks of Foundational Models - Stanford.pdf,"['34', 'centerforresearchonfoundationmodels', 'crfm', '2.3', 'robotics', 'author', 'siddharthkaramcheti', 'anniechen', 'suvirmirchandani', 'surajnair', 'krishnansrinivasan', 'kylehsu', 'jeannettebohg', 'dorsasadigh', 'chelseafinn', 'fig.8', 'foundationmodelsforroboticsrequiremassivedatasetsspanningdiverseenvironmentsandbehaviors', 'simulation', 'roboticinteraction', 'videosofhumans', 'andnaturallanguagedescriptionscouldallbeusefuldata', 'sourcesforthesemodels.despitethechallengesofacquiringdata', 'foundationmodelsforroboticshave', 'tremendouspotentialforavarietyofproblemformulationsintaskspecificationandrobotlearning.image', 'credit', '[', 'finnetal.2016b', 'szotetal.2021', ']', 'alongstandingchallengeofroboticsresearchistoendowrobotswiththeabilitytohandlethe', 'myriad', 'condition', 'encounter', 'real-world', 'settings', 'section', 'discuss', 'foundationmodelscanpotentiallyhelpbringabout', '“', 'generalist', '”', 'robotsthatcan', 'forexample', 'cook', 'anewmealinanewhouse', 'withanewkitchen.wefocusontheapplicationoffoundationmodels', 'tothechallengesofphysicalembodiment', '—anaxisthatpresentsastarkcontrastfromproblems', 'traditionallystudiedinlanguageandcomputervision', 'wheresuchmodelshavealreadyseensuccess', 'thepromiseoffoundationmodelsforroboticsisintheirabilitytoamplifythepotentialrobots', 'toimprovekeyfacetsofdailyliferangingfrommanufacturing', '[', 'nof1999', 'sannemanetal.2020', ']', 'construction', '[', 'khoshnevis2004', 'bock2007', ']', 'autonomousdriving', '[', 'thorpeetal.1988', 'badueetal', '2020', ']', 'household', 'aid', '[', 'thrun', 'mitchell', '1995', 'brook', '2002', 'dillmann', '2004', 'goodrich', 'schultz2007', 'guptaetal.2018', 'shridharetal.2020', ']', 'andpersonalassistance', '[', 'draganandsrinivasa', '2013', 'javdani', 'et', 'al', ']', 'amongst', 'others', 'discussion', 'section', 'primarily', 'focus', 'mobilemanipulationrobotsforhouseholdtasks', 'butweexpectitsessencetobebroadlyapplicable', 'totheotheruse-casesofroboticslistedabove', 'onthecriticalpathtowardsfoundationmodelsforroboticsisembracingopportunitiesintask', 'specificationandtasklearning', 'coupledwithtacklingchallengesindataacquisitionandsafetyand', 'robustness.considerthefollowingrobotlearningparadigm', 'startingwithadescriptionofatask', 'capturingwhatausermightliketherobottodo', 'e.g.', '“', 'makebreakfast', '”', '—learnacorresponding', 'policytogeneratethedesiredrobotactions.whilepoliciescanbeparameterizedindifferentways', 'commonchoiceisthatofafunctionthatmapsthetaskrepresentationandenvironmentobservation', 'e.g.', 'asceneimagefromafixedoregocentriccamera', 'orinputsfromalternativesensorslikelidar', 'torobotactions', '[', 'andrychowiczetal.2017', 'nairetal.2018', ']', '.astherobotactsinatask-conditioned', 'manner', 'thesubsequentstatesarefedbacktothepolicy', 'generatingmoreactionsuntilthetaskhas', 'beensatisfied']",34
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '35', 'yet', 'implementingsuchaparadigminpracticeisdifficult.tobegin', 'whatistherightinterface', 'fordescribingone', '’', 'sgoals', '?', 'foragivenuserinonecontext', '“', 'makebreakfast', '”', 'carriesanimplication', 'ofafullbreakfastthatconsistsoffriedeggs', 'toast', 'andaglassoforangejuice', 'foranotheruser', '“', 'makebreakfast', '”', 'mayimplyidliswithsambarandatumbleroffiltercoffee.ingeneral', 'high-level', 'context-dependentgoalslikethesedonotstandaloneandcanintroduceamultitudeofambiguities', 'howdoesonespecify', 'agoal', 'andcorrespondingsubgoals', 'withenoughclaritytobothresolve', 'theseambiguities', 'andinsodoing', 'allowarobottomakeprogressonthegiventask', '?', 'additionally', 'howmightwecraftgeneraltaskrepresentationsthatmightaidgeneralizationtosimilarobjectives', 'e.g.', 'fetchingaglassofmilkinsteadoforangejuice', '.goingastepfurther', 'howdowebuildmethods', 'thataidrobotsinlearningpoliciesfornewtasksandnewenvironments', 'inthiscase', 'abrandnew', 'kitchenwithnewutensils', 'appliances', 'layouts', 'etc.', '?', 'recentbreakthroughsinapplyingfoundationmodelsforlanguageandvision', '§2.1', 'language', 'and§2.2', 'vision', 'suggestseveralpotentialbenefitsthesemodelshaveforimprovinggeneralization', 'theabilitytotapintodiversestreamsofdatatolearnmeaningfulrepresentationalpriors', 'akinto', 'thoselearnedbymodelssuchasbertandgpt-3', 'holdspromiseforlearningpowerfulfoundation', 'model', 'task', 'specification', 'one', 'could', 'also', 'use', 'data', 'follow', 'work', 'computer', 'vision', 'andvideo-processing', 'tobootstrappowerfulfoundationmodelsforlearningaction-conditional', 'dynamicsmodelsorpoliciesindexinggeneralandsemanticallymeaningfulskills.yetwhilethese', 'opportunities', 'exist', 'key', 'stumble', 'block', 'collect', 'right', 'data', 'unlike', 'language', 'visiondata', 'roboticsdataisneitherplentifulnorrepresentativeofasufficientlydiversearrayof', 'embodiments', 'task', 'andenvironments—we', 'asafield', 'stillhavenotconvergedonthetypeofdata', 'thatwouldbemaximallyusefulforenablinggeneralistrobotics', 'e.g.', 'offlinedemonstrations', 'third-', 'personrecordingsofhumans', 'egocentricvideos', 'autonomousexperience', 'etc', 'coupledwithissues', 'inobtainingtherightscaleanddiversityofdataarequestionsofensuringsafetyandrobustness', 'howdowebehaveinanewenvironmentwithoutcausingdamage', '?', 'theapplicationoffoundationmodelsforroboticsthusconsistsofadichotomyofopportunities', 'andchallenges', 'opportunitiesfortaskspecificationandlearningbalancedagainstchallengesof', 'datacollectionandsafedeployment.thissectionexploresbothbypresentingapictureofhow', 'foundationmodelsmighthelpusdevelopgeneralistrobots', 'inawaythatnotonlymeaningfully', 'addressesthechallengesassociatedwithbuildingsuchsystems', 'butthatalsoembracesthepotential', 'ofmulti-modality—incorporatingperception', 'actuation', 'andlanguage—aswellashuman-robot', 'interactionforspecificationandlearning', '2.3.1', 'opportunities', 'foundationmodelsforroboticscouldtakeavarietyofforms', 'problemsinroboticsdonoteasily', 'conformtoaone-size-fits-allmodel', 'sincedifferentproblemshavedifferentinput-outputsigna-', 'tures—acontrasttodomainslikenlpwheremanyproblemscanbecastintoageneral', '“', 'text-in', 'text-out', '”', 'signature.wefocusonopportunitiesingeneralizabletaskspecificationandlearning', 'acrosstasks', 'environments', 'androbotembodiments', 'foundation', 'model', 'task', 'specification', 'robots', 'learn', 'solve', 'task', 'generalpurposeway', 'theymustunderstandwhat', 'thedesiredtaskis', 'forexample', 'tobeuseful', 'inanewkitchen', 'arobotneedstoknowwhatwewouldlikeittocook', 'aswellasbehaviorswe', 'wouldlikeittoavoid.therefore', 'anecessaryfirststeptowardsdevelopinggeneralistrobotsis', 'buildingmodelsforreliabletaskspecification', 'i.e.', 'theintuitiveandeffectivecommunicationof', 'task', 'objectives', 'preferences', 'constraints', 'formalize', 'task', 'specification', 'process', 'transformsahuman-providedtaskdescriptionintoaquantitativemetricthatmeasuresarobot', '’', 'taskcompletionandprogress—e.g.', 'arewardfunction.thissignaliscrucialforoptimizingrobot']",35
Opportunities and Risks of Foundational Models - Stanford.pdf,"['36', 'centerforresearchonfoundationmodels', 'crfm', 'behavior', 'diagnosingfailures', 'andpromptinghumanfeedback.asthemostnaturalwaytodescribea', 'taskcanvarydependingontheuser', 'environment', 'ortask', 'foundationmodelsfortaskspecification', 'shouldacceptavarietyofdescriptionmodalities', 'suchasgoalstates', '[', 'fuetal.2018', 'singhetal', '2019', ']', 'naturallanguage', '[', 'macglashanetal.2015', 'karamchetietal.2017', 'misraetal.2017b', 'co-reyes', 'etal.2019', 'shaoetal.2020', ']', 'videosofhumans', '[', 'shaoetal.2020', 'chenetal.2021c', 'liuetal.2018', ']', 'pairwiseorrankingcomparisons', '[', 'biyikandsadigh2018', ']', 'interactivecorrections', '[', 'co-reyesetal', '2019', 'karamchetietal.2020', ']', 'andphysicalfeedback', '[', 'rossetal.2011', 'bajcsyetal.2017', ']', 'important', 'requirement', 'general', 'purpose', 'model', 'task', 'specification', 'ability', 'transfertonewenvironmentsandtasks.reliablytransformingtaskdescriptionsintogeneralizable', 'rewardsignalsforrobotlearningremainsanopenproblem', '[', 'tayloretal.2016', ']', '—onethatfoundation', 'model', 'well', 'suit', 'apply', 'task', 'specification', 'foundation', 'model', 'provide', 'morerobust', '§4.8', 'robustness', 'generalpurposerewardsignalsbylearningfromlargeandbroad', 'datasets—evenleveragingmultipleofdescriptionmodalitieslistedabove.oneconcreteinstantiation', 'ofafoundationmodelfortaskspecificationmightbeamodelthatlearnsamappingfromarbitrary', 'language', 'currentobservation', 'pairstorewardsignalsbytrainingondiverselanguageandvision', 'datasets', '[', 'bahdanauetal.2019', 'fuetal.2019', 'chenetal.2021c', ']', '.bylearninginformativepriors', 'fromthesebroad', 'diversedatasets', 'suchamodelmaybeabletogeneralizetounseenlanguage', 'instructionsandobservationsinunseenenvironments.ingeneral', 'theabilityoffoundationmodels', 'todeftlybridgemodalitiesandgeneralizebroadlymakethemattractiveforgeneralpurposetask', 'specification', 'foundationmodelsfortasklearning', 'inadditiontoenablingmoregeneraltaskspecification', 'foundation', 'model', 'could', 'make', 'learn', 'solve', 'new', 'task', 'efficient', 'reliable', 'context', 'afoundationmodelforroboticsmighttaketheformofajointdistributionoveractions', 'observations', 'reward', 'andotherpropertiesofinterest.conditioningondifferentdimensionsofthis', 'jointdistributionrecoversdifferentinferenceproblems', 'eachcorrespondingtoadifferentsignature', '•', 'dynamicsmodeling', '𝑝', 'futureobservations', 'action', 'pastobservations', '[', 'finnandlevine', 'hafneretal.2019', 'wuetal.2021d', ']', '•', 'policylearning', '𝑝', 'actions|observations', 'goal', '[', 'kaelbling1993', 'schauletal.2015', 'dingetal', '2019', ']', '•', 'inversereinforcementlearning', '𝑝', 'rewardfunction', 'observations', 'action', '[', 'ngandrussell', '2000', 'ziebartetal.2008', 'finnetal.2016a', ']', 'totrainonrawdatafromadiversearrayofrobots', 'foundationmodelsoperatingonobservations', 'mustaccountforthevastsetofplausiblesensorconfigurationsandmodalities.whileseeminglya', 'challenge', 'thisactuallypresentsanopportunity', 'cross-modalrepresentationscanbemoregeneral', 'andgrounded', 'leveragingarbitraryinputconfigurationswhiletakingadvantageofcorrespondences', 'betweenmodalities', '[', 'kaiseretal.2017', 'lietal.2019b', 'leeetal.2020b', 'c', 'alayracetal.2020', 'jaegle', 'etal.2021b', ']', '.self-supervisionpresentsanadditionalopportunity', 'oneplausibletrainingobjective', 'forafoundationmodelforroboticsistopredictthedifferentelementsofthejointdistribution', 'describedaboveinanautoregressivefashion', '[', 'janneretal.2021', 'chenetal.2021b', '§4.1', 'model', ']', 'objective', 'could', 'allow', 'foundation', 'model', 'tap', 'unlabeled', 'data', '—', 'long', 'data', 'exhibitdiverse', 'meaningfulbehavior.§2.3.2', 'robotics-challengesdiscussesthechallengesof', 'collectingsuchdatafurther', 'inlanguageandvision', 'foundationmodelshavedemonstratedthecapabilitytolearnbroadly', 'applicablepriorsfromlarge', 'diversedatasets', 'thatcanbesubsequentlyadaptedtodownstream', 'task', '§2.1', 'language', '§2.2', 'vision', '.foundationmodelsforroboticshavethepotentialtosimilarly', 'enablefew-shotadaptationofperceptionandcontroltonewenvironments', 'task', 'andembodiments', 'considerourrunningkitchenexample.tocookinanewkitchen', 'arobotneedstoadapttothe']",36
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '37', 'specificenvironment—itsspatiallayout', 'theavailableequipment', 'etc.priorslearnedfromoffline', 'videosofhumans', 'roboticinteraction', 'text', 'and/orsimulation', '§2.3.2', 'robotics-challenges', 'might', 'encodegeneralaspectsofkitchens', 'suchasthefactthatstovesareusuallyagainstwallsandmust', 'beturnedoninordertoproduceheat.suchcommonsenseknowledge', 'physicalpriors', 'andvisual', 'priorscouldmakeadaptationtonewenvironmentsmoresampleefficient.similarly', 'afoundation', 'modelforrobottasklearningmightbeabletousealargenumberofcookingvideosinitstraining', 'datasettoadaptapolicyforacommonskill', 'suchas', '“', 'fryanegg', '”', 'toaspecificuser', '’', 'spreferences', 'fromalownumberofdemonstrations—allowingforsampleefficientadaptation.finally', 'theirpotentialtolearnthecross-modalrepresentationsdescribedearlier', 'foundationmodelsfor', 'roboticscouldhelpenableadaptationtonewembodiments.thisaspectofadaptationiscrucialto', 'makethesemodelswidelyuseful', '2.3.2', 'challengesandrisks', 'despitethisexcitingvision', 'multiplechallengesneedtobeovercome.toenablethegeneralization', 'discussedabove', 'wemustcollectroboticdatasetsofsufficientsizeanddiversity.additionally', 'needmechanismstoensurethatwecandeploylearnedbehaviorssafelyintherealworld', 'dataneeds', '&', 'challenge', 'learningapolicyforarobotthatperceivesthestateofitsenvironment', 'viasensorsandtakesactionstoaccomplishtaskstraditionallyrequireslargedatasetsoftherobot', 'interactingintherealworld.ontheotherhand', 'manylearningtasksincomputervisionandnatural', 'languageprocessingrelyonlargeanddiverseofflinedatasetsthatcaneasilybescrapedfromthe', 'web.motivatedbytheadvancesoffoundationmodelsinlanguageandvision', 'weareexcitedby', 'thepossibilityofleveraginglargeofflinedatasourcesforlearningsuchmodelsinrobotics', 'onepathtowardsthisgoaliscollectinglargedatasetsforofflinelearning', 'forexampleusing', 'teleoperation', '[', 'mandlekaretal.2019', ']', 'kinestheticteaching', '[', 'sharmaetal.2018', ']', 'orautonomous', 'methods', '[', 'pintoandgupta2016', 'guptaetal.2018', 'levineetal.2018', 'dasarietal.2019', 'kalashnikov', 'etal.2021', ']', 'whichhaveshownsomepromisingindicationsongeneralization.whilescalingup', 'robotdatacollectiontothesizeofvisionandlanguagedatasets', '[', 'dengetal.2009', 'krishnaetal', 'raffeletal.2019', 'gaoetal.2020a', ']', 'remainsanopenchallenge', 'theincreasingscaleandquality', 'ofroboticdatasetssuggeststheycanplayanimportantroleinlearningfoundationmodelsfor', 'robotics', 'giventhechallengingclosed-loopnatureoflearningcontrol', 'itispossiblethatcollectingsuch', 'datasetsofsizecomparabletothoseusedinvisionandlanguageisinsufficientforrobotics.one', 'excitingoptionistoadditionallyleverageexternal', 'non-roboticsourcesofdatasuchasvideosof', 'humansorexistingvisionandnaturallanguagedatasets.suchdataisdiverseandexistsinlarge', 'quantitiesontheweb', '[', 'dengetal.2009', 'leeetal.2012', 'heilbronetal.2015', 'goyaletal.2017a', 'damenetal.2018', 'gaoetal.2020a', ']', 'affordingthepossibilityofbroadgeneralizationifproperly', 'leveraged.elegantlyaddressingthegapbetweentherobot', '’', 'sdomainandthosefoundinvideosor', 'languageonthewebremainsanopenchallenge', 'however', 'recentprogressindomainadaptation', '[', 'smithetal.2019', 'schmeckpeperetal.2020', ']', 'andusingpretrainedvideoandlanguagemodelsin', 'robotics', '[', 'lynchandsermanet2020', 'shaoetal.2020', 'chenetal.2021c', ']', 'presentpromisingdirections', 'towardsclosingthisgap', 'finally', 'simulationpresentsaboundlesssourceofrichinteractivedatathatrobotscanlearnfrom', 'witharangeofsensormodalitieslikerenderedvisuals', 'point-clouds', 'andsimulatedtouch/audio', 'however', 'amajorchallengeliesinbridgingthegapbetweensimulationandtherealworld', 'bothin', 'theunderlyingphysicsandinthesemanticdistributionofenvironmentsandtasks.recentwork', 'hasshownthatbyusingextensivedomainrandomization', 'tasksrangingfromflight', '[', 'sadeghiand', 'levine2017', ']', 'tocontact-richmanipulation', '[', 'mahleretal.2017', 'openaietal.2019', ']', 'andlocomotion']",37
Opportunities and Risks of Foundational Models - Stanford.pdf,"['38', 'centerforresearchonfoundationmodels', 'crfm', '[', 'pengetal.2020', 'hwangboetal.2019', ']', 'skillslearnedinsimulationcanbetransferredtorealrobots', 'withsomesuccess', 'andthatthesemanticandvisualdistributionoftherealworldcanbesimulated', 'byscanningtherealworldintoasimulation', '[', 'changetal.2017', 'kolveetal.2017b', 'savvaetal.2019', 'szotetal.2021', 'shenetal.2021a', ']', '.whilethesearepromisingstepstowardsclosingthesim-to-real', 'gap', 'effectiveandgeneralsim-to-reallearningofmanipulationandlocomotionskillsremainsan', 'openchallenge.simulationdata', 'realrobotdata', 'videosofhumans', 'andnaturallanguagedatacould', 'allbeessentialtolearningfoundationmodelsforrobotics', 'safety', '&', 'robustness', 'furthercomplicatingthedevelopmentoffoundationmodelsforrobotics', 'isensuringtheirsafetyandrobustnesswhentrainingordeployingthemintherealworld.we', 'expect', 'safety', 'risk', 'model', 'robotics', 'different', 'language', 'counterpartsgiventhatembodiedagentsareempoweredtomanipulateandinteractwiththeir', 'surroundingsdirectlyinthephysicalworldwhilecollectingdata.onecoresafetychallengefor', 'learning-basedsystemsisthechicken-and-eggproblemofneedingtospecifysystemconstraints', 'forsafetypriortocollectingdata', 'afterwhichunforeseenunsafebehaviorsrequiringadditional', 'constraintsmayemerge.forinstance', 'anagentadaptingtoanewkitchenoutsideofthetraining', 'distributionrequiressufficientsafetyguaranteestoensuresafedatacollection', 'whichmayeither', 'adverselyaffecttaskperformanceorcausetheagenttofailinnovelways.onewaytoresolvethis', 'isrestrictingthecomplexityoftheenvironmentorincreasingthecomplexityoftherobotsuchthat', 'irrecoverablestatesorunsafeactionsareavoidedbyconstruction.therobotcanalsobetasked', 'withautonomouslyresettingtheenvironmenttofacilitateuninterruptedlearning', 'oradaptation', 'fromlarge-scaledatacollection', '[', 'eysenbachetal.2017', 'guptaetal.2021b', ']', '.thiswouldeithermean', 'ensuringthatnothinginthekitchenisbreakable', 'orensuringandreplacingtheitemstheagent', 'maybreakwhileitattemptstocollectdata', 'address', 'risk', 'pose', 'foundation', 'model', 'fail', 'generalize', 'produce', 'unexpected', 'behaviorstonewstimuli', 'potentialfuturedirectionsincludedevelopingacausalanalysisofagents', '[', 'déletangetal.2021', ']', 'newformalsafetyevaluationtools', 'andrealisticsimulationenvironments', '[', 'corso', 'et', 'al', '2020', 'dreossi', 'et', 'al', 'julian', 'kochenderfer', '2019', ']', 'finally', 'derive', 'formal', 'safetyguaranteesforfoundationmodels', 'e.g.', 'hamilton-jacobireachabilityofsafe-sets', '[', 'chowetal', 'fisacetal.2019', 'herbertetal.2021', ']', 'orbydevelopingsafetyboundariesforlearningthat', 'areinterpretable', '§4.11', 'interpretability', 'tohumanoperators', 'couldhelpreducerisksposed', 'byfoundationmodelsforrobotics', '[', 'berkenkampetal.2017', ']', '.asthestudyandimplementationof', 'foundationmodelsprogressesandintersectswithrobotics', 'solutionstothesechallengeswillbe', 'crucial', 'conclusion', 'whilethepromiseoffoundationmodelsforroboticsaremany—spanningmultiple', 'levelsoftheroboticspipelinefromtaskspecificationtotasklearning—thechallengesaresignificant', 'collectingdatainthephysicalworld', 'thatcoversdiverseenvironmentsandembodimentsatscaleis', 'asizablehurdle', 'andensuringthesafetyandrobustnessofsuchsystemsisequallyexigent.despite', 'ouroptimismprevails', 'tacklingthesechallengesnow', 'beforedevelopingmodelsoffersusthe', 'chancetoidentifywaystocollecttherightdata', 'fromtherightsources', 'attherightscaletobuild', 'safeandreliablefoundationmodelswiththecapabilitieswedesire', 'underpinningthissectionhasbeenathemeofmultimodality.foundationmodelsforrobotics—', 'inallpossibleinstantiations—haveandwillcontinuetobenefitfromworkinothersubfieldsof', 'aisuchaslanguageandvision', '§2.1', 'language', '§2.2', 'vision', '.yetasweconsiderincorporating', 'theseextensionsfromotherfields', 'thereareinterdisciplinarychallengesonthehorizonthattouch', 'otheraspectsoffoundationmodels', 'systemsinnovationfortraininganddeployingsuchmodels', 'forreal-timerobotics', '§4.5', 'systems', 'innovationininterfacesforrobusthuman-robotinteraction', '§2.5', 'interaction', 'andlessonstoincorporateaswebettergraspthesafetyandrobustnessof']",38
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '39', 'suchmodels', '§4.9', 'ai-safety', '§4.8', 'robustness', '.buildingareliableecosystemandthoughtful', 'researchpracticesaroundfoundationmodelsiskeytorealizingthesegoals']",39
Opportunities and Risks of Foundational Models - Stanford.pdf,"['40', 'centerforresearchonfoundationmodels', 'crfm', '2.4', 'reasoningandsearch', 'author', 'yuhuaiwu', 'friedarong', 'hongyuren', 'sangmichaelxie', 'xuechenli', 'andyshih', 'drewa', 'hudson', 'omarkhattab', 'fig.9', 'multimodalitycanallowfoundationmodelstonotonlyreasonwithformalsymboliclanguage', 'alsoexploitvisualaspectsoftheproblem', 'suchasequivalence', 'symmetry', 'andeuclideangeometry', 'toprune', 'theinfinitesearchspaceandfindpromisingconstructionsforasolution', '§2.4.1', 'reasoning-tasks', 'mimic', 'thewayhumansreasonaboutgeometryproblems', 'reasoningandsearchhavebeenacentralthemethroughoutthehistoryofai.classictestsof', 'intellect', 'fromstrategygamestoabstractmathematicaldiscovery', 'servedasinspirationalgoalposts', 'thatpushedthelimitsof', '“', 'machineintelligence', '”', 'throughaneedtodeviseeversmarterwaysof', 'searchingforwinningsolutions.intheearlydays', 'symbolicmethodswerethedominantapproach', 'reason', '[', 'russell', 'norvig', '2020', ']', 'involve', 'engineer', 'effort', 'need', 'formalizeheuristicstotackleintractablesearchspacesquicklyprovedcumbersome.morerecently', 'data-drivenmethodsusingneuralnetworkshaveshownencouragingresults—e.g.', 'defeatingthe', 'besthumansingo', '[', 'silveretal.2016', ']', 'aboardgamewithamuchlargerspaceofactionsthanthe', 'classicchallengeofchess—byexploitingstatisticalstructuresandlearningusefulheuristics.this', 'sectionoutlinesexistingreasoningtasks', 'onesthatrequirescalingtoever-largersearchspacesand', 'understandingtheworldbroadly', '§2.4.1', 'reasoning-tasks', '.wethenarguein§2.4.2', 'reasoning-', 'rolethatfoundationmodelsshouldplayacentralroletowardsgeneralreasoningasvehiclesfor', 'capturingthestatisticalregularitiesofunboundedsearchspaces', 'generativity', 'allowingpositive', 'transferacrosstasksandscenarios', 'universality', 'andexploitingthegroundingofknowledgein', 'multi-modalenvironments', 'ground', '2.4.1', 'whatarethecurrenttasks', '?', 'manyreasoningproblemsposeunboundedsearchspaces', 'wheresystemsmustdealwithnumerous', 'kindsofopen-endedalternatives.considertryingtoprovethattheangles∠𝐵and∠𝐶', 'areequalfor', 'anisoscelestriangle△𝐴𝐵𝐶', 'with𝐴𝐵', '=𝐴𝐶', 'figure9', '.asystemcanperformanynumberofactions', 'ateachstepofreasoning.forinstance', 'thesystemcouldaddanewauxiliarypointwithanarbitrary']",40
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '41', 'fig.10', 'leave', 'areactionroutefor1,6-heptadiene-3,5-dionepredictedbymachinelearning-baseddrug', 'retrosynthesisplanneraizynthfinder', '[', 'genhedenetal.2020', 'yoshikawaetal.2021', ']', '.right', 'asampleproof', 'treeinpropositionallogicwheretheformulasoutlinedingreenrepresentaxioms.althoughtheyarisefrom', 'differentdomains', 'bothtreesarestructurallythesame', 'construction', 'sayaperpendicularline', 'aparallelline', 'oratangentcircle', 'andthesearchspaceonly', 'growslargerasthediagramgrowsmorecomplicated.onewaytoprovethistheoremistodraw', 'aline𝐴𝐷', 'thatistheanglebisectorof𝐴', 'andusethecongruenceofthetwotriangles△𝐴𝐵𝐷', '△𝐴𝐶𝐷', 'toshow∠𝐵', '=', '∠𝐶', 'buthowcansystemsfindthiswithoutextensivesearch', '?', 'moregenerally', 'amathematicianisnotconfinedwithsearchingindiagramconstructionsand', 'euclideantheorems', 'mathematicianscanapplyavastnumberoftheoremsfromvariousbranches', 'ofmathematics', 'makehigh-levelconjectures', 'formalizenewmathematicalconcepts', 'orfindcoun-', 'terexamples.thiscontrastswithmorestructuredaichallengessuchasthegameofgo', 'whose', 'searchspaceisconsideredmuchsmaller.17', 'besidestheoremproving', 'manyreal-worldproblemsdealwithunboundedsearchspaces', 'suchas', 'programsynthesis', '[', 'gulwanietal.2017', ']', 'drugdiscovery', '[', 'drews2000', ']', 'chemicalsynthesis', '[', 'segler', 'etal.2018', ']', 'computer-aideddesign', '[', 'haigh1985', ']', 'combinatorialoptimization', '[', 'bengioetal.2021', ']', 'andmore.thesereasoningproblemstendtoexhibitsimilarstructure', 'likethebijectionbetween', 'retrosynthesisindrugdiscoveryandtheoremprovinginpropositionallogic', 'illustratedinfigure10', 'inbothproblems', 'oneisbuildingatreeofsynthesis', 'whosenodesarechemicalproductsonthe', 'onesideandpropositionsontheother', 'andtheleafnodesaretheproductsontheoneside', 'endaxiomsontheother.intheseproblems', 'asimulatedenvironmentisoftenprovided', 'allowsasolvertorunseveralsearchthreadstowardsbuildingthesolutiontree.thesimulator', 'oftenprovidesintermediatefeedback', 'say', 'informingthesolverwiththeremainingpropositions', 'toestablishbeforetheproofisconsideredcomplete.thesolverinturnneedstoselectthemost', 'promisingsearchthreadandproceedbasedontheintermediatefeedback', 'recently', 'therehasbeenasurgeofinterestinapplyinglearning-basedapproachestotackle', 'reasoningproblems.toovercometheunboundedsearchspacechallenge', 'researchersfirststarted', 'withaconstrainedsearchspacetomaketheproblemtractable', '[', 'huangetal.2018', 'bansaletal.2019', ']', 'butsuchapproachessufferedfromthelimitedkindsofactionsthesolvercouldissue.forexample', '17lessthanthenumberofgridpointsonthegoboard', 'i.e.,361actionsfora19×19board']",41
Opportunities and Risks of Foundational Models - Stanford.pdf,"['42', 'centerforresearchonfoundationmodels', 'crfm', 'thesolvercouldonlyapplytheoremsfromaknowndatabasetoprovethetargettheorem', 'instead', 'ofsynthesizingnoveltheoremsandlemmas.becauselargelanguagemodelsofferedagenericway', 'ofmodelingtheoutputspaceasasequence', 'theyquicklybecameamorefavorablechoice', 'allow', 'thegenerationofarbitrarykindsofactions.researchershaveappliedtheselanguagemodel-based', 'approachestovariousapplications', 'suchaspredictingproteinstructures', '[', 'senioretal.2020', ']', 'prove', 'formaltheorems', '[', 'poluandsutskever2020', 'hanetal.2021', ']', 'conjecturingtheorems', '[', 'urbanand', 'jakubuv2020', 'rabeetal.2021', 'lietal.2021b', ']', 'synthesizingprogramsfromnaturallanguage', '[', 'chen', 'etal.2021e', 'lingetal.2016', ']', 'repair', 'generatingandunderstandingcode', '[', 'yasunagaandliang', '2021', 'luetal.2021b', 'guoetal.2020', 'svyatkovskiyetal.2020', 'kimetal.2021b', 'zügneretal.2021', ']', '.it', 'hasalsobeenshownthatscalingmodelsizesignificantlyimprovesreasoningcapabilities', '[', 'poluand', 'sutskever2020', ']', 'andfurthermorestandardtechniquesfromlanguagemodelling', 'suchaspretraining', 'canalsogreatlyimproveperformanceonthesetasks', '[', 'rabeetal.2021', 'poluandsutskever2020', ']', '2.4.2', '’', 'stheroleoffoundationmodels', '?', 'generativity', 'webelievethatthegenerativecapabilitiesoffoundationmodelsareessentialfor', 'effective', 'reason', 'due', 'unbounded', 'search', 'space', 'become', 'intractable', 'enumerate', 'allkindsofpossibilities.instead', 'withfoundationmodels', 'onecanmodelthedistributionofthe', 'optimaldecisions', 'andgeneratesuitablecandidatestoproceedtothenextstep.inparticular', 'foundation', 'model', 'offer', 'generic', 'way', 'model', 'output', 'space', 'sequence', 'next', 'decisiongenerationisentirelyunconstrainedandhenceuniversal.suchflexibilityisessentialfor', 'manyofthereasoningchallengeswediscussed', 'toallowcreativegenerationindomainssuchas', 'mathematicalconjecturing', '[', 'lietal.2021b', ']', 'andsynthesizingnovelprograms', '[', 'chenetal.2021e', ']', 'asonescalesupfoundationmodels', 'thecapabilitiesofcapturingsuchstatisticalstructuresalso', 'growimmensely', '[', 'poluandsutskever2020', ']', 'universality', 'aswementionedinthelastsection', 'manyreasoningproblemsexhibitsimilarlatent', 'structures.webelievethattheunifyingframeworkimposedbyafoundationmodelcantransferand', 'sharesignificantheuristicsacrosstasks', 'rangingfromgeneralizinglow-leveltechniquesthatwork', 'wellforonetasktonewscenariosallthewaytodirectlyfindingmeta-techniquesthatworkwell', 'acrossnumerouskindsofproblems.inaddition', 'sinceafoundationmodelistrainedacrossmany', 'domains', 'itcanpositivelytransfermeta-knowledgeencodedinthefoundationmodels', '’', 'weight', 'acrosstasksanddomains', '[', 'papadimitriouandjurafsky2020', 'wuetal.2021f', 'luetal.2021a', ']', '.the', 'foundationmodeltrainingandadaptationframeworkencourageaseparationofconcerns', 'foundationmodeltraininglearnsmeta-knowledgesuchasthesharedsearchtreestructurebetween', 'drugretrosynthesisandpropositionallogicproofs', 'andtheadaptationphasecanfocusonlearning', 'thetaskspecificvocabulary.thus', 'foundationmodelscanreducethecomplexityofthelearning', 'problemintheadaptationphase', 'improvingsamplecomplexityandgeneralization', 'ground', 'reasoningproblemsareofteneasilyexpressedinsymboliclanguages', 'e.g.', 'mathe-', 'matics', 'code', 'smilerepresentationofmolecules', '.however', 'thesesymbolshavedeepunderlying', 'semanticmeanings—saying', '“', 'isoscelestriangle', '”', 'paintsavividimageinthehumanmind.founda-', 'tionmodelscanenabledeepgroundingsandsemanticmeanings.first', 'groundingrepresentations', 'inothermodalities', 'suchasvisualorphysical', 'areessentialtograspabstractconceptsinreasoning', 'tasksandendowthemwithconcretemeaning', '[', 'larkinandsimon1987', 'jamnik2001', ']', '.sincethe', 'modelsmaybetrainedonmultiplemodalities', 'foundationmodelscanassistinunderstandinga', 'rangeofdatasources', 'e.g.', 'image', 'texts', '.hence', 'inthegeometryexamplecase', 'withitsunderstand-', 'ingofgeometricalshapeslearnedinnaturalimages', 'afoundationmodelcouldeffectivelyutilize', 'thediagrammaticrepresentationoftheproblem.however', 'alignedmulti-modaldatainreasoning', 'isscarce', 'anditremainsanopenquestionwhetherfoundationmodelscandiscoverconnections']",42
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '43', 'betweendifferentmodalitiesinanunsupervisedmanner', 'e.g.', 'discoveringofcommutativediagram', 'withthecorrespondingalgebraicequations', '.furthermore', 'evenwithinthesymbolicdomain', 'sym-', 'bolscanhavevariouslevelsofinterpretation.forexample', 'high-levelprogramminglanguagescan', 'betranslatedtolow-levelassemblycodes.foundationmodelscanlearnasharedrepresentation', 'thatencompassesthesevariousviews.pastworkshaveshownthatself-supervisedtasks', '[', 'hanetal', '2021', 'pengetal.2021', 'lietal.2021a', ']', 'allowthemodeltounderstandtheinnerworkingsbehindthe', 'high-levelcodescripts', 'andfurtherassistdownstreamtasks', '2.4.3', 'futurechallengesinreasoning', 'duetotheintrinsicdifficultyoftheseproblems', 'high-qualityannotateddataisscarceandharder', 'tocollectcomparedtorawimagesandtext.therehavebeenseveralattemptstowardsalleviating', 'thisissue.inmathematics', 'researchersproposedtogeneratesynthetictheoremsinthehopeof', 'generalizingtorealistictheorems', '[', 'wanganddeng2020', 'wuetal.2021a', 'firoiuetal.2021', 'zhou', 'etal.2021c', ']', '.anotherapproachistodesignself-supervisedtaskstoaugmentdatasets', '[', 'yasunaga', 'andliang2020', 'renetal.2020', 'hanetal.2021', 'rozièreetal.2021', 'yasunagaandliang2021', ']', 'betterpretrainingobjectives', '[', 'wuetal.2021f', ']', '.however', 'westilllackgeneralprincipledapproaches', 'indesigningself-supervisedtasks', 'asmostoftheexistingworksaretailoredtospecificproblem', 'setups', '[', 'yasunagaandliang2020', 'renandleskovec2020', 'hanetal.2021', ']', '.buildingafoundation', 'modelwillencourageaunifyingframeworkofconstructingasuiteofself-supervisedtasksthat', 'apply', 'reason', 'problems', 'addition', 'interactivity', '§2.5', 'interaction', 'could', 'withenoughscalability', 'alleviatethedatascarcityproblembybringinghumansintotheloopto', 'minimallyguidethelearningcurriculumordataaugmentationprocess', 'forexample', 'inselecting', 'axiomstoaddorconjecturestoexplore.whileinteractivetoolsthemselvesareamotivatinguseof', 'foundationmodelsforreasoning', '[', 'hanetal.2021', 'chenetal.2021e', ']', 'inassistingpeoplewiththe', 'mostcognitivelydemandingorlaboriousaspects.interpretation-friendlyinteractivetoolscould', 'find', 'applications', 'education', 'assist', 'humans', 'learn', 'help', 'highly', 'capablefoundationmodels', '§3.3', 'education', 'improvingthehigh-levelreasoningcapabilitiesisacorechallengeforexistingfoundationmodels', 'humansperformabstractreasoningandhigh-levelplanningintacklingdifficultproblem-solving', 'task', '[', 'milleretal.1960', ']', '.forexample', 'whenbuildingasoftwaretoolorprovingatheorem', 'weoften', 'startwithahigh-levelsketchbeforedelvingintothelow-leveldetails', '[', 'koedingerandanderson', '1990', ']', '.existingfoundationmodelsarenottrainedtogeneratesuchhigh-levelplans.instead', 'oftenfocussolelyonpredictingthenextlow-levelsteps', '[', 'poluandsutskever2020', 'hanetal.2021', 'chenetal.2021e', ']', '.unfortunately', 'totrainfoundationmodelstoemulatehuman-likereasoning', 'weagainfaceadatacollectionchallenge.althoughsuchdatadoesexistinlimitedsettings', '[', 'li', 'etal.2021b', ']', 'ingeneral', 'dataforhigh-levelreasoningisscarceanddifficulttocollect.onelineof', 'researchistoletabstractandmodularhierarchytoemergebyitselfduringlearning', '[', 'ellisetal', '2021', 'hongetal.2021', ']', 'butitstillremainsanopenquestionhowtoscaletheseapproachestomore', 'generalandrealisticsettings', 'asidefromthesechallenges', 'thereexistmanyopenquestionsthatarealsoessentialtotopics', 'discussedinothersections.whatconstitutesagoodarchitectureforreasoningreliably', '§4.1', 'mod-', 'eling', '?', 'understand', 'interpret', 'model', 'theoretically', '§4.10', 'theory', 'practically§4.11', 'interpretability', '?', 'canwetrainrobustreasoningmodelsthatcouldgeneralize', 'toout-of-domainproblems', '§4.8', 'robustnessand§4.3', 'adaptation', '?', 'webelieveresearchabout', 'foundationmodelsoneachofthesefrontscangreatlybroadentheirimpactforthefieldofreasoning']",43
Opportunities and Risks of Foundational Models - Stanford.pdf,"['44', 'centerforresearchonfoundationmodels', 'crfm', '2.5', 'interaction', 'author', 'joonsungpark', 'chrisdonahue', 'minalee', 'siddharthkaramcheti', 'dorsasadigh', 'michaels', 'bernstein', 'fig.11', 'foundationmodelswillbringsignificantopportunitiestodevelopersbyloweringthedifficulty', 'thresholdforbuildingai-infusedapplications', 'andtotheapplicationusersbyraisingtheceilingforwhat', 'typesofinteractionsareachievable.insomecases', 'thelinebetweendevelopersanduserswillstarttoblur', 'andusersmaybeabletoeasilydeveloptheirownaiapplications', 'forinstancewithnaturallanguage', 'theearlyformsoffoundationmodelssuchasgpt-3', '[', 'brownetal.2020', ']', 'anddall·e', '[', 'ramesh', 'etal.2021', ']', 'havedemonstratedahighlevelofversatilitybothintermsoftheirabilitytoletevennon-', 'mlexpertstoprototypepowerfulai-infusedapplications', 'andtheirabilitytoseamlesslyintegrate', 'modalitiesrangingfromtextstoimages.asthedevelopmentoffoundationmodelsmatures', 'model', '’', 'capacitywillcontinuetoexpandandtheirversatilitymayultimatelyleadtofundamental', 'changesinhowweinteractwithaibyallowingustorapidlyprototypeandbuildhighlydynamic', 'andgenerativeai-infusedapplications.inthissection', 'wediscusstheopportunitiesthatthese', 'changespresentfromtheperspectivesoftwoimportantstakeholders', '1', 'applicationsdevelopers', 'whowillinteractwithfoundationmodelstodesignuserexperience', '2', 'end-userswhowilluse', 'orbeaffectedbytheai-infusedapplicationspoweredbyfoundationmodels.finally', 'weconsider', 'scenariosinwhichthelinethatrigidlyseparatesdevelopersandend-userstodaymaystarttoblur', 'affordingnewopportunitiesforcreatingai-infusedapplicationsthatmorecloselysatisfyusers', '’', 'needsandvalues', '2.5.1', 'impactonai-infusedapplicationdevelopers', '’', 'developmentprocess', 'howwillfoundationmodelstransformthewaydeveloperscreateai-infusedapplications', '?', 'despite', 'themonumentalprogressinmachinelearningalgorithmsandsystemsinfrastructure', 'somepoint', 'outthatdesigningnovelandpositiveformsofhuman-aiinteractionremainsdifficult', '[', 'doveetal', 'cooper', 'et', 'al', '2014', ']', 'vast', 'amount', 'data', 'compute', 'resources', 'skills', 'need', 'createapowerfultask-specificmodelisfrequentlyinconflictwiththeiterativeprototypingprocess', 'necessarytoelicitandsatisfyusers', '’', 'needsandvalues', '[', 'yangetal.2016', ']', '.thischallengeisfurther']",44
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '45', 'compoundedbythefactthatairesponsescanbeunpredictable', 'andmodelscanproduceavast', 'generativeoutputspace', 'makingitdifficultforpeopletobuildeffectivementalmodelsoftheir', 'performance.therehasalreadybeensomeprogressontacklingthesechallengesintheformof', 'workoninteractivemachinelearning', 'e.g.', 'crayon', '[', 'failsandolsen2003', ']', 'regroup', '[', 'amershietal', '2012', ']', 'anddesignframeworksforconveyinguncertaintyinaitoend-users', 'e.g.', 'principlesofmixed-', 'initiative', '[', 'horvitz1999', ']', '.however', 'moreworkisstillneededtoovercometheseobstacles', '[', 'yang', 'etal.2020', ']', 'foundationmodelsposeimportantopportunitiestoaddressmanyofthechallengesmentioned', 'above.forinstance', 'language-basedfoundationmodels', '’', 'abilitytotakenaturallanguageasinput', 'togeneralizetomanydownstreamtasks', 'couldsignificantlylowerthedifficulty', '“', 'threshold', '”', '[', 'myers', 'etal.2000', ']', 'forapplicationdevelopment', 'i.e.', 'byenablingthedevelopmentofsophisticatedmodels', 'withouthavingtocollectsignificantamountsofdataandtrainlargemodelsfromscratch.this', 'couldenableevennon-mlexpertstoquicklyprototypeai-infusedapplications.atthesametime', 'thepowerfulgenerativeandpotentiallymulti-modalcapabilitiesoffoundationmodelscouldoffer', 'afarhigher', '“', 'ceiling', '”', '[', 'myersetal.2000', ']', 'ofwhattypesofinteractionsareachievablebothinterms', 'oftheirqualityanddiversityaswewilldiscussbelow.however', 'howsuccessfullywecanleverage', 'thesecapacitieswilldependonhoweffectivelywecanwranglefoundationmodelsintoformsthat', 'willbemoremanageablebyapplicationdevelopers', 'unfortunately', 'thesamegeneralizabilityandhighceilingthatgivefoundationmodelstheiredge', 'canalsomakethesemodelsdifficulttoworkwith', 'astheymaybeevenmoreunpredictableand', 'complexthansingle-purposeaimodels.indeed', 'recentworkhasshownthatitcanbedifficultto', 'makemodelslikegpt-3consistentlyperformtheintendedtask', '[', 'reynoldsandmcdonell2021', ']', 'understand', 'capable', 'still', 'active', 'area', 'research', '[', 'hendrycks', 'et', 'al', '2021a', ']', '.inanefforttoimprovethereliabilityandtrustworthinessofai-infusedapplications', 'recommend', 'future', 'work', 'continue', 'investigate', 'achieve', 'predictable', 'androbustbehaviorsfromfoundationmodels', 'e.g.', 'throughfine-tuning', 'orincaseswherethe', 'mainmodeofinteractionisnaturallanguageprompt', 'throughprompt-engineering', '[', 'reynoldsand', 'mcdonell2021', 'liuetal.2021d', ']', 'calibrate', '[', 'zhaoetal.2021', ']', 'orpre-formattingatask-specific', 'endpoint.18pleasesee§4.8', 'robustnessformoredetails', '2.5.2', 'impactonend-userinteractionwithai-infusedapplications', 'beyondthenewwaysdevelopersmightcreateai-infusedapplications', 'whatchangeswillfoun-', 'dationmodelsbringtotheexperienceforend-usersinteractingwiththeseapplications', '?', 'exist', 'designframeworksfordevelopinguser-facingaiapplicationsfocusonaugmenting', 'ratherthan', 'replace', 'users', '’', 'abilitiesasdescribedbydouglasengelbart', '[', 'engelbart1963', ']', '—weexpectthatthese', 'frameworksshouldandwillremainrelevantforthedevelopmentoffutureai-infusedapplications', 'forinstance', 'maintainingusers', '’', 'agencyandreflectingtheirvalueswillcontinuetobeacentral', 'themeforfoundationmodel-poweredapplications.additionally', 'thebenefitsofallowingaiagents', 'take', 'initiatives', 'automate', 'users', '’', 'routines', 'versus', 'benefit', 'wait', 'users', '’', 'direct', 'manipulation', '[', 'shneiderman1997', ']', 'willneedtobecarefullyweighed', '[', 'horvitz1999', ']', '.moreover', 'users', '’', 'valuesshouldbedirectlygatheredandreflectedthroughprocessessuchasparticipatory', '[', 'lee', 'etal.2019', ']', 'andvalue-sensitivedesign', '[', 'smithetal.2020', ']', 'thatadvocateforactivelyinvolvingall', 'stakeholdersduringthedesigningoftheai-infusedapplications', 'theseissuesmaybecomeespeciallysalientwithfoundationmodelsbecausethemodelmay', 'behaveinwaysthatsurpriseanddisappointusersandcommunities.generativecapabilitiesmight', 'exposebiasesorpointsofviewthatarecountertothecommunities', '’', 'goals', 'ormoreinsidiously', '18https', '//beta.openai.com/docs/guides/classifications']",45
Opportunities and Risks of Foundational Models - Stanford.pdf,"['46', 'centerforresearchonfoundationmodels', 'crfm', 'drawonsuchassociationsintheirbehaviorwithoutthecommunitybeingaware.thiswillplacea', 'largeburdenonthegroupsutilizingfoundationmodelstomonitortheirmodels', '’', 'behavior', 'andto', 'theextentpossible', 'adaptthemtoactinappropriateways', 'design', 'frameworks', 'think', 'ai-infused', 'applications', 'augment', 'users', '’', 'abilitiesshouldremainthesame', 'theactualformsofinteractionsthatareattainablemaydramatically', 'diversifyduetofoundationmodels', '’', 'powerfulgenerativeandmulti-modalcapacities.already', 'early', 'generationsofwhatcanbeconsideredfoundationmodel-poweredsoftwaretoolsformultimedia', 'creationandeditinghavestartedtodriveanewfrontierthatempowersevennovicecontentcreators', 'togeneratehigh-qualitymultimediafromcoarse', 'intuitivespecifications', 'e.g.', 'paraphrasingfor', 'writers,19', 'foreground', 'segmentation', 'photographers,20', 'master', 'musicians,21', 'code', 'completionforprogrammers', '.22improvedfoundationmodelsmightenableevenmoreambitious', 'tool', 'e.g.', 'afanmightprovidethematicmaterialforasongwhichwillthenbegeneratedinthe', 'styleoftheirfavoriteband', 'orabusinessownermightprovidesimpledescriptionsoftheirproduct', 'whichwillbeusedtocreateafullwebsite', '.moreover', 'foundationmodelswillbeusedtoenrich', 'staticmultimedia', 'e.g.', 'automaticallyremasteringlegacymultimediacontentintonewformats', 'orgeneratinguniqueexperiencesforeachplayerinnewvideogames', 'andmayevenleadtonew', 'formsofmulti-modalinteractionsusinginterfacesthatthemselvesmixdifferentmodalities', 'asvisualandgesture-basedinteraction', 'start', 'see', 'glimpse', 'foundation', 'model', 'might', 'materialize', 'concrete', 'interactionsinapplicationsrangingfromaidungeon23tomicrosoftpowerapps24andcopilot.25', 'aswestarttoenvisionnewformsofinteractions', 'itisofincreasingimportanceforustothink', 'critically', 'potential', 'implications', 'interactions', 'individual', 'users', 'society', 'maximize', 'positive', 'impact', 'example', 'foundation', 'model-powered', 'applicationschangethewaywecommunicatewithoneanother', '?', 'willapowerfulmodelwrite', 'emailsinoursteadandifso', 'howwillthisreshapepeople', '’', 'strust', 'credibility', 'andidentityknowing', 'thatthewritersmaynothavewrittentheemailsthemselves', 'andhowwillthisalterourwriting', 'style', '[', 'hancocketal.2020', ']', '?', 'whowillowntheauthorshipofthemodel-generatedcontentand', 'howcouldtheshiftingresponsibilitiesandownershipoftheconsentbemisused', '[', 'weiner2018', ']', 'see§5.5', 'economicsforamorein-depthdiscussion', '?', 'whatarethelong-termimplicationsthat', 'foundationmodelswillhaveonourwork', 'languageandculture', '[', 'hancocketal.2020', 'buscheketal', '2021', ']', '?', 'ofparticularrelevancetothislastquestionisthefactthatfoundationmodelsaretrainedon', 'observeddataanddonotnecessarilyinformusaboutcausality.hence', 'howcanweensurethat', 'theuseoffoundationmodelsleadsustoadesiredfutureandnotarepetitionofthepast', '?', 'though', 'theseissuesarenotnecessarilyuniquetofoundationmodels', 'theywillbeamplifiedandbecome', 'moreprevalentasfoundationmodelsacceleratethecreationofeffectiveai-infusedapplications', '2.5.3', 'blurringthelinebetweendevelopersandend-users', 'today', 'thelinethatseparatesthedevelopersofaimodelsandend-usersisrigid—itisrarelythe', 'casethatanend-userhasthedata', 'computingresources', 'andexpertisetobeabletodevelopanew', 'modelthatsuitsone', '’', 'svaluesandneedswell.whileagenericmodel', 'i.e.', 'onethatisnotspecifictoa', 'specificuserorcommunity', 'couldbesufficientinsomecases', 'recentyearshaveseenanincreasing', '19https', '//www.wordtune.com/', '20https', '//helpx.adobe.com/photoshop/using/select-mask.html', '21https', '//www.landr.com/', '22https', '//copilot.github.com/', '23https', '//play.aidungeon.io/main/home', '24https', '//powerapps.microsoft.com/en-us/', '25https', '//copilot.github.com/']",46
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '47', 'numberofscenariosinwhichsuchmodelsfailtoserveusers.forinstance', 'atextclassification', 'modeldesignedtoidentifyproblematiccommentsforoneonlinecommunitymightworkwellfor', 'thatcommunitybutwillfailinotherswhosenormsandculturesmaydiffersignificantly', 'e.g.', 'nsfw', 'communitiesonredditmightbemoretolerantofcertaincontent', 'whilesciencecommunitiesmight', 'rejectseeminglymundaneanecdotesthatarenotbasedonscientificresearch', '[', 'chandrasekharan', 'etal.2018', ']', '.inanotherexample', 'ai-poweredsensorsandroboticstoolsdesignedforonetarget', 'populationmayfailwithouttheabilitytoquicklyadaptin-contextforuserswithdifferentabilities', 'andneeds', '[', 'karamchetietal.2021', ']', '.whilerecentworkhaspresentedpromisingavenuesforfuture', 'researchonhowend-usersmaybeabletoco-createaimodelsbymanuallyprovidingmodels', '’', 'parametersordatasets', 'e.g.', 'webuildai', '[', 'leeetal.2019', ']', 'theresultsarestillpreliminaryandoften', 'focusonrudimentarymodels', 'foundation', 'model', 'sufficiently', 'lower', 'difficulty', 'threshold', 'build', 'ai-infused', 'applications', 'theycouldpresentanimportantopportunitytomoretightlycoupleusers', '’', 'needsand', 'valueswiththemodels', '’', 'behaviorsbyallowinguserstoactivelypartakeinthedevelopmentprocess', 'ofthemodels.recentworkhasshownthatgpt-3', 'forexample', 'canrobustlyperformclassification', 'tasksinafew-shotoreveninzero-shotfashionwhengivenanadequatetaskdescriptioninits', 'naturallanguageprompt', '[', 'brownetal.2020', ']', '.anonlinecommunitytryingtomoderateitsown', 'contentmightbeabletoleveragesuchacapabilitytocreatebespokeaiclassifiersthatfiltercontent', 'basedonclassificationtaskdescriptionsthatthecommunityhasagreedon', 'ofcourse', 'thispower', 'couldalsobeinsteadmisusedtosilencethevoicesofcertainmemberswithinthecommunity—we', 'pointto§5.2', 'misuseforfurtherdiscussiononthistopic', '.inaddition', 'thepowerfulin-context', 'learningcapabilitiesthatfoundationmodelswillexhibitmayallowfoundationmodel-powered', 'applicationstomoreeffectivelyoptimizetheirinterfacesonaper-userbasis.thiscouldopendoors', 'totacklingmanysalientproblemsinhuman-computerandrobotinteractionsuchasbalancingthe', 'powerofusers', '’', 'directmanipulationandautomationinmixed-autonomysettings', 'course', 'still', 'important', 'challenge', 'would', 'need', 'overcome', 'truly', 'realizethispotentialforblurringthelinebetweenusersanddevelopers.thesechallengesinclude', 'mitigatingexistingbiasesinfoundationmodels', 'aswellasmakingthemodels', '’', 'behaviormore', 'robustandmanageableevenfornon-mlexperts', 'comparedtomlexperts', 'itcouldbeevenmore', 'difficultfornon-mlexpertstounderstandthefullcapacitiesandmechanismsoffoundationmodels', 'whichcanleadtounexpectedpitfallsinthedevelopmentcycle', '[', 'yangetal.2018', ']', '.futurework', 'shouldexplorehowfoundationmodelscouldbesituatedinthecontextofinteractivemachine', 'learningandstudyhowwecansupporteventhosewithlimitedexperiencewithmachinelearning', 'toleveragethesemodelsinarobustmanner.nonetheless', 'theabilityforend-userstobeinvolvedin', 'developingai-infusedapplicationsisanexcitingopportunitythatcouldintroduceanewparadigm', 'forhowwewillinteractwiththeseapplicationsinthefuture']",47
Opportunities and Risks of Foundational Models - Stanford.pdf,"['48', 'centerforresearchonfoundationmodels', 'crfm', '2.6', 'philosophyofunderstanding', 'author', 'christopherpotts', 'thomasicard', 'evaportelance', 'dallascard', 'kaitlynzhou', 'johnetchemendy', 'whatcouldafoundationmodelcometounderstandaboutthedataitistrainedon', '?', 'ananswer', 'tothisquestionwouldbeextremelyinformativeabouttheoverallcapacityoffoundationmodelsto', 'contributetointelligentsystems.inthissection', 'wefocusonthecaseofnaturallanguage', 'since', 'languageuseisahallmarkofhumanintelligenceandcentraltothehumanexperience', 'thebestfoundationmodelsatpresentcanconsumeandproducelanguagewithstrikingfluency', 'buttheyinvariablylapseintothesortofincoherencethatsuggeststheyaremerely', '“', 'stochastic', 'parrot', '”', '[', 'benderetal.2021', ']', '.aretheselapsesevidenceofinherentlimitations', 'ormightfuture', 'foundationmodelstrulycometounderstandthesymbolstheyprocess', '?', 'ouraiminthissectionistoclarifythesequestions', 'andtohelpstructuredebatesaroundthem', 'begin', 'explain', 'mean', 'foundation', 'model', 'pay', 'special', 'attention', 'foundationmodelsaretrained', 'sincethetrainingregimedelimitswhatinformationthemodelgets', 'abouttheworld.wethenaddresswhyitisimportanttoclarifythesequestionsforthefurther', 'developmentofsuchmodels.finally', 'weseektoclarifywhatwemeanbyunderstanding', 'address', 'bothwhatunderstandingis', 'metaphysics', 'andhowwemightcometoreliablydeterminewhether', 'amodelhasachievedunderstanding', 'epistemology', 'ultimately', 'conclude', 'skepticism', 'capacity', 'future', 'model', 'understand', 'naturallanguagemaybepremature.itisbynomeansobviousthatfoundationmodelsalonecould', 'everachieveunderstanding', 'butneitherdoweknowofdefinitivereasonstothinktheycouldnot', '2.6.1', 'whatisafoundationmodel', '?', 'thereisnotaprecisetechnicaldefinitionoffoundationmodel.rather', 'thisisaninformallabel', 'foralargefamilyofmodels', 'andthisfamilyofmodelsislikelytogrowandchangeovertimein', 'responsetonewresearch.thisposeschallengestoreasoningabouttheirfundamentalproperties', 'however', 'thereisarguablyonedefiningcharacteristicsharedbyallfoundationmodels', 'theyare', 'self-supervised.ourfocusisonthecasewhereself-supervisionisthemodel', '’', 'sonlyformalobjective', 'inself-supervision', 'themodel', '’', 'ssoleobjectiveistolearnabstractco-occurrencepatternsinthe', 'sequencesofsymbolsitwastrainedon.thistaskenablesmanyofthesemodelstogenerateplausible', 'stringsofsymbolsaswell.forexample', 'manyfoundationmodelsarestructuredsothatonecan', 'promptthemwithasequencelike', '“', 'thesandwichcontainspeanut', '”', 'andaskthemtogeneratea', 'continuation–say', '“', 'butterandjelly', '”', '.othermodelsarestructuredsothattheyarebetteratfilling', 'ingaps', 'youmightpromptamodelwith', '“', 'thesandwichcontains__andjelly', '”', 'andexpectitto', 'fillin', '“', 'peanutbutter', '”', '.bothcapabilitiesderivefromthesemodels', '’', 'abilitytoextractco-occurrence', 'patternsfromtheirtrainingdata', 'thereisnoobvioussenseinwhichthiskindofself-supervisiontellsthemodelanythingabout', 'whatthesymbolsmean.theonlyinformationitisgivendirectlyisinformationaboutwhichwords', 'tendtoco-occurwithwhichotherwords.onthefaceofit', 'knowingthat', '“', 'thesandwichcontains', 'peanut', '”', 'islikelytobecontinuedwith', '“', 'butterandjelly', '”', 'saysnothingaboutwhatsandwichesare', 'whatjellyis', 'howtheseobjectswillbecombined', 'etc.thismightseemtosuggestaninherent', 'limitationonwhatafoundationmodelcouldachieve.however', 'weneednotrestrictthemodelto', 'seeingonlytextualinput.afoundationmodelmightbetrainedonawiderangeofdifferentsymbols', 'notjustlanguagebutalsocomputercode', 'databasefiles', 'image', 'audio', 'andsensorreadings.as', 'longasitisjustlearningco-occurrencepatternsofthesequencesitisexposedto', 'thenitcountsas', 'afoundationmodelbyourdefinition.aspartofthislearning', 'themodelmightcometorepresent', 'strongassociationsbetweenagivenpieceoftextandaparticularsensorreading', 'orbetweena']",48
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '49', 'sequenceofpixelvaluesandadatabaseentry.theseassociationsmightreflectimportantaspects', 'oftheworldweinhabitandthelanguageweusetotalkaboutit', '2.6.2', 'whatisatstake', '?', 'beforeconsideringanalysesofwhatunderstandingis', 'itisworthreflectingonwhywemightcare', 'aboutthequestionofwhetherafoundationmodelcouldachieveit.thesemodelsarepoisedtobe', 'deployedfornumerouspurposeswithvariousfunctionalities.someofourgoalsindeployment', 'mayonlybemettotheextentthatthemodeliscapableofunderstanding.herewelistafewsuch', 'goals', '•', 'trust', 'onemightarguethatwecannottrustasystem', '’', 'slinguisticbehaviorunlessitun-', 'derstandsthelanguageitisusing.ofcourse', 'wecurrentlytrustengineeredsystemstodo', 'things', 'e.g.', 'manufacturingautoparts', 'withoutthequestionofunderstandingevenarising', 'butlanguagemightbespecialinthisregard', 'sinceitisuniquelyhuman.inaddition', 'language', 'canbeusedtodeceiveandmisrepresent', 'sounderstandingaloneclearlydoesnotimplytrust', 'onthewhole', 'understandingmightbetakenasanecessaryconditionfortrustinthe', 'contextoflanguageuse', '•', 'interpretability', 'ifgenuinenaturallanguageunderstandinginsomewayinvolvesmain-', 'tainingandupdatinganinternalmodeloftheworld', 'include', 'e.g.', 'thespeechcontext', 'andifwe', 'asengineers', 'areabletoanalyzehowlinguisticinputandoutputinterfacewith', 'thisinternalmodel', 'thatcouldaffordsubstantialgainsininterpretability', 'predictability', 'controlofthesesystems', '•', 'accountability', 'notunrelatedtothepreviouspoints', 'inthefuturewemayfinditdesirable', 'toholdartificialagentsinsomewayaccountableforthelanguagetheyproduce', '[', 'thehai', 'adaptiveagentsgroup2021', ']', '.dependingonhowwethinkaboutconceptslikeaccountability', 'responsibility', 'agency', 'andthelike', 'languageunderstandingmayemergeasaprerequisite', 'themerepossibilitythatunderstandingwillplayanindispensableroleinanyofthesematters', 'providesstrongmotivationtodevelopaframeworkfortheorizingaboutit', '2.6.3', 'whatisunderstanding', '?', 'ourcentralquestioniswhetherafoundationmodelcouldcometounderstandanaturallanguage', 'withtheabove', 'wecannowsharpenit', 'isself-supervisionsufficientforunderstanding', 'keepingin', 'mindthattherearenoconstraintsonthedatausedforthissupervision', '?', 'inordertoaddressthis', 'question', 'wefirstneedtodefinewhatwemeanbyunderstanding', 'asastart', 'wefindithelpfultomakeexplicitadistinctionthatissometimesconflatedindiscus-', 'sionsofthetopic.thedistinctionisbetweenthemetaphysicsandtheepistemologyofunderstanding', 'metaphysicsconcernswhatitwouldmean', '“', 'inprinciple', '”', 'foranagenttoachieveunderstanding', 'epistemology', 'bycontrast', 'concernshow', '“', 'inpractice', '”', 'wecouldevercometoknowthatanagent', 'hasachievedtherelevanttypeofunderstanding.inshort', 'metaphysicsismoreaboutourultimate', 'target', 'whereasepistemologyismoreabouthow', 'ifatall', 'wecouldknowwhenwehavereachedit', 'ourepistemologythusdependstosomeextentonourmetaphysics']",49
Opportunities and Risks of Foundational Models - Stanford.pdf,"['50', 'centerforresearchonfoundationmodels', 'crfm', 'metaphysics', 'understand', 'philosophy', 'language', 'offer', 'number', 'alternatives', 'whatitistounderstandnaturallanguage.26simplifyingthelandscapeforthesakeofbrevity', 'followingthreebroadclassesofviewsallhaveconnectionswithresearchlinesinaiandnlp:27', '•', 'internalism', 'languageunderstandingamountstoretrievaloftherightinternalrepresenta-', 'tionalstructuresinresponsetolinguisticinput.thus', 'languageunderstandingisnotevena', 'possibilitywithoutarichinternalconceptualrepertoireoftherightkind', '•', 'referentialism', 'roughly', 'anagentunderstandslanguagewhentheyareinapositionto', 'knowwhatitwouldtakefordifferentsentencesinthatlanguagetobetrue', 'relativetoa', 'context', '.thatis', 'wordshavereferentsand', 'declarative', 'utterancesaretruth-evaluable', 'understandinginvolvesacapacitytoevaluatethemrelativetopresentationofasituationor', 'scenario', '•', 'pragmatism', 'understand', 'require', 'nothing', 'way', 'internal', 'representations', 'computations', 'andtruthandreferencearenotfundamental.rather', 'whatmattersisthatthe', 'agentbedisposedtouselanguageintherightway.thismightincludedispositionstoward', 'inferenceorreasoningpatterns', 'appropriateconversationalmoves', 'andsoon.crucially', 'relevantverbalabilitiesconstituteunderstanding.28', 'whilethisisasimplifiedpictureofthespaceofpossibilities', 'wealreadyseehowtheyrelatein', 'quitedifferentwaystothegoalsmentionedabove.onthepragmatistview', 'forinstance', 'achiev-', 'inglanguageunderstandingdoesnotimplyanythingaboutourabilitytotrustorinterpretthe', 'system', 'insofarasitguaranteesnothingabouttheagent', '’', 'sinternalstructureoritsrelationtothe', 'non-linguistic', 'world.ontheinternalistview', 'bycontrast', 'afairlyrobustkindofinternal/causal', 'interpretabilityisatleaststronglysuggested.thequestionofwhetherornotafoundationmodel', 'couldunderstandlanguageinprincipletakesonaverydifferentcharacterdependingonwhichof', 'thesemetaphysicalcharacterizationsweadopt', 'internalismandreferentialismcanbothbecastasdefiningamappingproblem', 'toassociatea', 'linguisticsignwitha', '“', 'mean', '”', 'ora', '“', 'semanticvalue', '”', '.forinternalismthiswillbearepresentationor', 'concept', 'aprogramforcomputingavalue', 'orsomeothertypeofinternalobject.forreferentialism', 'itmightbeamappingfromawordtoanexternalreferent', 'oramappingfromasituationtoatruth', 'value', 'allrelativetoacontext', '.couldself-supervisionsufficeforachievingthedesiredmapping', 'inafoundationmodel', '?', 'thenatureofthetrainingexamplesmightberelevant.ifthemodel', 'receivesonlylinguisticinputs', 'thenitscapacitytolearnthismappingmightbefundamentally', 'limitedinwaysthatpreventitfromlearningtoreferintherelevantsense.', 'indeed', 'merrilletal', '[', '2021', ']', 'identifysometheoreticallimits', 'albeitunderverystrongassumptionsaboutwhatitmeansto', 'learnthemeaningofasymbol', 'however', 'iftheinputsymbolstreamsincludediversedigitaltraces', 'ofthingsintheworld–images', 'audio', 'sensors', 'etc.–thentheco-occurrencepatternsmightcontain', 'enoughinformationforthemodeltoinducehigh-fidelityproxiesfortherequiredmapping.29for', '26relatedly', 'thereisasizableliteratureinphilosophyofsciencefocusedontheconceptofunderstanding', 'mainlyasit', 'relatestoscientificexplanation.seegrimm', '[', '2021', ']', '27weareleavingasideotherquestionsthatmayberelevanttothemetaphysicsofunderstanding', 'suchaswhetherornot', 'consciousnessorsomeformofsubjectiveexperiencemaybenecessary.thesearepressingphilosophicalissues', 'butthey', 'arenoteasilyconnectedtoresearchinaiandnlp', '28foranaccessibleintroductiontointernalistaswellasreferentialviews', 'werecommendelbourne', '[', '2011', ']', '.thisversion', 'ofpragmatismarguablyfindsitsrootsinwittgenstein', '[', '1953', ']', 'butitisexpressedmostsuccinctlybyturing', '[', '1950', ']', 'inwhich', 'turingsuggestsreplacingthequestionofwhetheramachinecanthinkwithquestionsaboutaspecificbehavioraltest', 'whichcametobeknownastheturingtest', '29totheextentthatthemappingembodiescausalinformation', 'wemustalsocontendwiththeoreticallimitations', 'concerningthepossibilityofdrawingcausalinferencesfromcorrelational', 'orevenexperimental', 'data', 'seespirtesetal', '2001', 'bareinboimetal.2020']",50
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '51', 'referentialism', 'thereisstillafurtherquestionofhowtheseproxiesrelatetotheactualworld', 'thesamequestionarisesforhumanlanguageusersaswell', 'benderandkoller', '[', '2020', ']', 'giveaninterestingargumentthatcombinesreferentialismwithprag-', 'matism.theyimagineanagentothatinterceptscommunicationsbetweentwohumansspeaking', 'anaturallanguagel.oinhabitsaverydifferentworldfromthehumansandsodoesnothave', 'thesortofexperiencesneededtogroundthehumans', '’', 'utterancesinthewaysthatreferentialism', 'demands.nonetheless', 'olearnsfromthepatternsinthehumans', '’', 'utterances', 'tothepointwhereo', 'canevensuccessfullypretendtobeoneofthehumans.benderandkollerthenseektomotivatethe', 'intuitionthatwecaneasilyimaginesituationsinwhicho', '’', 'sinabilitytogroundlinthehumans', '’', 'worldwillrevealitself', 'andthatthiswillinturnrevealthatodoesnotunderstandl.theguiding', 'assumptionseemstobethatthecomplexityoftheworldissogreatthatnoamountoftextual', 'exchangecanfullycoverit', 'andthegapswilleventuallyrevealthemselves.inthetermswehave', 'define', 'theinabilitytoreferistakentoentailthattheagentisnotintherightdispositionalstate', 'forunderstanding', 'fundamentally', 'thescenariobenderandkollerdescribeisoneinwhichsomecrucialinformation', 'forunderstandingistakentobemissing', 'andasimplebehavioraltestrevealsthis.wecanagree', 'assessment', 'without', 'conclude', 'foundation', 'model', 'general', 'incapable', 'understanding.thisagainbringsusbacktothedetailsofthetrainingdatainvolved.ifwemodify', 'benderandkoller', '’', 'sscenariosothatthetransmissionsincludedigitallyencodedimages', 'audio', 'sensorreadingsfromthehumans', '’', 'world', 'andoiscapableoflearningassociationsbetweenthese', 'digitaltracesandlinguisticunits', 'thenwemightbemoreoptimistic–theremightbeapractical', 'issue', 'concern', '’', 'ability', 'get', 'enough', 'data', 'generalize', 'perhaps', 'principle', 'limitationonwhatocanachieve.30', 'wetentativelyconcludethatthereisnoeasyapriorireasontothinkthatvarietiesofunder-', 'standingfallingunderanyofourthreepositionscouldnotbelearnedintherelevantway.with', 'thispossibilitythusstillopen', 'wefacethedifficultepistemologicalchallengeofclarifyinghowwe', 'couldhopetoevaluatepotentialsuccess', 'epistemologyofunderstanding', 'apositivefeatureofpragmatismisthat', 'byidentifyingsuccess', 'withthemanifestationofconcretebehaviors', 'thereisnogreatconceptualpuzzleabouthowtotest', 'forit.wesimplyhavetoconvinceourselvesthatourlimitedobservationsofthesystem', '’', 'sbehavior', 'sofarindicateareliabledispositiontowardthemoregeneralclassofbehaviorsthatwetookasour', 'target.ofcourse', 'agreeingonappropriatetargetsisverydifficult.whenconcreteproposalsare', 'make', 'theyareinvariablymetwithobjections', 'oftenafterputativesuccessisdemonstrated', 'thehistoryoftheturingtestisinstructivehere', 'althoughnumerousartificialagentshavepassed', 'actualturingtests', 'noneofthemhasbeenwidelyacceptedasintelligentasaresult.similarly', 'recentyears', 'anumberofbenchmarktaskswithinnlphavebeenproposedtoevaluatespecific', 'aspectsofunderstanding', 'e.g.', 'answeringsimplequestions', 'performingcommonsensereasoning', 'whensystemssurpassourestimatesofhumanperformance', 'thecommunity', '’', 'sresponseisgenerally', 'thatthetestwasflawed', 'notthatthetargetwasreached.theremaybesomesuiteofbehaviors', 'thatisourrealtarget', 'butitisjusthardtocircumscribeorturnintoapracticaltest.31thenagain', 'thismightrevealthatinternalismorreferentialsmarewhatwehadinmindallalong', '30onourreading', 'benderandkoller', '[', '2020', ']', 'allowthatmultimodaldatamightchangethescenario', 'especiallyifois', 'allowedtohavecooperativeinteractionswiththehumansaboutsharedscenariosandtopics', '31partofthedifficultymayalsorelatetothefactthattypicalhumansmakefrequenterrorsinmanyofthesedomains', 'butnotnecessarilythesametypesoferrorsthataremadebycurrentsystems.characterizingthetargetbehavioursmay', 'thusinvolvemorethanjustidentifyingthe', '“', 'correct', '”', 'behaviour']",51
Opportunities and Risks of Foundational Models - Stanford.pdf,"['52', 'centerforresearchonfoundationmodels', 'crfm', 'take', 'internalism', 'referentialism', 'ultimate', 'target', '–', 'gold', 'standard', 'understandingis–thenbehavioraltestswillalwaysbeatbestimperfectasameansofassessing', 'whetherunderstandinghasbeenachieved.theimperfectionsaretwo-fold.first', 'behavioraltests', 'willalwayshavegapsthatcouldallowunsophisticatedmodelstoslipthrough.second', 'asystem', 'mighthaveachievedthemappingthattheseviewsrequire', 'butwemaybeunabletoshowthiswith', 'behavioraltesting.recentexperienceswiththemodelgpt-3showhowchallengingthismight', 'become', 'dependingonthepromptoneuses', 'onecanseesurprisinglycoherentoutputsorutter', 'nonsense', 'andsopromptengineeringrequiresdeepexpertise', '[', 'rong2021', ']', 'thus', 'bothinternalismandreferentialismcallforstructuralevaluationmethodsthatallowusto', 'studytheirinternalrepresentations', 'probingthemforinformation', '[', 'tenneyetal.2019', 'man', 'et', 'al', '2020', ']', 'study', 'internal', 'dynamics', '[', 'sundararajan', 'et', 'al', ']', 'perhaps', 'actively', 'manipulatingthemaccordingtospecificexperimentalprotocolssupportingcausalinference', '[', 'vig', 'etal.2020', 'geigeretal.2020', ']', '.theremaybefundamentallimitationsonwhatwecanlearnfrom', 'practicalexperimentsabouttheinnerworkingsofacomplexfoundationmodel', 'butitisclearthat', 'thesemethodswillbeusefulwheneverourtargetalignswithinternalismorreferentialism', '2.6.4', 'movingthediscussionforward', 'itseemsclearthattherearenoeasyanswerstothequestionofwhetherfoundationmodelswill', 'ever', 'understand', 'language', 'even', 'begin', 'address', 'question', 'one', 'must', 'resolve', 'difficult', 'metaphysicalquestionaboutwhichthereareanumberofsubstantivelydistinctviews.themeta-', 'physicalquestionthenfeedsintoanepistemologicalquestionthatposesmanypracticalchallenges', 'nonetheless', 'theabovediscussiondoesinviteonepracticalconclusion', 'iffoundationmodelsare', 'pursuedasapathtolanguageunderstandinginartificialagents', 'thenmultimodaltrainingregimes', 'maywellbethemostviablestrategy', 'astheywouldseemthemostlikelytoprovidethemodelwith', 'therequisiteinformation.whetherself-supervisionthensufficesisacompletelyopenquestion']",52
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '53', '3', 'applications', 'capabilities', '§2', 'capabilities', 'foundation', 'model', 'indicate', 'potential', 'totransformvarioussectorsandindustries', 'extendingtheroleaiplaysinsociety', '§5', 'society', 'amongthemyriadapplicationswherefoundationmodelsmaybeapplied', 'wewillfocusonthree', 'disciplines—healthcare', '§3.1', 'healthcare', 'law', '§3.2', 'law', 'andeducation', '§3.2', 'law', '—thatare', 'allfoundationaltosocietalfunction.withineach', 'wediscusstheopportunitiesthatfoundation', 'modelsposeforthisdomainalongsidechallenges', 'e.g.', 'interpretability', '§4.11', 'interpretability', 'andconcerns', 'e.g.', 'privacy', '§4.7', 'security']",53
Opportunities and Risks of Foundational Models - Stanford.pdf,"['54', 'centerforresearchonfoundationmodels', 'crfm', '3.1', 'healthcareandbiomedicine', 'author', 'michihiroyasunaga', 'jinghuang', 'camiloruiz', 'yuhuizhang', 'girayogut', 'saahiljain', 'william', 'wang', 'yusufroohani', 'hongyuren', 'antoinebosselut', 'ehsanadeli', 'jureleskovec', 'russaltman', 'fig.12', 'foundationmodelsinhealthcareandbiomedicine.wevisualizeaninteractiveframeworkwhere', 'foundationmodelsenablevarioustasksacrosshealthcareandbiomedicinewhentrainedonmultimodal', 'datageneratedbyvarioussourcesinthehealthcareecosystem.thefirstcolumnlistsseveralsourcesofdata', 'includingcareproviders', 'payers', 'institutions', 'universities', 'non-profits', 'andgovernments', 'pharma', 'wearables', 'andmedicalpublications/forums.thesecondcolumnshowsseveraldatamodalitiesgeneratedbythedata', 'sources.theyincludeimages', 'e.g.', 'chestx-rays', 'videos', 'suchasultrasounds', 'graphsofchemicalcompounds', 'tablesforelectronichealthrecords', 'ehrs', 'textsuchasclinicalnotes', 'timeseriessuchasecgs', 'andgenetic', 'data.thethirdcolumnvisualizesafoundationmodeltrainedonsuchdataandthenappliedtohealthcare', 'andbiomedicinedownstreamtaskslistedinthefourthcolumn.thisprocesscangeneratenewdatathatwill', 'furtherimprovethefoundationmodel', 'hencethebidirectionalrelationbetweenthefoundationmodelsand', 'thetasks', 'healthcare', 'biomedicine', 'enormous', 'application', 'area', 'society', 'instance', 'expendituresaccountingfor17', '%', 'ofgrossdomesticproduct', 'gdp', 'intheus', '[', 'swensenetal.2011', 'vanhartskampetal.2019', 'keehanetal.2020', ']', '.bothhealthcare', 'whichfocusesonthedeliveryof', 'caretopatientsviadiagnosis', 'treatment', 'andhealthadministration', 'andbiomedicalresearch', 'focusesonthescientificunderstandingofdiseaseandthediscoveryofnewtherapies', 'demand', 'significantexpenses', 'time', 'andcomprehensivemedicalknowledge', '[', 'yuetal.2018', 'korngiebeland', 'mooney2021', ']', '.weenvisionthatfoundationmodelscanbeacentralstorageofmedicalknowledge', 'thatistrainedondiversesources/modalitiesofdatainmedicine', '[', 'krumholzetal.2016', 'soltanian-', 'zadeh2019', 'sureshetal.2020', ']', 'figure12left', 'andcanbequeried/updatedinteractivelybymedical', 'professionals', 'e.g.', 'healthcareprovidersandbiomedicalresearchersaccesspublishedfindingsand', 'uploadnewpublications', '[', 'ionescuetal.2020', ']', 'andqueriedbythepublic.asfoundationmodels', 'strong', 'adaptation', 'capabilities', 'e.g.', 'fine-tune', 'prompt', '[', 'brown', 'et', 'al', '2020', ']', 'efficiently', 'adapt', 'various', 'individual', 'task', 'healthcare', 'biomedicine', 'e.g.', 'question']",54
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '55', 'answeringappusedbypatients', '[', 'klasnjaandpratt2012', 'zhuetal.2019', 'danieletal.2019', 'liuetal', '2020a', ']', 'clinicaltrialmatchingsystem', '[', 'nietal.2015', 'harreretal.2019', 'becketal.2020', ']', 'accessedby', 'researchersandpatients', 'figure12right', '.thisway', 'foundationmodelscanbeacentralinterface', 'thatsupportsvariousinteractionsbetweendata', 'task', 'andpeopleinhealthcareandbiomedicine', 'therebyadvancingtheefficiencyandaccuracyofhealthcare/biomedicalapplications', '[', 'elbattahetal', '2021', ']', '.weelaboratetheseopportunitiesin§3.1.1', 'healthcare-tasksand§3.1.2', 'biomed-tasks', 'atthesametime', 'healthcare/biomedicalapplicationsposeuniquechallengesthatmotivatefur-', 'therresearchinfoundationmodels', 'suchasintegratingmultimodaldatainhealthcare/biomedicine', '[', 'miuraetal.2021', 'liuetal.2021a', ']', 'andobservingethicalandlegalregulationsinmedicine', 'pri-', 'vacy', 'safety', 'explainability', '[', 'guan', '2019', 'xu', 'et', 'al', '2019', ']', 'elaborate', 'challenge', '§3.1.3', 'healthcare-biomed-challenge', '3.1.1', 'opportunitiesinhealthcare', 'foundationmodelsmayimprovethedeliveryofcaretopatientsthroughhealthcareprovidersand', 'hospitals.currently', 'healthcarecostincreaseseveryyear', '[', 'keehanetal.2020', ']', 'andstudiesestimate', 'that30', '%', 'ofhealthcarespendingmaybewastefulduetoadministrativeinefficiencyandpreventable', 'medicalerrors', '[', 'kocher2021', ']', '.moreover', 'asthedemandforhealthcareincreases', 'thesocietyfacesa', 'seriousshortageinhealthcareproviders', '[', 'kirchandpetelle2017', ']', '.thisinefficiencyandshortagein', 'healthcarenecessitatedevelopingfastandaccurateinterfacesforhealthcareprovidersandpatients', 'suchasautomatedaidsystemsfordiagnosis/treatment', 'summarizationofpatientrecords', 'answeringofpatientquestions', '[', 'davenportandkalakota2019', 'nieetal.2018', 'wangetal.2021b', ']', '.in', 'particular', 'inanurgentpandemiccrisissuchascovid-19', 'fastdiagnosis/screening', 'e.g.', 'automatic', 'analysisofchestx-rayimages', 'aswellasautomatedquestionansweringforpatients', 'e.g.', 'symptom', 'checkingandcare', 'andthepublic', 'e.g.', 'diseaseprevention', 'arevitaltoreducethespreadofdiseases', 'andallocatehealthcareresourcesforcriticalpatients', 'savingmorelives', '[', 'lalmuanawmaetal.2020', ']', 'foundation', 'model', 'strong', 'capability', 'serve', 'integrate', 'knowledge', 'reservoir', 'theycanbequeriedandadaptedtovariousindividualtasksinhealthcare.belowareexamplesof', 'importanttasksinhealthcarethatwouldbenefitfromfoundationmodels', 'interfaceforhealthcareproviders', 'foundationmodelscanimprovetheefficiencyandaccuracy', 'ofcarebyproviders.healthcareprovidersspendunnecessarytimeeditingelectronicheathrecords', 'ehrs', '[', 'kocher2021', ']', 'andpreventablemedicalerrors', 'e.g.', 'hospitalreadmissions', 'surgicalerrors', 'causewastesinhealthcare', '[', 'shranketal.2019', 'shahetal.2020', ']', '.foundationmodelscanbeadapted', 'asanefficientandaccurateinterfaceintoehrs', 'clinicalnotes', 'labvaluehistoriesandimagingfiles', '[', 'lietal.2020c', 'steinbergetal.2021', 'percha2021', ']', 'helpinghealthcareproviderscreatesummaries', 'ofpatientvisitation', '[', 'krishnaetal.2020', ']', 'retrievingrelevantcasesandliterature', 'andsuggesting', 'labtests', 'diagnosis', 'treatmentsanddischarges', '[', 'zhangetal.2019b', 'rasmyetal.2021', ']', '.foundation', 'modelscanalsobeadaptedtohelpasurgicalrobotmonitorandachieveaccuratesurgeries', '[', 'diana', 'andmarescaux2015', 'agrigoroaieandtapus2016', 'yuetal.2019', ']', '.see§2.3', 'roboticsformore', 'discussionsonfoundationmodelsforrobotics', 'interfaceforpatients', 'foundationmodelscanbeadaptedtoserveasaninterfacetopatients', 'pro-', 'vidingrelevantinformationaboutclinicalappointments', '[', 'bates2019', ']', 'answeringpatientquestions', 'relatedtopreventivecare', '[', 'demner-fushmanetal.2020', ']', 'alongwithrelevantmedicalexplana-', 'toryinformation', 'e.g.', 'textandgraphicsthatexplainconditions', '[', 'chaixetal.2019', ']', 'andhelping', 'assistive-carerobotsforpatients', '[', 'jeongetal.2015', 'abdietal.2018', ']', '.see§2.5', 'interactionfor', 'morediscussiononfoundationmodelsforuserinteraction.foundationmodelscanalsoserveas', 'aninterfacewiththegeneralpublictoanswerquestionsrelatedtopublichealthandpandemic', 'prevention', 'suchasthecovid-19case', '[', 'bhartietal.2020', 'herrimanetal.2020', ']', '.atthesametime']",55
Opportunities and Risks of Foundational Models - Stanford.pdf,"['56', 'centerforresearchonfoundationmodels', 'crfm', 'wenotethattheinterfacemustguaranteefactualaccuracytoensurepublictrustinmedicaladvice', '[', 'krepsandkriner2020', ']', 'see§3.1.3', 'healthcare-biomed-challenge', '3.1.2', 'opportunitiesinbiomedicine', 'foundationmodelsmayfacilitatebiomedicalresearchsuchasdiscoveryofdrugsandunderstanding', 'diseases', 'ultimately', 'translate', 'improve', 'healthcare', 'solutions', '[', 'hanney', 'et', 'al', ']', 'currently', 'biomedical', 'discovery', 'require', 'significant', 'human', 'resources', 'experimental', 'time', 'financialcosts.forinstance', 'drugdevelopmentinvolvesacomplexprocess', 'frombasicdrugresearch', 'ofproteintargetidentificationandpotentmoleculediscoverytoclinicaldevelopment', 'e.g.', 'clinical', 'trials', 'tothefinaldrugapproval', 'whichtypicallytakesover10yearsandcostsmorethanonebillion', 'dollars', '[', 'woutersetal.2020', ']', '.facilitatingandacceleratingbiomedicaldiscoveryusingexistingdata', 'andpublishedfindingsisanimperativeprobleminbiomedicine', '[', 'yuetal.2018', ']', '.inparticular', 'anovel', 'diseaseoutbreaksuchascovid-19costsmillionsoflivesandtrillionsofdollars', '[', 'lalmuanawma', 'etal.2020', 'mckibbinetal.2020', ']', 'ifwecanspeedupdrugdevelopmentfornewdiseases', 'thatwould', 'beveryhelpful.foundationmodelscanbeparticularlyhelpfulforbiomedicaldiscoveryintwo', 'aspects.first', 'foundationmodelshaveastronggenerativecapability', 'e.g.', 'coherenttextgeneration', 'ingpt-3', 'whichcanhelpgenerativetasksinbiomedicalresearchsuchasgeneratingexperimental', 'protocols', 'clinicaltrials', 'anddesigningmoleculesthatwork', 'drugdiscovery', 'givenexistingdata', '[', 'kadurinetal.2017', 'harreretal.2019', ']', '.second', 'foundationmodelshaveapotentialtointegrate', 'diversedatamodalitiesinmedicine', 'whichenablesinvestigatingbiomedicalconcepts', 'e.g.', 'disease', 'frommultiplescales', 'usingmolecule-', 'patient-andpopulation-leveldata', 'andmultipleknowledge', 'source', 'usingimaging', 'textualandchemicaldescriptions', '.thisfacilitatesbiomedicaldiscoveries', 'thataredifficulttoobtainifusingsingle-modalitydata', '[', 'lanckrietetal.2004', 'aertsetal.2006', 'kongetal.2011', 'ribeiroetal.2012', 'wangetal.2014,2015c', 'ruizetal.2020', 'wuetal.2021h', ']', 'foundationmodelsalsoenabletransferknowledgeacrossmodalities.luetal', '[', '2021a', ']', 'showedhow', 'atransformermodeltrainedonnaturallanguage', 'adata-richmodality', 'couldbeadaptedforother', 'sequence-basedtaskssuchasproteinfoldprediction', 'whichisalong-studiedpredictivetaskin', 'biomedicine', '[', 'jumperetal.2020', ']', '.belowareexamplesofimportanttasksinbiomedicinethatwill', 'benefitfromfoundationmodels', 'drugdiscovery', 'todiscoveradrugoratherapeuticthattreatsadisease', 'researchersmustfirst', 'identifyatarget', 'e.g.', 'proteins', 'genes', 'rnacausallyimplicatedinthedisease', 'andmustthensearch', 'formolecules', 'e.g.', 'chemicalcompounds', 'antibodies', 'thatbindtothetargetandtreatthedisease', 'typically', 'identifyingtheappropriatetargetandgeneratingacorrespondingmoleculerequires', 'yearsofexpensivewetlabexperiments', '[', 'hughesetal.2011', 'schenoneetal.2013', 'schneider2018', ']', 'foundationmodels', '’', 'generativitycanimprovethesearchspaceandefficiency', 'see§2.4', 'reason', 'reduce', 'amount', 'experiment', 'also', 'help', 'discover', 'new', 'better', 'drug', '[', 'jinetal.2018', 'youetal.2018', 'waltersandbarzilay2020', 'stokesetal.2020', ']', '.moreover', 'thesimultaneoussolutionofrelateddrugdiscoveryproblems', 'i.e.', 'targetidentification', 'efficacy', 'prediction', 'side', 'effect', 'prediction', 'others', 'single', 'foundation', 'model', 'may', 'improve', 'solutionstoeachofthem', '[', 'ramsundaretal.2015', 'camachoetal.2018', 'duran-frigolaetal.2020', 'huangetal.2021a', ']', '.asanexample', 'oneareawherefoundationmodelshaveshownsignificant', 'potential', 'impact', 'therapeutic', 'design', 'model', 'proteins', 'use', 'language', 'model', 'successfulapplicationsrangefrompredictingviralmutationsthatcanescapeavaccine-induced', 'immuneresponsetopredictingproteindockingpotentialforbetterdesignoftherapeuticantibodies', '[', 'beplerandberger2021', 'hieetal.2021', 'tsabanetal.2021', 'wuetal.2021b', 'rivesetal.2021', ']', 'personalizedmedicine', 'personalizedmedicineaimstoselecttheoptimaltreatmentforindividual', 'patientsbasedontheirhealthhistory', 'genetics', 'image', 'andotherpersonalmeasurements', '[', 'collins']",56
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '57', 'andvarmus2015', 'ashley2016', ']', '.forinstance', 'givenasetofdrugsandapatientgenome', 'foundation', 'model', 'may', 'help', 'predict', 'drug', 'likeliest', 'treat', 'patient', 'minimal', 'side', 'effect', '[', 'whirl-carrilloetal.2012', 'tatonettietal.2012', 'gerstungetal.2017', 'grinfeldetal.2018', 'adametal', '2020', ']', '.foundationmodelsareuniquelypowerfulintheirabilitytointegratemultimodalpatient', 'datarangingfromtheehr', '[', 'rajkomaretal.2018', ']', 'tomedicalimaging', '[', 'beraetal.2019', 'ouyang', 'etal.2020', ']', 'todrugandmolecularmeasurements', '[', 'gottliebetal.2011', 'ruizetal.2020', ']', 'tomakean', 'optimalprediction', 'clinicaltrials', 'clinicaltrialsstudyefficacyandsafetyoftreatmentordrugcandidates.conven-', 'tionalclinicaltrialsareinefficientandcostly:80', '%', 'oftrialsfailduetoinabilitytoshowefficacy/safety', 'orproblemswithpatientmatching', '[', 'alietal.2020', 'liuetal.2021c', ']', '.foundationmodelscanhelpin', 'thefollowing', 'predictingpotentialfailuresanddesignpromisingclinicaltrialprotocols', 'e.g.', 'patient', 'eligibilitycriteria', 'basedonexistingstudies', 'andautomatingmatchingofeligiblepatientsbasedon', 'patientindividualprofiles', 'whicharemultimodaldataincludingehrs', 'genesequence', 'etc', '[', 'harrer', 'etal.2019', ']', '3.1.3', 'challengesandfutureresearchinfoundationmodels', 'potential', 'opportunities', 'foundation', 'model', 'help', 'healthcare/biomedical', 'applicationsalsoposeuniquechallengesthatmotivatefurtherresearchinfoundationmodels', 'multimodality', 'medicaldataarehighlymultimodal', 'withvariousdatatypes', 'text', 'image', 'video', 'database', 'molecule', 'scale', 'molecule', 'gene', 'cell', 'tissue', 'patient', 'population', '[', 'kong', 'et', 'al', '2011', 'ruizetal.2020', ']', 'andstyles', 'professionalandlaylanguage', '[', 'lavertuandaltman2019', 'lietal', '2019a', ']', '.currentself-supervisedmodelsaredevelopedforeachmodality', 'e.g.', 'text', '[', 'leeetal.2020d', ']', 'image', '[', 'chaitanyaetal.2020', ']', 'gene', '[', 'jietal.2021', ']', 'protein', '[', 'jumperetal.2020', ']', 'anddonotjointly', 'learnfromdiversemodalities.tolearntheinter-modalityandcross-modalityinformationfrom', 'thesediversemultimodalmedicaldata', 'weneedtoinvestigatebothfeature-levelandsemantic-level', 'fusionstrategiesinthetrainingoffoundationmodels.ifdoneeffectively', 'thishasapotentialto', 'unifybiomedicalknowledgeandfacilitatediscoveriesasdiscussedin§3.1.2', 'biomed-tasks', 'explainability', 'explainability—providingevidenceandlogicalstepsfordecisionmaking—is', 'crucialinhealthcareandbiomedicine', '[', 'holzingeretal.2019', ']', 'andismadeobligatoryunderthe', 'generaldataprotectionregulation', 'gdpr', '.forinstance', 'indiagnosisandclinicaltrials', 'patient', 'symptomsandtemporalrelevancemustbeexplainedasevidence.thishelpstheresolutionof', 'potentialdisagreementbetweenthesystemandhumanexperts.explainabilityisalsoneededfor', 'informedconsentinhealthcare', '[', 'amannetal.2020', ']', '.however', 'currentfoundationmodels', '’', 'train', 'objectivesdonotincludeexplainability', 'requiringfutureresearchinthisdirection', '[', 'linardatosetal', '2021', ']', '.incorporationofknowledgegraphsmaybeasteptofurtherimprovemodelexplainability', '[', 'robertsetal.2020', 'xuetal.2020', 'jinetal.2021', ']', '.readersarereferedto§4.11', 'interpretability', 'formorediscussiononexplainability', 'legalandethicalregulations', 'healthcareapplicationsmustobservelegalandethicalregulations', 'withguarantees', 'suchaspatientsafety', 'privacyandfairness.forinstance', 'regardingsafety', 'predic-', 'tionsmadebyfoundationmodelsmustbefactuallyaccuratewithestablishedmedicalknowledge', 'andmustquantifyuncertaintyorchoosetodefertoanexpertwhenuncertain', '[', 'challenetal.2019', 'mozannarandsontag2020', ']', '.forprivacy', 'theuseofpatienthealthrecordsmustobservetheprivacy', 'laws', 'suchashipaa', '[', 'act1996', ']', 'inthecaseoftheus.federatedlearningisonepotentialsolutionto', 'keepingtheraw', 'sensitivedataprivateinthetrainingoffoundationmodels', '[', 'chamikaraetal.2021', ']', 'forfairness', 'researcherswillneedtobemindfulofcommonpitfallsorotherwiseriskexacerbating', 'exist', 'social', 'inequalities', '[', 'chen', 'et', 'al', '2019', 'wiens', 'et', 'al', '2019', 'chen', 'et', 'al', '2020b', ']', 'must']",57
Opportunities and Risks of Foundational Models - Stanford.pdf,"['58', 'centerforresearchonfoundationmodels', 'crfm', 'ensurethatthetrainingandevaluationdataforfoundationmodelsissufficientlyrepresentativeof', 'differentsexes', 'race', 'ethnicitiesandsocioeconomicbackgrounds', 'anareawheremedicaldatasets', 'andclinicaltrialshavehadalonghistoryofbias', '[', 'martinez-martinetal.2020', 'kaushaletal.2020', ']', 'researchisalsoneededtodebiasandregularizemodelstoensurefairnesswhenrepresentative', 'dataisscarce', '[', 'zhaoetal.2020a', ']', '.foundationmodeldevelopersalsoneedtoconsultwithethics', 'andlawresearchers', 'andobserveregulationsinthespecificcircumstances', 'e.g.', 'country', 'region', 'wheretheyaredeployed.wealsoreferreadersto§4.7', 'security', '§4.8', 'robustness', '§5.1', 'fairness', '§5.4', 'legalityfordetailsonprivacy', 'robustness', 'fairnessandlegality', 'extrapolation', 'theprocessofbiomedicaldiscoveryinvolvesextrapolation.forinstance', 'founda-', 'tionmodelsmustbeabletoquicklyadapttonewexperimentaltechnologies', 'e.g.', 'newassays', 'new', 'imagingtechniquessuchashighresolutionmicroscopy', 'ornewsettings', 'e.g.', 'newtargetdiseases', 'suchascovid-19', '[', 'jarochetal.2018', 'benametal.2019', ']', '.theabilitytoleverageexistingdatasets', 'andextrapolatetonewsettingsisakeymachinelearningchallengeinbiomedicine', '[', 'snelletal', 'maetal.2021b', ']', '.whilegpt-3exhibitssomeextrapolationbehaviors', 'e.g.', 'generatingnew', 'textnotseenbefore', 'itsmechanismisunclearandstillinitsinfancy.furtherresearchisneeded', 'forimprovingtheextrapolationcapabilityoffoundationmodels', 'especiallywhenconsideringthe', 'diverserangeofdatamodalitiesandtasksthatisinherenttohealthcareandbiomedicinebutisnot', 'commonlystudiedincurrentgpt-3andrelatedmodels.alsosee§4.8', 'robustness']",58
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '59', '3.2', 'law', 'author', 'peterhenderson', 'luciazheng', 'jennyhong', 'neelguha', 'markkrass', 'juliannyarko', 'daniele', 'ho', 'fig.13', 'anexampleofvariousstepsofacivilcaseintheunitedstatesandwherefoundationmodelsmight', 'help.ateachstagedifferentmodalitiesmightneedtobeprocessedandadaptationisneededtoanewcourt', 'orlegalperspective', 'fromfamilycourttocriminaljusticeandfromenvironmentalpolicytocorporatetransactions', 'thereachofthelawisvast.intheunitedstates,32', 'thereareover1.3mlawyers', '[', 'americanbar', 'association2021', ']', 'andannualrevenuesforlegalservicesexceed', '$', '300b', '[', 'marketline2021', ']', '.yet', '“', 'accesstojustice', '”', 'remainsfaroutofreachformost.legalservicescanbeprohibitivelyexpensive', 'roughly86', '%', 'oflow-incomeindividualswithcivillegalproblemsintheunitedstates', 'forinstance', 'reportreceivinginadequateornolegalhelp', '[', 'legalservicescorporation2017', ']', '.evenwhencounselis', 'appoint', 'lawyersmightbestrainedbyincreasinglylargecaseloads.studieshaveshownthatpublic', 'defenders', 'forexample', 'areoftenoverworkedandunderfunded', '[', 'lefsteinandspagenberg2009', 'schumm2012', 'americanbarassociation2004', ']', '.theu.s.departmentofjusticereportedthatin2007', '73', '%', 'ofcounty-basedpublicdefenderofficesexceededthemaximumrecommendedlimitofcases', 'receivedperattorneyand15of19reportingstatepublicdefenderprogramsexceededthemaximum', 'recommend', 'limit', 'felony', 'misdemeanor', 'case', 'attorney', '[', 'farole', 'langston', '2010', 'langstonandfarole2010', ']', '.eveninacountrywithoneofthehighestpercapitaratesofattorneys', 'justicecanappearoutofreach.u.s.presidentjimmycarteronceopined', '“', 'ninetypercentofour', 'lawyersservetenpercentofourpeople.weareoverlawyeredandunderrepresented', '”', '[', 'carter1978', ']', 'accordingtoaleadingvoiceinaccesstojustice', 'technologymayprovideapathforward', '[', 'rhode', '2014', ']', 'aviewechoedbymanyothers', '[', 'cabraletal.2012', ']', 'whatrolemightfoundationmodelsplayinthelaw', '?', '33amajorpromiseisthatfoundationmodels', 'canimproveaccesstojusticeandgovernmentservicesbylevelingproceduralandfinancialbarriers', 'tolegalservices.thechallengesposedbylegalapplicationscan', 'inturn', 'motivatebasicresearch', 'questionsforfoundationmodels.manylegalapplicationsposeuniquechallengestocomputational', 'solutions.legallanguageisspecializedandlegaloutcomesoftenrelyontheapplicationofambigu-', 'ousandunclearstandardstovariedandpreviouslyunseenfactpatterns.atthesametime', 'dueto', '32werestrictourdiscussiontolegalapplicationsintheunitedstatesbecauseoftheexpertiseoftheauthors.some', 'discussionheremayapplytolegalvenuesglobally', 'however', '33wenotethatforthepurposesofthissectionweconsiderfoundationmodelstobeanyself-supervisedpretrainedmodel', 'thatisusedtoquicklyadapttonewcontextswithlittlesupervisedlearning.seealsothediscussionin§1', 'introduction', 'and§2.6', 'philosophyforanexpandeddefinition']",59
Opportunities and Risks of Foundational Models - Stanford.pdf,"['60', 'centerforresearchonfoundationmodels', 'crfm', 'itshighcosts', 'labeledtrainingdataisscarce.dependingonthespecifictask', 'theseidiosyncrasies', 'canposeinsurmountableobstaclestothesuccessfuldeploymentoftraditionalmodels.incontrast', 'theirflexibilityandcapabilitytolearnfromfewexamplessuggestthatfoundationmodelscouldbe', 'uniquelypositionedtoaddresstheaforementionedchallenges', 'throughoutthissection', 'foundationmodelsmaytakeascontextmanymodalitiesasevidence', 'audioduringtrialproceedings', 'videoandimagesduringdiscovery', 'andtextinconductinglegal', 'research.yet', 'themajorityoflegaltasksinwhichrelianceonfoundationmodelswillbebeneficial', 'involvetext-basedinputsandoutputs.assuch', 'wemainlyfocusontext-baseddomainswhileonly', 'brieflydiscussingothers.togroundthediscussion', 'figure13describesthestagesofacivillawsuit', 'intheunitedstatesandwherefoundationmodelsmightcomeintoplayinthisprocess.figure14', 'showsthelogicflowrequiredtogeneratejustpartofoneparagraphofalegalbrief', 'whichmight', 'serveasaconcreteexampleofataskthatfoundationmodelsmightonedaybeusedfor', 'important', 'consideration', 'proceed', 'note', 'ethical', 'legal', 'fairness', 'considerationsexpandedonin§5.6', 'ethics', '§5.4', 'legality', 'and§5.1', 'fairnessareparticularly', 'importanttoexaminebeforeusingfoundationmodelsinanappliedlegalorgovernmentcontext', 'astheseapplicationsoftenhaveimportant', 'real-worldconsequencestothoseaffected', '[', 'surden', '2020', ']', '.foundationmodelsmustalsobethoroughlyscrutinizedbeforedeployment', 'asdiscussedin', '§4.4', 'evaluation.forexample', 'thelegalsystemplacesparticularemphasison—andmayeven', 'mandate—transparency', 'accountability', 'andexplainability.consequently', 'itisquestionablewhether', 'currentmodelsarepositionedtosolvemanyofthemostpressing', 'legalproblems.nonetheless', 'needtoexpandandimproveaccesstolegalandgovernmentservicesprovidesaworthygoalfor', 'foundationmodels', '3.2.1', 'opportunitiesinlaw', 'legalapplicationscanrangefromtheuseofmachinelearningingovernmentcontexts', '[', 'engstrom', 'etal.2020', 'coglianeseandbendor2020', 'reandsolow-niederman2019', ']', 'toaidinglawyersintheir', 'provisionoflegalservices', '[', 'zhengetal.2021', 'huangetal.2021b', 'ostendorffetal.2021', 'voldand', 'conrad2021', ']', '.wenotethatpriorworkhasalsosurveyedmachinelearning-assistedlegaltasksin', 'text-baseddomains', '[', 'zhongetal.2020', 'chalkidisetal.2020', ']', 'althoughithasbeennotedthatrecent', 'legalairesearchhasfocusedongeographicregionsoutsideoftheu.s', '[', 'zhengetal.2021', ']', '.while', 'manyofthetopicswediscussheremaybeapplicabletodifferentlegalsystems', 'duetotheexpertise', 'ofourteamwefocusprimarilyontheu.s.inparticular', 'weconcentrateonthreebroadcategories', 'oflegalapplicationsthatmaybenefitfromfoundationmodelsintheu.s.legalsystem', 'privatelaw', 'orciviljustice', 'claimsbetweenprivateindividuals', 'arisingoutof', 'forinstance', 'contract', 'property', 'ortorts', 'criminallaw', 'i.e.', 'theprosecutionofindividualsforcriminalbehavior', 'non-criminal', 'publiclaw', 'e.g.', 'theregulationofprivatebehaviorbygovernmentagencies', 'civillaw', 'inu.s.civilproceedings', 'partiesmusttypicallyfindandpayattorneystoberepresented', 'asaresult', 'manyindividuals', 'especiallythosewithlowincome', 'struggletosecureadequatelegal', 'representation', '[', 'rhode2004', ']', '.foundationmodelshavethepotentialtoimproveaccesstojusticeby', 'reducingthecost', 'improvingthequality', 'andextendingthereachoflegalservices.infigure13', 'describetheprocessbywhichacivillawsuitisfiledinau.s.courtandwherefoundationmodels', 'mayplayaroleinaidingbothattorneysandjudges', 'evenbeforeanattorneyisinvolvedinthelegalprocess', 'clientsmaybenefitfromthedeployment', 'offoundationmodels.recentworkhasusedmachinelearningmodelstoidentifytherelevantlegal', 'issuescontainedinaplain-languagedescriptionoffactspresentedbyaclient.34toolslikethese', 'canhelpprovidearecommendationforthetypeoflegalactionneededtoaddresstheissueathand', '34https', '//spot.suffolklitlab.org/']",60
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '61', 'ortorecommendaspecializedattorney.anumberofothersimilareffortshavesoughttoincrease', 'accesstojusticebyprovidinginformationtailoredtoaclient', '’', 'sparticularneeds', '[', 'cabraletal.2012', 'bresciaetal.2014', 'queudotetal.2020', 'westermannetal.2019', ']', 'onceaclientspeakswithanattorney', 'priortocivillitigation', 'theattorneymayseektoavoida', 'costlytrial.atthisstage', 'theycanrelyonfoundationmodelstoevaluatecontracts', 'reviewterms', 'service', 'find', 'relevant', 'patent', 'conduct', 'pre-litigation', 'process', 'order', 'ensure', 'thattheirclientsareatanadvantage', '[', 'bettsandjaep2017', 'elwanyetal.2019', 'lippietal.2019', 'leeandhsiang2019', 'hendrycksetal.2021c', 'hegeletal.2021', ']', '.notably', 'recentworkhasboth', 'describedthechallengesandbenefitsofusingfoundationmodelsforcontractreview', '[', 'leivaditi', 'etal.2020', 'hegeletal.2021', 'hendrycksetal.2021c', ']', '.inadditiontoreviewinganddraftinglegal', 'document', 'clientinteractionsanddocumentscanbetranslatedtoreducecostsandbarrierstothe', 'provisionoflegalservices', '[', 'cuéllar2019', ']', '.buttranslationoflegaldocumentsrequiresprecision', 'andanunderstandingofhighlytechnicallanguage', 'whichmakescollectingtrainingdatacostly', 'additionally', 'translatingclientstatementsortrialproceedingsoftenrequiresanunderstandingof', 'localdialectsandlanguage.this', 'makesitdifficulttocollectenoughgroundtruthtranslation', 'datatotrainon.asaresult', 'traditionalsupervisedmethodsrarelyachievethelevelofaccuracy', 'requiredinthelegaldomain', '[', 'vieiraetal.2020', ']', '.foundationmodelsmayimproveperformancein', 'thisareaoverfullysupervisedmechanismsbyadaptingquicklyintheselow-resourcecontexts', 'duringlitigation', 'foundationmodelscanhelplawyerstoconductlegalresearch', 'draftlegallan-', 'guage', 'orassesshowjudgesevaluatetheirclaims', '[', 'zhengetal.2021', 'huangetal.2021b', 'ostendorff', 'etal.2021', 'voldandconrad2021', 'chalkidisetal.2020,2019', ']', '.thiscouldpotentiallyreducethe', 'costsofandimprovelegalservices.forexample', 'recentworkhasutilizedpretrainedmodelsforthe', 'recommendationofrelevantcitationsandholdingstatementswhenwritinglegaltexts', '[', 'zhengetal', '2021', 'huangetal.2021b', 'ostendorffetal.2021', ']', '.otherworkusespretrainedmodelsforimproved', 'legalquestionansweringtopowercommonlyusedlegalsearchenginesandhelplawyersconduct', 'legal', 'research', '[', 'vold', 'conrad', '2021', ']', 'wide', 'variety', 'work', 'also', 'examine', 'automate', 'contractdraftingandreview', 'ataskthatcouldsimilarlybenefitfromfoundationmodels', '[', 'hendrycks', 'etal.2021c', 'bettsandjaep2017', ']', '.perhapsmostcompelling', 'foundationmodelsmayhelpassist', 'lawyers', 'generate', 'legal', 'brief', 'write', 'arguments', 'model', 'might', 'find', 'novel', 'arguments', 'identifyproblemsinattorney-writtenportionsofthebrief.forexample', 'tippettetal', '[', '2021', ']', 'predict', 'theoutcomeofalegalproceedingbasedonfeaturesextractedfromthefiledbriefs.foundation', 'modelscanbeleveragedtouserawlanguageasinputsratherthanextractedfeatures.thismight', 'provideattorneyswithmoreinformativerecommendationsastohowtheirbriefcouldbeimproved', 'toensureafavorableoutcome', 'afteropeningandreplybriefsarefiled', 'partiesthenbeginthediscoveryprocess', 'whichhas', 'already', 'use', 'simple', 'machine', 'learn', 'model', 'better', 'part', 'decade', '[', 'grossman', 'cormack2010', ']', '.attorneysusethesesystemstolabelwhetheradocumentshouldbeproducedto', 'theopposingparty.thedocumentsaremulti-modalinnature', 'oftencontainingvideo', 'image', 'audio', 'andtext.currentsystemsarecostlybecausetheyusedsupervisedlearningandactivelearning', 'tolabelthedocumentsasresponsive', '[', 'grossmanandcormack2010', 'oardetal.2018', 'yangetal', '2021', ']', '.instead', 'few-shotorzero-shotdocumentretrievalcapabilitiesthatmightbepossiblewith', 'foundationmodelswouldhelpeaseconcernsaboutthelargecostsofthecurrentprocess.35toavoid', 'thepossibilitiesofgamesmanshipinthediscoveryprocess', 'cui', '[', ']', 'hasproposedazero-shot', 'orfew-shot', 'adaptationprocessthatcanonlybeoperationalizedthroughtheuseoffoundation', 'model', '35https', '//www.kirkland.com/publications/article/2020/04/technology-assisted-review-framework']",61
Opportunities and Risks of Foundational Models - Stanford.pdf,"['62', 'centerforresearchonfoundationmodels', 'crfm', 'afterdiscovery', 'oncethetrialbegins', 'foundationmodelscouldhelppartiespreparefortrial', 'bypredictingwhatthejudgemightfocusonduringquestioning', '[', 'dickinson2018', ']', 'adaptingto', 'thecurrentcontextfromjudges', '’', 'priorpublishedopinions.inthecourtroom', 'foundationmodels', 'mightbeusedtoexamineaudioandvideoofcourtroomproceedingstodetermineifoutcomes', 'werebiasedagainstthedefendantbecauseoftheirraceordialect.36', 'oncethetrialconcludes', 'foundationmodelscouldhelpjudgesandlawclerkstoproperlyevaluate', 'legalclaimsfrombothpartiesusingsimilartechnologies', 'ortheuseofcontextualembeddingsfrom', 'foundationmodelsmightassistinstatutoryinterpretation', '[', 'nyarkoandsanga2020', 'choi2020', ']', 'recentwork', 'withoutrelianceonfoundationmodelsornlp', 'hasexaminedwhetheranappeals', 'decisioncanbepredictedfromasetofextractedfeatures', 'likecitationcountsandtheappearance', 'ofkeywords', '[', 'katzetal.2017', 'bonioletal.2020', ']', '.itispossiblethatsuchmodelscouldbeimproved', 'usingfoundationmodelsandappliedtohelpjudgesdraftdecisionsbyflaggingobviousmistakesin', 'theiropinion', 'ashasbeendiscussedinthecontextofadjudicativeagencies', '[', 'engstrometal.2020', 'rayandlubbers2014', ']', '.theycanalsobeusedtoidentifyracialbiasesinlegalopinionsandhelp', 'judgesrevisetheiropinionsaccordingly', '[', 'riceetal.2019', ']', 'criminallaw', 'oneparticularlycontentiousareahasbeentheuseofriskscoresingovernment', 'settings', 'particularlyincriminallaw.somemaywanttouselanguage-basedfoundationmodels', 'toaidinmakingchargingdecisionsorparoledecisionsbasedonagiventext-basednarrativeof', 'theevents.carefulconsiderationmustbetakenbeforeusingfoundationmodelsforriskscoring', 'duetothepotentialforbiases', 'especiallywhenlanguagedataisincluded', '[', 'benderetal.2021', 'berk', 'et', 'al', '2021', 'laufer', '2020', ']', 'foundation', 'model', 'may', 'play', 'role', 'many', 'dimension', 'criminaljustice.thesametoolsasincivillitigation', 'canalsobeusedbyprosecutorsand', 'defenseattorneys.thiscanhelpappointedattorneysperformtheirjobmoreefficientlyandreduce', 'unnecessary', 'overhead', 'result', 'may', 'able', 'balance', 'already', 'heavy', 'caseloads', 'effectively.forexample', 'publicdefendersareoftenviewedasbeingoverworkedandunderfunded', 'whichwouldleadtoavoidableproceduralerrors.37', 'foundationmodelscanhelpreducesomeof', 'theseresourceconstraintsbyidentifyingerrorsandautomatingsimpletasks.however', 'theyare', 'notasolutionontheirown', 'areas', 'foundation', 'model', 'act', 'oversight', 'mechanism', 'reduce', 'structural', 'inequities', 'pretrained', 'model', 'use', 'process', 'parole', 'hear', 'transcripts', 'find', 'instancesofanomalousoutcomes', '[', 'belletal.2021', ']', '.recentworkhasalsoremovedlinguisticcues', 'forasuspect', '’', 'sraceinpolicereportstopromoterace-blindchargingdecisionsandavoidracially', 'biasedprosecutions', '[', 'chohlas-woodetal.2020', ']', '.otherworkhashelpedidentifydisrespectfulpolice', 'communications', '[', 'voigtetal.2017', ']', '.inthesecontexts', 'itisverycostlytolabeldatasinceannotators', 'mustbegivenaccesstosensitivedataandappropriatebackgroundchecksareoftenrequired.to', 'reducethesecosts', 'foundationmodelscanbeusedtopretrainandadaptquicklytodownstream', 'taskswherelabelsarescarce', 'publiclaw', 'governmentagenciesregulatevastpartsofsociety', 'andfoundationmodelshavewide', 'potentialapplicabilityacrosspubliclaw.thisincludes', 'analyzingpubliccommentsinthenotice-', 'and-commentprocess', 'assistingpatentexamination', 'retrievingrelevantdocumentsinresponseto', 'freedomofinformationactrequests', 'aidinginmassadjudication', 'amongmanyothers.recent', 'workhassurveyedthesegovernmentapplicationsinavarietyofcontextsandwereferthereader', '36forexample', 'speakingafrican-americanvernacularenglishdialectsinthecourtroomhasbeenshownasapotential', 'sourceofbiasduringtrial.https', '//www.nytimes.com/2019/01/25/us/black-dialect-courtrooms.html', '37see', 'forexample', 'inpeoplev.superiorcourt', 'vasquez', ',27cal.app.5th36', 'adefendantdidnotreceiveatrialfor', '17yearsbecausethepublicdefender', '’', 'sofficehadseverebudgetcutsandunderstaffing.thecourtruledthatthesystemic', 'breakdowninthepublicdefender', '’', 'sofficeconstitutedadueprocessviolationandthedefendant', '’', 'scasewasdismissed']",62
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '63', 'totherelevantsourcesforin-depthdiscussion', '[', 'engstrometal.2020', 'coglianeseandbendor2020', ']', 'inmanyoftheseapplications', 'foundationmodelscanimprovethequality', 'efficiency', 'utility', 'accessibilityofgovernmentservices', 'labelsarescarce', 'resourcesareconstrained', 'andcontextsare', 'constantlyshifting.assuch', 'theadaptabilityandflexibilityoffoundationmodelsareoftenrequired', 'toimproveefficiencyandperformance.togiveanillustrativeexampleofjustonesuchapplication', 'existingworkhasleveragednlpforfacilitativemoderationinpubliccommentforums.inthis', 'usecase', 'predictivemodelshelplay-usersimproveargumentsandidentifymisstatementsintheir', 'comments.suchasystemhasalreadybeendeployedintheu.s.departmentoftransportation', 'rulemakingprocess', '[', 'parketal.2012', ']', 'althoughitcanlikelybeimprovedthroughthelinguistic', 'reasoningcapabilitiesoffoundationmodels.butgovernmentagenciesmustcomplywithconstitu-', 'tional', 'statutory', 'andadministrativeobligations', 'see§5.4', 'legality', 'soadditionalcareisneededin', 'thesesettings', '3.2.2', 'howcanfoundationmodelsuniquelyhelp', '?', 'theaboveexamplesoflegalapplicationsareuniqueinseveralways.first', 'thecostofannotating', 'dataisveryhigh.often', 'theexpertisetocreatehigh-qualitylabelscanonlybefoundinattorneys', 'whomaychargehundredsofdollarsperhour.evenafterlabelsareobtained', 'certaindatamaybe', 'sensitiveandcannotbepooledtogethertotrainingalargelanguagemodel.givenrecentprogress', 'infew-shotlearning', '[', 'brownetal.2020', ']', 'foundationmodelsareamongthemostpromisingpaths', 'forlearningmodelswithlimitedannotations', 'second', 'legaldecision-makingrequirescontextatvariousscales', 'knowledgeofallhistorical', 'decisions', 'standards', 'knowledge', 'case', 'law', 'remain', 'relevant', 'present', 'knowledgeofthenuancesoftheindividualcaseathand.foundationmodelsareuniquelypoisedto', 'havethepotentialtolearnsharedrepresentationsofhistoricalandlegalcontexts', 'aswellashave', 'thelinguisticpowerandprecisionformodelinganindividualcase', '3.2.3', 'whatarefoundationmodelslackingthatrequiresmoreresearch', '?', 'toillustratethedeficienciescurrentfoundationmodelsneedtoovercomeinordertoberealistically', 'deploy', 'weconsiderasanexampletheautomaticcreationofalegalbrieftosubmittoacourt', 'abrieflaysouttheargumentstoajudgebeforeahearing.onceapartyhasfiledanopening', 'brief', 'theopposingpartyfilesaresponse.thejudgethenevaluatesthebriefsandasksquestionsof', 'bothpartiesatahearingbeforemakingadecision.figure14visualizesthestructureofsuchalegal', 'briefwithsomeofitscharacteristicfeatures', 'anautomatedbriefgenerationmechanismmighttakeascontextrelevantdocumentsandfacts', 'ofacase', 'asspecifiedbyanattorney', 'aswellasaroughsketchofthedesiredoutcome.itwould', 'thengeneratealegalbriefwithcomplexlegalargumentstosubmittothecourt', 'longdocumentsandnarratives.toachievethisgoal', 'themodelmustbeabletoreadlongcontexts', 'andproducelongnarratives.legaldocumentstendtobefarlongerthandocumentsinanyother', 'context.theaverageu.s.supremecourtopinioncontainsaround4,700words,38', 'abriefonthe', 'meritstothesupremecourtcanhaveasmanyas15,000words,39alawreviewarticleoftencontains', '20,000to30,000words,40paroletranscriptscanbehundredsofpageslong', '[', 'belletal.2021', ']', 'trialrecordscanbeevenlonger.currentfoundationmodelshavestruggledwithsuchlongcontexts', 'andoutputs', 'see§4.1', 'modelingformorediscussion', '38https', '//www.americanbar.org/groups/public_education/publications/teaching-legal-docs/how-to-read-a-u-s–', 'supreme-court-opinion/', '39https', '//www.supremecourt.gov/casehand/courtspecchart02162010.aspx', '40https', '//www.stanfordlawreview.org/submissions/article-submissions/']",63
Opportunities and Risks of Foundational Models - Stanford.pdf,"['64', 'centerforresearchonfoundationmodels', 'crfm', 'fig.14', 'anextractfromafictionalbriefwrittenbyoneoftheauthorsofthiswork.theprototypicalform', 'thatlawstudentsareinstructedtowriteabriefinvolves', '1', 'introducingtheargument', '2', 'statingthelegal', 'ruleinapersuasivemanner', '3', 'applyingthelegalruletothefactsofthecase', '4', 'persuasivelyconcluding', 'theargument.thisofteninvolvesinformationretrievalandparaphrasingfrombothpriorcasesandthefacts', 'ofthecurrentcase', 'retrieval', 'conceptdrift', 'argumentformation', 'andlogicalreasoning.inadditiontoreadingcase-', 'specificdocuments', 'thefoundationmodelmustretrievetherelevantcaselawandunderstandwhich', 'caselawisstillvalidandwhichhasbeenoverruled', 'takingintoaccountpotentialconceptdriftsince', 'itwastrained.moreworkineditinggroundedinformationinfoundationmodelswillberequired', 'ascaselawevolves', '[', 'decaoetal.2021', ']', '.usingretrievedlegalstandards', 'thefoundationmodelmust', 'thenunderstandhowtoweavethemintoapersuasiveargument.emergingresearchhasstudied', 'waysofusingfoundationmodelstomeasure', 'detect', 'andgeneratepersuasivetexts', '[', 'duerrand', 'gloor2021', 'lietal.2020a', 'longpreetal.2019', ']', 'whichmayprovidesteppingstonestowardsthis', 'goal', 'butlegalbriefingalsorequirestheabilitytoidentifyarelevantlegalruleanddeterminehowit', 'appliestoanewsituation.forexample', 'holzenbergeretal', '[', '2020', ']', 'provideadatasetandmethodology', 'forevaluatingthisabilityincurrentmodelsbasedonthetaxcode.givenasetoftaxcoderules', 'andadescriptionofsomeone', '’', 'ssituation', 'themodelmustdeterminehowtherulesapplytothe', 'individualinordertodeterminewhattheirtaxliabilityis.41holzenbergeretal', '[', '2020', ']', 'foundthat', 'domainexpertscanexpresstherelevanttaxlawasaprologsolvertodetermineanindividual', '’', 'stax', 'liabilitywithperfectaccuracy.however', 'theyfoundthatsimplyusingabertmodel', 'evenwhen', 'pretrainedonin-domainlegaltext', 'wasnotsufficienttoallowthemodeltodeduceandapplythe', 'relevantrules', 'aprocessalsoreferredtoas', '“', 'legalreasoning.', '”', '41forexample', 'arulemightlooklike', '“', 'inthecaseofanindividualwhoisnotmarriedandisnotasurvivingspouse', 'paragraph', '1', '2', 'shallbeappliedbysubstituting', '‘', '$', '750', '’', '‘', '$', '600', '’', '”', 'usinternalrevenuecode', 'irc', '§63', 'f', '3']",64
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '65', 'thesechallengescanfurtherbeillustratedthrougharealexchangewithgpt-3', 'demonstrat-', 'ingthatcurrentmodelsareunabletoperformevencomparativelysimpletasksinvolvinglegal', 'reason', 'legalreasoningwithgpt-3', '“', 'liquidateddamages', '”', 'areaformofmonetarycompensationforabreachofcontractthatthe', 'partiesspecifyintheiragreement.ingeneral', 'courtsintheu.s.willnotenforceliquidated', 'damagesprovisionsiftheamountstipulatedinthecontractissohighthatitactsasaform', 'ofpunishment', 'ratherthantobemerelycompensatory', 'first', 'weseeifthemodelencodedthecorrectruleabouttheenforcementofliquidated', 'damagesprovisions', 'q', 'areliquidateddamagesclausesenforceable', '?', 'liquidateddamagesclausesaregenerallyenforceableunlessthesumstipulated', 'isexorbitantorunconscionable', 'rule', 'appear', 'correct', 'apply', 'rule', 'set', 'facts', 'model', 'needstoinferthatonemillionindamagesisexorbitantforatoyotacorollaandthus', 'liquidateddamagesprovisionshouldnotbeenforced', 'q', 'xandycontractoverthesaleofatoyotacorolla.theircontractspecifiesthat', 'xhastopayyonemilliondollarsindamagesifxdoesnotdeliverthecaron', 'time.xdoesnotdeliverthecarontime.isyentitledtodamages', '?', 'ifso', 'inwhat', 'amount', '?', 'yes', 'yisentitledto', '$', '1,000,000indamages.damagesaremeanttocompensate', 'theinjuredpartyforthelosssufferedduetothebreach.yhassufferedalossof', '$', '1,000,000becausexhasnotdeliveredthecarontime', 'themodelisunabletoinferthat', '$', '1mforatoyotacorollaisexorbitant.evenifthemodel', 'provide', 'abstract', 'rule', 'precise', 'translation', 'context', 'prompt—andtheapplicationshouldthusbetrivial—gpt-3isstillunabletoconductthe', 'logicalreasoningrequired', 'q', 'xandycontractoverthesaleofatoyotacorolla.theircontractspecifiesthat', 'xhastopayytheexorbitantamountofonemilliondollarsindamagesifx', 'doesnotdeliverthecarontime.xdoesnotdeliverthecarontime.thelaw', 'requiresthatliquidateddamagesclausesareenforcedunlessthesumstipulated', 'isexorbitantorunconscionable.isyentitledtodamages', '?', 'ifso', 'inwhatamount', '?', 'yes', 'entitle', 'liquidate', 'damage', 'amount', 'case', 'exorbitantsincethepricewassetbythepartiesthemselves', 'precision.thefoundationmodelalsocannotcreatefakefactsintheprocess', 'aproblemthathas', 'comeupincurrentmodels', '[', 'gretzetal.2020', 'zellersetal.2019b', ']', '.specificityandtruthfulnessareof', 'heightenedimportantinlegalcontexts', 'whereimprecisestatementscanhavedrastic', 'unanticipated', 'consequences', 'andfalsestatementscanleadtosanctionsagainstattorneys', 'few-shotlearning.somechallengesfacingfoundationmodelsbeyondthosedescribedinthe', 'aboveexampleincludefew-shotlearning', 'whichisstillinitsinfancy', '[', 'perezetal.2021', ']', '.researchon', 'few-shotlearningtechniquesandincreasingaccesstolegalcorporacanworkintandem.because', 'foundationmodelsneedtobeprecise', 'notonlyinfactualtruth', 'asdiscussedabove', 'butalsoin', 'technicallegallanguage', 'itremainsuncleartowhatextentinformationobtainedfromonecorpus', 'canbeutilizedinanothercorpusofadifferentdomain.few-shotlearningthusremainsimportant']",65
Opportunities and Risks of Foundational Models - Stanford.pdf,"['66', 'centerforresearchonfoundationmodels', 'crfm', 'adaptation.somegainshavebeenobservedfromdomain-adaptivepretrainingonunlabeled', 'legalcorpora.thesegainsappeartobemostpronouncedwhenthepretrainingcorpusishighly', 'relevanttothedownstreamtaskandlabeledtrainingdataislimited', 'asettingwhichiscommonin', 'thelaw', '[', 'zhengetal.2021', ']', '.ithasnotyetbeencomprehensivelystudiedwhetherthisextendsto', 'adiversesetoflegaltasks', 'butleveragingunlabeleddomain-specificcorporaforself-supervised', 'trainingoffoundationmodelsmayprovidecomplementaryimprovementstofew-shotmethods', 'accesstocleanin-domaindata.somerecenteffortshavesoughttocreatelargelabeleddatasets', 'formorechallenginglegalbenchmarktasksthroughautomation', '[', 'zhengetal.2021', ']', 'ormanual', 'annotationbyvolunteerlegalexperts', '[', 'hendrycksetal.2021c', ']', '.theseeffortshavedemonstrated', 'thatlargerlanguagemodelsthatarepretrainedonmoredataachieveperformancegainsoncertain', 'challengingtasks', 'comparedtomorelimitedgainsobservedinothersettings', '[', 'chalkidisetal.2020', 'elwanyetal.2019', 'zhongetal.2020', ']', '.thisworksuggeststhatlargerlegalbenchmarkdatasetsmay', 'benecessarytoobservefurthergainsfromapplyingtransferlearningtechniquestofoundation', 'models.however', 'creatingbenchmarkdatasetsfortasksthatarelegallymeaningfulanddifficult', 'fromannlpperspectivecanitselfbechallenging', 'ashumanexpertannotationcanbecostlyand', 'automatedmethodsthatutilizeconventionaltokenizationandsentencesegmentationtechniques', 'canfailtoaccountforuniqueaspectsoflegaltext', 'suchasthestructureoflegalcitations', '[', 'bommarito', 'etal.2018', 'savelkaetal.2017', ']', '.asaconsequenceofthesechallenges', 'manyexistinglegaldomain-', 'specificlabeleddatasetsaresmall', 'notpubliclyavailable', 'orreflectsimplertasksthathavebeen', 'solvedbymethodsoftenpre-datingthedevelopmentoffoundationmodels.42', 'muchavailablelegaldatamayalsobeunrepresentative.sinceonlyafractionofcasesendupin', 'legalopinions', 'itisunclearwhetherthedisputesinpubliclyavailabledataarerepresentativeofthe', 'typicaldisputespresentedtoamodelinpractice', '[', 'priestandklein1984', ']', '.costlytrainingdatafor', 'morerepresentativescenariosmaybeconcentratedinthebiggestlawfirms.theselawfirmsmay', 'havetheabilitytoretainandaccumulatedataacrossmanycasesandclients.oneconcernthenis', 'thatfoundationmodelscouldconcentratepowerevenmoreamongthefewactorsthathavethe', 'resourcestotrainmodelsonin-domaindata—unlessthemodelscangeneralizesufficientlywell', 'reliability.finally', 'weagainnotethateveniffoundationmodelscouldsuccessfullyperformall', 'tasksinthelegaldomain', 'deploymentremainsamajorchallenge', 'afailureofafoundationmodel', 'inthelawwillhavereal', 'damagingconsequencestobothclientsandattorneys', 'seealsodiscussion', 'onfairness', 'legality', 'andethicsin§5.1', 'fairness', '§5.4', 'legality', 'and§5.6', 'ethics', '.forthisreason', 'machine', 'translation', 'software', 'already', 'deem', 'unreliable', 'use', 'evidence', 'courts,43althoughitcontinuestoberelieduponinothers.44', 'givenallofthesecomplexities', 'legalbriefingandreasoningislikelybeyondthecapabilitiesof', 'currentmodels', 'butappearstobewithinthefuturerealmofpossibilities.assuch', 'theseserveasa', 'potentiallodestarfortheongoingdevelopmentoffoundationmodels', '42forlawfirmsandlegaltechnologycompanies', 'tasksforwhichhighperformancecanalreadybeachieved', 'andcan', 'thereforebemoreimmediatelyproductized', 'maybeconsideredmoreworthwhiletoinvestcostlymanuallabelingefforts', 'towards', '43seediscussionbyvieiraetal.', '[', '2020', ']', '44forexample', 'invasquezv.unitedstates', 'no.3:16-cv-2623-d-bn', 'dist.court', 'ndtexas2019', 'counselreliedongoogle', 'translatetoprovethattheprevious', 'nativespeaker', 'attorneyhasmistranslatedapleadeal']",66
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '67', '3.3', 'education', 'author', 'alimalik', 'dorottyademszky', 'pangweikoh', 'moussadoumbouya', 'drewa.hudson', 'allen', 'nie', 'hamednilforoshan', 'alextamkin', 'emmabrunskill', 'noahgoodman', 'chrispiech', 'fig.15', 'foundationmodelsineducationcouldbetrainedonmultipledatasourcestolearnthecapabilities', 'necessaryforeducation', 'anunderstandingofvarioussubjectmatteranddifferentpedagogicaltechniques', 'thesefoundationmodelscanbeappliedinageneral-purposewayacrossarangeoftasksandgoalssuchas', 'understandingstudents', 'assistingteachers', 'andgeneratingeducationalcontent', 'intheyear2000', 'thelargestgatheringofworldleadersconvenedattheunitednationsmillennial', 'summittoreflectonanidealvisionforthefuture.delegatesconcludedthataprimaryfocusshould', 'beeducation', 'declaringit', '“', 'afoundationforhumanfulfillment', 'peace', 'sustainabledevelopment', 'economicgrowth', 'decentwork', 'genderequalityandresponsibleglobalcitizenship', '``', 'thisdiscussion', 'wasultimatelyrecodifiedintotheunitednationssustainabledevelopmentgoalto', '“', 'ensureinclusive', 'andqualityeducationforallandpromotelifelonglearning', ""''"", '[', 'unitednationsgeneralassembly', ']', 'however', 'provide', 'high', 'quality', 'education', 'large', 'scale', 'pose', 'difficult', 'societal', 'economicchallenges.thepriceofeducationperstudentisgrowingfasterthaneconomy-widecosts', '[', 'bowen2012', ']', 'limitingtheresourcesavailabletosupportstudentlearning.intheunitedstates', 'onesymptomisthatprivateeducationdebtheldbystudentshasreached', '$', '1.6trillion', 'surpass', 'totalcreditcarddebt', '[', 'friedman2020', ']', '.consideringtherisingneedtoprovideadultretraining', 'gapbetweenthedemandforeducationandourabilitytoprovideitisalarminglylarge', 'advent', 'digital', 'age', 'rapid', 'growth', 'digital', 'learn', 'computational', 'approach', 'education', 'show', 'promise', 'increase', 'effectiveness', 'learners', 'teachers', 'several', 'core', 'directions', 'emerge', 'potentially', 'impactful', 'applications', 'ai', 'education', '[', 'woolfetal.2013', ']', 'suchassystemsthatcanprovidemeaningfulfeedbacktostudents', '[', 'maliketal.2021', ']', 'helpteachersimprove', '[', 'jensenetal.2020', 'demszkyetal.2021', 'sureshetal', '2021', ']', 'orevencreatepersonalisedandadaptivelearningexperiencesthattailorthelearningprocess', 'toindividualstudents', '’', 'needsanddispositions', '[', 'connor2019', ']']",67
Opportunities and Risks of Foundational Models - Stanford.pdf,"['68', 'centerforresearchonfoundationmodels', 'crfm', 'despitethispotential', 'computationaleducationhasproventobeexceptionallydifficult.existing', 'workhasfocusedoncustomsolutionstohighlyspecifictasksforwhichlargeamountsoftraining', 'datahastobecollectedfromscratch.duetothedifficultyandcostofcreatinglargedatasets', 'use', 'thisapproachtosolveeveryeducationaltaskindependentlyisfundamentallylimited.instead', 'needgeneral-purposeapproachesthatarereusableacrossvarioustasksandsubjects.inotherwords', 'webelievethatapproachestocomputationaleducationneedtoscalenotonlyacrossstudents', 'acrosstasksaswell.itisinthiscontextthatwethinkfoundationmodelswillplayanimportant', 'roleinthefutureofeducation', 'foundationmodelshavealreadystartedtoboosttheperformanceofsomespecificflagshiptasks', 'ineducation.recentexamplesincludeusingmathbert', '[', 'shenetal.2021b', ']', 'topower', '“', 'knowledge', 'trace', ""''"", '—thechallengeoftrackingastudent', '’', 'sunderstandingovertimegiventheirpastresponses—', 'andthe', '“', 'feedbackchallenge', ""''"", 'whereanalgorithmhastointerpretastudent', '’', 'sanswertoastructured', 'open-endedtask', 'suchasacodingquestion', '[', 'wuetal.2021e', ']', '.canfoundationmodelsleadtoeven', 'transformative', 'change', 'domain', '?', 'know', 'imagine', 'risk', 'foundationmodelsappliedtoeducation', '?', 'inthissection', 'wegroundourdiscussionintwoconcrete', 'task', '1', 'understandingstudentmisconceptions', '2', 'improvingstudentunderstandingthrough', 'instruction', 'explore', 'important', 'ethical', 'considerations', 'application', 'ai', 'education', 'includingthosebuiltwithfoundationmodels', '3.3.1', 'foundationmodelsofstudentthought', 'whatwouldittakeforafoundationmodeltobeabletoreasonaboutstudentunderstanding', '?', 'itis', 'easytoimagineafoundationmodelwhichhasbeenadaptedtoansweramathquestioncorrectly', 'butitislessclearhowtobuildamodelthatcandiagnosemistakesinstudentunderstandingbased', 'onthestudent', '’', 'sanswers.toexplorethistheme', 'weconsiderthecasestudyofprovidingfeedback', 'tostudentswhoareworkingonopen-endedtaskssuchaswritingashortparagraph', 'drawinga', 'physicsdiagram', 'orwritingcode.this', '“', 'feedbackchallenge', '”', 'exemplifieshowfoundationmodels', 'canbehelpfuloff-the-shelfforlearners', 'andalsodemonstratesopenareasforfoundationmodel', 'research', 'toeffectivelyprovidefeedbacktostudents', 'twocentralcapabilitiesarerequired', '1', 'understand-', 'ingthesubjectmatterofthetask', 'e.g.', 'physicsorcoding', '2', 'thediagnosticabilityto', '“', 'notice', ""''"", 'atechnicaltermineducationforinferringwhyastudentmadeamistake.fortypicalstudentin-', 'teractionsinatypicalclassroom', 'thereisnotenoughdataforanaimodeltolearn', 'fromscratch', 'bothofthesecentralcapabilities.evenformassivecourseswithmillionsofstudents', 'supervise', 'algorithmsbarelyunderstandthecomplexstudentreasoningbehindevenshort', 'four-lineprograms', '[', 'maliketal.2021', ']', '.assuch', 'thefeedbacktaskinherentlyrequiresatransferofunderstandingfrom', 'externaldataandexperience', 'foundationmodels', 'astheycurrentlyexist', 'aredirectlyhelpfulforthefirstofthesecapabilities', 'understandingaspecificsubjectmatter.forexample', 'whenlearningtoprovidefeedbackonshort', 'programmingquestions', 'afoundationmodelsuchasgpt-3canefficientlyunderstandwhatfluent', 'codelookslikewithafewexamples.someresearchinthisdirectionhasalreadystartedexploring', 'foundationmodelsthatcanquicklyadapttoquestionsinnewsubjectmatterdomains', '[', 'wuetal', '2021e', 'condoretal.2021', ']', '.similarly', 'foundationmodelscouldalsointegratemultiplemodesof', 'informationsuchasthetextofatask', '’', 'sprompt', 'diagramsinthequestion', 'oreventhecontentofa', 'gradingrubricprovidedtoteachingassistants.thisunifiedrepresentationalabilitycanhelpfoun-', 'dationmodelscomprehendasubjectmatterthroughrichersourcesofinformation.asaconcrete', 'casestudy', 'manyoftheseinsightswereleveragedascorecomponentsofanalgorithmwhichwas', 'abletogradeanintroductorycomputersciencemidtermatstanforduniversity', 'withthesame', 'effectivenessashumanteachingassistants', '[', 'wuetal.2021e', ']', '.inthiscase', 'subjectmatterencoding']",68
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '69', 'wasbuiltonafoundationmodelthathadbeenadaptedongithubcodeandacorrespondingsmall', 'datasetforeachquestion', '’', 'ssubjectmatter.ingeneral', 'wecanimagineleveragingvarioussourcesof', 'datatoadaptfoundationmodelstodifferentsubjectmatter.forexample', 'mathadaptationcoulduse', 'mathematicalwebsitesortextbooks', '[', 'shenetal.2021b', ']', 'orhistoricalstudentanswersonplatforms', 'suchasgradescope', 'spokenlanguageunderstandingcouldleverageradioarchivesorpodcasts', 'anddomainslikecreativewritingcouldlooktolargedigitalarchiveslikeprojectgutenberg', 'contrast', 'subject', 'matter', 'adapt', 'foundation', 'model', 'task', 'map', 'observe', 'mistake', 'flaw', 'student', '’', 'think', 'process', 'much', 'less', 'well-explored', 'ability', 'aninstructorto', '“', 'notice', '”', 'thereasonsbehindwhyastudentmakesaspecificmistakeisacritical', 'componentofthefeedbackchallenge.imagine', 'forexample', 'astudentlearningtwodigitaddition', 'whoanswersthequestion', '“', 'whatis26+19', '?', ""''"", 'withtheresponse', '“', '315', '``', 'takeamomentandtryto', 'guesswhytheygavethatanswerandwhatmisconceptionstheyhave.45.thisabilitytonoticecould', 'beposedasanadaptationtaskforfoundationmodels', '§4.3', 'adaptation', 'orperhapsevenasa', 'reasoningtask', '§2.4', 'reason', 'whiledifficult', 'traininganaisystemtonoticeisanachievablegoal.acrossclassrooms', 'acrosslearningtasksinagivendomain', 'therearegeneralizablepatternsinhowstudentsarriveat', 'theiranswers.thelabeleddatathatcandirectlybeusedforthisadaptationtask', 'suchasinstructor-', 'writtenfeedbacktostudentworkin', '[', 'wuetal.2021e', ']', 'areoftenheldprivatelybyinstructorsin', 'disparatedatasets.however', 'publiclyaccessibledata', 'suchasstackoverflowinteractions', 'mightalso', 'becreativelyusedtoadaptafoundationmodeltonotice.someresearchhasalsoexploredeffective', 'waysofextracting', 'frominstructors', 'generativedescriptionsofhowstudentsmakemistakes', '[', 'malik', 'etal.2021', 'gulwaniandsingh2013', ']', '—thesehand-writtengenerativemodelscouldalsobeusedto', 'generateadaptationdatatohelpfoundationmodelsdiagnosestudentmistakes', '3.3.2', 'foundationmodelsforinstruction', 'reason', 'student', 'understand', 'essential', 'step', 'improve', 'understand', 'throughinstruction.computationalapproachestoinstructionfocusondifferenttaskslikecontent', 'personalization', '[', 'connor2019', ']', 'questiongeneration', '[', 'guoetal.2016', 'willisetal.2019', 'srivastava', 'andgoodman2021', ']', 'adaptivecurriculumdesign', '[', 'mandeletal.2014', 'doroudietal.2017', ']', 'predict', 'instructor', 'intervention', '[', 'chandrasekaran', 'kan', '2019', 'alrajhi', 'et', 'al', '2021', ']', 'subsection', 'wediscusshowfoundationmodelscouldbeusefulintheactofteachingstudents', 'sinceeffectiveteachingrequiresreasoningaboutstudentunderstanding', 'thepreviousdiscussions', 'onunderstandingsubjectmatterand', '“', 'notice', '”', 'areextremelyrelevant.however', 'providingeffective', 'instructionrequiresanadditionalcapability', 'thatofunderstandingpedagogy', '[', 'mckenzie2003', ']', 'encapsulate', 'effective', 'understand', 'techniques', 'guide', 'student', 'ask', 'socratic', 'question', 'provide', 'analogies/contrasting', 'case', 'use', 'encourage', 'supportive', 'language', 'tailoringthedifficultyofquestionstothestudent', 'andgeneratingexamplesthatare', 'relevanttoastudent', '’', 'sinterestsandbackground', 'howcanfoundationmodelsbeadaptedtounderstandgoodpedagogyforinstruction', '?', 'oneidea', 'istoconsideradaptationusingdatasourcewhereinstructionistheprimaryrole.forexample', 'data', 'fromquestionansweringforumslikestackoverflowcouldpotentiallybeusedtobuildatutorwhich', 'canparrotcommonsocraticquestions.similarly', 'afoundationmodeladaptedonencyclopedias', 'suchaswikipediamightbeabletogiveanswerstostudentquestionswhichare', 'often', 'factually', 'correct.therearealsopublicdatasourcesliketextbooks', 'lecturevideos', 'lessonplans', 'andgraded', 'feedbackthatcollectivelycontainimportantpedagogicalbehaviourswhichcouldbeadaptedby', 'foundationmodels', 'figure15', '45thisstudenthasmadethecommonmistakeofconcatenatingtheresultsofaddingtheone', '’', 'sdigitandten', '’', 'sdigit']",69
Opportunities and Risks of Foundational Models - Stanford.pdf,"['70', 'centerforresearchonfoundationmodels', 'crfm', 'another', 'adaptation', 'challenge', 'instruction', 'base', 'foundation', 'model', 'learn', 'speaktostudentsliketeachers.thelanguageusedbyteachersisoftendifferentfromthelanguage', 'usedbythegeneralpopulation.teachersareideallytrainedtospeaktostudentswithrespectand', 'way', 'intentionally', 'help', 'form', 'positive', 'identity', 'subject', 'learn', '[', 'truax2018', ']', '.cautionaryexampleslikemicrosoft', '’', 's2016twitterbot', '“', 'tay', ""''"", 'achatbotthatstarted', 'generatinghatespeechwithin24hoursofbeingdeployedlive', 'showustheimportanceofexplicitly', 'accountingforthisfactorineducation.totrainalanguagemodelwhichismoreheavilyinfluenced', 'byprofessionalteachersinclassrooms', 'wecouldperhapsadaptfoundationmodelstodatasources', 'likelecturevideosorrecordedofficehourvideos', 'theadaptationproblemaboveiscompoundedbythefactthatdifferenteducationcontextsvary', 'significantlyinthekindoflanguagethatwouldbeappropriate', 'forexample', 'effectiveinstruction', 'ina5th-gradescienceclasswouldlookquitedifferentfromthatinacollegephysicsclass', 'much', 'lessacollegeliteratureclass.thispresentstechnicalchallengesbeyondwhatwouldbefacedin', 'typicalnlpdomainshiftsettings', 'e.g.', 'questionansweringbasedonnewsarticlesvs.redditposts', 'asthefoundationmodelwouldneedtobefluidlyadaptableintermsofitstoneandlanguage', 'notjustthefactualcontentthatitgenerates', 'beyondsoundpedagogicaltechniquesandinstructionallanguage', 'howmightfoundationmodels', 'provideevenmoreinsightfulformsofinstruction', '?', '§2.1', 'languageofthispaperhighlightsthefact', 'thatremarkablycomplexlanguagecanbeacquiredbybabiesinashortamountoftime.asthe', 'authorspointout', 'asalientdifferencebetweenfoundationmodeltrainingandhumanlanguage', 'acquisitionisthat', '“', 'humanlanguageisgroundedtotherealworld', 'forexample', 'ababy', '’', 'scaretakers', 'pointtoobjectswhiletheytalkaboutthem', '``', 'thissameinsightcanalsoinspireideasastohow', 'foundationmodelscanbeusedforgenerativeeducation.humansseemtolearnwellwhenpresented', 'withreal-worldanalogiesandcontrastswhichmaybecross-cuttingbetweentheircurrentcontext', 'andpastexperiences.forexample', 'whenteachingsignlanguage', 'aninstructormightuseananalogy', 'suchas', ""''"", 'thehandshapesfortheword', '‘', 'morning', '’', 'lookslikethesunrising', ""''"", 'ornotethat', '“', 'thehand', 'shape', 'make', 'look', 'similar', 'another', 'word', 'us', 'focus', 'differences', ""''"", 'anotherexample', 'whenteachingswahilitoalearnerwhoalreadyknowsarabicandenglish', 'instructorcouldpointoutthattheswahiliwordfor8', 'pronouncednane', 'isa', '“', 'falsefriend', '”', 'thatis', 'phoneticallysimilartoenglishwordfor9', 'pronouncednine', '.foundationmodelsthatcanintegrate', 'multi-modaldatahavethepotentialtomakethesekindsofrichanalogiesandcomparisonsthat', 'aretypicalinchildhoodlanguagelearning', 'figure16', '3.3.3', 'importantconcernsforcenteringfoundationmodelsineducationresearch', 'thefutureofaiforeducationisexciting', 'especiallyinthecontextoffoundationmodels.however', 'caution', 'reader', 'especially', 'thoughtful', 'impact', 'ai', 'research', 'apply', 'toeducation.46', 'thegoalofeducationistointentionallyguidethemindsoflearners.whilewe', 'actively', 'work', 'improve', 'digital', 'education', 'imperative', 'put', 'substantial', 'think', 'try', 'imagine', 'complexities', 'disruption', 'space', '[', 'piech', 'einstein', '2020', ']', 'ethicalchallengesrangefromissuessuchasdatabias', 'legalconstraints', 'andtheimpactofdigital', 'socialization', 'issue', 'unique', 'foundation', 'model', 'worth', 'reflect', 'onregularlyasresearchmakessubstantialprogressinaiforeducation.reflectiononimpactis', 'especiallyimportantwhenresearchstartsbyasking', '“', 'whatcannewaitechnologyafford', '?', ""''"", '46in2013', 'facebookinitiatedfreebasics', 'aprojecttoprovidefreeinternettotheworldandthusspreadopportunityand', 'interconnection.now', 'theunitednationshumanrightscouncilreportsthat', 'inmyanmar', 'facebook', '’', 'seffortstofollow', 'throughonsuchaspirationswithoutproperhumanmoderationacceleratedhatespeech', 'instigateddivision', 'andincited', 'offlineviolenceintherohingyagenocide.freebasicsnowservesasawarningofthecomplexitiesoftechnologicalimpact', 'onsociety']",70
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '71', 'fig.16', 'thefigureillustratesasystemthatembedssignalsfromvariousmodalities', 'image', 'speech', 'sign', 'text', 'andlanguagesintoauniversalfeaturespace.suchafeaturespaceallowsideastobelinkedacross', 'modalitiesandlanguages.pedagogicallyrelevantlinktypesincludeanalogies', 'similaritiesacrosslanguages', 'andcontrasts', 'distinctconceptsacrosslanguages', 'bothofwhichcanoccurinthesamemodalityoracross', 'differentmodalities', 'manyoftheissuesin§5.6', 'ethicsapplytoeducation.forexample', 'asinmanyotherdomains', 'smallbiasesinfoundationmodeltrainingdatacouldbehardtotrackdown', '[', 'dixonetal.2018', 'bolukbasietal.2016', ']', 'buthaveimportantimplicationsforequityofeducationalaccess.moreover', 'thesesystemsmayexperienceahighdegreeof', '“', 'feedback', ""''"", 'wherethecollecteddatacontinually', 'reinforce', 'model', '’', 'decisions', 'issue', 'bias', 'go', 'beyond', 'data', 'collect', 'in-', 'cludesconcernsovertheapplicationsthatresearcherschoosetoworkon.below', 'wediscussother', 'education-specificissues', 'privacyandsecurity', 'oneimportantethicalissueintheuseofaiineducationishighlightedby', 'thestrictlegalguidelinesconcerningprivacyinstudentwork.forexample', 'intheunitedstates', 'studentinformationisprotectedbythefamilyeducationrightsandprivacyact', 'ferpa', '.these', 'lawsandregulationsareespeciallyimportantforchildrenunder13', 'whohavetheirdataprivacyand', 'securityadditionallyprotectedbythechildren', '’', 'sonlineprivacyprotectionact.amongotherthings', 'ferpalimitsteachersfromsharingpersonallyidentifiablestudentwork.thiscoulddirectlyimpact', 'initiativestosharedatausedbothfortrainingandforevaluatingfoundationmodels.moreover', 'thereisanopenquestionastowhethertheweightsofafoundationmodelcouldsomehowleakthe', 'possiblyprivate', 'dataitwastrainedupon', '[', 'nasretal.2018', 'songetal.2017', ']', '.theseissues', 'theircorrespondingapproaches', 'aresimilartothechallengesdescribedin§3.1', 'healthcare', 'theimpactoffewerteachers', 'oneofthegoalsofdigitaleducation', 'especiallybasedonai', 'toincreasetheproductivityofthelearningexperiencesothatmorelearninghappensperunittime', 'orunitcost.onecanimaginethatdecisionmakerscouldusethisincreasedproductivitytoremove', 'humanteachersfromtheloop.thelongtermimplicationsofsuchdecisionsarehardtoknowa', 'priori.couldinteractingwithaneducationsystemoptimizedtomaximize', '“', 'learn', '”', 'haveadverse', 'effectsonsocioemotionalskilldevelopment', '?', 'coulditcreatefeweropportunitiesforinteracting']",71
Opportunities and Risks of Foundational Models - Stanford.pdf,"['72', 'centerforresearchonfoundationmodels', 'crfm', 'withothers', '?', 'lonelinessisontheriseinyoungergenerations', '[', 'cigna2018', ']', 'andteacherscouldbea', 'modulatingforceforpressuresthatairesearchersmightnotenvision', 'studentsusingfoundation-model-basedtools', 'anotherchallengeishowtoeffectivelyteach', 'studentswhohaveaccesstofoundation-model-basedtools.forexample', 'itwillbemuchmore', 'complexforteacherstounderstandtheextentofastudent', '’', 'scontributionifthestudentworked', 'togetherwithapowerfulgenerativemodel', 'ortoregulateineffectivecollaborationsanddetect', 'plagiarism.visualstudiohasrecentlyreleasedgithubcopilot', 'anaipair-programmerbuiltupon', 'gpt-3', '[', 'chenetal.2021e', ']', '.howwillthischangecomputerscienceeducation', '?', 'manychallenges', 'beginner', 'programmers', 'might', 'trivial', 'copilot', 'technical', 'successors', 'could', 'underminethelearningexperiencefornovices.itwouldbeinstructivetostudyotherexamplesof', 'technologicaladvancesthatdisruptededucationforcertainsubjects', 'suchascalculatorsinmath', 'classroomsandgoogletranslateinlanguagecourses', 'bothofwhichnowcoexistwithtraditional', 'instruction']",72
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '73', '4', 'technology', 'thetechnologicalfoundationsoffoundationmodelsgiverisetothecapabilities', '§2', 'capabilities', 'thatdeterminetheirpotential.tounderstandthetechnologyusedindevelopment', 'weconsider', 'thedata', '§4.6', 'data', 'modelarchitectures', '§4.1', 'model', 'andsystems', '§4.5', 'systems', 'usedto', 'train', '§4.2', 'train', 'andfurtheradapt', '§4.3', 'adaptation', 'thesemodelsalongsidethetheory', '§4.10', 'theory', 'thatshouldbedevelopedtounderstandthisparadigm.tothenunderstandthe', 'result', 'model', 'discuss', 'evaluate', '§4.4', 'evaluation', 'interpret', '§4.11', 'inter-', 'pretability', 'alongside', 'theimportance', 'robustness', '§4.8', 'robustness', 'securityand', 'privacy', '§4.7', 'security', 'andlong-termaisafety', '§4.9', 'ai-safety', 'forensuringthereliabilityofthese', 'modelswhendeployedinsociety', '§5', 'society']",73
Opportunities and Risks of Foundational Models - Stanford.pdf,"['74', 'centerforresearchonfoundationmodels', 'crfm', '4.1', 'model', 'author', 'drewa.hudson', 'antoinebosselut', 'alextamkin', 'omarkhattab', 'jaredquincydavis', 'jiaxuan', 'trevorgale', 'fig.17', 'thefivekeypropertiesofafoundationmodel', 'expressivity—toflexiblycaptureandrepresentrich', 'information', 'scalability—toefficientlyconsumelargequantitiesofdata', 'multimodality—toconnecttogether', 'variousmodalitiesanddomains', 'memorycapacity—tostorethevastamountofaccumulatedknowledge', 'andcompositionality—togeneralizetonewcontexts', 'tasksandenvironments', 'theemergingparadigmoffoundationmodelshasattainedimpressiveachievementsinaiover', 'thelastfewyears', 'asmodelssuchasbert', '[', 'devlinetal.2019', ']', 'shineatawidespectrumoflanguage', 'understandingtasks', 'fromtextualclassificationandentailmenttoquestionansweringandreading', 'comprehension', 'whilegpt-3composesrichandfluenttalesaboutunicorns', '[', 'brownetal.2020', ']', 'anddall-eshowssignsofvisualcreativity', 'generatingfromscratchstrikingly-realisticpictures', 'ofavocadochairs', '[', 'rameshetal.2021', ']', 'theseandotherinstancesofrecentfoundationmodelsnotonlyachieveremarkableperformance', 'acrossamultitudeofdiversedownstreamtasksandapplications', '[', 'rajpurkaretal.2018', 'wangetal', '2019a', ']', 'butalsomanifestnoteworthybehaviorsofinterpretability', '[', 'karrasetal.2020', ']', 'robustness', '[', 'devlinetal.2019', ']', 'controllability', '[', 'patashniketal.2021', ']', 'andgeneralization', '[', 'brownetal.2020', ']', 'whatdoesittakeforamodeltodemonstratesuchqualities', '?', 'whatarchitecturesarecapableof', 'consuminglargequantitiesofpotentiallymultimodalinformationandtranslatethemintorich', 'knowledgeoftheworld', '?', 'andoverall', 'whatdesirablepropertiesshouldanetworkpossesstogive', 'risetoafoundationmodel', '?', 'weidentifyanddiscussfivesuchproperties', 'spanningexpressivity', 'scalability', 'multimodality', 'memorycapacity', 'andcompositionality', 'thatwebelieveareessentialforafoundationmodelin', 'orderto', '1', 'distillandaccumulateknowledgefromvarioussourcesanddomains', '2', 'organizeitin', 'aneffectiveandscalablerepresentation', '3', 'flexiblygeneralizeittowardsnovelcontexts.for', 'eachoftheseproperties', 'wemotivatetheirnecessity', 'provideexamplesofcontemporarymodels', 'thatincorporatethem', 'andexplorekeychallengesandpromisingavenuesforfutureresearchand', 'development.seefigure17foranoverviewdiagram']",74
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '75', '4.1.1', 'expressivity', 'expressivityconcernswiththetheoreticalandpracticalcapacityofanetworktomodelthedata', 'distributionitistrainedoverandrepresentitinaflexiblemanner.priorworkshaveproposed', 'formalexpressivitymeasurestocharacterizethecomplexityoffunctionsanetworkcancompute', 'ormoreprecisely', 'approximate', 'whichisessentiallyaffectedbyitsdepth', 'width', 'connectivity', 'structuralpatterns', '[', 'raghuetal.2017', ']', 'asthenofreelunchtheoremsuggests', 'thereisnosinglemodeloralgorithmthatsuitsbestfor', 'allcases', '[', 'wolpertandmacready1997', ']', 'andso', 'forourpurposes', 'weareparticularlyinterestedin', 'identifyingwhichmodelscouldeffectivelycapturethefacetsofnaturalinformation', 'suchashuman', 'languageorreal-worldimages', '[', 'goodfellowetal.2016', ']', '.thesemodalitiesareeithercontinuous', 'invision', 'ordiscrete', 'asinlanguage', 'aredistinctlyhierarchicalandhigh-dimensional', 'andpresent', 'acomplexsetofrelationsandinteractionsamongtheirconstituentelements', 'whethertheseare', 'pixels', 'wordsorphysicalobjects', 'indeed', 'recent', 'breakthroughs', 'generative', 'model', 'provide', 'strong', 'evidence', 'high', 'expressivityofneuralnetworks', 'astheysuccessfullyexpressdistributionsoftextual', '[', 'brownetal', '2020', 'devlinetal.2019', 'lieberetal.2021', 'wangandkomatsuzaki2021', ']', 'auditory', '[', 'vandenoord', 'etal.2016', ']', 'andvisual', '[', 'karrasetal.2020', 'brocketal.2018', ']', 'domains', 'andgeneratesamplesofhigh', 'fidelity', 'diversityandrealism', 'inductivebiases', 'muchofthesuccessofneuralnetworksoverthelastdecadeinmodelingnatural', 'dataisowedtothenetworks', '’', 'highdepths', 'ascouldberoughlymeasuredbythenumberofstacked', 'non-linearlayerstheyarecomposedof', 'orthenumberofcomputationalstepstheytakeduring', 'theirchain-of-reasoning.greatdepthsplayacrucialroleinenhancingnetworks', '’', 'expressivity', 'allowingthemtoformpowerfulhierarchicalanddistributed', 'representationsthatcouldgeneralize', 'fromthetrainingdatatonewunseenexamples', '[', 'heetal.2016b', 'levineetal.2020', ']', 'theuniversalapproximationtheorem', '[', 'luetal.2019b', ']', 'indeedstatesthatevensimplemultilayer', 'perceptrons', 'mlps', 'canrepresentabroadsetoffunctions', 'whiledifferentinductivebiases', 'asthose', 'implementedinrecurrentneuralnetworks', 'rnns', 'orconvolutionalneuralnetworks', 'cnns', '[', 'goodfellowetal.2016', ']', 'canimprovethelearningefficiencyandenhancethecapacityofagiven', 'networktomodeldifferentformsofinformation', 'sequentialdata', 'commontolanguage', 'speechand', 'time-series', 'fortheformer', 'orspatially-invariantinformation', 'asinimagesorvideos', 'forthelatter', 'transformernetworks', '&', 'attention', 'meanwhile', 'transformernetworks', '[', 'vaswanietal.2017', ']', 'introducedmorerecently', 'demonstratetheimportanceofcapturinglong-rangedependenciesand', 'pairwiseorhigher-orderinteractionsbetweenelements.theybuildontheself-attentionmechanism', '[', 'vaswanietal.2017', 'bahdanauetal.2014', ']', 'thatenablesshortercomputationpathsandprovides', 'directmeanstocompareelementsfar-acrosstheinputdata', 'suchasapronounanditsantecedent', 'inasentence', 'ortwosentencesthatrefertothesametopic', 'fromanotherperspective', 'themultiplicativeinteractionembodiedinbothattentionaswellas', 'gatingstructures', 'asinlstms', '[', 'hochreiterandschmidhuber1997', ']', 'ormixture-of-experts', '[', 'shazeer', 'etal.2017', ']', 'offersamoreflexiblealternativetotherigidfixed-weightcomputationofmlpsand', 'cnns', 'dynamicallyadaptingthecomputationtotheinputathand.thisprovesespeciallyuseful', 'forlanguagemodeling', 'forinstance', 'givenasentencelike', '“', 'sheatetheice-creamwiththe', 'x', ""''"", 'whileafeed-forwardnetworkwouldalwaysprocessitintheverysamemanner', 'anattention-', 'basedmodelcouldadaptitscomputationtotheinput—updatingthecontextualrepresentationof', 'theword', '“', 'eat', '”', 'iftheprepositionalphrase', 'pp', 'attachmentxis', '“', 'spoon', '”', 'orinsteadlinkittothe', '“', 'ice-cream', ""''"", 'ifxreferse.g.', '“', 'strawberries', ""''"", '[', 'zavreletal.1997', ']']",75
Opportunities and Risks of Foundational Models - Stanford.pdf,"['76', 'centerforresearchonfoundationmodels', 'crfm', 'general-purposecomputation', 'afinalnotableadvantageofattentionoverpriorarchitectures', 'stemsfromitsstrongergenerality', 'whereitisnotstronglytiedtoaparticulartaskordomain', 'asisthe', 'caseforthelocalreceptivefieldofconvolutionorthesequentialassumptionofrecurrentnetworks', 'reflect', 'inherent', 'properties', 'specific', 'vision', 'language', 'modalities', 'respectively', 'hypothesize', 'general-purpose', 'nature', 'attention', 'transformers', 'contribute', 'theirbroadapplicabilityforawiderangeofresearchproblemsandapplications', '[', 'liuetal.2019', 'dosovitskiyetal.2020', 'hudsonandzitnick2021', ']', 'contrast', 'capture', 'general', 'trade-off', 'task-specialization', 'expressivity', 'model', 'stronger', 'structural', 'priors', 'leverage', 'improve', 'sample', 'efficiency', 'particulartasksthatbenefitfromtheseassumptions', 'whileconversely', 'modelsthatintegrateweaker', 'inductivebiaseslearnmoreslowly', 'butcaninturnscaletohighervolumesofdataandadapttoa', 'diversesetofdomains', 'sincetheydonotrelyonrestrictiveortask-specificsuppositions.asboth', 'dataandcomputeturnmoreaccessible', 'weobservethattheexplorationofmodelswithaminimal', 'setofinductivebiasesthatcan', '“', 'letthedataspeakforitself', ""''"", 'seemstoserveasamorepromising', 'approachforfutureresearchinthefield', 'challenge', '&', 'futuredirections', 'notwithstandingthestellarprogressandaccomplishmentsof', 'neuralnetworksingeneral', 'andfoundationmodelsinparticular', 'intermsofexpressivity', 'notable', 'challenge', 'still', 'remain', 'lead', 'approach', '[', 'choromanski', 'et', 'al', '2020', 'dosovitskiy', 'et', 'al', '2020', ']', 'keepstrugglingwithmodelingofextremelylong-rangedependencies', 'suchasthoseoccurringin', 'book', 'movies', 'orevendnasequences', 'whichmaybeattributedtothequadraticcomputationof', 'contemporarytransformer-basedapproaches', '[', 'wangetal.2020c', 'linetal.2021', ']', 'thischallengeessentiallyreflectsthetrade-offbetweenefficiencyandexpressivity', 'whereexplicit', 'model', 'long-distance', 'interactions', 'short', 'direct', 'computation', 'paths', 'improve', 'expressivityontheonehand', 'butcomesattheexpenseofscalabilityduetocomputationentailed', 'increase', 'connectivity', '[', 'child', 'et', 'al', '2019', 'kitaev', 'et', 'al', '2020', 'choromanski', 'etal.2020', ']', '.modelssuchastheganformer', '[', 'hudsonandzitnick2021', ']', 'andtheperceiver', '[', 'jaegle', 'etal.2021b', ']', 'explorewaystobalancethesetwopropertiesandproposetransformerswithlinear', 'complexitythatrelyonbipartiteorbottleneckattention', 'sotoimprovecomputationalefficiency', 'whilemaintaininghigh-expressivity.webelievethatidentifyinganeffectiveequilibriumbetween', 'thesetwoobjectivesoffersaninterestingavenueforfutureresearch', 'anotherimportantresearchdirectionrelatestotheexpansionoffoundationmodels', 'far', 'havemainlyfocusedonthelanguagedomain', '[', 'petersetal.2018', 'devlinetal.2019', 'brown', 'etal.2020', ']', 'todifferentmodalities', 'suchasthestructural', '[', 'scarsellietal.2008', 'veličkovićetal', ']', 'andperceptual', '[', 'tolstikhinetal.2021', 'jaegleetal.2021b', 'tanandle2021', ']', 'eachinvolvinga', 'uniquesetofassociatedchallenges.likewise', 'webelievethatexploringarchitecturesforreasoning', '§2.4', 'reason', 'whichdemandsiterativecomputationchainsandinteractionwithsymbolic', 'information', 'constitutesavaluablegoalforfuturefoundationmodelsresearch', '4.1.2', 'scalability', 'closelyconnectedtomodel', '’', 'sexpressivityisthenotionofscalability.asrichdatafromvaried', 'source', 'become', 'readily', 'available', 'computational', 'resources', 'get', 'stronger', 'efficient', '§4.5', 'systems', 'weshouldlookforwaystomatchthisrateofprogressandharnessit', 'toimproveaicompetencyandversatility.forfoundationmodelstoeffectivelyfitthecomplex', 'andhigh-dimensionaldistributionofimagesortext', 'theyshouldtherebybescalable', 'acrossall', 'dimension', 'include', 'model', '’', 'depth', 'width', 'well', 'train', 'time', 'number', 'parameters', 'andamountofdatatheycouldprocess']",76
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '77', 'optimization', 'specifically', 'foundationmodelsshouldbothbe', '1', 'easy-to-train', '§4.2', 'train', 'bybeingresilienttonoiseorimperfectionsinthedata', 'androbustagainstinstabilitieslikevanishing', '[', 'helfrichetal.2018', 'glorotandbengio2010', ']', 'orexplodinggradients', '[', 'hochreiterandschmidhuber', '1997', 'nairandhinton2010', ']', 'butalso', '2', 'easy-to-adapt', '§4.3', 'adaptation', 'byovercomingphe-', 'nomenaofcatastrophicforgetting', '[', 'kirkpatricketal.2017', ']', 'andsupportingfew-shotlearning', '[', 'sing', 'etal.2018', ']', '.wearestillintheearlydaysofunderstandingtheprinciplesthatdrivethescalability', 'oflearningalgorithms', 'andwhilerecentworkshavestartedtoshedsomelightonthesethemes', '[', 'liuetal.2020c', 'kuditipudietal.2019', 'nakkiranetal.2019', ']', 'muchworkremainstobedone', 'hardwarecompatibility', 'movingbeyondaspectsofrobustness', 'andoptimization', 'foundation', 'modelsshouldalsobepracticallyefficient', '§4.5', 'systems', 'andtakeadvantageofcontemporary', 'andfuturehardware', '[', 'hooker2020', ']', '.oneexampleofthatisparallelizablity', 'animportantproperty', 'thatcharacterizesthecomputationsupportedbygpus.indeed', 'muchofthetransformers', '’', 'great', 'successoverthepreviouslydominatingrecurrentapproachwasdrivenbytheirhigherdegreeof', 'parallelism', 'lookingforward', 'giventhefast-paceprogressofsystemsdevelopment', 'weshouldfurtherensure', 'thatmodelsaredesignedtoco-adapttofuturehardwareadvances.consequently', 'foundationmodels', 'shouldideallybeamenabletoschemessuchasdistributedtraining', 'whichisgainingpopularity', 'asisthecasefore.g.', 'mixture-of-experts', 'andpossiblyleveragepropertiessuchassparsityofthe', 'computationorrepresentation', 'asisthecaseforthelongformer', '[', 'beltagyetal.2020', ']', 'bigbird', '[', 'zaheeretal.2020', ']', 'andsparsetransformer', '[', 'childetal.2019', ']', 'approach', 'andwhichlikelywill', 'becomemorecentralinfuturehardwareandprocessors', '4.1.3', 'multimodality', 'traditionally', 'thefieldsofcomputervision', 'robotics', 'andnlphavemadeprogressinanindependent', 'manner', 'withseparatecommunitiesdevelopingspecificapproachessuitableforeachmodality', 'aconduciveconsequencetheriseofdeeplearninghasbroughtaboutwasthebridgesithelped', 'form', 'among', 'various', 'communities', 'research', 'areas', 'within', 'ai', 'seemingly', 'different', 'problemscouldnowbetackledbyclosely-relatedapproaches', 'andstudiesoforiginallyremote', 'topics', 'begin', 'converge', 'common', 'grind', 'breakthrough', 'open', 'new', 'range', 'possibilities', 'fosteringpioneeringexplorationintothethemeofmultimodality', 'encompassingareas', 'asvariedaslanguagegrounding', '[', 'lynchandsermanet2020', ']', 'visualsemantics', '[', 'conseretal.2019', ']', 'embodiedenvironments', '[', 'savvaetal.2019', ']', 'andinteractiveagents', '[', 'grayetal.2019', ']', 'essentially', 'multimodalityservesasakeycomponentofintelligence', 'andisacrucialfactorfor', 'thedevelopmentofboththoroughandbroadcomprehensionoftheworld.concretely', 'language', 'learningismoreeffectivewhenoccurringinagroundedenvironmentratherthaninavacuum', 'andinversely', 'fromthevisionperspective', 'languageencouragestheemergenceofabstractionsthat', 'linkbetweenlow-levelperceptualsignalsandstatisticstosemanticconceptsofobjects', 'properties', 'agentsandmotivations', 'therebyenrichingandelevatingvisualrepresentations', 'inlightoftheseobservations', 'wearguethatfoundationmodelsshouldideallyconnecttogether', 'thedifferentmodalities', 'distilltheirembodiedinformationintoasharedmultifacetedrepresentation', 'andcapturethefullrangeofinter-connectionsandrelationsamongthemsoastofurnishawide', 'rangeofcapabilities', 'see§2.1', 'language', '§2.2', 'vision', '§2.3', 'robotics', '§2.4', 'reason', 'generalityandspecialization', 'animportantdesignchoiceformultimodalfoundationmodels', 'isthedegreeofspecialization', 'orthestructuralsharingbetweenthemodulesresponsibleforeach', 'modality.naturally', 'dataofdifferentdomainsexhibitsdiversekindsofstructuresandproperties—', 'forinstance', 'languageisdiscretewhilevisioniscontinuous.atfirstsight', 'thisvariationhints', 'thatspecializedinductivebiasestailoredforeachmodalitycouldbeofaid.yet', 'astrainingscales']",77
Opportunities and Risks of Foundational Models - Stanford.pdf,"['78', 'centerforresearchonfoundationmodels', 'crfm', 'upwardsandmodelsareprovidedwiththeopportunitytobasetheirlearninglessonstructural', 'priors', 'data', 'general', 'approach', 'maintain', 'handful', 'broad', 'generalassumptionsproveinfactalotmoresuccessfulthantask-specificalternatives.andso', 'ascorroboratedbyrecentsuccessofgeneral-purposemodelsliketransformersacrossdifferent', 'modalities—bothlinguistic', '[', 'liuetal.2019', 'lanetal.2019', ']', 'andvisual', '[', 'dosovitskiyetal.2020', 'hudsonandzitnick2021', ']', 'weseethatgeneralityiscriticalforimprovingaicapabilities', 'multimodalinteractions', 'anotherkeyconsiderationformultimodalmodelsrelatestoweight', 'share', 'dothevariousmodalitiesbenefitfromusingthesameordifferentparametersfortheir', 'respectivecomponents', '?', 'priorworkshaveshownthatfruitfultransfercouldcertainlyoccuracross', 'modalities', 'buttheidealdegreeofsharingremainsunclear', 'soistheexistenceofprincipledways', 'fordiscoveringit', 'finally', 'amajordesignquestionconcernswiththeformsofthemultimodalinteractionssupported', 'bythemodel', 'whichvarywidelybetweenconcretecasesandexamples', 'cross-modalorlate-fusion', 'modelssuchasconvirt', '[', 'zhangetal.2020a', ']', 'andclip', '[', 'radfordetal.2021', ']', 'maintainfullyseparate', 'encodersforeachdatasource', 'andcomparetheirspacesonlyattheultimatecomputationstage', 'usinge.g.', 'asimpledotproduct.meanwhile', 'early-fusionmodels', 'suchasvilbert', '[', 'luetal.2019a', 'choetal.2021', ']', 'jointlyreasonovermultiplemodalitiesnecessaryfortasksofvisualreasoning', 'andquestionanswering.identifyingtheoptimalstageandformformergingtherespectivevector', 'space', '[', 'nagranietal.2021', ']', 'remainsanopenresearchquestion', 'overall', 'whilethereseemstobeaconsensuswithinthecommunityabouttheimportanceof', 'multimodality', 'modelsthatgobeyondshallowalignmentofvisionandlanguageareyettoexist', 'andthethemeofgroundedlanguagelearninginembodiedenvironmentsstillhasmuchroomfor', 'exploration', '4.1.4', 'memory', 'sofar', 'wehavediscussedthefoundationmodels', '’', 'goaltogatherandaccumulateinformationfrom', 'variedmodalitiesatlargescales.thisknowledgeencompassesbothbroadunderstandingofthe', 'worldaswellasspecificmasteryofnichesubjectsorparticularfacts.representingsuchalarge', 'bodyoflearnedinformationisbynomeanstrivial', 'andisleadingtointerestingquestionsabout', 'effectivemechanismsforaccess', 'storage', 'retrievalandmanipulationofparticularitemsormemories', 'explicitstorage', 'animportantdesignprinciplethatcouldachievethesedesiderataistoseparate', 'outcomputationfrommemory', '[', 'westonetal.2014', 'gravesetal.2016', 'hudsonandmanning2018', '2019a', ']', 'inordertoenhancemodels', '’', 'abilitytotransferknowledgebyapplyingpreviouslyacquired', 'abstract', 'skillstonewconcretesettings', 'inthiscontext', 'itisimportanttodistinguishbetweenexplicitfacts—thatcanbestoredinan', 'externalmemorystorage', 'andimplicitknowledge—thatisreflectedthroughthenetworks', '’', 'trainable', 'weights.suchdecouplingofexplicitandimplicitknowledgeenjoysmultipleadvantagescompared', 'tothealternativeofimplicitlyencodingallinformationtogetherthroughthenetworkweights', 'theseparationmitigatestheinflationinmodels', '’', 'sizeandnumberofparametersneededtostore', 'thegrowingquantitiesofknowledge', '[', 'guuetal.2020', ']', 'improvesmodels', '’', 'trustandreliabilityby', 'increasingtheirknowledgeprovenance', '[', 'cheneyetal.2009', ']', 'andmostnotably', 'iskeyformemory', 'update', 'manipulationoradaptation', '[', 'lewisetal.2020b', ']', '§4.3', 'adaptation', 'whichcouldinturn', 'enablegeneralizationtonovelcontextsanddownstreamtasks', 'indeed', 'disentanglementbetweenmemoryandcomputationhasbeenarecurringgoalindeep', 'learningandnlpresearchoverthelastyears', 'includingmodelssuchasmemorynetworks', '[', 'weston', 'etal.2014', 'sukhbaataretal.2015', ']', 'theneuralturingmachine', '[', 'gravesetal.2014,2016', ']', 'theneural', 'statemachine', '[', 'hudsonandmanning2019a', ']', 'andmac', '[', 'hudsonandmanning2018', ']', '.furthermore']",78
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '79', 'usingkey-valuestructures', '[', 'milleretal.2016', ']', 'foraccessingexternalmemorieshasbeenshowntobe', 'veryeffectiveformodelinglong-termdependencies', '[', 'henaffetal.2016', 'bosselutetal.2018', 'lample', 'etal.2019', ']', '.transformers', 'thecelebratedarchitectureunderlyingmostfoundationmodelstodate', 'likewiseexhibitsoperationsthatinvolvekey-valuememory-accessandcomputationamongthe', 'contextualwordrepresentationstheygraduallybuild', '[', 'gevaetal.2020', ']', 'informationretrieval', 'onceamodelcompletesgatheringtheinformationaftertraining', 'aremultiplewaystoretrieveparticularfactsormemoriesnecessaryfordownstreamapplications', 'andtasks.someemployexplicitpromptingtechniquesthatquerythemodel', '’', 'sknowledgethrough', 'inputsequences', '[', 'petronietal.2019', 'kassneretal.2021', 'jiangetal.2020', ']', 'whileotherapproaches', 'involve', 'implicit', 'recollection', 'reshape', 'prior', 'knowledge', 'adaption', 'phase', '[', 'bosselut', 'et', 'al', '2019', 'hwang', 'et', 'al', '2021', ']', 'third', 'category', 'methods', 'go', 'step', 'combinesneural-basedcomputationwithsymbolicaggregationandretrievalofinformationfrom', 'eitherunstructuredtextualrepositories', '[', 'karpukhinetal.2020', 'lewisetal.2020b', 'khattabetal', '2020', ']', 'orevenstructuredresourcessuchasknowledgegraphs', '[', 'zhangetal.2019a', 'petersetal.2019', 'liuetal.2020e', 'vergaetal.2020', 'yasunagaetal.2021', ']', 'however', 'thereistrade-offbetweenthestrongmemorizationskillsofferedbyretrievalmechanisms', 'ontheonehandandthericherrepresentationslearnedwhenthereisaninformationbottleneckon', 'theother.indeed', 'over-relianceonretrievalreducestheopportunitiestolearnhowtorepresent', 'informationincompactandabstractmanners', 'distillkeyinsightsandconceptsoutofthevast', 'amountsofinputinformationthemodelisexposedtoo', 'basically', 'separatethewheatfrom', 'thechaff.forinstance', 'thein-contextlearningabilitiesofgpt-3possiblyemergeasaby-product', 'enforce', 'network', 'represent', 'input', 'sequential', 'data', 'bound', 'memory', 'architecture', '[', 'brownetal.2020', ']', '.overall', 'whiletheycertainlyhavesomemerits', '[', 'guuetal.2020', ']', 'modelsthatrelyonexternalretrievalmechanismsmaynotlearntogeneralizeaseffectivelyas', 'bound', 'compactandabstractrepresentations', 'knowledgemanipulation', 'finally', 'whenconsideringlarge-scalelearningoverlongdurations', 'itiscrucialtonotethedynamicnatureofknowledge', 'wherefacts', '’', 'correctnessandvaliditycan', 'changeovertimeastheworldkeepsevolving—andwhatwastrueorrelevantyesterdaymaynot', 'besotomorrow.itisthereforecrucialforamodeltorepresentitsknowledgeinamannerthat', 'supportsefficientupdateormanipulationoffactsaspartofitslifelonglearning', '4.1.5', 'compositionality', 'compositionality', 'canbedefinedastheprincipleaccordingtowhichthemeaningofthewholeis', 'derivedfromthemeaningofitsconstituentparts', 'andtherulesappliedtocombinethem', '[', 'janssen', 'andpartee1997', 'bottou2014', ']', '.itisacrucialingredientofhumanintelligence', '[', 'lakeetal.2017', ']', 'underlie', 'capabilities', 'plan', 'reason', 'learn', 'readily', 'efficiently', 'handful', 'examples.compositionalitymayholdthekeytoachieveout-of-distribution—orspecifically—', 'combinatorialgeneralization.drawingonclassicideasfromsymbolicai', 'itencouragesandenhances', 'desirable', 'properties', 'within', 'neural', 'network', 'interpretability', 'controllability', 'data-', 'efficiency', '[', 'lakeetal.2017', ']', 'andcantakedifferentforms', 'characterizingvarietyofelements', 'model', 'compositionalitycanbereflectedatthemodellevel', 'intermsofitsarchitecturalproperties', 'structure', 'anddegreeofmodularity—whichcanincreasetrainingandinferenceefficiencyoflarge', 'neuralmodels', '[', 'shazeeretal.2017', ']', '.italsolinkstothemesofinterpretabilityandmultimodality', 'itrelatestotheinterfacesbetweenthedifferentmodulesthemodeliscomposedof', 'whatmodesof', 'interactionstheyemploy', 'andhowtransparenttheyare']",79
Opportunities and Risks of Foundational Models - Stanford.pdf,"['80', 'centerforresearchonfoundationmodels', 'crfm', 'computation', 'modelssuchasmodulenetworks', '[', 'andreasetal.2016', ']', 'andmixture-of-experts', '[', 'shazeer', 'et', 'al', ']', 'go', 'along', 'direction', 'exhibit', 'structural', 'modularity', 'butalsocompositionalcomputation', 'supportedbythespecializationofsub-networks', 'todifferent', 'operations', 'inamannerthatadaptsandtailorsthemodelbehaviortotheinputathand.while', 'somemethodsrelyonconcatenationofhand-engineeredmodules', '[', 'andreasetal.2016', ']', 'alternative', 'approachesenablethenetworkspecializationtonaturallyemergethroughlearning', '[', 'shazeeretal', ']', '.othermodels', 'suchasmac', '[', 'hudsonandmanning2018', ']', 'anddynamicmemorynetworks', '[', 'xiongetal.2016', ']', 'performanexplicititerativecomputation', 'whereagiventaskisdecomposed', 'intomultiplereasoningsteps', 'performedonebyone', 'manifestingsequentialprogressionfromaset', 'ofinitialfactstonovelinferencesandconclusions', 'train', '&', 'data', 'notonlycanthemodeloritscomputationbecompositional', 'butsocanbethe', 'dataortrainingprocessestoo', '[', 'andreas2020', ']', '.insteadoftrainingonemodeloveracompletedataset', 'onecouldsplit', 'ordecomposeitintosubsets', 'traindifferentmodelsoneachoneindependently', 'andultimatelyrecombinethemattesttimethroughvariousensembletechniques', '[', 'dietterich2000', ']', 'suchapproachescouldhavefar-reachingimplicationsonthetraininganddeploymentprocedures', 'offoundationmodels', 'inbothpracticalandevensocietalregards', 'representation', 'wehavediscussedcompositionalityofdifferentelements', 'suchasthemodel', 'computation', 'thetrainingschemesorthedata.butmostnotably', 'thelearnedrepresentationitself', 'whichemergesoverthecourseofthemodeltrainingandadaptation', 'canalsobecompositional', '[', 'andreas2019', ']', '.indeed', 'apromisingmannertorepresentknowledgeisthroughstructured', 'poten-', 'tiallygraph-based', 'object-orientedrepresentations', '[', 'zhangetal.2019a', 'wangetal.2021a', ']', 'centeraroundidentifyingentitiesandeventnodesandformingconnections', 'analogiesandrelation', 'edgesamongthem.itreflectsanaturalwaytoorganizeinformationabouttheworld', 'whereinputs', 'fromdifferentmodalitiescanbechanneledandaggregatedaroundsemanticmulti-facetedconcepts', 'suchrepresentationscouldsupportmulti-hopreasoningandinference', '[', 'washingtonetal.1995', 'sun', 'etal.2020b', 'yuetal.2020c', ']', 'andpotentiallyalsoenablestrongerout-of-distributiongeneralization', 'throughrecombination', 'however', 'compositionalitycanalsohindertheexpressivityoftherepresentation', 'andimpedeits', 'capacitytoaccountforidiosyncrasies', 'exceptions', 'andcontextualcorrelations', '[', 'misraetal.2017a', ']', 'inotherwords', 'thewholecansometimesbegreaterthanthesumofitsparts', 'whereforinstance', 'redwineisnotthesameasredonion.butwhilemanyapproachesthathavedominatedoverthe', 'lastdecadetendtofocusmostlyononeendofthespectrum', 'andlearnmonolithicdistributed', 'representations', 'webelievethatexploringmannerstoreachabetterbalancebetweencontextuality', 'andcompositionalityisapromisingavenueforfutureresearch', '4.1.6', 'summary', 'wehaveintroducedfivepropertiesthatwebelieveareessentialforthenextgenerationoffoundation', 'model', 'inordertoeffectivelydistillthelargeamountsofinformationaroundussotosuccessfully', 'addressdownstreamtasks', 'expressivity—toflexiblycaptureandassimilatereal-worldinformation', 'scalability—toadeptlyhandlehighvolumesofhigh-dimensionaldata', 'multimodality—toconsume', 'processandpotentiallyproducecontentfromdifferentsourcesanddomains', 'memorycapacity—', 'toeffectivelystoreandretrievetheacquiredknowledge', 'andfinally', 'compositionality', 'tofoster', 'successfulgeneralizationtonoveltasks', 'settingsandenvironments.webelievethattherealization', 'ofthefullpotentialoffoundationmodels', 'asisenvisionedanddiscussedindetailthroughoutthis', 'report', 'willrelyonresearchofnewarchitecturalandmodelingadvancestofulfillthesedesiderata']",80
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '81', '4.2', 'train', 'author', 'alextamkin', 'trainingobjectivesaremathematicalfunctionsdescribinghowtotransformamodelarchitecture', 'andlargeamountofbroaddataintoafoundationmodel.forexample', 'gpt-3wastrainedwith', 'alanguagemodelingobjective', 'whichrewardsthemodelforpredictingthenextwordcorrectly', '[', 'shannon1948', ']', '.webeginbylayingoutsomegoalsofthesetrainingapproaches', 'describeimportant', 'designtrade-offsincurrentapproaches', 'andoutlineimportantgoalsforthepathahead', '4.2.1', 'goalsoftrainingobjectives', 'hereweoutlinesomekeygoalsfortrainingalgorithmsinlightoftherecentrapidprogressin', 'thesemethodsandmodels.47', 'leveragingbroaddata', 'theriseofself-supervised', 'learningalgorithmshasunlockedthepower', 'ofinternet-scaledatasetswhichwouldbeintractabletoannotatebyhand.thiskindofbroaddata', 'comesinmanyforms', 'includingimages', 'audiorecordings', 'andvideo', '§2.2', 'vision', 'roboticand', 'sensordata', '§2.3', 'robotics', 'andtext', 'eitherinisolationorpairedwithothermodalitieslikeimages', '§2.1', 'language', '.becausethisdatalacksexternalannotations', 'amajorfocusforresearchersis', 'designingbespokeself-supervisedalgorithmsthatleveragetheuniquestructurewithineachkind', 'ofdatatoproduceatrainingsignalforafoundationmodel', 'domain', 'completeness', 'important', 'goal', 'foundation', 'model', 'train', 'algorithms', 'domaincomplete', 'inthesensethatsolvingthetrainingtaskrequirescapabilitiesthatarebroadly', 'usefulfordownstreamtasksinthedomain', 'see§2.1', 'language', '§2.2', 'vision', '§2.3', 'robotics', '.this', 'propertyiscrucialforthegeneralityofafoundationmodel.forexample', 'languagemodelingmay', 'requiremodelstoacquirecapabilitiesaswide-rangingascoreference', 'sentimentandtranslationas', 'themodellearnstopredictthenextwordinadocument.incontrast', 'asupervisedlearningtask', 'likesentimentclassificationmayleadtoamorenarrowsetofcapabilities', 'see§2.1', 'language', '.as', 'importantasthisqualityis', 'itisnotobviousaprioriwhattaskswillresultinadomaincomplete', 'capabilities', 'orevenhowtoevaluatethefullbreadthofamodel', '’', 'scapabilities', 'see§4.4', 'evaluation', 'and§4.10', 'theory', 'scalingandcomputeefficiency', 'proceduresfortrainingfoundationmodelsmustreliablyconvert', 'data', 'amodelarchitecture', 'andcomputeintoabroadlycapablemodel.tomaximizethecapability', 'ofafoundationmodel', 'wecanidentifythebottleneckstothisprocessandproposenewtraining', 'algorithmswhichremovethem.theriseofself-supervisedalgorithmshasmademodelsizeand', 'computeresourcesincreasinglysalientbottlenecks', '[', 'kaplanetal.2020', 'henighanetal.2020', ']', 'lead', 'toashiftwheremodelsareevaluatednotsolelyontheircapabilitiesbutratherontheamountand', 'kindofcomputeneededtoreachthosecapabilities', '§4.4', 'evaluation', '.theefficiencyoftraining', 'objectivescanvarytremendously,48layinginsharpreliefhowimportantthedesignofatraining', 'approachistotheemergenceofpowerfulcapabilitiesgivenafixedcomputebudget.thus', 'amajor', 'goalfortrainingresearchersistodesigntrainingobjectiveswitharichertrainingsignal', 'result', 'inmodelswhichlearnfasterandattainstrongercapabilities.49oneforceaidingthisdevelopment', 'isthesurprisingpredictabilityofhowcapabilitiesscalewithdifferentkindsofarchitectures', 'data', '47weuse', '“', 'train', ""''"", 'insteadofpretrainingtoemphasizetheprimacyofthefoundationmodelitself', 'andbecausesome', 'methodsforadaptingfoundationmodelstodownstreamtasksdonotinvolveanylaterstageoftraining', '48e.g.,4xforelectra', '[', 'clarketal.2020', ']', 'vsbert', '[', 'devlinetal.2019', ']', ',12xforcontrastivevsgenerativeapproachesto', 'cliptraining', '[', 'radfordetal.2021', ']', '49ofcourse', 'akeygoalforcomputersystemsdesignersistoalleviatecomputeasabottleneckfortraining', 'see§4.5', 'sys-', 'tems', 'andthechoiceofatrainingmethodisultimatelyalsoconstrainedbytheavailabilityofdiverse', 'high-qualitydata']",81
Opportunities and Risks of Foundational Models - Stanford.pdf,"['82', 'centerforresearchonfoundationmodels', 'crfm', 'size', 'andcompute', '[', 'hestnessetal.2017', 'kaplanetal.2020', ']', 'astrikingphenomenonwhichenables', 'modeldeveloperstomakechoicesbasedonclearertrendsinsteadofmorecostlyrandomsearches', '4.2.2', 'designtrade-offsincurrentsslmethods', 'currentself-supervisedlearning', 'ssl', 'methodsfortrainingfoundationmodelsarediverse', 'whatunitesthemisthattheyproducepredictionproblemsfromunlabeleddatawithouttheneed', 'forhumanannotators.sslobjectivesmanufacturearichtrainingsignalfromthisdatathrough', 'carefully-designedconstraints', 'eitheronthedataitself', 'e.g.', 'redactingornoising', 'orontheway', 'themodelisabletorepresentorprocessthedata', 'e.g.', 'latentbottlenecks', '.atsomelevel', 'constraints', '“', 'bakein', ""''"", 'thekindsofcapabilitiesdesiredwhenadaptingmodelstodownstreamtasks', '§4.3', 'adaptation', '.50', 'wedescribethreeimportantdesignchoicesthatcurrentmodelsexplore', 'alongwiththeir', 'respectivetradeoffsintermsoftheirresultingcapabilities', 'level', 'abstraction', 'model', '?', 'fundamental', 'question', 'input', 'representationofafoundationmodelshouldbe.oneoptionistomodeltheinputatthelevelofraw', 'bytes.however', 'thishighdimensionalitymaycausethemodeltofocusonpredictinglesssemantic', 'aspects', 'input,51', 'slow', 'rate', 'acquire', 'generally-useful', 'capabilities', 'theseapproachesalsobecomeintractablewhentrainingmodelsliketransformers', '[', 'vaswanietal', ']', 'whose', 'compute', 'cost', 'grow', 'quadratically', 'input', 'size.52', 'another', 'option', 'use', 'domainknowledgetoreducetheinputspaceofamodel—suchstrategiesincludepatchembeddings', '[', 'dosovitskiyetal.2020', ']', 'aswellasfixedorlearnedtokenization', '[', 'schusterandnakajima2012', 'sennrichetal.2016', 'kudoandrichardson2018', 'vandenoordetal.2017', 'rameshetal.2021', ']', '.these', 'methodsmayalleviatesomechallengesfacinggenerativeapproaches', 'buthavethetrade-offthat', 'theymayjettisonpossibly-usefulinformationintheinput.53thechoiceofacontinuousvsdiscrete', 'inputalsohastrade-offsforadaptation', '§4.3', 'adaptation', 'moreworkisneededtocapturethe', 'benefitsofbothapproaches', 'generativevsdiscriminativemodels', 'generativetrainingapproachesareconceptuallyelegant', 'yetpowerful—theytrainmodelstolearnjointorconditionaldistributionsovertraininginputs', 'twomajorfamiliesofgenerativefoundationmodelsincludeautoregressivefoundationmodels', '[', 'van', 'den', 'oord', 'et', 'al', 'radford', 'narasimhan', 'chen', 'et', 'al', '2020d', 'yang', 'et', 'al', '2019', 'rameshetal.2021', ']', 'whichgenerateinputspiecebypiece', 'anddenoisingfoundationmodels', '[', 'devlin', 'et', 'al', '2019', 'raffel', 'et', 'al', '2019', ']', 'corrupt', 'recover', 'input', 'specific', 'kind', 'generationperformedinthetrainingprocessdetermineswhatkindofinteractivityisavailable', '§4.6', 'data', 'whichcontinuestobeamajorchallengeformanydomains', 'includingrobotics', '§2.3', 'robotics', 'andlow-resource', 'languages', '§2.1', 'language', '50forexample', 'thecausallanguagemodelingobjectiveusedtotraingpt-3', '[', 'brownetal.2020', ']', 'enabledconditioningit', 'viaprefixes.andthecolorjitteraugmentationsusedduringcontrastivelearning', '[', 'chenetal.2020c', ']', 'encourageinvariance', 'topropertiesnotthoughttobeusefulfordownstreamtasks.betterunderstandinghowtheparticularchoiceandstructure', 'oftheseconstraintsinfluencesthecapabilitiesacquiredbythemodelisanimportantareaforfuturework', '§4.10', 'theory', '51e.g.', 'bladesofgrass', 'audiocompressionartifacts', 'orspellingsofwords', '52see§2.2', 'visionand§4.1', 'modelingfordiscussionsoftrainingcostsforhigh-dimensionalsequences', 'suchasimages', 'andvideo', '53forexample', 'tokenizingtextmaymakeithardertolearnrhymes', 'pun', 'orothertasksthatbenefitfromcharacter-level', 'information', '[', 'branwen2020', ']']",82
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '83', 'duringadaptation54', 'see§2.5', 'interactionand§4.3', 'adaptation', 'andfuturemodelsmayenable', 'anevenrichersetofinteractions.55', 'whilegenerativetrainingapproacheshavetheirbenefits', 'severaldiscriminativeapproacheshave', 'alsorecentlygainedtraction.thesemethodsdonotenablegeneration-basedinteraction', 'yetthey', 'mayenablemoreefficientlearningforclassification-orregression-basedtasksinhigh-dimensional', 'continuoussettingslikeimages', 'audio', 'andvideo.mostofthesemethodsoutputvectorsfor', 'part', 'input', 'whicharetrainedtobesimilarfordifferent', '“', 'view', '”', 'ofaninput', '[', 'wuetal.2018', 'vanden', 'oordetal.2018', 'chenetal.2020c', 'heetal.2020', 'grilletal.2020', 'caronetal.2021', 'zhangetal', '2020a', 'radfordetal.2021', ']', 'orusedtopredictwhetherpartsofinputsarerealorfake', '[', 'clarketal', '2020', 'iidaetal.2021', ']', '.betterunderstandingthetrade-offsbetweengenerativeanddiscriminative', 'train', 'aswellascapturingthebestofbothapproaches', 'remaininterestingavenuesforfuture', 'study', 'capturingmultimodalrelationships', 'anotherincreasinglyimportantresearchareaiscaptur-', 'ingtherelationshipsbetweenmultiplekindsofdata.whatthismeansmaydifferbasedonthe', 'contextandthegoalsofamodeler.forexample', 'clip', '[', 'radfordetal.2021', ']', 'andvilbert', '[', 'luetal', '2019a', ']', 'arebothmultimodalvision-language', 'butdifferintheprecisewaytheyaremultimodal.56', 'theformerencodesimagesandtextseparatelyintovectors', 'enablinguserswhohaveexamples', 'fromasinglemodalitytoretrieve', 'score', 'orclassifyexamplesfromtheothermodality.thesecond', 'processesimagesandtextjointlyatanearlystageofthemodel', 'enablingdownstreamapplications', 'likevisualquestionansweringwherereasoningoverpairsofrelatedimagesandtext', 'e.g.', 'image', 'andquestionsaboutthem', 'areprovided.multimodalfoundationmodelsremainanascentresearch', 'area', 'muchisstillunexploredaboutthedifferentwaysamodelcanbemultimodalaswellasbetter', 'understandingthecapabilitiestheseadditionalmodalitiesbring', '4.2.3', 'pathsforward', 'weclosewithsomeimportantgoalsforthefutureoffoundationmodeltraining', 'out-of-the-box', 'ssl', 'right', 'ssl', 'objectives', 'highly', 'domain-specific', 'different', 'methods', 'currentlyprevailinnaturallanguageprocessing', 'computervision', 'andspeechprocessing.this', 'hastwomajordisadvantages', 'first', 'thesedifferenttechniquesmakeitchallengingtograspthe', 'commonthreadsandscientificprinciplesunderlyingwhy', 'eachofthesemethodswork.second', 'thisdomain-specificityrequiresdevelopingnewfoundationmodeltrainingmethodsfromscratch', 'foreachnewfield', 'includingmedical', 'scientific', 'andnewmultimodalsettings.amoregeneral', 'objectiveforefficientlytrainingfoundationmodelsonanykindofdatawouldrepresentasignificant', 'milestoneforthefoundationmodeltrainingcommunity', '[', 'tamkinetal.2021a', ']', 'obtainingarichtrainingsignal', 'itisclearthatnotalltrainingobjectivesaremadeequal—some', 'areradicallymoreefficientthanothers', 'translatingintofarmorecapablefoundationmodelsfora', 'givencomputebudget.aretheretrainingmethodsordersofmagnitudemoreefficientthanthose', 'currentlyknown', '?', 'ifso', 'howcanwefindthem', '?', 'theseinvestigationswillbeshapedbymanyforces', 'includingwhatfuturesoftwareandhardwareadvances', '§4.5', 'systems', 'makepossible.wealso', 'neednotviewdata', '§4.6', 'data', 'andtrainingalgorithmsasindependentfactors', 'notonlydoesthe', '54forexample', 'autoregressivemodelslikegpt-3enableprefix-basedconditioning', 'whiledenoisingmodelsliket5or', 'bertfacilitatetheuseofbidirectionalcontexttoreplacearbitrary-lengthspansorfixtypos', '55otherkindsofgenerativeapproacheslessstudiedinafoundationmodelingcontextincludediffusionandscore-based', 'model', '[', 'sohl-dicksteinetal.2015', 'songandermon2019', 'hoetal.2020', ']', 'vaes', '[', 'kingmaandwelling2014', ']', 'flowmodels', '[', 'dinhetal.2015', 'kingmaanddhariwal2018', ']', 'andgans', '[', 'goodfellowetal.2014', ']', '—itremainstobeseenwhethertheseor', 'otherfutureapproachescanalsoenablelearningasdiversevarietyofcapabilitiesasautoregressiveordenoisingapproaches', '56see§2.2', 'visionand§2.1', 'languageformorediscussionofmultimodalityinvisionandlanguagespecifically']",83
Opportunities and Risks of Foundational Models - Stanford.pdf,"['84', 'centerforresearchonfoundationmodels', 'crfm', 'qualityandavailabilityofthedatainfluencethetrainingsignal,57butthetrainingalgorithmitself', 'couldadaptivelyseekoutorconstructrichertrainingexamplesasthemodelimprovestoaccelerate', 'learn', '[', 'tamkinetal.2021b', ']', 'goal-directedtrainingoffoundationmodels', 'adaptationmethodssuchasprompting', '§4.3', 'adap-', 'tation', 'drawonemergentpropertiesthatresultalmostasanafterthoughtoftraining.canwetrain', 'foundationmodelswheretheabilitytounderstandandreliablycarryoutgoalsinacomplexworldis', 'partofthemodel', '’', 'strainingobjective', '?', 'afocusondevelopinggeneralcapabilitiesdistinguishesthis', 'directionfromthegoalofadaptinganexistingfoundationmodeltoaspecifictaskviareinforcement', 'learn', 'e.g.', 'stiennonetal', '[', '2020', ']', '.instead', 'onemightimaginemoresophisticatedversionsof', 'currentmethodswhichacquireadiverserangeofreal-worldcapabilitiesfromrawonline', '[', 'klyubin', 'etal.2005', 'singhetal.2005', 'salgeetal.2013', 'shakirmohamed2015', 'florensaetal.2017', 'pathak', 'etal.2017', 'haberetal.2018', ']', 'oroffline', '[', 'precupetal.2000', 'langeetal.2012', 'ajayetal.2021', 'yang', 'andnachum2021', 'schwarzeretal.2021', ']', 'interactions', 'withouttheneedforhumanannotationsor', 'taskconstruction.suchmethodsmightusetechniquesquitesimilartoexistingsslalgorithms', 'e.g.', 'trainingsequencemodelsingoal-directedcontextswheretheycanbedirectlyasked', 'tocarry', 'outcertaintasksviaconditioning', 'e.g.', 'udrl', '[', 'schmidhuber2019', 'srivastavaetal.2019', ']', 'ordecision', 'transformer', '[', 'chenetal.2021b', ']', 'alsosee§2.3', 'robotics', '.thecomplexbehaviorsthathavealready', 'emergedinsimpleinteractiveenvironments', '[', 'bakeretal.2020', ']', 'suggestmultitask', 'multiagent', 'multimodalgoal-directedtrainingoffoundationmodelsasaninterestingavenueforfuturestudy', '57includinganyundesirableorbiasedcapabilities', '§5.1', 'fairness']",84
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '85', '4.3', 'adaptation', 'author', 'xianglisali', 'ericmitchell', 'sangmichaelxie', 'xuechenli', 'tatsunorihashimoto', 'fig.18', 'duringadaptation', 'afoundationmodelisconvertedintoanadaptedmodel', 'bottomrow', 'inorderto', 'reflectupdatedinformation', 'desiredbehaviors', 'ordeploymentconstraints', 'whilefoundationmodelsprovideapowerfulgeneral-purposeengineforprocessingmulti-modal', 'information', 'adaptingafoundationmodelbeforeuseisnecessaryforsomeapplications.broadly', 'adaptationprocedureproducesanadaptedmodelbyconditioningafoundationmodelonadditional', 'information', 'either', 'prim', 'foundation', 'model', 'inclusion', 'new', 'data', 'promptinitsinputorbyupdatingsomeorallofthefoundationmodel', '’', 'sparameterstoreflect', 'new', 'information', 'example', 'text', 'summarization', 'append', 'prompt', 'tl', 'dr', 'totheinputarticlecanimprovefoundationmodelperformance', '[', 'radfordetal.2019', ']', 'byacting', 'asataskspecificationforthefoundationmodel.alternatively', 'fine-tuningtheparametersofa', 'foundationmodelwithanorganization', '’', 'sinternal', 'domain-specificdatacouldimprovethemodel', '’', 'accuracybyaddinginformationrelevanttotheorganization', '’', 'susecase.inthissection', 'wedescribe', 'existingapproachestoadaptationandseveralfactorsthatdeterminewhetheraparticularadaptation', 'procedureisappropriateforaparticularsetting.weadditionallydescribevarioususecasesfor', 'foundationmodeladaptation', 'includingrelativelywell-studiedsettingssuchasspecializationofa', 'foundationmodeltoaparticulartaskordomainaswellasmorespeculativesettingsliketest-time', 'dataremoval', '[', 'bourtouleetal.2019', ']', 'andeditingmodelbehavioronparticularinputs', '[', 'sinitsinetal', '2020', ']', '.weconcludebypresentingalong-horizongoalforfutureresearchinfoundationmodel', 'adaptation', '4.3.1', 'methodsforfoundationmodeladaptation', 'many', 'methods', 'adapt', 'foundation', 'model', 'propose', 'make', 'decision', 'whichadaptationproceduretouseforaparticularproblemorcomputeenvironmentdifficult.we', 'emphasizethreefactorsofparticularimportanceforpractitionerstoconsiderwhenselectingan', 'adaptationprocedure', '1', 'thecomputebudget', 'specificallystorageandmemory', '2', 'theamountof', 'task-specificdataavailable', '3', 'extentofaccesstofoundationmodelgradients']",85
Opportunities and Risks of Foundational Models - Stanford.pdf,"['86', 'centerforresearchonfoundationmodels', 'crfm', 'factor1', 'computebudget', 'forfoundationmodelswithbillionsortrillionsofparameters', 'fine-', 'tuningallmodelparametersmaydemandprohibitivelylargememory.also', 'separatelyfine-tuning', 'formanytaskscanincurunacceptablestoragecosts.therearemanyworksthatproposemethods', 'toreducethestorageforadaptingfoundationmodels', 'andwerefertothisclassoflightweight', 'adaptationmethodsaslow-storageadaptation.typically', 'methodsinthisclassfreezemostofthe', 'pretrainedfoundationmodelparametersandonlylearnarelativelysmallnumberoftask-specific', 'parameters', 'eitherbyfine-tuningsomepretrainedparametersorbyaddingaltogethernewmodules', 'reducingthestorageoverheadforeachtask', 'thekeydesigndecisionforsuchalgorithmsisthechoiceofparameterstobeadapted.perhaps', 'thesimplestapproachistotuneonlythefinallayerofthepretrainedmodel', 'whileotherworkstune', 'onlythemodel', '’', 'sbiasvectors', '[', 'zakenetal.2021', ']', 'low-rankresidualstomodelweighttensors', '[', 'hu', 'etal.2021', ']', 'ormasksovermodelparameters', '[', 'zhaoetal.2020b', ']', '.anotherlineofresearchtunes', '“', 'soft', '”', 'prompt', '[', 'liandliang2021', 'qinandeisner2021', 'liuetal.2021e', 'lesteretal.2021', 'hambardzumyan', 'etal.2021', ']', 'correspondingtosequencesofarbitraryparametervectorsratherthanembeddingsof', 'themodel', '’', 'svocabulary', 'andconditionsthefoundationmodelonthesepromptsbyconcatenation', 'withinputactivations', 'eitherattheinputlayeroratalllayers.anotherapproachfreezesallmodel', 'parametersandinterleavesnewmlpmoduleswithtrainableparametersbetweenexistingmodel', 'layer', '[', 'houlsby', 'et', 'al', '2019', ']', 'lightweight', 'adaptation', 'techniques', 'seem', 'trade', 'parameterefficiencyandperformanceondownstreamtasks', 'theysometimesachievecomparable', 'performancetofullfine-tuning', 'despiteupdating1000×fewerparameters', '[', 'zakenetal.2021', 'li', 'andliang2021', 'huetal.2021', ']', '.lesteretal', '[', '2021', ']', 'showsaninstancewhentheperformancegap', 'betweenfullfine-tuningandlightweightadaptationvanishesasthemodelsizeincreases.weremain', 'uncertainhowlightweightadaptationtechniquesscaleasmodelsizeincreases', '[', 'aghajanyanetal', '2020', ']', '.becausegpumemoryistypicallyamorelimitingresourcethandiskstorage', 'low-memory', 'adaptationproceduresareperhapsevenmorecriticaltodemocratizingfoundationmodelsthan', 'low-storageadaptationprocedures.varioustechniquesforlow-memorymodeltraininghavebeen', 'propose', 'whichcanbedirectlyappliedtofine-tuning-basedadaptationprocedures', '§4.5', 'systems', 'however', 'somelow-memoryproceduressuchasgradientcheckpointing', '[', 'chenetal.2016', ']', 'trade', 'computation', 'memory', 'potentially', 'exacerbate', 'significant', 'energy', 'consumption', 'foundationmodels', '[', 'benderetal.2021', ']', 'factor', '2', 'data', 'availability', 'task', 'specialization', 'mostly', 'demand', 'task-specific', 'label', 'data', 'trainingsignals.58however', 'thecostofannotationvariesgreatlyacrosstasksandlanguages', 'example', 'annotatingmridatarequiresexpertmedicalknowledge', 'whereaslabelingsentiment', 'forenglishtextsrequiresonlycommonsensejudgement.whenadaptationdataisplentiful', 'mightapplytraditionalfine-tuningapproachesortheirlightweightcounterparts.inlow-resource', 'language-basedsettings', 'combiningpromptingandfine-tuninghasbeenshowntobeapromising', 'direction', '[', 'schickandschütze2021a', 'b', 'gaoetal.2020c', 'perezetal.2021', 'ivetal.2021', 'minetal', '2021', ']', '.lescaoandrush', '[', '2021', ']', 'showsthatawell-tunedpromptcanbewortharound100training', 'examples', 'andfine-tuningacarefullypromptedfoundationmodelissignificantlymoredata-efficient', 'thanfine-tuninganunconditionedfoundationmodel', 'factor3', 'accesstofoundationmodelgradients', 'despitethesignificantimpactoffoundation', 'modelsonsomeresearchcommunities', 'littlestandardizationofdistributionpracticesexistsforlarge', 'scalefoundationmodels', 'withmorethan50billionparameters', '.aswegraduallybecomeawareof', 'thepotentialhazardsfromthemisuseoffoundationmodels', 'see§5.2', 'misuse', 'providingaccesstoall', '58promptsareanexception', 'althoughwemightconsiderpromptstoimplicitlyrepresenttheinformationcontainedina', 'batchoflabeleddata', '[', 'lescaoandrush2021', ']']",86
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '87', 'ofafoundationmodel', '’', 'sparametersforfine-tuningmightresultinethicalconcerns.moreover', 'usersdonothaveenoughcomputeresourcestoexploittheirfullaccess.forexample', 'thememory', 'requirementsoffoundationmodelsmightprecludetheirdirectfine-tuningformanyorganizations', 'andinstitutions.consequently', 'futurefoundationmodelproviderswouldlikelyrestrictaccessto', 'thefullparametersofthemodelandinsteadprovidesurrogateapiaccess', 'asexemplifiedbyan', 'earlyfoundationmodel', 'gpt-3.ononeextreme', 'ifafoundationmodelproviderenablesaccess', 'onlytothemodeloutput', 'e.g.', 'thetextualcontinuationofaprompt', 'thegeneratedimage', 'orascore', 'evaluatingthealignmentbetweenanimageandatextualdescription', 'foundationmodelscanbe', 'adaptedusingin-contextlearning', '[', 'brownetal.2020', ']', '.in-contextlearningfreezesthefoundation', 'modelparameters', 'andsteerstheoutputofthefoundationmodelsbyconditioningona', 'typically', 'naturallanguage', 'prompt', 'whichmightbecomposedoftaskinstructionsordemonstrations.to', 'improvetheperformanceofin-contextlearning', 'thepromptneedstobecarefullydesigned', 'either', 'bymanualsearchoranautomatedprocedure', '[', 'jiangetal.2020', 'shinetal.2020', ']', 'andvalidatedonthe', 'adaptationdata.attheotherextreme', 'ifthefoundationmodelprovidergrantsaccesstogradients', 'withrespecttomodelparameters', 'fullfine-tuningcanbeapplied', 'whereallmodelparametersare', 'updatedtoimproveperformanceonadownstreamtask.asamiddleground', 'wemightobtain', 'gradientaccessonlytofoundationmodelinputs,59whichareconsiderablylowerdimensionalthan', 'foundationmodelparameters.inthiscase', 'wecoulddeploylightweightadaptationtechniques', '[', 'liu', 'etal.2021e', 'liandliang2021', 'lesteretal.2021', ']', 'whichfreezethemodelparametersandoptimize', 'acontinuousprefixorpromptforeachtask', '4.3.2', 'usecasesforadaptation', 'adaptationisusefulwheneverthedesiredusecaseofamodeldiffersfromtherelativelygeneral', 'trainingobjectiveusedforfoundationmodeltraining', '§4.2', 'train', '.mostcommonlyconsidered', 'isthecaseinwhichafoundationmodelisadaptedtoperformaspecifictask', 'e.g.', 'textsummarization', 'oranimalclassificationfromimages', 'narrowingthescopeofthemodel.indeed', 'thevastmajority', 'ofexistingapproachesdescribedearlierinthissectionhavetargetedthissetting.however', 'formsofadaptationareuseful', 'suchasmakinglocalmodeleditstocorrectundesirablepredictions', 'forparticularinputsoraddingprivacyconstraintstothetrainedfoundationmodel', 'whichare', 'task-agnostic.inthissubsection', 'wedescribeavarietyofusecasesforadaptation', 'themethods', 'thataremostapplicabletothem', 'andremainingchallengesinaddressingthesesettings', 'taskspecialization', 'themostwidely-studiedcaseoffoundationmodeladaptationisthatoftask', 'specialization', 'inwhichafoundationmodelisadaptedtooptimizeperformanceforaspecifictask', 'orsetoftasks.forexample', 'specializingforsummarizationtaskswouldinducefoundationmodel', 'behaviortoextractkeyideasfromtheinputdocument', 'andre-organizetheminshortsummary', 'sentences.variousadaptationprocedureshaveproveneffectivefortaskspecialization', 'show', 'significant', 'improvement', 'performance', 'unadapted', 'model', '[', 'howard', 'ruder', 'brownetal.2020', ']', '.inadditiontotherelativelywidely-studiedsettingofspecializingfoundation', 'modelstospecifictasks', 'othertask-agnosticadaptationproblemsbecomeincreasinglychallenging', 'butnolessimportant', 'forfoundationmodelsowingtotheirsizeandcomputationaldemands', 'forexample', 'thecostoftrainingfoundationmodelsmakescontinualtrainingovertimetokeep', 'model', '’', 'predictions', 'date', 'current', 'events', 'particularly', 'expensive', 'additionally', 'challengeofcollectingmassiveanonymizeddatasetsusedtotrainfoundationmodels', '§4.6', 'data', 'makethelikelihoodofpersonalinformationleakageintotrainingsetsnon-trivial', 'mechanismsto', 'efficientlyremovetrainingdatafromafoundationmodelpost-factoarethereforedesirable', '59assumingthefoundationmodelproviderenablestheinputspacetobecontinuous']",87
Opportunities and Risks of Foundational Models - Stanford.pdf,"['88', 'centerforresearchonfoundationmodels', 'crfm', 'temporaladaptation', 'ideally', 'foundationmodelsstoreknowledgethatcloselyrepresentsthe', 'stateoftheworld', 'independentofmodality.however', 'theworldisconstantlychanging', 'newheads', 'ofstateareelected', 'clothingstyleschange', 'socialnormsandbeliefsshift', '§5.6', 'ethics', 'andtheuse', 'oflanguageevolves', 'causingashiftintheinputdistribution', 'targetpredictivedistribution', 'orboth', 'thistemporalshiftpresentsachallengingstatisticalproblemduetotheinduceddistributionshift', 'asdiscussedin§4.8', 'robustness.forfoundationmodels', 'temporalshiftalsopresentsaparticu-', 'larlydifficultcomputationalproblem', 'duetothecomputationallydemandingnatureoftraining', 'foundationmodels', '[', 'shoeybietal.2019', 'brownetal.2020', ']', 'frequentre-trainingfromscratchmight', 'carryunacceptablefinancialorenvironmentalimpacts', '[', 'benderetal.2021', ']', '§5.3', 'environment', 'orsimplytaketoolongtobeaviablemethodforkeepingmodelsuptodate.invisualdomains', 'gradualself-trainingonunlabeleddataacrossintermediatetimepointscanbridgethetemporal', 'shiftacrossalongtimeperiod', 'butremainsanexpensiveretrainingprocedure', '[', 'kumaretal.2020a', ']', 'inthecontextoflanguagemodels', 'temporally-partitioneddiagnosticdatasetshelpquantifythe', 'rateatwhichlargelanguagemodelsbecomeoutdated', '[', 'lazaridouetal.2021', 'hombaiahetal.2021', 'dhingraetal.2021', ']', 'showingthatclassictechniqueslikere-weightingtrainingdataanddynamic', 'evaluation', 'updatingmodelparameterswithnewdataatproductiontime', '[', 'mikolovetal.2010', ']', 'canpartiallyalleviate', 'butnotfullysolve', 'thisproblem.explicitlyconditioningalanguagemodel', 'time', 'period', 'intend', 'model', 'another', 'technique', 'show', 'promise', '[', 'dhingraetal.2021', ']', '.analternativestrategytoaddressingtemporalshiftistodesignretrieval-', 'base', 'semi-parametric', 'model', 'whichaugmentthemodelinputwithadditionalcontextretrieved', 'fromalarge', 'human-interpretabledatabase', 'e.g.', 'wikipediaarticles', '[', 'karpukhinetal.2020', 'lewis', 'etal.2020b', 'guuetal.2020', 'khandelwaletal.2020', 'khattabetal.2020', ']', '.forretrieval-basedmodels', 'adaptationcorrespondstoupdatingindividualunitsofinformationinthedatabase', 'e.g.', 'single', 'paragraphsofencyclopediaarticles', 'withoutre-trainingthemodel.whilepromising', 'challenge', 'forretrieval-basedapproachesremainbothintraininganaccurateretrievalmechanismandin', 'accuratelyconditioningontheretrievedinformation', '[', 'lewisetal.2020b', ']', '.werevisittheproblem', 'oftemporaladaptationinthemoregeneralcontextofcontinuallearninglaterinthesection', 'domainspecialization', 'inadditiontotaskspecialization', 'itisoftennecessarytospecializea', 'foundationmodeltoaparticulardomain', 'suchaslegaldocuments', 'withoutlimitingthebreadthof', 'tasksthefoundationmodelcanaccomplish.thisspecializationinducesamismatchbetweenthe', 'foundationmodeltrainingandadaptationdatadistributions', '§4.8', 'robustness', 'whichmayrequire', 'newadaptationmethodstohandle.priorworkshavefoundthatdiverseandgeneralpretraining', 'datacancausenegativetransferforcurrentadaptationmethods.forexample', 'coleetal', '[', '2021', ']', 'showsthatfine-tuningamodelpretrainedonly', 'ontheinaturalistanimalclassificationdataset', 'providesbetterdownstreamperformancethanfine-tuningamodelpretrainedoninaturalistalong', '750k', 'image', 'similarly', 'legalbert', '[', 'chalkidis', 'et', 'al', '2020', ']', 'pretrained', 'onlegaldocuments', 'improvesoverbert', '[', 'devlinetal.2019', ']', 'whichistrainedonamuchmore', 'diversetrainingsetonthedownstreamtaskoftextclassificationandsequencetagginginlegal', 'documents.oneapproachtodomainspecializationistoincludeanintermediateadaptationstep', 'wherethefoundationmodelcontinuestrainingonunlabeleddatafromthespecializeddomain.for', 'instance', 'thisapproachimprovesthedownstreamperformancesignificantlyforsatelliteimagesand', 'specializedtexttopics', '[', 'reedetal.2021', 'gururanganetal.2020', ']', '.however', 'continualfoundation', 'modeltrainingmayperformworsethanre-trainingfromscratchincertaindomainssuchaslegal', 'document', '[', 'chalkidisetal.2020', ']', '.elucidatingthescenariosinwhichcontinualtrainingdoesor', 'doesnotbenefitperformanceisanimportantdirectionforfuturework', 'localmodelediting', 'insomesettings', 'itisusefultoadaptafoundationmodellocally', 'mean-', 'ingthatthemodel', '’', 'spredictivedistributionshouldbeadaptedonlyforasingleinputoralocal']",88
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '89', 'neighborhoodaroundasingleinput', 'withoutchangingthemodel', '’', 'sbehaviorforunrelatedinputs', 'forexample', 'whenafoundationmodelproducesanespeciallyproblematicmistranslationfora', 'particularinputphraseandtargetlanguage', 'itisdesirabletocorrectthismistranslationwithout', 'affectingthemodel', '’', 'sbehaviorforunrelatedphrases.pastworkhasstudiedtheproblemofapplying', 'approximatelylocalizedupdatestolargeneuralnetworksthroughnewpretrainingobjectivesthat', 'enableeasyeditingwithstandardgradientdescent', '[', 'sinitsinetal.2020', ']', 'higher-ordernetworks', 'thatpredictparametereditsforanunderlyingmodel', '[', 'caoetal.2021', ']', 'andconstrainedfine-tuning', 'procedures', '[', 'zhuetal.2020', ']', '.however', 'existingmethodsvaryinthereliabilitywithwhichthey', 'canperformmodeleditswithoutdamagingglobalmodelperformance.furthermore', 'scalingthese', 'methodstomassivefoundationmodelsisnotstraightforwardduetotheirsizeandthecomputa-', 'tionalcostoftrainingobjectivesthatrequirecomputinghigher-ordergradients', '[', 'sinitsinetal.2020', 'caoetal.2021', ']', 'applyingconstraints', 'therearesettingsinwhichfoundationmodelsneedtobeadaptedtosatisfy', 'privacyconstraints.forinstance', 'carlinietal', '[', '2021', ']', 'demonstratedthatexistingfoundationmodels', 'areabletomemorizesensitiveinformationinthetrainingdataandcanregurgitatesuchdatawhen', 'queriedviastandardapis.whilethisphenomenoncallsforimproveddatacuration', 'develop', 'adaptationprocedureswhicheliminateorreducetheinfluenceofspecificdataexamplesonthe', 'trainedmodelwouldbeacomplementarysolution.improvedadaptationstrategies', 'alongwith', 'betterpretrainingmethods', 'inthisdirectionwillalsobenefitinstitutionsworkingwithfoundation', 'modelsunderthegeneraldataprotectionregulation', 'gdpr', 'asthemandategivesuserstheright', 'tobeforgotten.whileresearchonthetopicofmachineunlearning', '[', 'bourtouleetal.2019', 'caoand', 'yang2015', ']', 'hasstartedtogaintraction', 'theproblemhasnotyetbeenstudiedindepthforfoundation', 'models.inaddition', 'foundationmodelstrainedonlesscuratedinternetdatahavebeenshownto', 'exhibitharmfulbiasestargetingspecificgroups', 'e.g.', 'genderandracialbias', '[', 'benderetal.2021', 'bastaetal.2019', 'kuritaetal.2019', 'shengetal.2019', ']', 'andcanproducetoxicoutputs', '[', 'gehmanetal', '2020', ']', '§5.2', 'misuse', '.whilestrategiessuchasfurtherfine-tuningthefoundationmodeloncarefully', 'curateddatasets', 'forpotentiallymultiplegenerations', '[', 'solaimananddennison2021', ']', 'orapplying', 'controllablegenerationtechniques', '[', 'keskaretal.2019', ']', 'haveshownsomesuccessinmitigating', 'harmfulbehavior', 'aframeworkfortrainingequitableandsafefoundationmodels', '§5.1', 'fairness', 'willlikelyrequirefurtherresearchwithacollectiveeffortacrossthedatacollection', 'train', 'adaptationphasesaswellasconsultationwithdomainexperts', '4.3.3', 'along-termgoalforfoundationmodeladaptationresearch', 'totheextentthatadaptationisconcernedwithefficientlyintegratingamodel', '’', 'sexistingknowledge', 'withnewdataorobjectives', 'anaturalextensionofadaptationiscontinuallearning', '[', 'mccloskey', 'andcohen1989', 'parisietal.2019', ']', '.theabilitytoadaptafoundationmodelcontinuallyisdesir-', 'able', 'whethertokeepamodel', '’', 'sknowledgecontinuallyup-to-datewithworldeventsorcultural', 'developments', 'continuallyadddatafromcompletelynewdomainsormodalitiesastheybecome', 'available', 'orcontinuallyeditamodel', '’', 'smemoriestocomplywithprivacyorlegalconstraintsasa', 'society', '’', 'svaluesorlawsevolve.however', 'continuallearningproblemstypicallyinducecatastrophic', 'forget', '[', 'mccloskeyandcohen1989', 'ratcliff1990', 'kirkpatricketal.2017', ']', 'inneuralnetworks', 'whereoldtasksordataarerapidlyforgottenasthetrainingdistributionchanges', 'weconsidercontinualadaptationofafoundationmodelasonepossible', '‘', 'grandchallenge', '’', 'future', 'adaptation', 'research', 'likely', 'require', 'innovations', 'model', 'architectures', 'train', 'objectives.asnotedinthetemporaladaptationsub-sectionabove', 'thereisagrowingbodyofwork', 'particularlyfocusedoncontinuouslanguagemodeltraining.amoregeneral', 'concretemilestone', 'wouldbetoincrementallytrainafoundationmodelonanon-repeatingstreamoftasks/datasuch']",89
Opportunities and Risks of Foundational Models - Stanford.pdf,"['90', 'centerforresearchonfoundationmodels', 'crfm', 'thatitattainsthesamelevelofdownstreamproficiencyasastationaryfoundationmodeltrained', 'onalltasks/datasimultaneously.accomplishingsuchagoalmayrequirenewunderstandingof', 'howtheproblemofcatastrophicforgettingmanifestsatthescaleoffoundationmodels', 'leverage', 'insightsfrommeta-learning', '[', 'schmidhuber1987', 'santoroetal.2016', 'finnetal.2017', ']', 'tolearneach', 'newdomain', 'modality', 'ortaskasquicklyaspossible', 'developingnewarchitecturesortraining', 'objectives', 'solve', 'unforeseen', 'challenge', 'nonetheless', 'continual', 'foundation', 'model', 'adaptationholdsthepromiseofmorerapidlyrespondingtoshiftsinsocio-culturalvalues', 'better', 'leveragingexistingknowledgetolearnnewconcepts', 'lesseningtheenvironmentalimpactand', 'increase', 'accessibility', 'foundation', 'model', 'eliminate', 'computational', 'burden', 'trainingfromscratch', 'andreducingtheextentthatpreviously-learnedconceptsmustbere-learned', 'duetoforgetting']",90
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '91', '4.4', 'evaluation', 'author', 'rishibommasani', 'kawinethayarajh', 'omarkhattab', '4.4.1', 'introduction', 'evaluationgivescontexttomachinelearningmodels', 'itservesasameansfor', '1', 'trackingprogress—', 'measure', 'performance', 'model', 'design', 'improve', 'model', '§4.1', 'model', '2', 'understanding—whatbehaviorsdomodelsexhibit', '§4.11', 'interpretability', 'andhowdotheyperformondifferentslicesofdata', '§4.8', 'robustness', '3', 'documentation—how', 'doweefficientlysummarizemodelbehaviorandcommunicatethistodiversestakeholders.for', 'foundationmodels', 'eachofthesepurposesforevaluationarecriticalbutthenatureoffoundation', 'modelsintroducesnewchallengesthatarenotgenerallyencounteredinotheraiormlsettings', '1', 'trackingprogressrequiresrelativecomparison', 'butcomparingfoundationmodelsiscompli-', 'catedbythefactthatfoundationmodelsmustbeadapted', 'potentiallyindifferentways', 'performtasks', '2', 'understandingrequiresspecifiedin-advanceknowledge', 'e.g.', 'taxonomies', 'ofwhatisbeing', 'evaluatedfor', 'butfoundationmodelsacquireemergentskills', 'e.g.', 'in-contextlearning', 'willbedifficulttoanticipateindesigningevaluations', '3', 'documentationrequirescleardesideratatomeaningfullyinformdecision-making', 'butfoun-', 'dationmodelscanbeadaptedformyriadapplications', 'whichmakescomprehensivedocu-', 'mentationchallenging', 'toorientthediscussionofevaluatingfoundationmodels', 'wedistinguishtwoclassesofevaluation', 'thatarisefromtheabstractionoffoundationmodels', 'intrinsicevaluationofthefoundationmodel', 'whichisinherentlydivorcedfromaspecifictaskduetothetask-agnosticityofthesemodels', 'extrinsicevaluationoftask-specificmodels', 'whichisnecessarilydependentonboththefoundation', 'modelandtheadaptationmechanism.further', 'werecognizethatduetotheanticipatedimpact', 'andscopeoffoundationmodels', 'avarietyofstakeholders', 'e.g.', 'foundationmodelprovidersand', 'application', 'developers', 'auditors', 'policymakers', 'practitioners', 'researchers', 'require', 'evaluationofbothfoundationmodelsandtask-specificderivatives', 'withtheseevaluationsserving', 'differentpurposesandinvolvingdifferentdesideratabasedonthestakeholder.withthisinmind', 'standardparadigmsfortheevaluationofmachinelearningmodelsarenotdesignedexplicitlyfor', 'thesettingoffoundationmodels.therefore', 'weemphasizeintrinsicevaluation', '§4.4.2', 'evaluation-', 'intrinsic', 'theimportanceofadaptationinextrinsicevaluation', '§4.4.3', 'evaluation-adaptation', 'andevaluationdesign', '§4.4.4', 'evaluation-design', 'asclearstepstowardsanevaluationframe-', 'workthatisbettersuitedtofoundationmodels.thisdiscussioncontributestobroaderdialogue', 'surroundingtheroleofevaluationofmachinelearningsystems', '[', 'galliersandspärckjones1993', 'liptonandsteinhardt2019', 'ribeiroetal.2020', 'linzen2020', 'kielaetal.2021', 'millietal.2021', 'jacobs', 'andwallach2021', 'bowmananddahl2021', 'dehghanietal.2021', 'maetal.2021a', 'interalia', ']', 'giventhecomplexitiesofevaluation', 'maybenefitfromdrawingupontheoriesofmeasurement', 'andevaluationthatexistbeyondmachinelearning', '[', 'messick1987', 'jackman2008', 'loevinger1957', 'messick1988', 'hand2010', 'brewerandcrano2014', ']', '4.4.2', 'intrinsicevaluation', 'evaluationofmachinelearningsystemshastraditionallybeengroundedintasks', 'oftenonesthat', 'areenvisionedasfunctionsspecificallyusefulforapplications', 'e.g.', 'translation', 'objectrecognition', 'contrast', 'since', 'foundation', 'model', 'intermediary', 'assets', 'must', 'adapt', 'specializedtoperformusefultasks', 'thestandardevaluationparadigmmustbealteredtofacilitate', 'thedirectunderstandingandcomparisonoffoundationmodels']",91
Opportunities and Risks of Foundational Models - Stanford.pdf,"['92', 'centerforresearchonfoundationmodels', 'crfm', 'oneapproachistoevaluatefoundationmodelsintermsofthetaskassociatedwiththetraining', 'objective.forexample', 'alanguagemodellikegpt-3', 'whichwastrainedbypredictingthenextword', 'giventheprecedingcontext', 'maybeevaluatedbasedontheprobabilitiesitassignswordsgiven', 'theirprecedingcontextinheld-outtestdata', 'i.e.', 'perplexityonlanguagemodellingbenchmarks', 'like', 'lambada', '[', 'paperno', 'et', 'al', ']', 'approach', 'show', 'promise', 'nlp', 'thus', 'far', 'identify', 'two', 'fundamental', 'limitations', 'exhibit', 'first', 'rely', 'train', 'objective', 'evaluation', 'lack', 'generality', 'foundation', 'model', 'train', 'use', 'different', 'incompatible', 'objectives', 'cannotbereadilycomparedorunderstoodinaconsistentframe.second', 'evaluationinthisway', 'rely', 'upon', 'proxy', 'relationship', 'meaningful', 'i.e.', 'measurements', 'term', 'train', 'objectiveshouldcorrelatewithothermoremeaningfulandintelligiblequantities', 'e.g.', 'thequality', 'ofcontentgeneratedviaafoundationmodel', '.whilethisproxyrelationshiphasproventoberobust', 'inthepastinsomecontexts', 'itlikelywillbreakdownwhenassessingmorediversecapabilitiesof', 'foundationmodels', 'theirbehaviorinmorediverseenvironmentsordomains', 'andconsiderations', 'beyondin-domainaccuracy', 'wediscussthismoreextensivelyin§4.4.4', 'evaluation-design', '.in', 'lightoftheselimitations', 'weanticipatethattwoapproacheswillneedtobeconsidered', 'offer', 'complementarybenefits', 'imputingintrinsicevaluationfrombroadextrinsicevaluation', 'oneroutetowardsevaluat-', 'ingfoundationmodelsistoadaptthemtoawiderangeoftasksandmeasuretheperformance', 'result', 'task-specific', 'model', 'foundation', 'model', 'share', 'basis', 'across', 'model', 'performance', 'aggregate', 'reflect', 'nature', 'quality', 'share', 'basis.atpresent', 'manysubareasofaihavebeguntoconstructmeta-benchmarks', 'i.e.', 'asingle', 'evaluationthatconsolidatesindividualevaluationsacrossanumberofdifferenttasksordomains', '[', 'wangetal.2019b', 'huetal.2020', 'santurkaretal.2020', 'gehrmannetal.2021', 'hendrycksetal', '2021b', 'kohetal.2021', 'tamkinetal.2021a', ']', '.giventhegrowingadoptionofthisparadigmand', 'establish', 'strengths', 'note', 'likely', 'insufficient', 'fully', 'satisfy', 'goals', 'evaluationswithrespecttofoundationmodels.meta-benchmarkevaluationrequiresadaptation', 'minimallytospecializethefoundationmodeltoeachofthetasksinthemeta-benchmark', 'makesreasoningaboutthefoundationmodelitselfchallenginggiventheadditionprocess', 'i.e.', 'adap-', 'tation', 'involved.specifically', 'thiscomplicatesmattersofprogress', 'bothintermsoftracking', 'e.g.', 'performanceattributabletopotentfoundationmodelsorwell-designedadaptionpractices', 'intermsofidentifyingimprovementsintheprocessusedtolearnfoundationmodels', 'e.g.', 'fun-', 'damentalimprovementsindataselection', '§4.6', 'data', 'trainingobjectives', '§4.2', 'train', 'modelarchitectures', '§4.1', 'model', 'maybedifficulttoidentifybycomparingtheperformanceon', 'ameta-benchmarkbetweentwofoundationmodels', '.inaddition', 'thisevaluationparadigmmakes', 'itdifficulttounderstandordocumentpropertiesandcapabilitiesspecifictothefoundationmodel', 'whichmaymakeitunwieldytoconveytocertainstakeholders', 'e.g.', 'superglueperformance', 'maynotbesufficientlyinformative', 'ormaybemisleading', 'forpolicymakers', 'oruseasgroundsfor', 'anticipatingtheirbehaviorfornewtasksordomains', 'directevaluationofintrinsicproperties', 'tocomplementtheuseofmeta-benchmarks', 'wealso', 'argueforwhymeasuringtheproperties', 'e.g.', 'specificcapabilitiesorbiases', 'offoundationsmodels', 'directly', 'valuable', 'divorce', 'specific', 'tasks.60', 'example', 'may', 'endeavor', 'directly', 'measurethelinguisticcapabilitiesoffoundationmodelstoidentifysyntacticallyvalidandinvalid', 'sentences.tomotivatethevalueofthisapproach', 'wereturntothepurposesforevaluation.notably', '60strictlyspeaking', 'thesedirectevaluationsmaystillinvolveformulationasataskandfoundationmodelspecialization', 'toperformthetask', 'buttheobjectiveismoreakintoprobing', 'see§4.11', 'interpretability', 'oftryingtomeasurethe', 'foundationmodelasdirectlyaspossible']",92
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '93', 'articulatingthepresenceandintensityofcapabilities', 'skills', 'andbiasesidentifiesconcreteareasfor', 'improvement', 'progress', 'elucidatesthecurrentpotential', 'understand', 'andexpressesrelevant', 'aspectsefficiently', 'documentation', '.suchanapproachalsoisinserviceofbroadlycomprehensible', 'evaluation', 'i.e.', 'evaluationthatcanbeunderstoodbybothtechnicalexperts', 'non-technicalexperts', 'e.g.', 'policymakersorsocialscientists', 'andthegeneralpurpose.forexample', 'characterizingthe', 'persuasiveorrhetoricalcapabilitiesofthesemodelsmayespeciallyintuitiveforinternalizingtheir', 'potentialfordisinformationandmisuse', '§5.2', 'misuse', '[', 'buchananetal.2021', ']', 'directevaluationofpropertiesalsoservesasanimportantpathwaytowardsbetterhandlingofthe', 'emergentpropertiesoffoundationmodels', 'todemonstratethis', 'wetakein-contextlearningasacase', 'study.inparticular', 'brownetal', '[', '2020', ']', 'notonlydemonstratedgpt-3', '’', 'ssignaturecapabilityofrobust', 'in-contextlearning', 'butalsowerethefirsttospecificallyidentifyin-contextlearningasaspecific', 'waytoadaptandinteractwithmodels', 'throughtheirexplorationofgpt-3', '.traditionaltask-based', 'extrinsicevaluationdoesnotprovideaclearmeansbywhichin-contextlearningcouldhavebeen', 'identify', 'directlyinteractingwiththefoundationmodelappearstobenecessaryinthiscase.more', 'generally', 'whileitappearsinevitablethatmanyunanticipatedphenomenalikein-contextlearning', 'willberecognizedthroughtheunstructuredorlooselystructuredexplorationofthesemodelsand', 'theircapabilities', 'webelievenewapproachestoevaluationshouldbesoughtoutthatstructure', 'thisexplorationor', 'moreambitiously', 'suggestnewpropertiesthatcanthenbemorerigorously', 'testedfor.intrinsicevaluationmayalsolowerthethresholdfordemonstratingthepotentialof', 'foundationmodels', 'newapproachesforfoundationmodelsmaybesufficientlypromisingifthey', 'demonstrateimprovementsinintrinsicevaluation', 'eveniftheyarenotimmediatelyaccompaniedby', 'correspondingwell-suitedadaptationmethodsforelicitingthesecapabilitiesinextrinsicevaluation', 'thereisasignificantopenquestionofhowintrinsicevaluationshouldbeimplemented', 'mechanicsofsuchevaluationareunclear.weenumerateafewgeneralprinciplesandconsiderations', 'thatmayhelpinformthedesignandexecutionofintrinsicevaluation', '1', 'inspiration', 'evaluation', 'humans', 'many', 'relevant', 'properties', 'capabilities', 'biasesweareinterestedinforfoundationmodelsarealsoofinterestforhumans', 'suggeststhatmethodsformeasuringthesepropertiesinhumansmayprovetobeinstructive', 'orevendirectlytranslatable', 'forevaluatingfoundationmodels.forexample', 'psycholinguistic', 'measuresofhumanlinguisticcompetenciescanbemodifiedtoevaluatefoundationmodel', 'linguisticcompetencies', '[', 'levy2008', 'franketal.2013', 'linzenetal.2016', 'ettingerandlinzen', 'marvinandlinzen2018', 'vanschijndelandlinzen2018', 'futrelletal.2019', 'prasadetal', '2019', 'ettinger2020', ']', 'orpsychologicalmeasuresofhumansocialbiasescanbemodifiedto', 'evaluatefoundationmodelsocialbiases', '[', 'greenwaldetal.1998', 'caliskanetal.2017', 'may', 'etal.2019', 'guoandcaliskan2021', ']', '2', 'human-in-the-loopevaluation.human-in-the-loopevaluationmayprovetobecriticalto', 'provideamoreexploratorymeansforunderstandingfoundationmodels', 'includingassessing', 'theirgenerativeorinteractivecapabilities.inparticular', 'humaninteractionwithfoundation', 'modelsdirectlymaybetteridentifytheiremergentcapabilitiesandlimitationsanddirect', 'auditingoffoundationmodels', '[', 'e.g.', 'rajiandbuolamwini2019', '§5.6', 'ethics', ']', 'mayadvances', 'goalsfordocumentationandtransparency', '3', 'validityofintrinsicmeasures.whileintrinsicmeasuresallowfordirectmeasurementatthe', 'source', 'i.e.', 'measurementandevaluationofthepropertiesofafoundationmodelindependent', 'adaptation', 'specific', 'task', 'pose', 'challenge', 'build', 'trust', 'validity', '[', 'messick1987,1988', ']', 'oftheevaluation.inparticular', 'extrinsicevaluationoutcomesmayalso', 'beimportantinvalidatingintrinsicmeasuredesign', 'e.g.', 'thepredictivevalidityofintrinsic']",93
Opportunities and Risks of Foundational Models - Stanford.pdf,"['94', 'centerforresearchonfoundationmodels', 'crfm', 'measure', 'i.e.', 'theirabilityto', 'statistically', 'predictedrelateddownstreamoutcomes', 'may', 'provetobeacentralcriterion', '4.4.3', 'extrinsicevaluationandadaptation', 'evaluatingtask-specificmodelshashistoricallyinvolvedreportingtheperformance', 'generally', 'meaningtheaccuracy', 'ofthemodelonaspecificheld-outtestset.whilethisparadigmmaypartially', 'sufficetounderstandordocumentamodel', 'itoftenamountstounfaircomparisonsbetweentask-', 'specificmodelsproducedwithdifferent', 'potentially', 'unequal', 'resources', 'makingitdifficult', 'togaugehowmuchprogresshasbeenmade.theconcernofunfaircomparisonsisexacerbated', 'inthefoundationmodelregime', 'differentfoundationmodels', 'e.g.', 'bertandgpt-3', 'mayform', 'thefoundationfordifferenttask-specificmodels', 'andthesefoundationmodelsmayinvolvevastly', 'differentamountsoftrainingdataandcomputation', 'toaccountfortheresourcesrequiredtoachievespecificlevelsofperformance', 'linzen', '[', '2020', ']', 'arguesthat', 'pre', 'trainingresourcesshouldbeacknowledgedandtrackedinevaluation.webelieve', 'thisisascientificallyprincipledproposal', 'comparingdifferentapproachesfortrainingfoundation', 'modelswithoutaccountingfortrainingresourcesislikelytobemisleading.however', 'giventhat', 'theprocessforcreatingfoundationmodelsisespeciallyexpensive', 'e.g.', 'requiringsignificanthuman', 'andfinancialcapital', 'andoftengovernedbysocietalfactors', 'e.g.', 'commercialincentives', 'inaddition', 'toscientificfactors', 'itmaybethecasethatthefoundationmodelsinpracticewillvarygreatly', 'inthetrainingresourcesafforded', 'makingcontrolledcomparisondifficult.here', 'weconsideran', 'alternative', 'whichmaybemorepervasivelyviable', 'topartiallyaccountfortheresourcesinvolved', 'tocomplementtheproposaloflinzen', '[', '2020', ']', '.inparticular', 'weconsiderwhyextrinsicevaluation', 'shouldacknowledgeadaptationresources', 'whichiscriticalforensuringthatextrinsicevaluationis', 'abletoidentifythemostperformantadaptationmethods', 'whichintrinsicevaluation', 'fundamentally', 'cannotdo', '.wedrawattentiontothefactthatadaptationresourcesoftenareconstruedasthedata', 'usedtoadaptmodels', 'butadditionalresources', '[', 'e.g.', 'datausedtochooseadaptationmethods', 'perez', 'etal.2021', ']', 'andconstraints', 'e.g.', 'thelevelofaccessrequiredtoadaptthefoundationmodel', 'see', '§4.3', 'adaptationand§5.6', 'ethicsforfurtherdiscussion', 'shouldalsobeaccountedfor', 'accountingforadaptationresources', 'accountingfortheresourcesexpendedtoadaptfounda-', 'tionmodelsforspecifictasksrequiresacompleteunderstandingofwhatresourcesorconstraintsare', 'usedfordifferentadaptationmethods', 'i.e.', 'evaluationsthatendeavortoaccountfortheseresources', 'mustevolvealongsidedevelopmentsinwhatresourcesareusedinadaptation', '§4.3', 'adaptation', 'inexistingtask-specificevaluations', 'mostevaluationsspecifytheamountofdatathatcanbeused', 'toadapta', 'foundation', 'modeltothetask.however', 'perezetal', '[', '2021', ']', 'identifyakeynuancehere', 'discount', 'past', 'work', 'encapsulate', 'data', 'use', 'inform', 'adaptation', 'i.e.', 'boththedatausedtoadaptthefoundationmodelandthedatausedtochoosethe', 'adaptationmethod.further', 'inthefoundationmodelregime', 'thenotionofaccessrequirementsfor', 'differentadaptationmethodsisalsoanewconsiderationthatshouldbefactoredintoevaluation', 'concretely', 'someadaptationmethodsmaygenerallyoutperformothersbutmayrequiregreater', 'abilitytoaccessormodifythefoundationmodelcomparedtoothers', 'e.g.', 'fine-tuningrequires', 'foundationmodelgradientstomodifyafoundationmodel', 'whereaspromptingmayonlyrequire', 'blackboxaccessinspecifyinginputs', 'accountingfortheresourcesinvolvedinadaptationenricheswhatconclusionscanbereasonably', 'drawnfromevaluationoftask-specificmodels.atpresent', 'task-specificevaluationmayprovide', 'sufficientclarityforcertaintypesofunderstandingordocumentationofparticulartask-specific', 'artifacts', 'i.e.', 'theexactmodelsbeingevaluated', 'butdonotprovideclearsignalforhowdifferent', 'adaptationmethodsperformandhowtoselectaspecificadaptationmethodinagivencontext.in']",94
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '95', 'contrast', 'byaccountingfortheresourcesandaccessrequirementsinvolvedinadaptation', 'evaluation', 'betterenablesresearchtoidentifywhichadaptationmethodsorprocessesmakebestuseofthe', 'resourcesprovided', 'i.e.', 'signalisofferednotjustforthespecificartifactsbeingevaluatedbutthe', 'moregeneralprocessesbywhichtheywerederived.theproposedevaluationprotocol', 'therefore', 'clearlyworkstowardsidentifyingwhichadaptationmethodsshouldbeused', 'wenotethatallof', 'theseconclusionsshouldalwaysbetakenasspecifictoagivenfoundationmodel', 'asevaluationin', 'thisformdoesnotprovidesufficientevidencetoconcludeanadaptationmethodisuniformlythe', 'bestacrossfoundationmodels.61', '4.4.4', 'evaluationdesign', 'theory', 'goal', 'evaluation', 'measure', 'characterize', 'various', 'theoretical', 'construct', 'e.g.', 'accuracy', 'robustness', '§4.8', 'robustness', 'fairness', '§5.1', 'fairness', 'efficiency', '§4.5', 'systems', 'environmental', 'impact', '§5.3', 'environment', 'service', 'various', 'purpose', 'i.e.', 'progress', 'un-', 'derstanding', 'documentation', '.however', 'inpractice', 'theutilityofevaluationwillbedetermined', 'evaluations', 'design', 'execute', 'example', 'automate', 'measurements', 'generativecapabilitiesoffoundationmodels', 'e.g.', 'theirfactualcorrectness', 'maypoorlycapturethe', 'natureofthesequalitiesand', 'instead', 'human-in-the-loopevaluationmaybettercontextualizethese', 'capabilities', 'consider', 'evaluation', 'design', 'envision', 'foundation', 'model', 'adapt', 'derivatives', 'webeginwiththemechanicsofevaluation.traditionally', 'theevaluationofmachine', 'learn', 'model', 'involve', 'large', 'train', 'set', 'use', 'learn', 'model', 'optional', 'validationsetthatisusedtosethyperparameters', 'andatestsettoevaluatethegeneralizationof', 'thelearnedmodeltoheld-outdata', '[', 'bishop2006', ']', '.asaresult', 'creatingbenchmarkstoevaluate', 'modelshashistoricallyrequiredlargeamountsofdata', 'mostofwhichisallocatedtowardstraining', 'whichcomplicatesthedesignofcertaindiagnosticornuancedevaluationswhendataisscarceor', 'expensivetoattain', '[', 'rogers2020,2021', ']', '.incontrast', 'becausethebenefitsoffoundationmodelswill', 'oftencoincidewiththesampleefficiencyofadaptation', 'i.e.', 'few-shotorzero-shotcapabilities', 'thediversityofpossibleapplications', 'weinsteadenvisionaregimewherebenchmarksforindividual', 'tasksaremuchsmaller', 'sincefarlessdataneedstobeprovidedas', '“', 'train', ""''"", 'i.e.', 'adaptation', 'data', 'andarefarmorediverse', 'bothtocapturevariouscapabilitiesinintrinsicevaluationandmore', 'stronglygroundevaluationinecologicallyvalidways', '[', 'bronfenbrenner1977', 'devriesetal.2020', ']', 'duringextrinsicevaluation', '.thissuggeststhatthenatureoffoundationmodelsmaycauseashift', 'innatureofbenchmarks', 'andthementalityofthoseconstructingbenchmarks', 'de-emphasize', 'quantityasakeypriorityinbenchmarksasopposedtoqualityanddiversity.thenlpcommunity', 'hasbeguntoseethebeginningsofsucharegimewithexpansiveanddiversebenchmarkslike', 'big-bench62', 'andflex', '[', 'braggetal.2021', ']', 'thisparadigmlowersthebarrierforbenchmarkdesign', 'therebyenablingthebroadercommunitytopartakeinevaluationdesign.63', 'alongsidethemechanicsofevaluation', 'thepresentationofandinterfacetotheevaluationresults', 'informshowtheseresultswillbeusedinformdecision-making', 'e.g.', 'newmodellingapproaches', 'modelselection', 'audit', '.leaderboardshavebecomethedefactoparadigminmachinelearning', 'wherebymodelsarerankedbyaspecificandsingularcriterion', 'generallyaformofaccuracy', '.this', 'approachhasgenerallyledtosignificantandrapidprogressinsystemqualityovertime', '[', 'e.g.', 'wang', '61currentresults', 'instead', 'suggestthatdifferentadaptationmethodsarebetter-suitedtodifferenttypesoffoundation', 'modelsandtrainingobjectives', '[', 'liuetal.2021e', 'lesteretal.2021', ']', '62https', '//github.com/google/big-bench', '63traditionally', 'thedesignofbenchmarkslikeimagenet', '[', 'dengetal.2009', ']', 'andsquad', '[', 'rajpurkaretal.2016', ']', 'hasbeen', 'conductedbyhigh-resourcedresearchlabsthatcanaffordtopayforthecreationofthesedatasetsthroughcrowdsourcing', '[', 'rogers2020', ']']",95
Opportunities and Risks of Foundational Models - Stanford.pdf,"['96', 'centerforresearchonfoundationmodels', 'crfm', 'etal.2019a', ']', 'butsignificantconcernshavebeenraisedofwhetherthisyieldsmoregeneralim-', 'provements', '[', 'e.g.', 'linzen', '2020', 'bowman', 'dahl', '2021', ']', '.64', 'true', 'machine', 'learn', 'model', 'itisrarelythecasethatthedesiderataforfoundationmodelsandtheirderivativeswillbe', 'singular', 'instead', 'weanticipatethebreadthoftheirapplicationandsocietalimpactnecessitates', 'heighten', 'consideration', 'criteria', 'beyond', 'accuracy', 'e.g.', 'robustness', 'fairness', 'efficiency', 'environmentalimpact', '.tothisend', 'wenotethatevaluationoffoundationmodelsshouldreport', 'measurementsacrossthesediversefronts', 'existingbenchmarksareincreasinglydesignedtoreflect', 'morethanjustaccuracy', 'e.g.', 'robustness', '[', 'kohetal.2021', 'goeletal.2021', ']', 'fairness', '[', 'nadeemetal', '2021', 'nangia', 'et', 'al', '2020', ']', 'efficiency', 'environmental', 'impact', '[', 'coleman', 'et', 'al', ']', 'wenotethatifthereportingofperformanceacrossthisdifferentcategoriesisdoneintheform', 'ofaleaderboard', 'mechanismstodisambiguatepotentialtrade-offs', 'toinducearanking', 'willbe', 'especiallynecessary', '[', 'ethayarajhandjurafsky2020', ']', '.inparticular', 'sincedifferentstakeholders', 'willhavedifferentpreferences', 'e.g.', 'theweighttheyascribetodifferentproperties', 'andvalues', '[', 'birhaneetal.2020', ']', 'leaderboarddesignshouldallowstakeholderstointeractandmanipulatehow', 'therankingisdonetoalignwiththeirvalues', 'maetal', '[', '2021a', ']', 'presentsanearlyattempttoenable', 'thisbycomparingtheutilityofmodelsusinganeconomicframingbasedonauser', '’', 'sspecified', 'utilityfunction', '4.4.5', 'takeaways', 'evaluationperformsseveralroles', 'i.e.', 'progress', 'understand', 'documentation', 'thatarevitalfor', 'allmachinelearningparadigms', 'includingthefoundationmodelparadigm.foundationmodels', 'introducenewchallengesforexistingevaluationframeworks', 'designingevaluationsthatdirectly', 'targetthefoundationmodelregimewillbetterservenotonlythemultiplepurposesofevaluation', 'butalsothemyriadofstakeholdersinvolved', '1', 'whilemachinelearningevaluationtraditionallyhasconsideredtask-specificmodels', 'evalu-', 'atingfoundationmodelsinvolvesengagingwiththefactthatthesemodelsarenotspecific', 'task', 'evaluation', 'model', 'likely', 'involve', 'integrate', 'two', 'complementary', 'approach', 'impute', 'properties', 'foundation', 'model', 'broad', 'evaluation', 'task-specificderivativesand', 'b', 'directmeasurementofthesepropertiesinfoundationmodels', '2', 'existingevaluationframeworksoftendonotaccountfortheresourcesrequiredtocreatethe', 'modelsbeingevaluated', 'leadingtounfaircomparisons.forfoundationmodels', 'wediscussan', 'evaluationparadigmthatemphasizesaccountingforadaptationresources', 'e.g.', 'alldataused', 'inadaptation', 'accessrequirementsforthefoundationmodel', 'whichappearstoleadtomore', 'informativeevaluationsthatbettershapehowadaptationisconducted', '3', 'existingevaluationdesignoftenislimitedinthediversityofmetricsconsideredandrequires', 'largeadaptationdatasets.forfoundationmodels', 'weechogrowingcallsforevaluationto', 'considerabroaderrangeofdesiderata', 'e.g.', 'robustness', 'fairness', 'efficiency', 'environmental', 'impact', 'tocapturethewiderangeofstakeholdervalues/preferences', 'aswellhighlighthow', 'thesampleefficiencyofadaptingadaptionmodelsmayallowformorediverseevaluations', 'byre-allocatingresourcesinvolvedindesigningevaluations', '64wenotetheconnectiontostrathern', '’', 'slaw', '[', 'strathern1997', ']', 'sometimesreferredtoasgoodhart', '’', 'slaw', '[', 'goodhart', '1984', ']', '“', 'whenameasurebecomesatarget', 'itceasestobeagoodmeasure', ""''""]",96
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '97', '4.5', 'systems', 'author', 'deepaknarayanan', 'trevorgale', 'keshavsanthanam', 'omarkhattab', 'tianyizhang', 'matei', 'zaharia', 'fig.19', 'plotshowingthegrowthofparametersandnumberoftrainingoperations', 'flop', 'oftransformer-', 'basedlanguagemodels', 'showninblue', 'andmemorycapacityandpeakdevicethroughputofnvidiap100', 'v100', 'anda100gpus', 'showninred', 'withtime.therateofgrowth', 'slopeofeachline', 'ofstate-of-the-art', 'languagemodels', 'roughly10×ayear', 'farexceedstherateofincreaseincomputationalcapacityofhardware', 'roughly10×infouryears', 'motivatingtheneedforparallelismacrossalargenumberofacceleratorsand', 'co-designofalgorithms', 'model', 'software', 'andhardwaretodrivefurtherprogress.parametersandnumberof', 'trainingoperationsareobtainedfromrelevantpapers', '[', 'brownetal.2020', ']', 'andmemorycapacitiesandpeak', 'throughputsareobtainedfromgpuspecificationsheets', 'computersystemsareoneofthelargestbottleneckstodevelopingfoundationmodels.foundation', 'modelsarefrequentlytoolargetofitinthemainmemoryofasingleaccelerator', 'e.g.', 'gpu', 'requireanimmenseamountofcomputationtotrain', 'e.g.', '>', '1000petaflop/s-daysforgpt-3', '[', 'brown', 'etal.2020', ']', '.inaddition', 'thesemodelswilllikelygetlargerovertime', 'forinstance', 'thecompute', 'memory', 'requirements', 'state-of-the-art', 'language', 'model', 'grow', 'three', 'order', 'magnitudeinthelastthreeyears', 'andareprojectedtocontinuegrowingfarfasterthanhardware', 'capabilitiesdo', 'figure19', '.moreover', 'evenoncetrained', 'theselargemodelsareexpensivetoperform', 'inferencewithanddifficulttodebug', 'monitor', 'andmaintaininproductionapplications.webelieve', 'thatfurtheradvancesintheperformanceandusabilityoffoundationmodelswillrequirecareful', 'co-designacrossalgorithms', 'model', 'software', 'andhardwaresystems', 'aswellasnewinterfacesfor', 'programminganddeployingmlapplications.inthissection', 'wediscussthekeycomputersystems', 'challengesindevelopingandproductionizinglarge-scalefoundationmodels', '4.5.1', 'improvingperformancethroughco-design', 'today', 'traininglarge-scalefoundationmodelsrequirescustomsoftwaresystemssuchasmegatron', 'anddeepspeed', '[', 'shoeybietal.2019', 'rasleyetal.2020', ']', 'builtontopofstandardframeworkslike', 'pytorchandtensorflow', '[', 'paszkeetal.2019', 'abadietal.2016', ']', '.thesesoftwaresystemsrelyon', 'anumberofinnovationsacrossthestacktotrainmodelsefficientlyatscale', 'newparallelization', 'dimension', 'pipeline', 'parallelism', '[', 'huang', 'et', 'al', '2019', 'narayanan', 'et', 'al', '2019', ']', 'limit']",97
Opportunities and Risks of Foundational Models - Stanford.pdf,"['98', 'centerforresearchonfoundationmodels', 'crfm', 'communicationwhilekeepingdevicesbusy', 'state-shardingoptimizerstoreducememoryusage', '[', 'ra-', 'jbhandarietal.2020', ']', 'just-in-time', 'jit', 'compilerstooptimizethecomputationgraph', '[', 'pytorch', '2021', ']', 'andoptimizedlibrarieslikecudnnandnccl', '[', 'nvidia2021', ']', '.megatronanddeepspeed', 'areefficienttoaparticularscale', 'forexample', 'megatroncanextractupto52', '%', 'ofthetheoretical', 'peakthroughputofmodernhardwarewithapproximately3000gpusonamodelwithatrillion', 'parameters', '[', 'narayanan', 'et', 'al', '2021b', ']', 'however', 'scale', 'larger', 'model', 'gpus', 'still', 'challenge', 'since', 'exist', 'parallelization', 'strategies', 'break', 'larger', 'gpu', 'count', 'data', 'parallelism', 'limit', 'batch', 'size', '[', 'li', 'et', 'al', '2020e', ']', 'pipeline', 'parallelism', 'number', 'layersinthemodel', '[', 'huangetal.2019', 'narayananetal.2019', ']', 'andtensormodelparallelismbythe', 'numberofgpusinasingleserver', '[', 'shoeybietal.2019', ']', 'whilewewillcontinuetorealizeperformancegainsfromnewhardware', 'growthintheresource', 'requirements', 'large', 'model', 'far', 'outstrip', 'generational', 'hardware', 'improvements', '[', 'brown', 'et', 'al', '2020', ']', 'facilitate', 'next', 'major', 'leap', 'model', 'capacity', 'democratize', 'advance', 'modelquality', 'itwillbeincreasinglycriticaltoco-designtrainingalgorithms', 'model', 'software', 'andhardware', 'becausemanyoftheavenuestoincreaseperformancealterthesemantics', 'ofthe', 'trainingcomputation.forexample', 'executingoperationsinlowerprecision', 'suchasfp16', 'canhelp', 'increasethroughputonmodernhardware', 'e.g.', 'thev100anda100gpushavededicatedtensorcore', 'unitsforlower-precisionmatrixmultiplication', 'butalsoaffectthenumericsoftheoptimization', 'procedure', '[', 'micikeviciusetal.2017', ']', '.similarly', 'exploitingweightsparsitycansignificantlyimprove', 'trainingandinferencetimes', '[', 'elsenetal.2020', 'galeetal.2020', ']', 'byonlyperformingmathematical', 'operationsonthenon-zerosinthemodel', 'butrequiresdifferenttrainingalgorithms', '[', 'jayakumaretal', '2021', 'evcietal.2020', 'dettmersandzettlemoyer2019', ']', '.otherexamplesofco-designincludemodel', 'architecturesthatmapmoreefficientlytohardware', '[', 'soetal.2019', 'childetal.2019', 'wangetal', '2020c', 'lee-thorpetal.2021', 'kitaevetal.2020', 'beltagyetal.2020', 'tayetal.2020', 'renetal.2021', ']', 'efficientoptimizers', '[', 'aniletal.2020', 'shazeerandstern2018', ']', 'noveltokenizationalternatives', '[', 'xue', 'etal.2021', 'tayetal.2021', ']', 'speciallyarchitectedhardwaretrainingplatforms', '[', 'jouppietal.2017', 'mudigereetal.2021', 'selene2021', ']', 'anddistributedparallelizationstrategieswithrelaxedweight', 'updatesemantics', '[', 'narayananetal.2019,2021a', ']', 'case', 'study', 'efficient', 'knowledge', 'representation', 'concrete', 'case', 'study', 'successful', 'co-', 'design', 'retrieval-basedmodelssuchasrealm', 'rag', 'andcolbert-qa', '[', 'guuetal.2020', 'lewisetal', '2020b', 'khattabetal.2020', ']', 'takeadifferentapproachtomodeldesignthansimplyincreasingthe', 'numberofmodelparameters.insteadoftryingtoaccumulateimplicitknowledgefromever-larger', 'datasetsdirectlyintoadnnmodelwithbillionsofparameters', 'suchasgpt-3', 'retrieval-based', 'model', 'store', 'knowledge', 'outside', 'model', 'parameters', 'form', 'text', 'passages', 'capture', 'knowledgewithinthepassageswithdensevectorrepresentations.thesemodelsthenusescalable', 'top-𝑘', 'searchmechanismstoextractknowledgepertinenttoeachinput', 'whilekeepingthednn', 'model', 'small', '§4.1.4', 'modeling-memory', 'design', 'improve', 'computational', 'efficiency', 'well', 'maintainability', 'model', 'production', 'example', 'developers', 'update', 'knowledgeofthemodeljustbyreplacingatextpassage', 'withoutneedingtoretrainalargednn', 'retrieval-basedmodelshaveachievedpromisinginitialresultsbyleveragingseveralnewcross-', 'functionalideas', 'includingbackpropagatingthelossthroughtheretrieverduringtraining', '[', 'guuetal', '2020', ']', 'whichrequiresapproximatingthegradientthroughaknowledgestorecomprisingmillions', 'ofpassages', 'andmodelingfine-grainedinteractionsbetweenqueriesandpassages', '[', 'khattaband', 'zaharia2020', 'khattabetal.2020', ']', 'whichrequiresdecomposingthecomputationintovector-level', 'nearest-neighborsearchoperations', '.thesetechniquesallowretrieval-basedmodelstobeaccurate', 'efficient', 'demand', 'functionality', 'readily', 'support', 'popular', 'ml', 'frameworks', 'nearest-neighborindexes', 'e.g.', 'faiss', '[', 'johnsonetal.2019', ']']",98
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '99', '4.5.2', 'automatedoptimization', 'another', 'important', 'challenge', 'systems', 'automate', 'application', 'optimizations', 'straddlealgorithms', 'model', 'software', 'andhardware.whilemanyoptimizationsandparallelization', 'strategies', 'complementary', 'identify', 'effective', 'combination', 'optimizations', 'challenge', 'since', 'joint', 'search', 'space', 'grow', 'combinatorially', 'optimizations', 'interact', 'non-trivialways', '[', 'narayananetal.2021b', ']', '.foundationmodelsheightentheneedforautomated', 'optimizationasmanualexperimentationisexpensiveandtime-consumingatthescaleofthousands', 'ofgpus', 'recentworkinthisareahasfocusedonsystemstargetingsemantics-preservingoptimizations.in', 'particular', 'systemshavebeenproposedtoautomaticallydiscovermathematically-equivalentgraph', 'substitutions', '[', 'jiaetal.2019a', 'wangetal.2021c', ']', 'facilitatethedistributedexecutionofoperator', 'graphsthroughbothhigh-levelapisandlow-levelcompilers', '[', 'rasleyetal.2020', 'mandeepbaines', '2021', 'bradburyetal.2018', 'shazeeretal.2018', 'lepikhinetal.2020', ']', 'andautomatetheselectionof', 'hybriddistributionstrategies', '[', 'jiaetal.2019b', 'santhanametal.2021', ']', '.thesesystemshavehelped', 'deploymanyfoundationmodelsinindustry', '[', 'fedusetal.2021', 'm2m-1002020', 'turing-nlg2020', ']', 'unfortunately', 'automate', 'optimization', 'become', 'much', 'harder', 'compose', 'semantics-', 'alter', 'optimizations', '§4.5.1', 'systems-co-design', 'often', 'unclear', 'jointly', 'model', 'thestatisticalimpactsofthesetechniques', 'e.g.', 'howmanytrainingiterationsareneededtoreach', 'aspecificaccuracy', '?', '.wewillthereforeneednewsoftwaretools', 'libraries', 'andcompilerstoau-', 'tomaticallyidentifycompositionsofoptimizationsthattargetcomprehensivemetricsliketime-', 'to-accuracy', '[', 'coleman', 'et', 'al', 'mattson', 'et', 'al', '2020', ']', 'build', 'tool', 'require', 'tight', 'collaborationbetweensystemsandmachinelearningexperts', '4.5.3', 'executionandprogrammingmodels', 'theuniquemulti-tasknatureoffoundationmodelsprovidesanopportunitytoamortizetraining', 'andinferencecostsovermanyapplications.inparticular', 'paradigmssuchasadaptationmeanmore', 'sharingacrossmodelinstances.forexample', 'twomodelsprefix-tuned', '[', 'liandliang2021', ']', 'fromthe', 'samepretrainedmodelcansharethesamemodel', '“', 'stem', '”', 'reducingthestoragefootprint', 'theshared', 'stemonlyneedstobestoredonce', 'whilealsomakingitpossibleforexecutiontobesharedand', 'batchedacrosstheprefix-tunedmodels', '[', 'shenetal.2019', 'narayananetal.2018', ']', '.consequently', 'specificadaptationmechanismusedinformssystemoptimization', '§4.3', 'adaptation', 'itisanopenquestionastowhatprogramminginterfaceshouldbeusedtospecifythatvarious', 'adaptedmodelsarederivedfromthesamepretrainedmodel', 'e.g.', 'models𝑌', 'and𝑍', 'arederived', 'fromthesamepretrainedmodel𝑋', 'orthatvariouscomponentsoftwomodelsshareparameters', 'e.g.', 'two', 'models𝐴', 'and𝐵', 'share', 'stem', 'layer𝑖', 'ludwig', '[', 'molino', 'et', 'al', '2019', ']', 'pytorch', '’', 'smoduleoffereasywaystocomposefunctionalitywithinamodel', 'butnosystemtoday', 'supportscross-modeldependencies.givinguserstheopportunitytoprovideannotationswillallow', 'trainingandinferencesystemstooptimizeandorchestratecomputationmoreefficiently', 'without', 'suchannotations', 'systemswillnothavevisibilityintowhatcomputationandparameterscanbe', 'share', 'across', 'model', 'instance', 'model', '’', '“', 'adaptation', 'history', '”', 'model', 'particular', 'model', 'adapt', 'also', 'use', 'debug', 'adapt', 'model', '’', 'errors', 'particular', 'typesofinputscouldoriginatefromthepretrainedmodel', 'pointingtoissuesinthepretraining', 'process', 'versus', 'adaptation', 'process', 'frameworks', 'like', 'pytorch', 'well', 'software', 'libraries', 'trainingfoundationmodelssuchashuggingfacetransformers', '[', 'wolfetal.2020', ']', 'donotallowfor', 'fine-grainedlineageinformationacrossentiremodelinstancestobespecified', 'buildingandmaintainingaclusterofthousandsofacceleratorsalsorequirestremendouseffort', 'newtrainingparadigmslikelearning', 'home', '[', 'ryabininandgusev2020', 'diskinetal.2021', ']', 'explore', 'leveragingvolunteercomputeovertheinternettotrainfoundationmodelscollaboratively.such']",99
Opportunities and Risks of Foundational Models - Stanford.pdf,"['100', 'centerforresearchonfoundationmodels', 'crfm', 'fundamentally', 'new', 'execution', 'model', 'decrease', 'cost', 'train', 'one', 'entity', 'requirecollaborationacrossanumberofdifferentareaslikesecurity', 'toensurethatamalicious', 'volunteercannotsignificantlyalterthetrainingprocess', 'distributedsystems', 'todealwithfault', 'toleranceissuesasvolunteersdrop', 'andcrowdsourcing', '4.5.4', 'productionizationoffoundationmodels', 'asthecommunitycontinuestopushthecapabilitiesoffoundationmodels', 'realizingtheirpotential', 'willrequireaddressingthechallengesassociatedwithdeployingtheseresource-intensivemodels', 'inproduction.thesechallengesincludeperformingmodelinferencewithtightlatencytargets', 'ensuringthatmodelsanddataaremonitoredinanautomatedway', 'forapplicationswithstrictcostandlatencyconstraints', 'modelcompressiontechniqueslike', 'distillation', '[', 'hintonetal.2015', 'lietal.2020d', 'sanhetal.2019', ']', 'quantization', '[', 'polinoetal.2018', 'gholamietal.2021', 'zhouetal.2018', ']', 'prune', '[', 'lecunetal.1990', 'gordonetal.2020', 'mccarleyetal', '2019', 'wangetal.2019c', 'sajjadetal.2020', ']', 'andsparsity', '[', 'galeetal.2020', 'elsenetal.2020', ']', 'could', 'aiddeploymentbytransforminglargermodelstoobtaindesiredinference-timeproperties.these', 'techniqueswereoriginallyintendedforsmallermodels', 'e.g.', 'bert-l', 'inlow-memoryenvironments', 'e.g.', 'mobilephones', 'butarenownecessarytohandletheextremescaleofmodernfoundation', 'modelsindatacenterdeployments.parallelizationtechniquesliketensormodelparallelism', '[', 'shoeybi', 'etal.2019', ']', 'traditionallyusedfortraining', 'mightalsobeusefultoreduceinferencelatency', 'alsoprovideadditionalmemorycapacityacrossgpustofitthemodel', '’', 'sparameters', 'inadditiontothesepracticalconstraints', 'increasesinthesizeandcomplexityoffoundation', 'modelsandthedatasetsusedtotrainthemposenewchallengestomodelanddatasetlifecycle', 'management.sincemodelswithalargenumberofparametersarehardtomanuallyinspectby', 'humans', 'weneedbettersystemsforautomateddatasetcuration', '§4.6', 'data', 'andmodelquality', 'assurance.techniqueslikebehavioraltesting', '[', 'ribeiroetal.2020', ']', 'andmodelassertions', '[', 'kangetal', '2020', ']', 'facilitateeasiermodelmaintenanceinproductionbyprovidinganalogstounittests', 'runtime', 'monitor', 'intheformoftest-timeassertions', 'andcontinuousmodelimprovement', 'asnewinputs', 'comein', 'formodelsdeployedinendapplications.thesetoolscanhelpaddressissuesoffairness', 'andbias', '§5.1', 'fairness', 'andreducemodelmispredictions']",100
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '101', '4.6', 'data', 'author', 'laurelorr', 'simranarora', 'karangoel', 'avanikanarayan', 'michaelzhang', 'christopherré', 'foundationmodelssignalaparadigmshiftwhereincreasinglymassivequantitiesofdataare', '“', 'feed', '”', 'model', 'improve', 'adaptation', 'performance', '[', 'devlin', 'et', 'al', '2019', 'radford', 'etal.2021', 'tolstikhinetal.2021', ']', 'withtheoverarchingrule-of-thumbbeing', ""''"", 'themoredatathe', 'better', ""''"", '[', 'kaplanetal.2020', ']', '.asprevioussectionshavementioned', 'thisfocusondatacurationhas', 'raisedconcernsaroundthefoundationmodeldatalifecycleincluding', '1', 'managingthedataat', 'suchalargescale', '§1', 'introduction', '2', 'integratingdataacrossnewmodalities', '§2.3', 'robotics', '§3.1', 'healthcare', '3', 'reasoningoverlicensingandgovernanceregulations—especiallywhen', 'consideringthemassingweb-crawlsusedinfoundationmodelstraining—', '§3.1', 'healthcare', '§5.4', 'legality', '4', 'understandingthedataquality', '§4.4', 'evaluation', 'foundation', 'model', 'add', 'new', 'difficult', 'facets', 'challenge', 'see', 'parallel', 'issue', 'core', 'challenge', 'communities', 'data', 'management', 'data', 'analytics', 'well', 'industrial', 'ml', 'pipelines', 'example', 'data', 'management', 'long', 'study', 'scalabledeclarativesystemsfordataanalysis', 'versioning', 'provenance', 'andintegration—addressing', 'challenge', '1', '2', '[', 'zahariaetal.2012', 'cudré-maurouxetal.2009', 'stonebrakerandweisberg', '2013', 'stonebrakerandilyas2018', 'hellersteinandstonebraker2005', ']', '.industryhaspipelinesdealing', 'withchallenge', '3', 'tomanagediversedatalicensesandhelpmitigatedataviolations.thereisan', 'entireecosystemofresearchandsystemstacklingchallenge', '4', 'tosupportinteractivedataanalytics', 'andvisualization', '[', 'hohmanetal.2020', ']', '.65', 'whilethesesolutionsarenotnecessarily', ""''"", 'foundation', 'model-ready', ""''"", 'webelieveapathtobettermanagementofthefoundationmodeldatalifecycleshould', 'takeinspirationfromtheseexistingsystems', 'section', 'address', 'manage', 'foundation', 'model', 'data', 'lifecycle', 'first', 'outline', 'fourdesiderataincludingdatamanagementatscale', 'supportforheterogenousdatasources', 'data', 'governance', 'anddataqualitymonitoring.wethenenvisionhowalloftheserequirementscanbe', 'integratedintoaholisticdatamanagementsolutioncalledadatahub.thedatahubissimplya', 'datamanagementtoolkitthatcanbeusedbytheprivateorpublicsectorstobettersupportthe', 'interactivemanagementofthefoundationmodeldatalifecycle', '4.6.1', 'datamanagementdesiderata', 'currentpracticesinfoundationmodeldevelopmentaregenerallyad-hocacrosstheentirelifecycle', 'fromdatacurationanddatadocumentationtomodelmonitoringandpatching', '[', 'gebruetal.2018', 'bandyandvincent2021', 'benderandfriedman2018', ']', '.researchinthedatamanagementcommunity', 'show', 'well-defined', 'data', 'management', 'platforms', 'facilitate', 'ml', 'model', 'development', 'scale', 'data', 'ingestion', 'data', 'versioning', 'data', 'provenance', 'efficient', 'analysis', 'model', 'monitor', '[', 'hellersteinandstonebraker2005', 'agrawaletal.2019', 'vartaketal.2016', 'ikedaand', 'widom', '2010', ']', '.66', 'take', 'inspiration', 'data', 'management', 'community', 'consider', 'core', 'desideratawhenbuildingaholisticdatamanagementplatformforfoundationmodels', '1', 'scalability', 'foundation', 'model', 'train', 'increasingly', 'massive', 'quantities', 'data', '[', 'kaplanetal.2020', ']', 'withthewudao2.0modelbeingtrainedon4.9tbofmulti-modal', 'data.67thisscaleisexpectedtoincreaseasmostrecentmodelsaretrainedlargelyonpublic', '65vis', 'chi', 'siggraphareafewcommunitiesthatresearchinteractivedataanalyticsmethodsandsystems.software', 'systemsandlibrariessuchaspandas', 'matplotlib', 'andseabornalsoaidusersininteractiveexploration', '66featurestoreslikemichelangeloalsosupportend-to-endmlmodelbuildinghttps', '//eng.uber.com/michelangelo-', 'machine-learning-platform/', '67https', '//www.scmp.com/tech/tech-war/article/3135764/us-china-tech-war-beijing-funded-ai-researchers-surpass-', 'google-and']",101
Opportunities and Risks of Foundational Models - Stanford.pdf,"['102', 'centerforresearchonfoundationmodels', 'crfm', 'facingdatasets.publicdatarepresentsanextremelysmallfractionofdatacomparedtothe', 'petabytesofbusinessandpersonaldatacollectedeverydayandusedinindustrialfoundation', 'modelpipelines', '[', 'marr2017', ']', '.thereisthereforeagrowingneedforhighlyscalabletechniques', 'thatcanhandlemulti-modalfoundationmodeldatasets', '2', 'data', 'integration', 'recent', 'work', 'use', 'foundation', 'model', 'demonstrate', 'leverage', 'integratedstructuredandunstructureddatacanhelpmodelsbettergeneralizetorarecon-', 'cepts', '[', 'orretal.2020', ']', 'andimprovefactualknowledgerecall', '[', 'orretal.2020', 'logeswaran', 'etal.2019', 'zhangetal.2019a', 'petersetal.2019', 'poerneretal.2020', ']', '.despitetheserecent', 'successes', 'integratingdatasetsforfoundationmodelsremainsachallenge.manyworksuse', 'unstructuredtextdatawithstructuredentityknowledgeorimagedata', '[', 'antoletal.2015', ']', 'thereisagrowingneedtointegratedatasetsacrossdiversemodalitiessuchastext', 'video', 'eye-tracking', '[', 'hollensteinetal.2020', ']', 'androboticsimulations', '[', 'lynchandsermanet2021', ']', 'see§2.3', 'robotics', '.weneeddata-integrationsolutionsthatcanbeappliedatanindustrial', 'scaletomultiplemodalitiesandtomultipledomains', 'suchasgovernment', 'business', 'science', '3', 'privacyandgovernancecontrols.thetrainingdatausedforfoundationmodelsmayrisk', 'theviolationoftheprivacyofdatasubjects', 'theirdatamaybedisclosed', 'collect', 'orused', 'withouttheirconsent', '[', 'joandgebru2020', ']', 'oroutsidethecontextforwhichconsentwas', 'originallygiven.theissueofconsentanduseisespeciallyrelevantforfoundationmodels', 'wheredownstreamapplicationscannotalwaysbeanticipated.asexplainedin§5.4', 'legality', 'theseissuesarecompoundedwiththeprevalenceofwebscrapeddatasetsforfoundation', 'modeltraining.astherearestillopenlegalquestionsabouthowweb-crawleddatawillbe', 'governedandcopyrighted,68theconsequencesofusingwebdataremainuncleartofoundation', 'modelprovidersinthepublicandprivatesector.weneedtoolingtohelpfoundationmodel', 'providersadapttoemergingregulationsandguidelinestoensuresafeandresponsibledata', 'management', '4', 'understandingdataquality.dataqualityimpactsmodelperformance', '[', 'leeetal.2021', ']', 'however', 'toolkitsormethodstosystematicallyandscalablyunderstandthetrainingdata', 'andrelevantdatasubsetsarestillintheirinfancy.thedatacreationprocesscanbemessy', 'andthedatacancontaindifferenttypesofbiases', '[', 'blodgettetal.2020', 'benderetal.2021', ']', 'see§5.1', 'fairness', 'andconsistofpoisoned', 'false', 'orduplicatedinformation', '[', 'changetal', '2020', 'carliniandterzis2021', 'buchananetal.2021', 'leeetal.2021', ']', '.dataisalsocontinuously', 'updatedandrefined', '[', 'kielaetal.2021', ']', 'andmayhaveemergententities', '[', 'fetahuetal.2015', ']', 'distributionshift', '[', 'chenetal.2021a', ']', 'andconceptmeaningshift', '[', 'kenteretal.2015', 'lazaridou', 'etal.2021', ']', '.further', 'oncedeployed', 'foundationmodelsmaypresentundesirablebehavioron', 'critical', 'fine-grainedsub-populationsofdatathatfoundationmodelprovidersneedtodetect', 'andmitigate', '[', 'goeletal.2021', 'hohmanetal.2018', 'réetal.2019', 'oakden-rayneretal.2019', ']', 'weneedtoolkitsthatcandetectandpotentiallymitigatedifferenttypesofundesirabledata', 'toimprovemodelperformanceinaninteractiveanditerativefashion.suchtoolkitsalsoneed', 'toadapttothedynamicalnatureoftrainingdata', '4.6.2', 'datahubsolution', 'pullingonyearsofworkfromdatamanagement', 'datascience', 'anddataanalytics', 'weenvisiona', 'foundationmodellifecycledatamanagementsolution', 'whichwetermadatahub.whileexamples', '68theseissueshaverecentlycometobearbythedebatesurroundingtheuseofgithubdataincopilot', '’', 'scodextoolto', 'helpdeveloperscodehttps', '//www.pwvconsultants.com/blog/questions-around-bias-legalities-in-githubs-copilot/']",102
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '103', 'ml-focused', 'data', 'hubs69', 'well', 'traditional', 'data', 'management', 'systems', 'exist,70', 'either', '1', 'donottreatdataintegrationasafirstclassprimitive', '2', 'donotnativelysupportthe', 'end-to-endlifecyclewithmodelpredictions', '3', 'donotallowforinteraction-drivendatacuration', 'andrefinement', 'wherefoundationmodelproviderscandynamicallyexploreandupdatepossible', 'datasetssubjecttoaccesscontrolguidelines.wenowdiscusshowthedatahubaddressesthefour', 'desiderata', 'datascale', 'toaddressthemanagementatscalechallenge', 'thedatahubwillneedstandarddata', 'managementsolutions', '[', 'armbrustetal.2009', ']', 'suchasinfrastructuretostoreandmaintainlarge-', 'scaledatasetsastheychangeovertimeandscalableinterfacestoquery', 'select', 'andfilterdatasets', 'thehubshouldsupportheterogenouscomputeaswellascloudinfrastructuretosupportscalable', 'solutionsindifferentenvironments', 'dataintegration', 'thehubshouldincorporatedataintegrationasafirstclasscitizen.itwillneed', 'advanceddataintegrationsolutions', '[', 'stonebrakerandilyas2018', 'abiteboul1997', 'dongetal.2020', 'rekatsinasetal.2017a', ']', '71toallowforthemergingofstructuredandunstructuredknowledgeacross', 'modalitiesanddomains.further', 'thisimpliesthehubwillneedtosupportstoringandquerying', 'overheterogeneousdatasetsandsources', 'accesscontrol', 'consideringtheaccesscontrolsofthehub', 'thehubwillneedtosupportdiverse', 'documentation', 'e.g.', 'datasetsheets', '[', 'gebruetal.2018', ']', 'ordatastatements', '[', 'benderandfriedman', ']', 'toallowdatacuratorstoreflectontheirprocessesandbetransparentabouttheintended', 'usecases', 'potentialbiases', 'andlimitationsoftheirdataset.thedatahubwillneedtodecidewhich', 'documentationisrequiredfordatatobeuploaded', 'e.g.', 'thedatasourceanddatadescription', 'information', 'recommend', 'e.g.', 'task', 'data', 'could', 'use', 'furthermore', 'documentationmayneedtobeupdatedasdatasetsevolve', '[', 'goeletal.2021', ']', 'data', 'source', 'often', 'associate', 'license', 'hub', 'need', 'integrate', 'different', 'source', 'different', 'legal', 'concern', 'condition', '[', 'masur', ']', '.72', 'certain', 'datasets', 'havelegalguidelinestoprotecttheprivacyofthedatasubjects.thehubwillneedmethodsto', 'ensureadatasetdoesnotreleasepersonallyidentifiableinformation', 'pii', ',73thattheaggregation', 'ofanonymizedorde-identifieddatadoesnotreleasepii,74andthatthedatasubjectshavegiven', 'informedconsentfortheirdatatobedisseminated.75', 'pullingonideasfromdataintegration', '[', 'rekatsinasetal.2017b', ']', 'thehubshouldsupportmech-', 'anismstoenableefficientandsafemaintenanceandsharingofdataresources.especiallyasthe', 'legalityofcertainpublicdatasets', 'e.g.', 'webdumps', 'arestillbeingdecided', '§5.4', 'legality', 'hubcriticallyneedstoolingtohelpidentifylicensingviolationsandmitigatetheimpactofany', 'governanceviolation.ascertainviolationswilllikelyrelatetomodelbehavior', 'weneedsystemsto', 'supportbetterunderstandingofmodelbehavior', 'aswedescribenext', 'dataqualitytooling', 'drawingonthefieldofdataanalysisandexploration', 'asusersinteractively', 'select', 'filter', 'andrefinethedatatousefortrainingoradaptation', 'thehubwillneedtoolstoquickly', '69some', 'public', 'data', 'hubs', 'include', 'https', '//data.world/', 'https', '//dataverse.harvard.edu/dataverse/harvard', 'https', '//', 'datacommons.org/', 'https', '//www.data.gov/', 'https', '//www.kaggle.com/', 'https', '//huggingface.co/datasets', 'https', '//www.ldc', 'upenn.edu/', '70sometraditionaldatamanagementsystemsforfoundationmodelsinclude', 'https', '//aws.amazon.com/big-data/datalakes-', 'and-analytics/', 'https', '//eng.uber.com/michelangelo-machine-learning-platform/', 'https', '//kafka.apache.org/', '71https', '//www.tamr.com/', '72https', '//content.next.westlaw.com/4-532-4243', '73https', '//www.justice.gov/opcl/privacy-act-1974', '74http', '//www2.ed.gov/policy/gen/guid/fpco/ferpa/library/georgialtr.html', '75https', '//www.dhs.gov/sites/default/files/publications/privacy-policy-guidance-memorandum-2008-01.pdf']",103
Opportunities and Risks of Foundational Models - Stanford.pdf,"['104', 'centerforresearchonfoundationmodels', 'crfm', 'understand', 'user', '’', 'current', 'dataset', 'impact', 'model', 'behavior', '[', 'hohman', 'et', 'al', '2020', ']', '.76', 'furthermore', 'thesesystemscanallowend-to-endfoundationmodelmonitoringbyincorporating', 'modelperformancethroughrecentworkonslice', 'sub-population', 'find', '[', 'chungetal.2019', ']', 'model', 'validationonrelevantsubsets', '[', 'goeletal.2021', 'ribeiroetal.2020', ']', 'anddatavaluation', '[', 'ghorbaniand', 'zou2019', ']', '.recentworksalsopresentmethodsthatusethemodeltodetectwhichsubpopulations', 'ofdatacontributethemosttoagivenoutputtofurtheraidmodeldebugging', '[', 'keskaretal.2019', ']', 'onceuserscanmonitormodelbehavior—especiallyonrare', 'yetcriticalsub-populations—', 'hubshouldprovidemethodsandguidanceforuserstomaintainmodelsbycorrectingmodelerrors', 'although', '“', 'modelpatching', '”', '[', 'goeletal.2020a', ']', 'isstillanopenproblem', 'theworkof', '[', 'orretal.2020', ']', 'providesafirstdescriptionofusingdataengineeringtomaintainaproductionself-supervised', 'systemthatcorrectedforundesirablebehaviorthroughchangestothedata', 'notmodel.webelieve', 'thedatahubwillneedtosupportinterfacesforuserstoinjecttargeteddatamodificationsformodel', 'maintenance', 'wealsoacknowledgethatdatacurationandexplorationarenotperformedinisolation', 'believe', 'data', 'hub', 'support', 'community', 'around', 'share', 'useful', 'metrics', 'analysis', 'pipelines.inspiredbysimilarcommunitysharingplatformslikehuggingface', '’', 'smodelhub77or', 'tableaupublic', '’', 'svisualizationsharingplatform,78wewantuserstoshareinsightsaboutfoundation', 'modeltrainingdata', 'openquestions', 'althoughourdescribeddatahubisinspiredbyexistingtoolkitsandsolutions', 'wedonotbelievetheyareallreadyforthechallengesoffoundationmodels.inparticular', 'openquestionsrevolvingarounddesigningadatahubare', '•', 'howshouldwesupportdataversioningsodatasetscanbeupdatedwhilemaintainingold', 'versions', 'reproducibility', '[', 'agrawal', 'et', 'al', '2019', ']', '?', 'model', 'deploy', 'error', 'bucketsareidentified', 'datasetsmayneedtobeupdatedtoincludemoreexamplesfromthese', 'errorbuckets.howshouldthesenew', 'targetedexamplesbecollected', '?', '•', 'asdescribedin§4.2', 'train', 'weimaginefewermodelswillbetrainedfromscratchand', 'morewillbefine-tuned.howdowesupportprovenanceorlineageinformationtounderstand', 'wheretheoriginaldatacamefrom', 'whilemaintainingsubjectprivacy', '[', 'chenetal.2015a', ']', '?', '•', 'inthepublicsector', 'adatahubmaybeorganizedandrunbyanopen-sourcecommunity', 'ofindividualsconsistingofdatacuratorsandfoundationmodelproviders.inthissetting', 'answerstoquestionssuchaswhostoresthedata', '?', 'whopaysforanycompute', '?', 'whoisliableif', 'licensingisviolated', '?', 'areparticularlymurky.howcanthedatahubprovidethatrighttooling', 'sothatonceanswerstosuchquestionsareresolved', 'theycanbeoperationalizedwithease', '?', '•', 'whatistherightsetofstatisticsoverthedatatoprovideadequatedocumentation', 'without', 'beingtoocostlyordifficulttoobtain', '?', '•', 'howcanadatahubsupporttargeteddatamodificationssuchasaugmentation', '[', 'ma2019', 'shortenandkhoshgoftaar2019', ']', 'ordataprogramming', '[', 'ratneretal.2017', ']', '?', '•', 'howcanmonitoringtoolkitsbetterdetectwhenafoundationmodelneedstobeupdated', 'duetopoorperformanceondynamicallychangingevaluationdata', '?', 'ourvisionforadatahubisnotcompleteorfullydetailed.however', 'wepresentinitialthoughts', 'ondatachallenges', 'andonesolutiontopromptthinkingforhowtoimprovedatamanagementfor', 'thefoundationmodellifecycle', '76examplesofdata-focusedinteractivetoolkitsincludehttps', '//www.tableau.com/andhttps', '//www.paxata.com/', '77https', '//huggingface.co/models', '78https', '//public.tableau.com/en-us/s/about']",104
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '105', '4.7', 'securityandprivacy', 'author', 'floriantramèr', 'rohithkuditipudi', 'xuechenli', 'fig.20', 'risksandopportunitiesraisedbyfoundationmodelsforsecurityandprivacyofmlsystems', 'ascentralcomponentsincriticaldata-drivendecision-makingsystems', 'machinelearningmodels', 'mustaddressavarietyofsecurityandprivacythreats.79thesethreatscanbecharacterizedusing', 'thetraditional', '“', 'ciatriad', '”', 'ofcomputersecurity.mlsystemsshouldprotecttheconfidentiality', 'ofuserdataagainstinferenceandreconstructionattacks', '[', 'fredriksonetal.2015', 'shokrietal.2017', 'carlinietal.2019,2021', ']', '.moreover', 'thesecrecyoftrainedmodelsthemselvescanbeatriskof', 'modelstealingattacks', '[', 'tramèretal.2016', 'papernotetal.2017', ']', '.theintegrityofmlsystemscan', 'becompromisedbyadversarialexamples', '[', 'biggioetal.2013', 'szegedyetal.2014', ']', 'anddatapoisoning', 'attack', '[', 'biggioetal.2012', 'chenetal.2017', ']', '.finally', 'resource-depletionattacks', '[', 'shumailovetal', '2020', 'hongetal.2020a', ']', 'canthreatentheavailabilityofmlsystems', 'inregardtothesethreats', 'wepositthatthesecurityroleoffoundationmodelsinfuturemachine', 'learningsystemswillbeakintotheroleplayedbytheoperatingsystemintraditionalsoftware', 'systems.duetoitsgeneralityandubiquity', 'afoundationmodelmaybecomeasinglepointoffailure', 'andthusaprimetargetforattacksagainstapplicationsderivedfromthismodel.inturnhowever', 'foundationmodelimbuedwithstrongsecurityandprivacypropertiescouldformthebackbonefor', 'thedesignofavarietyofsecureandreliablemlapplications.ofcourse', 'theseapplicationsmay', 'stillhavetobedesignedtoenforcespecificsecurityandprivacyguarantees', 'inthesamewaythat', 'softwaredesignerscannotrelyonasecureoperatingsystemtoprotectagainstallsecurityrisks', '4.7.1', 'risk', 'singlepointsoffailure', 'afoundationmodelthatisadaptedtoavarietyofapplicationsrepresents', 'asinglepointoffailurefortheseapplications.forexample', 'datapoisoningattacksonafoundation', 'model', 'whereanadversaryinsertsmaliciousexamplesintothetrainingdata', 'mightimpactall', 'adaptedapplicationsaswell.similarly', 'adversarialexamplesagainstafoundationmodel', 'i.e.', 'small', 'input', 'perturbations', 'cause', 'model', 'output', 'different', 'feature', 'could', 'easily', 'transfertoadaptedapplications.wallaceetal', '[', '2019', ']', 'evenfindthatasingleadversarialtrigger', '79inthissection', 'wefocusonsecurityforfoundationmodels.someapplicationsoffoundationmodelsforsecurity', 'e.g.', 'de-', 'tectionoftoxiccontent', 'arediscussedin§5.2', 'misuse']",105
Opportunities and Risks of Foundational Models - Stanford.pdf,"['106', 'centerforresearchonfoundationmodels', 'crfm', 'addedtoanyinputcancauselanguagemodelssuchasgpt-2tooutputapredefinedpieceoftext', 'foundation', 'model', 'also', 'become', 'single', 'point', 'failure', 'data', 'privacy', 'foundation', 'modelispretrainedonacompany', '’', 'sprivatedataandthemodelmemorizespartofthisdata', 'downstreamapplicationscouldruntheriskofexposingthisdata', '[', 'carlinietal.2021', ']', '.theprovider', 'ofafoundationmodelmayalsobeasinglepointoftrustfortheprivacyofapplicationdata.for', 'example', 'thecurrentapiforgpt-3requiresthatall', 'potentiallysensitive', 'datausedforfine-tuning', 'orinferencebeuploadedtoopenai', '’', 'sservers.designingafoundationmodelservicethatavoids', 'thiscentralizationoftrustisaninterestingproblem', 'iftheparametersofafoundationmodelarepublic', 'modelstealingattacksonadaptedapplications', 'couldbefacilitated', 'astheattackeronlyneedstoreverse-engineerthe', '“', 'delta', '”', 'withrespecttothe', 'publicfoundationmodel', '[', 'krishnaetal.2019', ']', 'e.g.', 'alinearmodeltrainedonfeaturesextracted', 'fromapublicfrozenmodel', 'finally', 'denial-of-serviceattacksonthefoundationmodelprovidercouldalsobeaconcernand', 'mightbeexacerbatedbyqueryingthemodelwithspecialhigh-costinputs', '[', 'shumailovetal.2020', ']', 'datapoisoning', 'successfulfoundationmodelshavesofarbeentrainedonlargeandoftenuncu-', 'rateddatasetsscrapedfromtheweb', '[', 'radfordetal.2021,2019', ']', '.thispermissivedatacollection—', 'coupledwithalackofdirecttrainingsupervision—facilitatespoisoningattacksonafoundation', 'model', '’', 'strainingdata', 'e.g.', 'injectinghatefulspeechtargetedataspecificindividualorcompany', 'intoafewoutboundpagesfromreddit', '.worse', 'thepowerofpoisoningattacksmaybeexacerbated', 'bythegrowingsizeandaccuracyoftoday', '’', 'smodels', '[', 'carlini2021', ']', 'toillustrate', 'schusteretal', '[', '2021', ']', 'showthatacodeauto-completionsystemtrainedwithgpt-', '2ongithubdatacanbepoisonedintosuggestinginsecurecodesnippetswiththeinjectionof', 'onlyafewmaliciousfiles.carliniandterzis', '[', '2021', ']', 'furthershowthattargetedattacksagainst', 'clip-style', '[', 'radfordetal.2021', ']', 'modelsrequiremodifyingaslittleastwooutof3milliontraining', 'examples', 'functioncreep', '&', 'dualuse', 'foundationmodelslearngeneralfeaturesthatenablethemtobe', 'easilyadaptedtoavarietyoftasks.thisflexibility', 'however', 'raisesconcernsthatfoundationmodels', 'couldbeusedbeyondtheiroriginallyforeseenpurposes—ariskcommonlyreferredtoasfunction', 'creepordualuse.examplesoffunctioncreepinmachinelearningincludeoverlearning', '[', 'songand', 'shmatikov2019', ']', 'andadversarialreprogramming', '[', 'elsayedetal.2018', ']', 'toillustrate', 'clipwasoriginallytrainedtosolvethegenerictaskofpredictingimage-textpairs', 'butindoingsoalsolearnedtocapturerichfacialfeatures', '[', 'gohetal.2021', ']', '.whileclip', '’', '“', 'model', 'card', '”', '80', 'explicitly', 'placesfacialrecognition', 'andothersurveillancetechnologies', 'asout-of-scope', 'clipcancertainlybere-purposedforsuchtasks', '[', 'radiya-dixitandtramèr2021', ']', '.thisexample', 'illustratesthatitmaybechallengingtoconstrain', 'orevenforesee', 'thepossiblenefarioususesofa', 'foundationmodelwhenitisdesigned.§5.2', 'misuseprovidesfurtherdiscussionsondual', 'mis', 'use', 'offoundationmodels', 'multimodalinconsistencies', 'multimodalitymayincreasetheattacksurfaceoffoundationmod-', 'els', 'byenablingadversariestoexploitinconsistenciesacrossmodalities.thepossibilityofsuch', 'attackswasdemonstratedinan', 'famousexampleofclipclassifyinganapplewiththeword', '“', 'ipod', '”', 'stucktoitasanipod', '[', 'gohetal.2021', ']', '.moregenerally', 'wheneveraconceptcanbeexpressed', 'usingdifferentmodalities', 'inconsistenciesacrossthesemodalitiesmaybeexploitable', 'suchinconsistenciesareparticularlyconcerningwhenafoundationmodelisadaptedtoatask', 'thatprimarilyreliesononlyoneofthelearnedmodalities.forexample', 'considerusingfeatures', 'extractedfromclipforfacialrecognition.thisisapurelyvisualtask', 'yettheadaptedmodel', '’', '80https', '//github.com/openai/clip/blob/main/model-card.md.accessed06.30.2021']",106
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '107', 'featureswillstillbesensitivetotextualsignals', 'thus', 'anattackermightbeabletoevadefacial', 'recognitionbywearingclotheswithimprintedtext', '.alternatively', 'consideranautonomousdriving', 'system', 'anapplicationthatalsoreliesprimarilyonvision', 'thatseesabillboardwiththeword', '“', 'green', '”', 'onit', 'andmistakenlyinterpretsthisasagreenlight', '4.7.2', 'opportunities', 'security', 'choke', 'point', 'adapt', 'applications', 'inherit', 'vulnerabilities', 'foundation', 'model', 'theycanalsoinheritdesirablesecuritycharacteristics—suchasrobustnesstoadversarial', 'examplesorpoisoningattacks.foundationmodelscouldthusserveassecuritychokepoints.for', 'example', 'amodelrobusttoadversarialexamplescanretainitsrobustnesswhenitisadaptedto', 'othertasks', '[', 'shafahietal.2019', ']', '.similarly', 'afoundationmodelproviderthatcan', 'somehow', 'defend', 'againstpoisoning', 'model-stealingorresource-depletionattackscouldthenprovidesuchsecurity', 'guaranteesforitscustomers', '’', 'applications', 'thetradeoffbetweenafoundationmodel', '’', 'sroleasasinglepointoffailureorasasecuritychoke', 'pointisreminiscentofsimilarsecuritytradeoffsinotherabstractionlayersinthesoftwarestack', 'e.g.', 'anoperatingsystem', 'databasesystem', 'orawebbrowser', '.byvirtueofservingmanydifferent', 'applications', 'anabstractionlayerisaprimetargetforattack', 'butcantypicallyalsoleveragefar', 'greaterresourcestoenhanceitssecuritycomparedtoanysingleapplication', 'cheaperprivatelearning', 'currentfoundationmodelsareoftentrainedbyamassingvastamounts', 'ofdatafrompubliclyavailablesources', 'e.g.', 'fromtheopenweb', '.thispracticemayraiseconcerns', 'aboutprivacy—inthebroadsenseoftakinguserdataoutofitsintendedcontext', '[', 'nissenbaum', '2004', 'carlinietal.2021', ']', '.yet', 'itcouldalsoendupbeingawinforuserprivacyinapplicationsthat', 'handlescarceandsensitivedata', 'e.g.', 'inhealthcare', 'example', 'consider', 'problem', 'train', 'differentially', 'private', 'model', '[', 'dwork', 'et', 'al', '2006', ']', 'healthcare', 'task', 'train', 'model', '“', 'end-to-end', '”', 'i.e.', 'without', 'leverage', 'pretraining', 'toadecentprivacy-utilitytradeoffcurrentlyrequiresvastamountsofprivacy-sensitive', 'data', '[', 'mcmahanetal.2018', 'basuetal.2021', ']', '.incontrast', 'afoundationmodelpretrainedonpublic', 'datacouldpotentiallybeadaptedtothespecifichealthcaretaskwithsignificantlylessconfidential', 'data', '[', 'bommasanietal.2019', 'tramèrandboneh2021', ']', 'robustness', 'adversarial', 'examples', 'scale', 'evidence', 'suggest', 'train', 'model', 'robust', 'adversarial', 'examples', 'require', 'vastly', 'data', 'compare', 'standard', 'train', '[', 'schmidtetal.2018', ']', 'butthatunlabeleddatamaysufficetobridgethisgap', '[', 'carmonetal', '2019', 'uesatoetal.2019', ']', '.moreover', 'increasingmodelsizeandcapacity', 'i.e.', 'over-parameterization', 'hasalsobeenshowntobenecessaryforachievingadversarialrobustnessinsomesettings', '[', 'madry', 'etal.2018', 'bubeckandsellke2021', ']', '.understandinghowbesttoleverageover-parameterization', 'andunlabeleddatatoachieveadversarialrobustnessisanimportantdirectionforfutureresearch', 'giventheirunprecedentedscale', 'bothintermsofmodelsizeandtrainingsetsize', 'foundation', 'modelsareuniquelypositionedtobenefitfromthislineofinquiry', 'despite', 'unprecedented', 'scale', 'current', 'foundation', 'model', 'unfortunately', 'see', 'little', 'gain', 'inrobustnesstoworst-caseadversarialperturbations', '[', 'fort2021', 'wallaceetal.2019', ']', '.however', 'multimodalmodelssuchascliparesurprisinglyrobustto', 'non-adversarial', 'distributionalshifts', 'see§4.8', 'robustness', '.whetherthesegainsindistributionalrobustnesscantranslatetoincreased', 'resilience', 'real-world', 'attack', 'another', 'excite', 'open', 'question', 'particularly', 'settings', 'whereadversariesaresubjecttovariousconstraints', 'e.g.', 'limitedqueryaccessorcomputational', 'budget', 'reason', 'optimistic', 'enhance', 'distributional', 'robustness', 'could', 'lead', 'concomitantgainsinoverallsecurity—evenifthefoundationmodelremainsvulnerabletoworst-', 'case', '“', 'white-box', '”', 'attack']",107
Opportunities and Risks of Foundational Models - Stanford.pdf,"['108', 'centerforresearchonfoundationmodels', 'crfm', '4.8', 'robustnesstodistributionshifts', 'author', 'sangmichaelxie', 'ananyakumar', 'rohantaori', 'tonylee', 'shiorisagawa', 'pangweikoh', 'tatsunorihashimoto', 'real-worldmlsystemsneedtoberobusttodistributionshifts—theyshouldworkwellontest', 'distributionswhichdifferfromthetraindistribution.high-stakesapplicationssuchaspoverty', 'map', 'under-resourced', 'countries', '[', 'xie', 'et', 'al', 'jean', 'et', 'al', ']', 'self-driving', 'cars', '[', 'yu', 'etal.2020a', 'sunetal.2020a', ']', 'andmedicaldiagnosis', '[', 'albadawyetal.2018', 'daiandgool2018', ']', 'allrequiremodelsthatgeneralizewelltocircumstancesnotseeninthetrainingdata', 'e.g.', 'test', 'examplesfromdifferentcountries', 'underdifferentdrivingconditions', 'orfromdifferenthospitals', 'priorworkhasshownthatthesetypesofdistributionshiftscancauselargedropsinperformance', 'eveninstate-of-the-artmodels', '[', 'blitzeretal.2006', 'dauméiii2007', 'sugiyamaetal.2007', 'ganin', 'andlempitsky2015', 'pengetal.2019', 'kumaretal.2020a', 'arjovskyetal.2019', 'szegedyetal.2014', 'hendrycksanddietterich2019', 'sagawaetal.2020a', 'rechtetal.2019', 'abney2007', 'ruderandplank', 'geirhosetal.2018', 'kumaretal.2020b', 'yuetal.2020b', 'geirhosetal.2020', 'xieetal.2021a', 'kohetal.2021', ']', 'inthissection', 'weconsidertheroleoffoundationmodelsonrobustnesstodistributionshifts.a', 'foundationmodelistrainedonalargeanddiverseunlabeleddatasetsampledfromadistribution', '𝑝', 'andcanbeadaptedtomanydownstreamtasks.foreachdownstreamtaskt', 'thefoundation', 'pre', 'modelisadaptedtolabeledtrainingdatasampledfromanin-distribution', 'id', 'trainingdistribution', '𝑝t', 'andthenevaluatedonanout-of-distribution', 'ood', 'testdistribution𝑝t', '.forexample', 'id', 'ood', 'povertypredictionmodel', '[', 'xieetal.2016', 'jeanetal.2016', ']', 'maybepretrainedonunlabeledsatellite', 'datafromacrosstheworldtolearnusefulfeaturesforallcountries', 'thenfine-tunedonlabeled', 'examplesfromnigeria', 'andfinallyevaluatedinmalawiwherelabeledexamplesarescarce', 'wearguethat1', 'foundationmodelsareaparticularlypromisingapproachtorobustness.existing', 'workshowsthatpretrainingonunlabeleddataisaneffective', 'general-purposewaytoimprove', 'accuracy', 'ood', 'test', 'distributions', 'contrast', 'many', 'robustness', 'interventions', 'constrainedtonarrowtypesofdistributionshifts.however', 'wealsodiscusswhy2', 'foundation', 'modelsmaynotalwaysmitigatedistributionshifts', 'suchascertainshiftsduetospuriouscorrelations', 'orchangesovertime.finally,3', 'weoutlineseveralresearchdirectionstoleverageandimprove', 'foundationmodelsforrobustness', 'wenotethatoneofthewaysinwhichfoundationmodelsleadtoimprovedextrapolationisby', 'providinginductivebiases', 'viamodelinitialization', 'fortheadaptedmodel', 'whicharelearnedona', 'diversedatasetthatextendsbeyondthedownstreamtrainingdata.however', 'thissameinductive', 'biascanalsoencodeharmfulassociationsfromthepretraineddataandleadtorepresentational', 'andallocationalharmsinthepresenceofdistributionshift.see§4.6', 'dataand§5.1', 'fairnessfor', 'furtherdiscussionofsuchharmsandmethodsformitigation', '4.8.1', 'advantage', 'bylearningrepresentationsonalargeanddiversefoundationmodeltrainingdistribution𝑝', 'pre', 'foundationmodelscanimproveaccuracyoftheadaptedderivativeonthedownstreamtestdis-', 'tribution𝑝t', '.openai', '’', 'sclipmodel', 'whichisafoundationmodeltrainedonadiversesetof', 'ood', 'imagesandnaturallanguage', 'hasbeenshowntoberobusttoaclassofdistributionshiftsonima-', 'genet', '[', 'radfordetal.2021', ']', 'forexample', 'bothclipandastandardresnet50obtain76', '%', 'accuracy', 'onimagenet', 'butclipachieves6', '%', 'higheraccuracyonimagenetv2', '[', 'rechtetal.2019', ']', 'and35', '%', 'higheraccuracyonimagenetsketch', '[', 'radfordetal.2021', ']', 'whicharebothrelatedbutdifferent', 'fromtheoriginalimagenettrainingdistribution.incontrast', 'manyotherrobustnessinterventions', 'suchasadversarialtraining', '[', 'madryetal.2018', ']', 'invariantriskminimization', '[', 'arjovskyetal.2019', ']']",108
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '109', 'fig.21', 'in-distribution', 'id', 'andout-of-distribution', 'ood', 'inputsforavarietyofdistributionshifts.we', 'taketheimpliedtasktobeimageclassificationforimagesandfactverificationfortext.althoughrepre-', 'sentationslearnedbyfoundationmodelsimprovedownstreamrobustnessformanyshifts', 'e.g.', 'common', 'corruptions', '[', 'hendrycksanddietterich2019', 'xieetal.2021a', 'radfordetal.2021', ']', 'someshiftssuchasspurious', 'correlations', 'wheregrassispredictiveofcow', '[', 'beeryetal.2020', ']', 'andextrapolationacrosstime', 'withfacts', 'thatchangeovertime', '[', 'lazaridouetal.2021', ']', 'arestilllikelyunaddressedbyfoundationmodels', 'orusinglargermodelshavehadlittleimpactoneffectiverobustness', 'definedasthegapbetween', 'in-distributionandout-of-distributionperformance', 'ontheseimagenettasks', 'especiallywithout', 'explicitknowledgeofthedistributionshift', '[', 'taorietal.2020', 'santurkaretal.2020', 'radfordetal', '2021', 'milleretal.2021', ']', 'manyotherworksdemonstratethatpretrainingonlargedatasetscanimproverobustnessto', 'commonimagecorruptions', 'labelshift', 'andlabelcorruptions', '[', 'hendrycksetal.2019a', 'b', ']', 'tonatural', 'geographicshiftsinsatelliteimagerytasks', '[', 'xieetal.2021a', ']', 'andtoshiftsacrosstopicsinnatural', 'languageunderstandingtasks', '[', 'hendrycksetal.2020', 'fischetal.2019', 'yogatamaetal.2019', ']', '.as', 'another', 'example', 'diversify', 'foundation', 'model', 'train', 'data', 'multiple', 'languages', 'multilingualbert', '[', 'liuetal.2020b', ']', 'significantlyimprovesperformanceinunseenlanguagepairs', '4.8.2', 'persistentchallenges', 'despitepromisingsignsthatfoundationmodelswillresultinsubstantialimprovementstorobust-', 'ness', 'weanticipatethatfoundationmodelsarenotapanaceafordistributionshifts.wediscussthis', 'inthecontextoftwobroadcategoriesofdistributionshiftsbelow', 'spuriouscorrelations', 'spuriouscorrelationsarestatisticalcorrelationsbetweenfeaturesand', 'labelswithpredictivepoweronthetrainingdistributionbutnotonatestdistribution', '[', 'heinze-', 'demlandmeinshausen2017', 'arjovskyetal.2019', 'sagawaetal.2020a', ']', '.well-knownexamples', 'includerelianceonbackgroundcolorforobjectrecognition', '[', 'xiaoetal.2020', ']', 'surgicalmarkersfor', 'medicaldiagnostics', '[', 'winkleretal.2019', ']', 'annotatorbiasesincrowdsourceddata', '[', 'tsuchiya2018', 'gururanganetal.2018', 'poliaketal.2018', 'gevaetal.2019', ']', 'anddemographicbiases', '[', 'abidetal', '2021', 'nadeemetal.2021', 'gehmanetal.2020', ']', '.modelslearnthesespuriouscorrelationslargely', 'becausethefoundationmodeltrainingandadaptationdataexhibitthesebiases', '[', 'nagarajanetal']",109
Opportunities and Risks of Foundational Models - Stanford.pdf,"['110', 'centerforresearchonfoundationmodels', 'crfm', '2020', 'gehmanetal.2020', ']', 'andthisissuecannotsimplybeaddressedwithlargermodels', '[', 'sagawa', 'etal.2020b', ']', 'foundation', 'model', 'may', 'exacerbate', 'mitigate', 'effect', 'spurious', 'correlations', 'dependsonthenatureoftheparticulardownstreamtaskanditsrelationtothefoundationmodel', 'trainingdataandalgorithm.bytrainingwithadiversedataset', 'foundationmodelsmayimprove', 'robustnesstospuriouscorrelationsthatarefoundonlyinasubsetofthetrainingdata', 'e.g.', 'exist', 'studiesfindthatpretrainedlanguagemodelscanavoidspuriouscorrelationsbyquicklylearning', 'fromcounterexamplestothespuriouscorrelations', '[', 'tuetal.2020', ']', '.however', 'foundationmodels', 'canalsoexacerbatetheissuebyintroducingbiasespresentinthefoundationmodeltrainingdata', 'asobservedfordemographicbiasesingpt-3andothernlpmodels', '[', 'abidetal.2021', 'nadeemetal', '2021', 'gehmanetal.2020', ']', '.moreover', 'trainingatscalealoneneednotfullyaddresstherootissueof', 'identifyingandnotrelyingonthefeaturesthatarepredictiveonthedownstreamtrainingsetbut', 'notonthedownstreamtestset', '[', 'heinze-demlandmeinshausen2017', ']', '.addressingthesechallenges', 'willrequireustounderstandandmanagetheinductivebiasfromfoundationmodeltrainingand', 'developadaptationalgorithmsthatareresistanttolearningspuriouscorrelations', 'extrapolation', 'temporal', 'drift', 'finally', 'few-', 'zero-shot', 'capabilities', 'foundation', 'modelswillmeanthatthesemodelswillincreasinglybeusedfarbeyondthetrainingdistribution', 'large-scale', 'foundation', 'model', 'train', 'help', 'certain', 'form', 'extrapolation', 'newdistributions', '[', 'papadimitriouandjurafsky2020', ']', 'theremaybelimitstotheirextrapolation', 'capabilities.forexample', 'existinglanguagemodelscannothandlechangestoworldknowledgeor', 'languagechangewithoutre-training', '[', 'lazaridouetal.2021', 'dhingraetal.2021', ']', 'zero-shottransfer', 'inclipsuffersgreatlyinsatelliteimagedomains', '[', 'radfordetal.2021', ']', 'andimagenetpretraining', 'doesnotsubstantiallyimprovetheperformanceoflargemodelsonmedicalimages', '[', 'raghuetal', '2019', 'ke', 'et', 'al', '2021', ']', 'believe', 'foundation', 'model', 'assume', 'automatically', 'extrapolatewithinagivenmodality', 'e.g.', 'allimages', 'anditwillbecomeincreasinglyimportant', 'todefineandseparatetheformsofextrapolationthatarenewlyenabledbyfoundationmodels', 'fromthosethatremainoutofreach.thoughexistingtaxonomiesfordistributionshiftshavebeen', 'proposedingenerality', '[', 'quiñonero-candelaetal.2009', 'yeetal.2021', ']', 'fullyunderstandingand', 'definingthetypesofdistributionshiftsforwhichfoundationmodelsareeffectiveisamajoropen', 'problemforrobustnessresearch', '4.8.3', 'opportunities', 'foundation', 'model', 'hold', 'substantial', 'promise', 'general-purpose', 'robustness', 'intervention', 'distributionshifts', 'andopennewavenuesforrobustnessresearch.weoutlinesomeopportunities', 'andopenquestionsbelow', 'understandingfoundationmodelrepresentations', 'existingstudiesoftherobustnessoffoun-', 'dationmodelshavebeenlargelyempirical', 'andthereislittleunderstandingofthemechanism', 'behindgainsinrobustness.sunetal', '[', '2019b', ']', 'hypothesizethatpretrainedrepresentationsbring', 'disparatedomains', 'suchasidandooddistributions', 'closertogether', 'whichcaninturnimprove', 'generalizationfromlabelediddatatoooddata', '[', 'ben-davidetal.2010', ']', '.controlledexperimenta-', 'tiononmeasuringthedistancebetweendomainrepresentationswithandwithoutpretrainingcan', 'elucidatethiseffect.thereareinitialpromisingdirectionsincharacterizingfoundationmodeltrain-', 'ing', 'e.g.', 'contrastivelearningasaspectralgraphdecomposition', '[', 'haochenetal.2021a', ']', 'andtheir', 'inductivebiases', '[', 'saunshietal.2020a', 'leeetal.2020a', 'zhangandhashimoto2020', 'xieetal.2020', ']', 'howeverthesetheoriesarelimitedandfailtoaddressotherempiricallyeffectivefoundationmodels', 'suchasfullygenerativelanguagemodels', 'e.g.', 'gpt-3', '[', 'brownetal.2020', ']', 'andimage-gpt', '[', 'chen']",110
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '111', 'etal.2020d', ']', '.furtherunderstandinghowtheseinductivebiasesareusefulunderdistributionshift', 'mayleadtoamorecompletetheory', '§4.10', 'theory', 'ofhowfoundationmodelsimproverobustness', 'dataaugmentationinfoundationmodeltraining', 'whilefoundationmodelstrainedwithout', 'knowledgeofthedownstreamtaskscanavoidsometask-specificbiasesandoftenimproverobust-', 'ness', 'certainstatisticalbiasesstemmingfromhowthefoundationmodelwastrainedmaypersist', 'asaconcreteexample', 'manycontemporaryself-supervisionalgorithmsareheavilydependent', 'onchoosinganappropriatesetofdataaugmentations', '[', 'chenetal.2020c', ']', 'whichinturnconfers', 'differenttypesofrobustnessintheadaptationphase', 'xiaoetal', '[', '2021', ']', 'showthatafoundation', 'modelforvisiontrainedwithcontrastivelearningonrotationaugmentationsmayimproveood', 'performanceonadaptationtaskswithrotationinvariance', 'butmaynotimproverobustnessfor', 'taskswhereoodgeneralizationrequiresotherinvariances.furtherresearchintowhattypesof', 'dataaugmentationsimproverobustnessforawiderangeofdownstreamtasks—includingdata', 'augmentationsthatarelearnedfromdata', '[', 'wongandkolter2020', 'tamkinetal.2021b', ']', 'ordesigned', 'tobegenerallyapplicableacrossdatamodalities', '[', 'vermaetal.2021', ']', '—willinformbetterfoundation', 'modeltrainingalgorithms', '§4.2', 'train', 'encodingstructureinfoundationmodeltraining', 'ingeneral', 'exploringnewwaysofencoding', 'knownstructureandinvariancesinthedataisanimportantpathforwardforfoundationmodel', 'training.manyreal-worldtaskshaveadditionalmetadata', 'e.g.', 'spatiallocationcoordinates', 'climate', 'informationfromauxiliarysatellitesinpovertyprediction', 'whichmayprovideadditionalstructure', 'ood', 'generalization', 'e.g.', 'across', 'geographic', 'areas', '[', 'xie', 'et', 'al', '2021a', 'koh', 'et', 'al', '2021', ']', 'example', 'xieetal', '[', '2021a', ']', 'showthatmetadatacanbeusedastargetsforpretrainingtoimprove', 'downstreamoodaccuracy.inlanguage', 'modelingthetagsinhtmldataprovidesadditional', 'downstream-task-adjacentsupervision', 'allowsfornewformsofprompting', 'e.g.', 'fillingin', '<', 'title', '>', 'tagsfortitlesuggestion', 'andimprovesdataefficiency', '[', 'aghajanyanetal.2021', ']', '.whilecurrent', 'dataaugmentationmethodsencodehand-craftedknowledge', 'otheravenuessuchasexploiting', 'metadatacouldprovideamoreautomatedwayofdeterminingwhichstructuresandinvariancesto', 'incorporateforfoundationmodeltraining', 'specialization', 'vs.', 'diversity', 'foundation', 'model', 'train', 'data', 'choice', 'foundation', 'modeltrainingdatahasdownstreameffects—trainingonamorediversedatasetisnotalways', 'betterfordownstreamperformancethanamorespecializedfoundationmodel', '[', 'coleetal.2021', 'chalkidisetal.2020', ']', 'see§4.3', 'adaptationforamoredetaileddiscussion', '.insomedomainssuch', 'assatelliteimagesandspecializedtexttopics', 'continuedpretrainingonthespecializeddomain', 'improvesthedownstreamperformancesignificantly', '[', 'reedetal.2021', 'gururanganetal.2020', ']', '.this', 'isapotentialsourceoftension', 'ononehand', 'wemightwanttotrainthefoundationmodelona', 'large', 'diversedatasetinordertohavemorerobustperformanceunderdistributionshifts', 'whileon', 'theotherhand', 'wemightneedtospecializethefoundationmodeltoimproveitsin-distributionand', 'out-of-distributionperformanceondownstreamtasks.abetterunderstandingofhowspecialization', 'affectsthein-distributionandout-of-distributionperformanceoffoundationmodelswillallowus', 'todesignandcollectmoreeffectivefoundationmodeltrainingsets', 'adaptation', 'methods', 'although', 'foundation', 'model', 'provide', 'strong', 'start', 'point', 'adaptationmethodusesthepretrainedinformationcanaffectrobustness.forinstance', 'lightweight', 'tuningmethodsforlanguagemodels', 'e.g.', 'adapter/prefix/prompttuning', '[', 'houlsbyetal.2019', 'li', 'andliang2021', 'lesteretal.2021', ']', 'whichadaptthemodelforanewtaskbyoptimizingasmallset', 'ofparameters', 'suchasacontinuousprompt', 'whilekeepingtheotherfoundationmodelparameters', 'freeze', 'seemtogiveoodperformancebenefits', '§4.3', 'adaptation', '.xieetal', '[', '2021b', ']', 'explainthis', 'inaspecialcase', 'wherecomposingalearnedmodelwithafrozenfoundationmodelcanreducethe']",111
Opportunities and Risks of Foundational Models - Stanford.pdf,"['112', 'centerforresearchonfoundationmodels', 'crfm', 'complexityofthelearnedmodel', 'improvinggeneralizationbothidandood.however', 'itispoorly', 'understoodingeneralwhyfreezingparametersseemstoimproveoodperformance.finally', 'currentadaptationmethodsmaysufficeforgoodidgeneralization', 'theydonotexplicitlyaccount', 'fordistributionshift.asafirststep', 'wecaninvestigatehowmethodsfordistributionshiftssuchas', 'domainadaptation', 'domaingeneralization', 'andsemi-supervisedlearningmethodsinteractwith', 'foundationmodelswhenusedforadaptation.progressinthesedirectionscanleadtoadaptation', 'methodsthatcanbetterleveragefoundationmodelsforrobustness']",112
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '113', '4.9', 'aisafetyandalignment', 'author', 'alextamkin', 'geoffkeeling', 'jackryan', 'sydneyvonarx', 'thefieldofartificialintelligence', 'ai', 'safetyconcernsitselfwithpotentialaccidents', 'hazard', 'andrisksofadvancedaimodels', 'especiallylarger-scaleriskstocommunitiesorsocieties.current', 'foundationmodelsmaybefarfromposingsuchrisks', 'however', 'thebreadthoftheircapabilities', 'andpotentialapplicationsisstriking', 'andaclearshiftfrompreviousmlparadigms.whileai', 'safetyhashistoricallyoccupiedamoremarginalpositionwithinairesearch', 'thecurrenttransition', 'towardsfoundationmodelsandtheircorrespondinggeneralityoffersanopportunityforaisafety', 'researcherstorevisitthecorequestionsofthefieldinanewlightandreassesstheirimmediateor', 'near-futurerelevance.81', '4.9.1', 'traditionalproblemsinaisafety', 'amajorbranchofaisafetyresearchconcernstheimplicationsofadvancedaisystems', 'include', 'might', 'match', 'exceed', 'human', 'performance', 'across', 'broad', 'class', 'cognitive', 'task', '[', 'everittetal.2018', ']', '.82acentralgoalofsafetyresearchinthiscontextistomitigatelarge-scalerisks', 'posedbythedevelopmentofadvancedai.83', 'theserisksmaybesignificantlymorespeculative', 'thanthoseconsideredin§5.2', 'misuse', '§4.8', 'robustness', 'and§4.7', 'security', 'however', 'theyareof', 'fargreatermagnitude', 'andcouldatleastinprincipleresultfromfuture', 'highly-capablesystems.of', 'particularconcernareglobalcatastrophicrisks', 'roughly', 'risksthatareglobalortrans-generational', 'inscope—causingdeathorotherwisesignificantlyreducingthewelfareofthoseaffected', 'e.g.', 'nuclearwarorrapidecologicalcollapse', '[', 'bostromandcirkovic2011', ']', '.whataisafetyresearch', 'amountsto', 'isafamilyofprojectswhichaimtocharacterizewhat', 'ifany', 'catastrophicrisksare', 'posedbythedevelopmentofadvancedai', 'anddevelopplausibletechnicalsolutionsformitigating', 'theprobabilityortheseverityoftheserisks.thebest-casescenariofromthepointofviewofai', 'safetyisasolutiontothecontrolproblem', 'howtodevelopanadvancedaisystemthatenablesus', 'toreapthecomputationalbenefitsofthatsystemwhileatthesametimeleavinguswithsufficient', 'controlsuchthatthedeploymentofthesystemdoesnotresultinaglobalcatastrophe', '[', 'bostrom', 'andcirkovic2011', ']', '.howevertechnicalsolutionsarenotsufficienttoensuresafety', 'ensuringthat', 'safealgorithmsareactuallythoseimplementedintoreal-worldsystemsandthatunsafesystems', 'arenotdeployedmayrequireadditionalsociotechnicalmeasuresandinstitutions', 'reinforcementlearning', 'rl', 'whichstudiesdecision-makingagentsoptimizedtowardsrewards', 'hasbeenadominantfocusinaisafetyforthepastdecade.whatisatissuehereisthedifficultyof', 'specifyingandinstantiatingarewardfunctionfortheaithatalignswithhumanvalues', 'inthe', 'minimalsenseofnotposingaglobalcatastrophicthreat.84', 'whilethisproblem', 'knownasvalue', 'alignment', '[', 'gabriel2020', 'yudkowsky2016', ']', 'mayseemtrivialatfirstglance', 'humanvaluesare', 'diverse,85amorphous', 'andchallengingtocapturequantitatively.duetothis', 'asalientconcernis', 'rewardhacking', 'wheretheaifindsanunforeseenpolicythatmaximizesaproxyrewardforhuman', 'wellbeing', 'butwhosemisspecificationresultsinasignificantharm.86manyeffortstocombatthe', '81seeamodeietal.', '[', ']', 'andhendrycksetal.', '[', '2021d', ']', 'forbroaderperspectivesonopenproblemsinaisafety', '82thisisreferredtobysomeasagiorartificialgeneralintelligence', 'althoughterminologyusevaries', '[', 'e.g.', 'seekarnofsky', ']', '83notethatthisdoesnotrequireabeliefthatbuildingcertainkindsofadvancedaiisadesirablegoal', 'norevencertainty', 'thatitisanachievableone', '84seehubingeretal', '[', '2019', ']', 'foradiscussionofsomechallengesthatariseatthethresholdbetweenrewardspecification', 'andrewardinstantiation', '85seegabriel', '[', '2020', ']', 'foranextendeddiscussionofhumandiversity', 'ethics', 'andthevaluealignmentproblem', '86seethisspreadsheetforalistofreal-worldexamplesofrewardhacking', 'includinganaircraftlandingalgorithmwhich', 'achievedaperfectscorebyoutputtinglargeforcesthatexploitedaflawinthesimulator']",113
Opportunities and Risks of Foundational Models - Stanford.pdf,"['114', 'centerforresearchonfoundationmodels', 'crfm', 'valuealignmentproblemhavefocusedonmaximizingcorrigibility', 'whichiswhenerrorsinthe', 'designofasystemcanbecorrectedoncethesystemisrunning', '[', 'soaresetal.2015', ']', '.thiscanbefar', 'fromstraightforward—intherlcontext', 'anagentwithaspecifiedgoalwouldbeincentivizedto', 'prohibitattemptstoalterthatgoal', 'asanyattempttoalterthatgoalwouldlikelybesuboptimalfor', 'thegoal', '’', 'srealization', '[', 'omohundro2008', ']', 'however', 'purerlisnottheonlytheorizedroutetoadvancedai.foundationmodelscanalsobe', 'trainedwithsimple', 'self-', 'supervisedobjectiveslikenext-tokenprediction', 'yetcanstillbeusedin', 'interactiveandgoal-directedways', 'withorwithoutadditionalrltraining.moreover', 'itappears', 'thatmanyofthesemethodsmayresultinincreasedcapabilitiesthroughstraightforwardscalingof', 'compute', 'numberofparameters', 'anddatasetsize', '[', 'hestnessetal.2017', 'kaplanetal.2020', ']', '.what', 'conceptslikevaluealignmentandcorrigibilityamounttointhebroadercontextoffoundation', 'modelsdifferinseveralrespectstothepurerlcase', 'andmustaccordinglybecarefullytheorized', '4.9.2', 'currentfoundationmodelsandaisafety', 'manyoftheserisksintherlsettingresultfrommodelsoptimizedtocarryoutgoals.however', 'keychallengeforaisafetyresearchonrecentfoundationmodelsisthatgoal-directedbehavior', 'mayemergedespitenotbeingexplicitlyoptimizedfor', 'seealso§4.2', 'train', '.asanexample', 'largelanguagemodelsmaybetrainedoncorporawhereagentsuselanguageingoal-directedways', 'suchasinpersuasivetext.topredictthenexttokenwell', 'amodelmayacquireageneralcapability', 'toreasonandproducearguments', 'whichcouldemergewithsuitablecontexts.foundationmodels', 'trainedonotherkindsofhumandatamaycaptureotherkindsofgoal-directedbehaviorpresentin', 'thedata', 'e.g.', 'roboticagentstrainedtomimichumansinvideosmayattempttopunchorknock-out', 'theirhumanoperatorsiftheirtrainingdataincludesvideosofboxingmatches.recentworkhas', 'alsoattemptedtodirectlytrainagentstoproducegoal-directedbehavior', 'forexample', 'thedecision', 'transformertrainsasequencemodelontrajectoriesprependedwiththeirreturns', '[', 'srivastavaetal', '2019', 'schmidhuber2019', 'chenetal.2021b', ']', '.onecanthengeneratehigh-returntrajectoriesby', '“', 'prompt', '”', 'thismodelwithahighreturn', 'whichraisessimilarquestionsofrewardhackingfrom', 'therlcontext', 'however', 'amajoraimofsafetyresearchongoal-directedmodelsistogainmoreprincipled', 'controlandexplainabilityovertheactionsbeingpursuedbytheagent', 'asopposedtorelyingon', 'inscrutabledecisionsfromablackboxneuralnetwork.87thismakescurrentfoundationmodels', 'anexcitingavenueofstudyforaisafetyresearch', 'asaligningthemmaybeausefulprecursorfor', 'aligningmoreadvancedmodels', '[', 'christiano2016', 'cotra2021', 'kentonetal.2021', ']', '.onechallengeis', 'themisalignmentbetweenthefoundationmodel', '’', 'strainingobjectiveandthedesiredbehavior', 'example', 'alanguagemodelmaybetrainedtopredictthenextwordofalldocumentsinthetraining', 'corpusregardlessofveracity', 'butusersmaywantthemodeltoonlyoutputtrueorhelpfultext', 'onepotentialwaytosteergoal-directedagentstowardsdesiredbehaviormaybetotrainthem', 'withnaturallanguagedescriptionsofactions—thismayenablesteeringthemwithlanguageas', 'wellasenablingthemtooutputinterpretablelanguagedescribingthetaskthey', ""''"", 'believe', ""''"", 'theyare', 'perform', 'similartomethodsforcontrollablegenerationandsourceattribution', '[', 'e.g.', 'keskaretal', '2019', 'seealso§2.3', 'robotics', '§2.5', 'interaction', 'and§4.11', 'interpretability', ']', '.however', 'advanceswouldbenecessarytoensurethereliabilityandself-consistencyofsuchmodelsinthe', 'wild', '§4.8', 'robustness', 'aswellasgainingamoremechanisticunderstandingofhowthesemodels', 'operate', '[', 'cammarataetal.2020', 'alsosee§4.11', 'interpretability', ']', '.andevenifnaturallanguage-', 'basedcontroloffuturefoundationmodelsenablesbettertaskspecificationandmonitoring', 'model', '87formoreontherelationshipbetweenunderstandingandsemanticssee§2.6', 'philosophy']",114
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '115', 'may', 'acquire', 'deceptive', 'otherwise', 'undesirable', 'behavior', 'human', 'data', '—', 'identify', 'neutralizingthisbehaviorisanotherimportantdirectionforfuturestudy', 'whiletheself-supervisedobjectivesdescribedinthepreviousparagraphtrainmodelstocapture', 'humanbehaviorinthedata', 'newtrainingparadigmsmayproducegoal-directedfoundationmodels', 'capableofcarryingoutawiderangeoftasksincomplexenvironments', 'andwhichexhibitcapa-', 'bilitiessuperiortohumansindifferentdomains', 'see§4.2', 'train', '.forexample', 'goal-directed', 'foundationmodelsmaybetrainedinanopen-endedself-playsetting', 'similartoalphago', 'orinvast', 'multitasksingle-agentrlsetups.thismightleadtoemergentcapabilitiesthatcomplicateeffortsto', 'getagentstocarryoutgoals', 'especiallyifmanyagentsaretrainedtogetherinarichworld-simulator', 'thatencouragesthedevelopmentofskillslikedeception', 'misdirection', 'dissimulation', 'persuasion', 'andstrategicplanning.asidefromcounteringdeceptivebehavior', 'italsoremainsunclearhowto', 'effectivelyevaluateandcontrolthebehaviorofverycapablemodels', 'knownasscalableoversight', 'oralignment', '[', 'amodeietal.2016', 'leikeetal.2018', ']', 'e.g.', 'scoringnovelreactionsproposedbya', 'chemicalfoundationmodel', 'see§4.4', 'evaluation', '.newhuman-in-the-loopapproachesfortraining', 'steer', 'monitor', 'andunderstandingthesemodelsarethusexcitingfuturedirections', 'finally', 'even', 'advance', 'capabilities', 'emerge', 'important', 'research', 'areaforaisafetyintheneartermischaracterizingandforecastingthecapabilitiesofcurrent', 'self-supervisedfoundationmodels.therearethreeaspectswhichmakethischallenging.first', 'generalityoffoundationmodelsmeansthattheycanbeappliedtocountlessdifferentkindsof', 'applicationsinunexpectedways.enumeratingcurrentandplannedapplicationsoffoundation', 'modelsisnotsufficienttocapturethefullrangeofwaystheycouldbeused.second', 'evenwithin', 'aparticularapplication', 'modelcapabilitiesareemergent', 'theygrowandchangeinunexpected', 'waysasmodelsscale.forexample', 'theabilitytocontrolgpt-3via', '“', 'prompt', ""''"", 'wasanemergent', 'phenomenonofwhichonlythebarestglimpseswereevidentinthesmallergpt-2model', '[', 'radford', 'etal.2019', 'brownetal.2020', ']', '.whattheemergentpropertiesoffuturefoundationmodelswilllook', 'likeisunknown.third', 'evenwithinaparticularapplicationandscale', 'amodel', '’', 'scapabilitiesarenot', 'easytocharacterize.forexample', 'theabilityofgpt-3toperformadditionimprovesdramatically', 'oncecommasareaddedtotheinputs', '[', 'branwen2020', 'brockman2020', ']', '.similarly', 'smallrewordings', 'ofpromptscanhavelargeimpactsontaskperformance.sincethespaceofpromptsisintractableto', 'enumerate', 'itischallengingtodefinitelyassertthatanytaskisoutsidethereachofcurrentprompt-', 'basedfoundationmodels—thisisamajorchallengeforreasoningaboutpossiblecatastrophicrisks', 'fromfoundationmodels', '4.9.3', 'potentialcatastrophicrisksfromfuturefoundationmodels', 'thebroadandquickly-growingcapabilitiesofcurrentmodelssuggestthebenefitofattemptingto', 'characterizepossiblecatastrophicrisksfrommoreadvancedsystems.weseeatleasttwowaysin', 'whichadvancedfoundationmodelsmightcontributetosuchoutcomes', 'catastrophicrobustnessfailures', '§4.8', 'robustnessdiscusseshowmodelsmaybehaveinunex-', 'pectedorharmfulwayswhenconfrontedwithnewkindsofdata', '[', 'amodeietal.2016', 'yudkowsky', 'etal.2008', ']', '.thesefailuresmaybeespeciallyconsequentialiffoundationmodelsareintegrated', 'intoimportantsystemsthatleveragefoundationmodels', '’', 'abilitytoquicklyadapttomanydifferent', 'tasksandsituations.failurescouldbecatastrophiciftheyoccurinwarfaresystems', 'resultingin', 'unwanteddischargeofweapons', 'possiblyignitingaconflict', 'criticalinfrastructure', 'accidental', 'destructionofcriticalenergyoragriculturalcapabilities', 'oriftheybecomeessentialtoalarge', 'fractionofeconomicactivity', 'whoseunexpectedfailurecouldresultinasuddencollapseinliving', 'standardsandpoliticalinstability', 'seealso§5.5', 'economics', '.indeed', 'thethreatofcatastrophic', 'robustnessfailuresisparticularlypertinentforfoundationmodelsincontrasttootherkindsof']",115
Opportunities and Risks of Foundational Models - Stanford.pdf,"['116', 'centerforresearchonfoundationmodels', 'crfm', 'ai.thisisbecauseafoundationmodelconsistsofasinglemodelthatmaybeadaptedformany', 'differentusecases', 'suchthatrobustnessfailuresderivedfromthestatisticalassociationslearnedby', 'themodelcouldinprinciplemanifestinacorrelatedwayacrossseveraldifferentdomains.ifthe', 'samefoundationmodelisintegratedintomultiplecriticalfunctions', 'thenlackofrobustnessinthe', 'modelcouldleadtocorrelatedfailuresthatspanmultiplecriticalfunctionsorfailsafes', 'misspecifiedgoals', 'theuseoffoundationmodelsmightincreasetherisksofoptimizingmis-', 'alignedyeteasy-to-specifygoals', 'oftenreferredtoasgoodhart', '’', 'slaw', '[', 'kentonetal.2021', 'goodhart', '1984', ']', '.acurrent-dayexampleoftheserisksisthenegativeeffectsofsomerecommendersystems', 'e.g.', 'polarization', 'mediaaddiction', 'whichmayoptimizesimpleengagementmetricsratherthan', 'aharder-to-measurecombinationofsocietalandconsumerwell-being', '[', 'burretal.2018', 'milano', 'et', 'al', '2020', ']', 'future', 'institutions', 'may', 'leverage', 'uninterpretable', 'foundation', 'model', 'maximize', 'simplemeasuressuchasprofitorgdp', 'duetothesemodels', '’', 'abilitytoadapttothemanydifferent', 'subproblemseachofthesemetricsisdependenton.however', 'atlargerscalesoptimizingforthese', 'proxymetricsinsteadofamoreholisticgoaldesignedforhumanwelfarecouldinadvertentlylead', 'toenvironmentalorgeopoliticalharms', '[', 'gabriel2020', 'creelandhellman2021', ']', '4.9.4', 'conclusion', 'insum', 'wearguethatcurrentandpotentialfutureemergentpropertiesoffoundationmodelsmake', 'themripeobjectsofstudyforthefieldofaisafety.weencouragefutureworkoncharacterizing', 'andforecastingtheexactcapabilitiesandrisksoffoundationmodels', 'developingnewmethods', 'toalignfoundationmodelstohumanvaluesanddesiredgoals', 'andforstates', 'researchlabs', 'businessestocoordinateonproactivemeasurestomitigatesalientrisks']",116
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '117', '4.10', 'theory', 'author', 'aditi', 'raghunathan', 'sing', 'michael', 'xie', 'ananya', 'kumar', 'niladri', 'chatterji', 'rohan', 'taori', 'tatsunorihashimoto', 'tengyuma', 'rigorousmathematicaltheoryplaysafoundationalroleinmanyengineeringandsciencedisci-', 'plines', 'e.g.', 'informationtheoryinelectricalengineering', '.webelievethattheoryoffoundation', 'modelscanbeparticularlybeneficialinguidingtechnicaldecisionsandinnovationsbecauseof', 'thehugecomputationalcostsassociatedwithexperimentingonfoundationmodels.inaddition', 'theoreticalinsightshelpelucidatefundamentallimitationsandexplainsurprisingempiricalphe-', 'nomena.however', 'thecommunitycurrentlyhasalimitedtheoreticalunderstandingoffoundation', 'model', 'despitemuchrecentprogress', '[', 'aroraetal.2019b', 'haochenetal.2021a', 'weietal.2021', '2020b', 'zhangandhashimoto2021', 'saunshietal.2020b', 'daoetal.2019', 'toshetal.2020,2021', 'cai', 'etal.2021', 'leeetal.2020a', 'zimmermannetal.2021', 'bansaletal.2020', 'wangandisola2020', 'tsai', 'etal.2020', 'tianetal.2020a', 'b', 'tripuranenietal.2020', 'duetal.2020', ']', 'deepneuralnetworksformthebackboneoffoundationmodels.eveninthewell-studiedsu-', 'pervisedlearningsetting', 'wherethetrainandtestscenarioshavethesamedistribution', 'thereare', 'numerousopenquestionsarounddeepnetssuchasunderstandingnon-convexoptimization', 'implicitregularizationeffectofoptimizers', 'andexpressivity.foundationmodelsraisequestions', 'thatsignificantlygobeyondthesuperviseddeeplearningsetting.thecoreproblemintheoretically', 'analyzingfoundationmodelsisunderstandingwhytrainingononedistributionwithapossibly', 'unsupervised/self-supervisedlossleadstogoodadaptationperformanceondifferent', 'downstream', 'distributionsandtasks.88', 'wewilldiscussanintuitivemodularizationtoanalyzefoundationmodelsthatlaysbarethe', 'connections', 'supervise', 'learn', 'foundation', 'model', 'concrete', 'core', 'technical', 'question', 'andsomepromisingtheoreticaltoolstoaddressthesequestions.thesenewcorequestions', 'canprovideusefulinsightintofoundationmodelsandcanbestudiedinparalleltosupervised', 'deeplearningtheory.whilewefocusonanalyzingthedownstreamperformance', 'theproposed', 'modularizationandtoolscouldproveusefultoanalyzeothermetricsofinterestsuchasrobustness', 'todistributionshifts', '§4.8', 'robustness', 'andsecurity', '§4.7', 'security', 'fig.22', 'theanalysisoffoundationmodelsfrompretrainingondiversedatatodownstreamperformanceon', 'adaptedtasksinvolvescapturingtherelationbetweendifferentlosstermsasshownabove.themainchallenge', 'istoanalyzethehighlightedpretraining-adaptationinterfacewhichrequiresreasoningcarefullyaboutthe', 'populationlossesinadditiontothemodelarchitecture', 'lossesanddatadistributionsofthepretrainingand', 'adaptationstages', '§4.10.2', 'theory-interface', '.analysisofgeneralizationandoptimizationlargelyreducesto', 'theiranalysisinstandardsupervisedlearning', '88thetheoryforfoundationmodelscloselyrelatesto', 'butalsogoesbeyondthetheoryfortransferlearning', 'whichis', 'itselfanunderexploredarea', 'foundationmodelsarepossiblytrainedwithunlabeleddataandwillbeadaptedtomanyorall', 'naturaltasks', 'whereastransferlearningtypicallystudieslabeledsourcetasksandafixednumberoftargettasks']",117
Opportunities and Risks of Foundational Models - Stanford.pdf,"['118', 'centerforresearchonfoundationmodels', 'crfm', '4.10.1', 'theoreticalformulationsandmodularizations', 'recallthatfoundationmodelsaretrainedonalargeamountofrawdata', '§4.2', 'train', 'adapt', 'specific', 'task', '§4.3', 'adaptation', 'therefore', 'decompose', 'naturally', 'trainingandadaptationphases.weidentifyinterfacesbetweenthemanddisentanglepartsspecific', 'tofoundationmodelsfrompartsthatrequirestandarddeeplearningtheory', 'sothattheycanbe', 'independentlyworkedon.weintroduceamodularizedanalysisframework', 'whichhasalsobeen', 'implicitlyorexplicitlyemployedinrecentworks', 'e.g.', 'aroraetal.', '[', '2019b', ']', 'haochenetal', '[', '2021a', ']', 'weietal.', '[', '2020b', ']', 'tripuranenietal', '[', '2020', ']', '.thecrucialcomponentinthismodularizedanalysis', 'turnsouttobethepretrain-adaptationinterface.wefirstdescribethemodularization', 'anddiscuss', 'whywefindthismodularizationpromisingandfinallysomelimitations', 'wewillrefertothetrainingphaseexplicitlyas', '“', 'pretraining', '”', 'todistinguishitfromtheadaptation', 'phasethatcouldalsoinvolvetrainingonafewsamplesfromaparticulartask', 'pretrainingphase', 'thepretrainingoffoundationmodelsofteninvolvesadatadistribution𝑝', 'pre', 'e.g.', 'thedistributionofnaturaltext', 'andapretraininglossfunctionℓ', '𝑥', '𝜃', 'thatmeasuresthe', 'pre', 'loss', 'e.g.', 'languagemodelinglossingpt-3', 'onaninput𝑥', 'foramodelwithparameters𝜃', '∈θ.let', '𝑝ˆ', 'denotetheempiricaldistributionoveralargenumberofindependentsamplesfrom𝑝', 'pre', 'pre', 'pretraining', 'minimize', 'loss', 'ℓ', 'on𝑝ˆ', 'call', 'empirical', 'pretraining', 'loss', 'pre', 'pre', 'producesamodel𝜃ˆ', 'fm', 'cid:98', '𝐿pre', '𝜃', 'd=ef', 'e𝑥∼𝑝ˆpre', '[', 'ℓpre', '𝑥', '𝜃', ']', 'and𝜃ˆfm', 'd=ef', 'argmin', 'cid:98', '𝐿pre', '𝜃', '1', '𝜃∈θ', 'weconsiderthecorrespondinglossonthepopulationdistribution𝑝', 'calledthepopulation', 'pre', 'pretrainingloss', 'asacentralconcept', '𝐿pre', '𝜃', 'd=ef', 'e𝑥∼𝑝pre', '[', 'ℓpre', '𝑥', '𝜃', ']', '2', 'optimization-basedadaptationphase', 'weframeadaptationasageneralconstrainedoptimiza-', 'tionproblemthatdependson𝜃ˆ', 'abstractingawaythoseadaptationmethodsthatarebasedon', 'fm', 'optimizingcertainlossfunctionssuchasfine-tuningandprompt-tuning', 'see', 'e.g.', '[', 'houlsbyetal', '2019', 'liandliang2021', 'lesteretal.2021', ']', 'and§4.3', 'adaptation', 'sincedifferentadaptationmethodscouldmodifydifferentsubsetsofthemodelparameters', 'denotethespaceofadaptedmodelparametersbysomeγ.givenadownstreamtaskdistribution', '𝑝', 'e.g.', 'questionansweringinaparticulardomain', 'andafewempiricalsamples𝑝ˆ', 'sample', 'task', 'task', 'from𝑝', 'wemodeltheadaptationphaseasminimizingsomeadaptationlossℓ', 'on𝑝ˆ', 'w.r.t', 'task', 'adapt', 'task', 'adaptedparameters𝛾', '∈', 'γ', '𝛾task', '𝜃ˆfm', 'd=ef', 'argmin', 'cid:98', '𝐿adapt', '𝛾', '𝜃ˆfm', '3', '𝛾∈γ', '𝐶', '𝛾', '𝜃ˆfm', '≤𝑐0', 'cid:98', '𝐿adapt', '𝛾', '𝜃ˆfm', 'd=ef', 'e𝑥∼𝑝ˆtask', '[', 'ℓadapt', '𝑥', '𝛾', '𝜃ˆfm', ']', 'istheempiricaladaptationloss', 'and𝐶', '𝛾', '𝜃ˆfm', '≤𝑐0', 'isanoptionalconstraintthatcontrolsthecomplexityoftheadaptedparameters', 'encompass', 'bothexplicitregularization', 'e.g.', 'modeldimensionalityandnorm', 'andtheimplicitregularization', 'oftheadaptationprocess', 'welistsomecommonadaptationmethodsanddiscussthecorrespondingadaptedparameter𝛾', 'andconstraints𝐶', '𝛾', '𝜃ˆ', '≤𝑐', 'fm', '0', '1', 'linearprobing', 'trainingalinearclassifierontopoftherepresentationsfromafoundation', 'model.hereγ', '=r𝑘', 'isthesetoflinearclassifiersontherepresentationsofdimensionality𝑘', 'and𝐶', '𝛾', '𝜃ˆ', 'couldbetheℓ', 'orℓ', 'normof𝛾', 'fm', '2', '1']",118
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '119', '2', 'fine-tune', 'optimize', 'randomly', 'initialize', 'linear', 'head', 'step', 'parameters𝜃', 'fromtheinitializationof𝜃ˆ', '.here𝛾', 'istheconcatenationof𝜃', 'andthelinear', 'fm', 'head', 'process', 'could', 'correspond', 'implicit', 'regularization', 'of𝛾', 'towards', 'initialization𝜃ˆ', 'capturedby𝐶', '𝛾', '𝜃ˆ', '≤𝑐', '.theexactterm𝐶', '𝛾', '𝜃ˆ', 'woulddependonthe', 'fm', 'fm', '0', 'fm', 'optimizationalgorithmused', 'andsuchacharacterizationoftheimplicitregularizationof', 'optimizationisanareaofactiveresearchstudy', '[', 'e.g.', 'gunasekaretal.2017', 'soudryetal', 'gunasekaretal.2018', 'aroraetal.2019a', 'blancetal.2019', 'woodworthetal.2020', 'wei', 'etal.2020a', 'haochenetal.2021b', 'damianetal.2021', 'andreferencestherein', ']', '.89', '3', 'prompt-tuning', 'optimizingasmallsetofcontinuoustask-specificvectorsthatprependthe', 'taskinputs.here𝛾', 'isthecontinuouspromptvectorswhichoftenhassmalldimensionality', 'andwemayoptionallyhaveaconstraintonthenormsof𝛾', 'oneobviouslimitationtonoteisthatthisformulationexcludesadaptationmethodssuchas', 'in-contextlearning', '[', 'brownetal.2020', ']', 'wherethereisno', '“', 'train', '”', 'i.e.', 'theminimizationofsome', 'empiricaladaptationloss', 'duringtheadaptationphase.wediscussthisandotherlimitationsin', '§4.10.3', 'theory-incontext', 'twocentralquantitiesfortheadaptationphasearethepopulationadaptationloss', '𝐿adapt', '𝛾', '𝜃ˆfm', '=e𝑥∼𝑝task', '[', 'ℓadapt', '𝑥', '𝛾', '𝜃ˆfm', ']', '4', 'andtheminimaladaptationloss', '𝐿★', '𝜃ˆ', '=', 'min', '𝐿', '𝛾', '𝜃ˆ', '5', 'adapt', 'fm', 'adapt', 'fm', '𝛾∈γ', '𝐶', '𝛾', '𝜃ˆfm', '≤𝑐0', 'separateanalysisformodularizedphases', 'existinggeneralizationtheoryforstandardsuper-', 'vised', 'learn', 'aim', 'show', 'cid:98', '𝐿pre', '≈', '𝐿pre', 'cid:98', '𝐿adapt', '≈', '𝐿adapt', 'address', 'question', 'specificallyfordeepnetsisanactiveresearcharea.wecanalsoleveragethestandardlearning', 'theorydecompositiontoboundthefinaldownstreamtasklossbytheexcessgeneralizationerror', 'andtheminimaladaptationlossasfollows', '𝐿', '𝛾', '𝜃ˆ', '≤', '𝐿★', '𝜃ˆ', '+generalizationerror', '6', 'adapt', 'task', 'fm', 'adapt', 'fm', 'cid:32', 'cid:32', 'cid:32', 'cid:32', 'cid:32', 'cid:32', 'cid:32', 'cid:32', 'cid:32', 'cid:32', 'cid:32', 'cid:32', 'cid:32', 'cid:32', 'cid:124', 'cid:123', 'cid:122', 'cid:125', 'minimaladaptationloss', 'wherethegeneralizationerrorcapturestheclosenessbetween𝐿adaptand', 'cid:98', '𝐿adapt.90thedecomposition', 'relationship', 'key', 'quantities', 'show', 'figure', '22', 'generalization', 'optimizationarrows', 'asarguedabove', 'largelyreducetodeeplearningtheoryinthesupervised', 'setting.whatweareleftwithisthemainchallengewithfoundationmodels', 'whichistounderstand', 'whytheminimaladaptationloss𝐿∗', '𝜃ˆ', 'canbesmallasaresultofasmallpretrainingpopulation', 'adapt', 'fm', 'loss', 'whichwediveintonextin§4.10.2', 'theory-interface', 'theworkofaroraetal', '[', '2019b', ']', 'pioneeredthepursuitofthisquestionbyboundingfromabove', '𝐿★', '𝜃ˆ', 'by𝐿', '𝜃ˆ', 'inthecontextofcontrastivelearning', 'andhaochenetal', '[', '2021a', ']', 'tosh', 'adapt', 'fm', 'pre', 'fm', 'etal', '[', '2020,2021', ']', 'relaxthedataassumptions.otherpretrainingmethodssuccessfullyanalyzed', 'underthisframework', 'implicitlyorexplicitly', 'includepretrainingwithlanguagemodels', '[', 'weietal', '89itmaynotalwaysbefeasibletocharacterizetheinductivebiasofadaptationviaanexplicitconstraint𝐶', '𝛾', '𝜃ˆfm', '≤𝑐0', 'themodularizationweproposeisalsoapplicableinthesecases', 'butfornotationalsimplicity', 'wefocusonthecasewhere', 'implicitregularizationcanbeapproximatedviaanexplicitconstraint', '90moreprecisely', 'thegeneralizationerrortermisthesumof𝐿adapt', '𝛾task', '𝜃ˆfm', '−𝐿', 'cid:98', 'adapt', '𝛾task', '𝜃ˆfm', 'and𝐿', 'cid:98', 'adapt', '𝛾t★ask', '𝜃ˆfm', '−', '𝐿adapt', '𝛾★', '𝜃ˆfm', '=', '𝐿', 'cid:98', 'adapt', '𝛾t★ask', '𝜃ˆfm', '−𝐿a★dapt', '𝜃ˆfm', 'where𝛾t★ask', 'minimizer', '5', '6', 'follow', 'easily', 'use', '𝐿', 'cid:98', 'adapt', '𝛾task', '𝜃ˆfm', '≤𝐿', 'cid:98', 'adapt', '𝛾t★ask', '𝜃ˆfm']",119
Opportunities and Risks of Foundational Models - Stanford.pdf,"['120', 'centerforresearchonfoundationmodels', 'crfm', '2021', ']', 'orself-supervision', '[', 'leeetal.2020a', ']', 'withself-trainingalgorithms', '[', 'weietal.2020b', 'caietal', '2021', ']', 'andwithmultiplesupervisedtasks', '[', 'tripuranenietal.2020', 'duetal.2020', ']', '4.10.2', 'whyisthepretraining-adaptationinterfaceinteresting', '?', 'asshowninfigure22', 'themainmissinglinkbeyondstandardsupervisedtheoryis', 'underwhatconditionsdoesasmallpopulationpretrainingloss𝐿', '𝜃ˆ', 'implyasmallminimal', 'pre', 'fm', 'adaptationloss𝐿★', '𝜃ˆ', 'andwhy', '?', 'adapt', 'fm', 'theconditionsthatleadtoasuccessfulinterfacecoulddependonseveralquantitiessuchasthe', 'pretrainingandadaptationdistributions', 'objectivesandtrainingmethods', 'aswellasthemodel', 'architecture.thisquestionisbeyondthescopeofstandardgeneralizationtheory', 'butitdoesnarrow', 'usdowntoafewimportantfactorsspecifictofoundationmodels', 'andcapturestheessenceof', 'variousimportantopenquestionsonfoundationmodelsaswearguebelow', 'first', 'note', 'interface', 'deal', 'population', 'quantities', 'concern', 'two', 'different', 'distributions.hence', 'theconditionsforasuccessfulinterfacearelikelytoinvolvespecialproperties', 'ofthedistributions', 'forexample', 'thediversityofthepretrainingdistributionandstructuralshifts', 'betweenthepretrainingandadaptationdata.thismakestheanalysisoftheinterfacechallenging', 'asdiscussedbelowin§4.10.4', 'theory-tools', 'asweneedtomakecarefulmodelingassumptions', 'abouthowthetwodistributionsrelatetooneanother.however', 'thispresentsthepossibilitythat', 'toolsandtechniquesdevelopedtoanalyzesuchinterfacescouldbeusefultounderstandtheeffect', 'ofdistributionshiftsandtopredictwhenfoundationmodelscanimproverobustness', 'second', 'thepopulationlossesandpossiblytheconditionsofasuccessfulinterfacedependon', 'themodelarchitecture.thisraisesthechallengeofopeninguptheblack-boxoftheneuralnets', 'whatdoesasmallpretraininglossonaparticulardistributiontellusaboutthepropertiesofthe', 'intermediatelayers', '?', 'suchanalyseswouldalsoguideusindesigningnewadaptationmethodsthat', 'morecarefullyexploitdifferentintermediaterepresentations', 'third', 'few-shot', 'learn', 'sample', 'efficiency', 'adaptation', 'capture', 'constraintonthecomplexitymeasure𝐶', '𝛾', '𝜃ˆ', '<', '𝑐', 'intheminimaladaptationloss.weneedto', 'fm', '0', 'formallycharacterizethesecomplexitymeasures', 'e.g.', 'byunderstandingtheimplicitregularization', 'effectoftheadaptationprocess', 'andfurtherunderstandwhyasmallpopulationpretrainingloss', 'wouldimplyalow-complexityadaptationparameters𝛾', '.asatisfactoryanswertothisquestion', 'task', 'wouldlikelyallowustoimprovethesample-efficiencyofdownstreamadaptation', 'finally', 'andimportantly', 'criticalcomponentsoftheinterfacearethechoiceofthepretraining', 'andadaptationlosses.wewanttounderstandhowtobestcombinethepretrainingandadaptation', 'objectivesforsuccessfuladaptation.itispossiblethatthepretrainingobjectivethatbestguarantees', 'successfuladaptationdiffersfromwhatisexplicitlyminimizedduringthepretrainingprocess—the', 'interfaceaboveallowsonetouseanysurrogatepopulationobjectiveonthepretrainingdistribution', 'inaddition', 'newsurrogateobjectivesthatprovablyleadtogoodadaptationacrossabroadsetof', 'taskscouldshedlightonthefundamentalaspectsthatmakefoundationmodelssuccessful', 'summarize', 'interface', 'preclude', 'issue', 'generalization', 'allow', 'us', 'formally', 'reasonabouttheinteractionbetweenseveralimportantquantitiesofthepretrainingandadaptation', 'phasesthatcanguidepracticeinimportantways', '4.10.3', 'challenge', 'analysisofin-contextlearningandotheremergentbehavior', 'gpt-3', '[', 'brownetal.2020', ']', 'demonstratesthepowerofin-contextlearning', 'anadaptationmethod', 'thatdoesnotneedanyparameteroptimization.intheadaptationphase', 'thepretrainedlanguage', 'foundationmodeltakesinaprompt—asequenceoftokensthatconcatenatesinput-outputexamples', 'fromthetask—followedbyatestexampleandsimplygeneratesthelabelofthetestexample']",120
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '121', 'byconditioningonthesequenceseenthusfar', 'promptplustestexample', '.inotherwords', 'isnoexplicittrainingorchangetothemodelparameters.whatisthemechanismbywhichthe', 'model', '“', 'learn', '”', 'fromthedifferentexamplesbysimplyexecutingwiththeexamplesasinputs', '?', 'previousmodularizationdoesnotdirectlyapplybecausewedonotobtainnewmodelparameters', 'duringadaptation', 'butratherweonlyusethegenerativecapabilitiesofthefoundationmodelby', 'executingonstructurally-designedinputs.morebroadly', 'theproposedmodularizationprovidesa', 'niceframeworktogainusefultheoreticalinsightsintofoundationmodelsasdiscussedabove.but', 'itispossiblethatsomeemergentbehaviorlikein-contextlearningandothercapabilitiesyettobe', 'discoveredwouldrequiregoingbeyondthemodularization', '4.10.4', 'challenge', 'appropriatedataassumptionsandmathematicaltools', 'understandingtheinterfacebetweenpretrainingandadaptationphasesrequiresamorecareful', 'studyofdatadistributionsthanintraditionalsupervisedlearning.thisisbecausethepretraining', 'andtaskadaptationdistributionsareinherentlydifferent.bydefinition', 'foundationmodelsare', 'trainedonrawdatathatistypicallyextremelydiverseandtask-agnostic', 'whiletheadaptation', 'datadependsheavilyonthetask.similarly', 'in-contextlearningemergesasaresultoflearningto', 'generatedatathatlookslikethepretrainingdistribution', 'andtherebyunderstandingin-context', 'learningrequirescarefulmodelingofthepretrainingdata.henceansweringthecentralquestions', 'aroundfoundationmodelsrequiresrealisticandinterpretableassumptionsthatarealsoamenableto', 'analysis.recentworkseitherassumecertainpropertiesofthepopulationdata', 'e.g.', 'theexpansion', 'propertyinhaochenetal.', '[', '2021a', ']', 'weietal', '[', '2020b', ']', 'orthatthepopulationdataisgenerated', 'fromlatentvariablemodelswithsomestructure', '[', 'saunshietal.2020a', 'weietal.2021', 'aroraetal', 'leeetal.2020a', 'zhangandhashimoto2020', 'toshetal.2021', ']', 'wegenerallylackmathematicaltoolsforrelatingpropertiesoffoundationmodelstothestructure', 'inthepopulationdatadistribution.haochenetal', '[', '2021a', ']', 'appliesspectralgraphtheorytoleverage', 'theinner-classconnectivityinthepopulationdistribution.moreprecisecharacterizationof𝜃ˆ', 'via', 'fm', 'probabilisticandanalyticalderivationsispossibleforlatentvariablemodels', 'butsofarrestrictedto', 'relativelysimpleones.thecommunitywillsignificantlybenefitfrommoresystematicandgeneral', 'mathematicaltoolstoaddressthisquestion', 'itisalsohighlydesirabletodefinesimpletoycasessothattheoreticianscanpreciselycompare', 'thestrengthsofvarioustoolsandanalyses.forexample', 'haochenetal.', '[', '2021a', ']', 'andweietal', '[', '2020b', ']', 'considerthemixtureofmanifoldsproblemwhichmightpotentiallybeagoodsimplified', 'testbedforvisionapplications.weneedmoreinterestingtestbedsfordiscretedomainssuchas', 'nlp.webelievethattractabletheoreticalmodelswhichcapturerelevantpropertiesofrealdatasets', 'areacrucialsteptowardsplacingfoundationmodelsonsolidtheoreticalfooting']",121
Opportunities and Risks of Foundational Models - Stanford.pdf,"['122', 'centerforresearchonfoundationmodels', 'crfm', '4.11', 'interpretability', 'author', 'john', 'hewitt', 'armin', 'w.', 'thomas', 'pratyusha', 'kalluri', 'rodrigo', 'castellon', 'christopher', 'd.', 'man', 'comparedtomostothermachinelearningmodels', 'foundationmodelsarecharacterizedbyavast', 'increaseintrainingdataandcomplexityandtheemergenceofunforeseencapabilities', 'foundation', 'modelsareabletodounforeseentasksanddothesetasksinunforeseenways.theincreasing', 'adoption', 'foundation', 'model', 'thereby', 'create', 'grow', 'desire', 'demand', 'unprecedented', 'challengesforunderstandingtheirbehavior', 'incontrasttotask-specificmodels', 'foundationmodelsaretrainedacrossvastandhighlydisparate', 'datasets', 'potentiallyspanningmanydomainsandmodalities', 'see§4.2', 'train', '.throughthis', 'train', 'foundation', 'model', 'learn', 'exceptionally', 'wide', 'range', 'behaviors', 'vary', 'profoundlybetweentasksanddomains', 'asdemonstratedbytheirabilitytobeadaptedtomany', 'differenttypesofdownstreamtasksandtoexhibitbehaviorsthatarespecificforeachofthesetasks', 'see§4.3', 'adaptation', '.takegpt-3asanexample', 'whichwastrainedasonehugemodeltosimply', 'predictthenextwordinatext.whilethisisaveryspecificandsimple-to-definelearningtask', 'hasenabledgpt-3togaincapabilitiesthatfarexceedthosethatonewouldassociatewithnext', 'wordprediction', 'bycombiningitwithavasttrainingdatasetthatcomprisesallkindsofinternet', 'text.asaresult', 'gpt-3cannowadaptbehaviorsthatareclearlyoutsideofthescopeofitsoriginal', 'train', 'task', 'simple', 'arithmetic', 'computer', 'program', 'provide', 'trainingsamples.thisdemonstratesthatitischallengingtoanswereventheseeminglysimplest', 'questionaboutafoundationmodel', 'whatcapabilitiesdoesithave', '?', 'moreover', 'itisanopenquestiontowhatextentthesediversecapabilitiesrelyondistinctor', 'sharedmodelmechanisms', 'akintoalgorithmicbuildingblockswithinthemodel.ontheonehand', 'foundationmodelscanbeinterpretedassinglemodels', 'whichutilizesomesetofgeneralizable', 'modelmechanismstoperformwellacrosstasksanddomains.inthiscase', 'afullunderstandingof', 'theirbehaviorcanbegainedbyidentifyingandcharacterisingthesemechanisms.ontheother', 'hand', 'theabilityoffoundationmodelstoadaptprofoundlydistinctbehaviorsfordifferenttasks', 'suggeststhattheycanalsobeunderstoodasalargecollectionofindependentexpertmodels', 'tailoredtoaspecifictask.forexample', 'itseemsunlikelythatthemodelparametersthatgpt-3', 'usestodoarithmeticcouldhavemuchtodowiththeparametersusedtotranslatefromenglish', 'tofrench.inthiscase', 'explanationsofmodelbehaviorinonetaskarethereforenotnecessarily', 'informativeaboutbehaviorinothertasks.werefertothisastheonemodel-manymodelnature', 'offoundationmodels', 'seefigure23', 'andarguethatunderstandingwherefoundationmodelsare', 'locatedonthisspectrumbetweenoneandmanymodelswillbecentraltounderstandingtheir', 'behavior', 'towardsystematizingthisareaofstudy', 'wepresentanddiscussthreelevelsofunderstanding', 'foundationmodels', '[', 'inspiredbymarr1982', ']', 'insimpleterms', 'wefirstdiscussthechallengesand', 'opportunities', 'understand', 'model', 'capable', 'output', 'certain', 'behaviors', 'andlastlyhowitdoesit.specifically', 'questionsof', '‘', '’', 'aimtocharacterizethekindsof', 'behaviorsthatamodelcanperformwithout', '“', 'peekinginside', ""''"", 'themodel', 'whilequestionsof', '‘', '’', 'aimtoprovideexplanationsofthemodel', '’', 'sbehaviorsintermsofpotentialcausesinthedata', 'questionsof', '‘', '’', 'aimtounderstandtheinternalmodelrepresentationsandmechanismsthat', 'producethesebehaviors.afterpresentingallthreelevels', 'weconcludebydiscussingpotential', 'consequencesresultingfromthenon-interpretabilityandinterpretabilityoffoundationmodels']",122
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '123', 'fig.23', 'onemodel-manymodelnatureoffoundationmodels', 'acentralquestionfortheinterpretabilityofa', 'foundationmodelistounderstandwhereitislocatedonthespectrumbetweenonemodelandmanymodels', 'asonemodel', 'behaviorcanbemadeinterpretablebyidentifyingandcharacterisingthefinitenumberof', 'generalizablemodelmechanismsthatthemodelusestoproducebehaviorsacrosstasks', 'e.g.', 'mechanisms', 'thatassignmeaningtowords', 'comparequantities', 'andperformarithmetic', '.asmanymodels', 'explanationsof', 'modelbehaviorinonetaskarenotnecessarilyinformativeaboutbehaviorinothertasks', 'thusrequiringto', 'studybehaviorindependentlyineachtask', '4.11.1', 'characterizingbehavior', 'thesimplestunderstandingofatechnologyiswidelytakentobeknowingwhatdoesthetechnology', '?', 'thisseeminglystraightforwardquestionissignificantlychallengingforfoundationmodels', 'duetothemyriadofunforeseenbehaviorsandtasksthatthesemodelsarecapableofperforming', 'task-specificneuralnetworkmodelsaretrainedtoperformasingletaskinasingledomain', 'e.g.', 'imageclassification.theirtaskandtheinputandoutputdomainsarethereforeclear', 'yeteven', 'forthesemodelsitcanbechallengingtoknowexactlywhatthemodelwilldo', 'givenaparticular', 'input', 'forinstance', 'modelbehaviorscanunexpectedlydiffergreatlyfortwoperceptuallysimilar', 'input', '[', 'garg', 'ramakrishnan', '2020', 'jin', 'et', 'al', '2020', ']', 'two', 'subpopulations', 'data', 'stratify', 'forexample', 'byraceorgender', '[', 'hovyandsøgaard2015', 'blodgettetal.2016', 'tatman', 'buolamwiniandgebru2018', ']', 'thischallengeofcharacterizingamodel', '’', 'sbehaviorisamplifiedmanyfoldforfoundationmodels', 'thespaceoftasksthatthemodelisabletoperformisgenerallylargeandunknown', 'theinputand', 'outputdomainsareoftenhigh-dimensionalandvast', 'e.g.', 'languageorvision', 'andthemodelsare', 'lessrestrictedtodomain-specificbehaviorsorfailuremodes.consider', 'forexample', 'thesurprising', 'abilityofgpt-3tobetrainedonlargelanguagecorporaandtosubsequentlydeveloptheability', 'togeneratemostly-functionalsnippetsofcomputerprograms.akeychallengeforcharacterizing', 'thebehavioroffoundationmodelsisthereforetoidentifythecapabilitiesthatithas.evenfurther', 'foreachtaskthatafoundationmodelcanperform', 'andtheremaybemanyorinfinitelymany']",123
Opportunities and Risks of Foundational Models - Stanford.pdf,"['124', 'centerforresearchonfoundationmodels', 'crfm', 'thechallengesremainthatonefaceswhentryingtounderstandthebehaviorofmuchsimpler', 'task-specificmodels', 'characterizingeach', '‘', 'task', '’', 'thatafoundationmodelcanperformisfurthercomplicatedbytheir', 'onemodel-manymodelsnature', 'seefigure23', '.againtakinggpt-3asanexample', 'itwasshown', 'thatitcanbetailoredtomanytasksthroughsimpleprompting', 'see§4.3', 'adaptation', '.yet', 'taskcanbespecifiedthroughmanypossiblepromptsandslightvariationsinpromptscanresultin', 'meaningfulchangesofmodelbehavior.forinstance', 'thetaskofsentimentclassificationofamovie', 'reviewcanbespecifiedbypresentingthemoviereviewfollowedby', '‘', 'hersentimenttowardsthe', 'filmwas', '...', '’', '‘', 'myoverallfeelingwasthatthemoviewas', '...', '’', 'despitethesepromptsappearingto', 'posecloselyrelatedtasks', 'gpt-3willexhibitdifferentresponseaccuraciesforeachprompt', '[', 'zhao', 'etal.2021', ']', '.observationsliketheseraiseimportantquestionsregardingtherelationshipbetween', 'thecharacteristicsofpromptsandtheresultingmodelbehaviors.specifically', 'canmeaningfully', 'different', 'responses', 'seemingly', 'similar', 'prompt', 'actually', 'consider', 'result', 'samemodelordotheyresultfromhighlydistinctmodelmechanisms', 'anddoescharacterizingthe', 'behaviorsofthefoundationmodel', 'oritsadaptedderivatives', 'inonetasktrulyaidincharacterizing', 'thebehaviorsofotherpossibleadaptationsofthemodel', '?', 'toidentifythecapabilitiesthatafoundationmodelhasandthoseitismissing', 'researcherscan', 'utilizecontrolledevaluations.here', 'domainexpertsdesignpromptsthatareknowntorequire', 'particular', 'competence', 'study', 'ability', 'model', 'respond', 'correctly', 'prompt', '[', 'papadimitriouandjurafsky2020', 'luetal.2021a', 'kataokaetal.2020', 'wuetal.2021c', 'xieetal.2021a', 'kohetal.2021', ']', '.forexample', 'psycholinguistshavedesignedpromptsthatrequire', 'alanguagemodeltochoosebetweenagrammaticallycorrectsentenceandthesamesentence', 'specific', 'grammatical', 'inaccuracy', 'know', 'whether', 'model', 'consistently', 'prefer', 'grammaticallycorrectsentenceoveritsgrammaticallyincorrectcounterparttellsuswhetherthe', 'modelhastheparticulargrammaticalcompetencerequiredtoidentifythisinaccuracy', '[', 'linzenetal', ']', 'giventhehugerangeofpossiblecapabilitiesoffoundationmodels', 'andourcurrentlackofany', 'generalmethodfordeterminingaprioriwhetherafoundationmodelwillhaveagivencapability', 'bespeak', 'evaluations', 'like', 'crucial', 'allow', 'explore', 'range', 'behaviors', 'foundationmodelsarecapableof', 'whilerequiringrelativelyminimalmodelaccess', 'weonlyneedto', 'presentinputsandreceivemodeloutputs', 'andweneednotdependonaccesstotheimplementation', 'orparameters', 'ofamodel', 'giventheinfinitely', 'manydesirableandundesirable', 'task', 'subtasks', 'andbehaviorsthatfoundationmodelsmaybecapableof', 'orincapableof', 'characterizingmodel', 'behaviorsandcapabilitieswillbeincreasinglychallengingandimportant.webelievethatinsteadof', 'relyingonfewexpertstoformulateandtestforpossiblebehaviors', 'itwillbecriticaltoextendthese', 'typesofanalysestotestformanymorebehaviors', 'inpartbyopeningupthislineofexplorationto', 'diversecommunitiesandexpertsinmanydisciplines', 'aswellasbyincreasingaccesstoandscale', 'oftheseevaluations', '4.11.2', 'explainingbehavior', 'inadditiontocharacterizingwhatafoundationmodelisdoing', 'onecantrytocharacterizewhy', 'itperformscertainbehaviorsbyprovidingexplanationsofthesebehaviorsintermsofpotential', 'causesinthedata.whilecurrentexplanationapproaches', 'whichprovidesuchexplanationsof', 'behavior', 'canrevealqualitiesofinputsthataffectamodel', '’', 'sresponses', 'theyoftenrequirefullaccess', 'model', 'generally', 'limit', 'ability', 'elucidate', 'general', 'model', 'mechanisms', 'whichfoundationmodelsusetorespondtomanyinputs', 'task', 'anddomains']",124
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '125', 'current', 'explanatory', 'approach', 'generally', 'understand', 'distinct', 'model', 'designedtoprovideanexplanationofparticularbehaviorsofanotherblackbox', 'model.impor-', 'tantly', 'theseapproachesareseparatefromthemodelwhosebehaviorisanalyzed', 'whichbyitself', 'isnotinterpretable.thisseparationcanbeproblematic', 'astheprovidedexplanationscanlack', 'faithfulness', '[', 'jacoviandgoldberg2020', ']', 'bybeingunreliableandmisleadingaboutthecausesofa', 'behavior', '[', 'c.f.', 'rudin2019', ']', '.evenfurther', 'unsoundexplanationscanenticehumansintotrusting', 'unsoundmodelsmorethantheyotherwisewould', 'foradetaileddiscussionoftrustinartificialin-', 'telligence', 'seejacovietal', '[', '2021', ']', '.thesetypesofconcernsgrowaswetransitionfromtask-specific', 'modelstowardsthewideadoptionoffoundationmodels', 'astheirbehaviorisvastlymorecomplex', 'current', 'explanatory', 'approach', 'largely', 'divide', 'either', 'provide', 'local', 'global', 'explanationsofmodelbehavior', '[', 'doshi-velezandkim2017', ']', '.localexplanationsseektoexplain', 'amodel', '’', 'sresponsetoaspecificinput', 'e.g.', 'byattributingarelevancetoeachinputfeaturefor', 'thebehaviororbyidentifyingthetrainingsamplesmostrelevantforthebehavior', '[', 'simonyan', 'etal.2013', 'bachetal.2015', 'sundararajanetal.2017', 'shrikumaretal.2017', 'springenbergetal', '2014', 'zeilerandfergus2014', 'lundbergandlee2017', 'zintgrafetal.2017', 'fongandvedaldi2017', 'kohandliang2017', ']', '.globalexplanations', 'incontrast', 'arenottiedtoaspecificinputandinstead', 'aimtouncoverqualitiesofthedataatlargethataffectmodelbehaviors', 'e.g.', 'bysynthesizingthe', 'inputthatthemodelassociatesmoststronglywithabehavior', '[', 'simonyanetal.2013', 'nguyenetal', ']', 'localandglobalexplanationshaveprovidedusefulinsightsintothebehavioroftask-specific', 'model', '[', 'e.g.', 'lietal.2015', 'wangetal.2015b', 'lapuschkinetal.2019', 'thomasetal.2019', 'poplinetal', ']', '.here', 'theresultingexplanationsareoftentakentobeaheuristicofthemodelmechanisms', 'thatgaverisetoabehavior', 'forexample', 'seeingthatanexplanationattributeshighimportanceto', 'horizontallineswhenthemodelreadsahandwrittendigit', '‘', '7', '’', 'easilycreatestheimpressionthat', 'horizontal', 'line', 'generally', 'important', 'feature', 'model', 'use', 'identify', 'sevens', 'perhapstodistinguishalldigits', 'giventheonemodel-manymodelsnatureoffoundationmodels', 'seefigure23', 'however', 'shouldbecarefulnottojumpfromspecificexplanationsofabehaviortogeneralassumptions', 'model', '’', 'behavior', 'current', 'explanatory', 'approach', 'may', 'shed', 'light', 'specific', 'behaviors', 'forexample', 'byidentifyingaspectsofthedatathatstronglyeffectedthesebehaviors', 'theresultingexplanationsdonotnecessarilyprovideinsightsintothemodel', '’', 'sbehaviorsforother', 'evenseeminglysimilar', 'input', 'letaloneothertasksanddomains', 'another', 'approach', 'could', 'sidestep', 'type', 'post-hoc', 'explanations', 'all-together', 'leveragingthegenerativeabilitiesoffoundationmodelsintheformofself-explanations', '[', 'c.f.', 'elton', '2020', 'chen', 'etal', ']', 'thatis', 'trainingthese', 'model', 'togenerate', 'notonlythe', 'responseto', 'input', 'jointly', 'generate', 'human-understandable', 'explanation', 'response', 'itiscurrentlyunclearwhetherthisapproachwillbefruitfulinthefuture', 'therearereasonsto', 'beskeptical', 'languagemodels', 'andnowfoundationmodels', 'areexceptionalatproducingfluent', 'seeminglyplausiblecontentwithoutanygroundingintruth.simpleself-generated', '“', 'explanations', '”', 'couldfollowsuit.itisthusimportanttobediscerningofthedifferencebetweentheabilityofa', 'modeltocreateplausible-soundingexplanationsandprovidingtrueinsightsintoitsbehavior', '4.11.3', 'characterizingmodelmechanisms', 'deepunderstandingofsystemsisgenerallytakentomeanunderstandinghowasystemperforms', 'whichknowledgeandmechanismsdoesitcontain', 'andhowaretheseassembledtoformthewhole', '?', 'ifthisisindeedpossible', 'characterizingtherepresentationswithinfoundationmodelsandthe', 'mechanismsthatoperateonthemwillbecentraltosatisfyingthedesiretothoroughlyunderstand', 'proliferate', 'model', 'whether', 'mechanisms', 'many', 'specific']",125
Opportunities and Risks of Foundational Models - Stanford.pdf,"['126', 'centerforresearchonfoundationmodels', 'crfm', 'generalizable', 'seefigure23', 'theyareatthecoreoftheabilityoffoundationmodelstoadopta', 'widerangeofbehaviorsinvariedtasksanddomains', 'make', 'notions', 'model', 'representations', 'mechanisms', 'concrete', 'consider', 'simple', 'behaviorexhibitedbygpt-3', 'itwasquicklyobservedwhatgpt-3didwhenprovidedwithexamples', 'oftheadditionofsmallnumbersandthenqueriedtoperformadditionoftwonewnumbers', 'highprobability', 'itpredictedthecorrectresultoftheaddition', '[', 'branwen2020', 'brockman2020', ']', 'whenaskingwhygpt-3performedasitdid', 'onecouldfindevidenceintheinput', 'likeaspectsof', 'itspromptthathighlyaffecteditsresponse', 'thesemightbethetwonumberstobeadded', 'though', 'necessarily', 'aspects', 'gpt-3', '’', 'train', 'data', 'affect', 'response', 'might', 'examplesofaddition', 'thoughnotnecessarily', '.delvingintothemodel', 'wemayenvisionadeeper', 'understand', 'mechanisms', 'gpt-3', 'use', 'add', 'specific', 'pair', 'number', 'mechanismthatitusestoaddotherarbitrarypairsofnumbers.wemayalsoenvisionadeeper', 'understandingofwhetherthesemechanismsaresimilartothemathematicalnotionof', '’', 'addition', '’', 'ormerelycorrelatedwiththisnotion', 'byunderstandingindividualmodelmechanisms', 'wecanbuildupacompositionalunderstanding', 'ofcomplexbehaviorsofafoundationmodel.ataskslightlymorecomplexthantheadditionof', 'number', 'solve', 'mathematical', 'word', 'problems', 'number', 'come', 'units', 'problemispresentedinnaturallanguage.onceweunderstandthemechanism', 'ormechanisms', 'bywhichamodelperformsaddition', 'wecaninvestigatewhetherthismechanismisusedasan', 'intermediatestepinsolvingthewordproblems.iftheadditionmechanismisused', 'wehavebuilt', 'upourunderstandingofhowthemodelsolveswordproblems', 'wehaveincreasedconfidencethat', 'thefoundationmodelgeneralizesthenotionsofquantitiesandaddition', 'notanothercorrelationor', 'heuristic', 'furthermore', 'wehaveincreasedconfidenceinourabilitytopredictthemodel', '’', 'swhy', 'whichpartsoftheinputsitisattendingto', 'andtheoutput', '’', 'swhat', 'additionoftwonumbers', '.ifthe', 'additionmechanismisnotused', 'wemayretainahealthyskepticismthatthisistrulyaddition', 'wecaninvestigatewhichrepresentationsandmechanismsareusedinstead', 'itisimportanttobeawarethattherearemanypotentialcasesofmorecomplexandconcerning', 'model', 'mechanisms', 'instance', 'estimation', 'race', 'character', 'name', 'pixelsinanimage.establishingevidenceofsuchamechanisminafoundationmodelanditsuse', 'cansupportamoralorlegalresponsibilitytobanthemodelfromtaskslikepredictivepolicing', 'market', 'loanapplications', 'andsurveillanceatlarge', 'aplethoraofmethodshaveemergedtoinvestigatetheseinternalaspectsofneuralnetwork', 'models.typically', 'theseapproachesseparatethemodelintonodes', 'e.g.', 'neurons', 'layer', 'orparts', 'oflayers', 'theninterrogateeithertherepresentationscapturedinnodesorthemechanismsby', 'whichnodesareassembled.someapproachesarehypothesisdriven', 'byhypothesizingthatnodes', 'maycapturecertaininformation', 'e.g.', 'agrammaticalfeatureofaword', 'ortheraceofaperson', 'onecanprobeallnodestoquantifyhowmuchofthatinformationtheymakeavailable', '[', 'alain', 'andbengio2016', 'veldhoenetal.2016', 'belinkovetal.2017', 'adietal.2017', 'conneauetal.2018', 'hewitt', 'liang', '2019', 'hewitt', 'man', '2019', 'voita', 'titov', '2020', 'pimentel', 'et', 'al', '2020', ']', 'approach', 'build', 'explanatory', 'methods', 'instead', 'identify', 'data', 'cause', 'certainbehavior', 'seekto', 'identify', 'datacause', 'certainnode', 'activate', 'orwhich', 'nodescauseanothernodelaterinthemodeltoactivate', 'therebyuncoveringcollectionsofmodel', 'representationsandmechanisms', '[', 'olahetal.2020', 'muandandreas2020', 'carteretal.2019', 'goh', 'etal.2021', ']', '.takentogether', 'theseapproachesinspecttheinteriorofmodelsandprovideabasis', 'fortheongoingexplorationsofthebehavioroffoundationmodels.yet', 'thenumberofpotential', 'representationsandmechanismswithinfoundationmodelsisvast', 'particularlygiventheirone', 'model-manymodelsnature', 'seefigure23', 'andthesetypesofapproachesoftenonlycaptureasmall', 'sliceofamodel', '’', 'sinteriority.itisthusanopenchallengetoexpandthediscoveryofrepresentations']",126
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '127', 'andmechanismsandtoelucidatethosethataremostrelevantorgeneralformodelbehavior.as', 'withmanyapproachestointerpretingfoundationmodels', 'thesetypesofexplorationswillbenefit', 'fromincludingandsupportingmorediverseandinterdisciplinaryinvestigatorsandfrommore', 'accessible', 'flexible', 'andscalablemethodsofdiscovery', 'summary', 'believe', 'one', 'model-many', 'model', 'nature', 'foundation', 'model', 'see', 'figure23', 'providesnovelopportunitiesandchallengesforcurrentinterpretabilityresearch', 'many', 'adaptations', 'single', 'foundation', 'model', 'simply', 'know', 'extent', 'whichtheysharecommonmechanisms.totheextentthatmechanismsareshared', 'understand', 'foundation', 'model', 'may', 'tractable', 'problem', 'characterize', 'mechanisms', 'relations.totheextentthatmechanismsareindependent', 'eachadaptationofafoundationmodel', 'mustbeanalyzedindependently', 'leadingtoprofounduncertaintyaboutthenatureofanynew', 'adaptationofthefoundationmodel', '4.11.4', 'impactsofnon-interpretabilityandinterpretability', 'lastly', 'wewouldliketohighlightthatthewideadoptionoffoundationmodelsisatoddswitha', 'recentpleaofmanyinterdisciplinaryresearchersnottousecomplexblackboxmodelsforhigh', 'stakesdecisions', '[', 'e.g.', 'rudin2019', ']', 'butinsteadtofocusonthelong-standingdevelopmentand', 'applicationofmoreintrinsicallyinterpretablemodels', 'inthemidstofthesepleas', 'workaimedatinterpretingfoundationmodelsisadouble-edged', 'sword.largemachinelearningmodels', 'andnowfoundationmodels', 'areoftensolelydeployableby', 'powerfulcorporationsandinstitutions', 'andincrementaladvancesininterpretabilitycanbeexag-', 'geratedto', '‘', 'ethics-wash', '’', 'andcontinueuseofmodelsasthoughtheyhaveachieved', 'interpretability', 'belyingtherealitythattheyremainfarbelowtraditionalstandardsofalgorithmicinterpretabil-', 'ity.moreover', 'whenapproachestointerpretabilityregularlypresumeeasyaccesstomodelsand', 'theirimplementationandparameters', 'interpretabilitycanservenotonlyascoverforpowerful', 'institutionsbutalsocentralizemodelknowledgeinthesamehands.forthoseworkingtoward', 'theinterpretabilityoffoundationmodels', 'itisaresponsibilitytoconsistentlyaskwhetherone', 'work', 'toward', 'make', 'foundation', 'model', 'interpretable', 'researchers', 'model', 'owners', 'interpretabletoeveryone', 'simultaneously', 'extent', 'foundation', 'model', 'already', 'deploy', 'work', 'interpretabilitypresentsuniqueopportunitiestoshiftknowledgeoffoundationmodels', 'andthus', 'power', 'backtodatafiedandevaluatedpeoples.interpretationcanfacilitatethediscoveryofsocietally', 'salientaspectsofmodels.moreradically', 'workcreatingaccessiblemethodsthatallowanyoneto', 'interpretthebehavioroffoundationmodelsshiftspowertodiversepeoples', 'creatingopportunities', 'toinvestigatemodels', 'opportunitiestodiscoveraspectsofmodelsimportanttoindividualsortheir', 'communities', 'andopportunitiestomeaningfullyconsentto', 'improve', 'orall-togethercontesttheuse', 'offoundationmodels.itisalsoimportantforresearcherstoviewtheinterpretabilityoffoundation', 'modelsasnotonlyagoal', 'butaquestion', 'workcanservetoexploreandassesswhetherthelackof', 'foundationmodelinterpretabilityisintrinsicandshouldbedeeplystudiedandwidelyknownasa', 'seriousissuediscouraginguse', 'orincreasingregulation', 'ofthesesystems', 'orwhetheritispossible', 'forfuturefoundationmodelstoupholdahighstandardofinterpretabilityforall']",127
Opportunities and Risks of Foundational Models - Stanford.pdf,"['128', 'centerforresearchonfoundationmodels', 'crfm', '5', 'society', 'thesocietalimpactoffoundationmodels', 'referringbothtotheconstructionofthemodelsthem-', 'selves', 'role', 'develop', 'applications', 'require', 'careful', 'examination', 'specifically', 'anticipatethatfoundationmodelswillhavewide-rangingsocietalconsequencesthatarechalleng-', 'ingtounderstand', 'foundationmodelsareintermediaryassetsthatarenotdirectlydeployed', 'ratherserveasafoundationthatisfurtheradapted.asaresult', 'traditionalapproachestoreasoning', 'aboutthesocietalimpactoftechnologyarelikelycomplicated', 'societalimpactiseasier', 'butstill', 'difficult', 'tograspforsystemswithwell-specifiedpurposes.inthischapter', 'wediscusshowwe', 'maygrapplewithandbeginningtounderstandthecomplexityofthesocietalimpactofmodels', 'foundationmodels.specifically', 'wediscuss', 'theharmswithrespecttoinequity', '§5.1', 'fairness', 'misuse', '§5.2', 'misuse', 'ii', 'impact', 'respect', 'economy', '§5.5', 'economics', 'environment', '§5.3', 'environment', 'iii', 'thebroaderconsiderationswithrespecttothelaw', '§5.4', 'legality', 'andethics', '§5.6', 'ethics']",128
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '129', '5.1', 'inequityandfairness', 'author', 'rishibommasani', 'fereshtekhani', 'esindurmus', 'faisalladhak', 'danjurafsky', 'fig.24', 'theintrinsicbiaspresentwithinfoundationmodelsisthebyproductofvarioustrainingbiassources', 'leave', 'alongsidebiasesintroducedduringadaptation', 'determinestheextrinsicharms', 'right', 'experience', 'byusersinthecontextofspecificdownstreamapplications.weemphasizethatthesamefoundationmodel', 'isthesharedfoundationformanydifferentapplications', 'itsbiasespervadetothesemanyapplicationsasa', 'result.further', 'sincetheharmsexperiencedbyusersaretheresultofspecificadaptedmodels', 'attribute', 'theseharmstothevariousprocessesandsourcesdepictedinthisdiagramisbothcrucialandchallenging', '5.1.1', 'introduction', 'foundationmodelshavethepotentialtoyieldinequitableoutcomes', 'thetreatmentofpeoplethatis', 'unjust', 'especiallyduetounequaldistributionalonglinesthatcompoundhistoricaldiscrimination', '[', 'hellman', '2021', ']', 'like', 'ai', 'system', 'foundation', 'model', 'compound', 'exist', 'inequities', 'producingunfairoutcomes', 'entrenchingsystemsofpower', 'anddisproportionatelydistributing', 'negativeconsequencesoftechnologytothosealreadymarginalized', '[', 'sweeney2013', 'kayetal.2015', 'buolamwiniandgebru2018', 'benjamin2019', 'ajunwa2019', '’', 'ignazioandklein2020', 'crawford', '2021', ']', '.hereweaskwhatfairness-relatedharmsrelatetofoundationmodels', 'whatsourcesare', 'responsiblefortheseharms', 'andhowwecanintervenetoaddressthem.theissueswediscuss', 'herearerelatedtobroaderquestionsofalgorithmicfairnessandaiethics', '[', 'corbett-daviesand', 'goel2018', 'chouldechovaandroth2020', 'hellman2020', 'johnson2020', 'fazelpouranddanks2021', ']', 'raceandtechnology', '[', 'benjamin2019', 'hannaetal.2020', 'gebru2021', 'fieldetal.2021', ']', 'andthe', 'coexistenceofsocietyandtechnology', '[', 'abebeetal.2020', ']', '5.1.2', 'harm', 'foundationmodelsareintermediaryassetswithnospecifiedpurposebeforetheyareadapted', 'understandingtheirharmsrequiresreasoningaboutboththeirpropertiesandtheroletheyplayin', 'buildingtask-specificmodels.wedelineateintrinsicbiases,91i.e.', 'propertiesofthefoundationmodel', 'thatindirectlybutpervasivelyaffectdownstreamapplications', 'andextrinsicharms', 'i.e.', 'harmsthat', 'ariseinthecontextofspecificdownstreamapplications', '[', 'galliersandspärckjones1993', ']', '91weusethewordbiastodenotethepropertiesofafoundationmodelthatcontributetoinequity', 'wefollowblodgett', 'etal', '[', '2020', ']', 'inattempting', 'whenpossible', 'todelineatewhoisharmedandhowtheyareharmed']",129
Opportunities and Risks of Foundational Models - Stanford.pdf,"['130', 'centerforresearchonfoundationmodels', 'crfm', 'intrinsicbiases', 'propertiesofthefoundationmodelcanleadtoharmindownstreamsystems', 'asaresult', 'theseintrinsicbiasescanbemeasureddirectlywithinthefoundationmodel', 'though', 'harm', 'realize', 'foundation', 'model', 'adapt', 'thereafter', 'apply', 'i.e.', 'thesearelatent', 'biasesorharms', '[', 'decampandlindvall2020', ']', '.wefocusonthemostwidely', 'studiedformofintrinsicbias', 'representationalbias', 'specificallyconsideringmisrepresentation', 'underrepresentationandoverrepresentation.peoplecanbemisrepresentedbyperniciousstereo-', 'type', '[', 'bolukbasietal.2016', 'caliskanetal.2017', 'abidetal.2021', 'nadeemetal.2021', 'gehmanetal', '2020', ']', 'ornegativeattitudes', '[', 'hutchinsonetal.2020', ']', 'whichcanpropagatethroughdownstream', 'modelstoreinforcethismisrepresentationinsociety', '[', 'noble2018', 'benjamin2019', ']', '.peoplecanbe', 'underrepresentedorentirelyerased', 'e.g.', 'whenlgbtq+identityterms', '[', 'strengersetal.2020', 'olivaetal.2021', 'tomasevetal.2021', ']', 'ordatadescribingafricanamericans', '[', 'buolamwiniandgebru', 'koeneckeetal.2020', 'blodgettando', '’', 'connor2017', ']', 'isexcludedintrainingdata', 'downstream', 'modelswillstrugglewithsimilardataattest-time.peoplecanbeoverrepresented', 'e.g.', 'bert', 'appearstoencodeananglocentricperspective', '[', 'zhouetal.2021a', ']', 'bydefault', 'whichcanamplify', 'majorityvoicesandcontributetohomogenizationofperspectives', '[', 'creelandhellman2021', ']', 'monoculture', '[', 'kleinbergandraghavan2021', ']', '§5.6', 'ethics', '.theserepresentationalbiasespertainto', 'allaisystems', 'buttheirsignificanceisgreatlyheightenedinthefoundationmodelparadigm.since', 'thesamefoundationmodelservesasthebasisformyriadapplications', 'biasesintherepresentation', 'ofpeoplepervadetomanyapplicationsandsettings.further', 'sincethefoundationmodeldoes', 'muchoftheheavy-lifting', 'comparedtoadaptation', 'whichisgenerallyintendedtobelightweight', 'weanticipatethatmanyoftheexperiencedharmswillbesignificantlydeterminedbytheinternal', 'propertiesofthefoundationmodel', 'extrinsicharms', 'userscanexperiencespecificharmsfromthedownstreamapplicationsthatare', 'createdbyadaptingafoundationmodel.theseharmscanberepresentational', '[', 'barocasetal.2017', 'crawford2017', 'blodgettetal.2020', ']', 'suchasthesexualizeddepictionsofblackwomenproducedby', 'informationretrievalsystems', '[', 'noble2018', ']', 'themisgenderingofpersonsbymachinetranslation', 'systemsthatdefaulttomalepronouns', '[', 'schiebinger2013,2014', ']', 'orthegenerationofpernicious', 'stereotype', '[', 'nozzaetal.2021', 'shengetal.2019', 'abidetal.2021', ']', '.theycanconsistof', 'abuse', 'aswhendialogueagentsbasedonfoundationmodelsattackuserswithtoxiccontent', '[', 'dinanetal', '2021', 'gehmanetal.2020', ']', 'ormicroaggressions', '[', 'breitfelleretal.2019', 'jurgensetal.2019', ']', '.allof', 'theseuser-facingbehaviorscanleadtopsychologicalharmsorthereinforcementofpernicious', 'stereotype', '[', 'spenceretal.2016', 'williams2020', ']', 'inadditiontoharmsexperiencedbyindividuals', 'groupsorsub-populationsmayalsobesubject', 'toharmssuchasgroup-levelperformancedisparities.forexample', 'systemsmayperformpoorly', 'ontextorspeechinafricanamericanenglish', '[', 'blodgettando', '’', 'connor2017', 'koeneckeetal.2020', ']', 'incorrectlydetectmedicalconditionsfromclinicalnotesforracial', 'gender', 'andinsurance-status', 'minoritygroups', '[', 'zhangetal.2020b', ']', 'orfailtodetectthefacesofpeoplewithdarkerskintones', '[', 'wilsonetal.2019', 'buolamwiniandgebru2018', ']', '.asfoundationmodelsaremorepervasively', 'apply', 'includinginhigh-stakesdomains', 'thesedisparitiescanspiralintofurther', 'andmoresevere', 'harms.koeneckeetal', '[', '2020', ']', 'discusshowifafricanamericanenglishspeakerscannotreliably', 'usespeechrecognitiontechnologies', 'e.g.', 'duetoinequitiesinunderlyingfoundationmodels', 'maymeantheycannotbenefitfromcertainderivativeproducts', 'e.g.', 'voiceassistants', 'assistive', 'technologies', 'andwillbedisadvantagedifthesetechnologiesareusedtoconductinterviewsfor', 'employmentortranscribecourtroomproceedings.moregenerally', 'characterizingthesegroup-level', 'harm', 'andworkingtowardsjusticeforthoseharmed', 'alsorequirestheaicommunitytoimprove', 'itsunderstandingofgroup-basedprejudice', '[', 'allport1954', ']', 'andsocialgroups', 'wepointtorelevant', 'workinthesocialsciencesandothercommunitiesonmovingbeyondbinarytreatmentsofgender']",130
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '131', '[', 'lindsey', 'westbrook', 'saperstein', 'richards', 'et', 'al', 'darwin', 'key', 'hydeetal.2019', 'caoanddauméiii2020', 'dinanetal.2020', ']', 'morenuancedtreatmentsofrace', '[', 'e.g.', 'pennerandsaperstein2008', 'freemanetal.2011', 'sapersteinandpenner2012', 'saperstein', 'etal.2013', 'pennerandsaperstein2015', 'fieldetal.2021', ']', 'betteraddressingintersectionalidentities', '[', 'e.g.', 'crenshaw1989', 'nash2008', 'gines2011', 'pennerandsaperstein2013', 'ghavamiandpeplau', '2013', 'brightetal.2016', 'buolamwiniandgebru2018', 'mayetal.2019', '’', 'connoretal.2019', 'guo', 'andcaliskan2021', ']', 'andmoremoderntreatmentsofdisability', '[', 'e.g.', 'batterbury2012', 'spieletal', '2019', 'hutchinsonetal.2020', ']', 'additionalconsiderations', 'tomorecompletelyunderstandtheharmsoffoundationmodels', 'furtherdocumentationisrequiredofboththeintrinsicbiasesandextrinsicharms', 'futurework', 'articulate', 'relationship', 'intrinsic', 'bias', 'extrinsic', 'harm', '[', 'blodgett', 'et', 'al', '2020', '2021', 'goldfarb-tarrant', 'et', 'al', '2021', ']', 'documentation', 'require', 'center', 'stakeholders', 'beyondacademicsandindustrypractitioners', 'theinequitableimpactoffoundationmodelswill', 'beexperiencedlargelybyminoritypopulations', 'whichareunderrepresentedinbothacademia', 'andindustry.forfoundationmodelsspecifically', 'theircreationandstudylikelywillbeconducted', 'bythosewiththeaccessandresourcesrequired', 'furtheremphasizingtheimportanceofvenues', 'thatcentermarginalizedvoices', '[', '’', 'ignazioandklein2020', '§5.6', 'ethics', ']', '.inparticular', 'userstudies', 'specific', 'adapt', 'model', 'aggregate', 'across', 'applications', 'provide', 'compel', 'individualize', 'documentation', 'harm', 'derive', 'intrinsic', 'bias', 'foundation', 'model', 'allwhilecenteringindividualusers.inthisway', 'weimaginethemethodologiesinhuman-', 'computerinteraction', 'hci', 'withsomeadjustmenttoaccommodatetheabstractioninvolvedin', 'foundationmodels', 'willhelpcenterthevoicesofmarginalizedcommunities', 'furtherdiscussionin', '§2.5', 'interaction', '5.1.3', 'source', 'inordertofullycharacterizeandproperlyinterveneontheharmsoffoundationmodels', 'wemust', 'beabletotracetheirsourcetothepropertiesofthefoundationmodelandtheadaptationprocess', 'andfurtherdecomposetotherolesofindividualsourcesofbiases', '[', 'friedmanandnissenbaum', '1996', ']', '.sourcetracingisvitalforattributingethicalandlegalresponsibilityforexperiencedharm', 'thoughattributionwillrequirenoveltechnicalresearchthatforegroundsmatterssuchascausality', '[', 'pearl2000', ']', 'andinfluence', '[', 'kohandliang2017', ']', 'data', 'dataofseveraltypesshapesthebehaviorofapplications', 'andtheassociatedextrinsicharms', 'basedonfoundationmodels', 'thetrainingdatausedtotrainthefoundationmodel', 'theadaptation', 'datausedtoadaptthefoundationmodel', 'andtest-timeuserdata/interaction.forallofthesedata', 'source', 'thepropertiesofthedata', 'e.g.', 'toxicityandhatespeech', '[', 'hendersonetal.2017', ']', 'abusive', 'language', '[', 'waseemetal.2017', ']', 'microaggressions', '[', 'breitfelleretal.2019', ']', 'stereotype', '[', 'voigtetal', ']', 'willmanifestinthebiasesofthefoundationmodel', 'anditsadaptedderivatives', '.92', 'since', 'thetrainingdataisthekeydatasourcethatdeterminesthefoundationmodelandtheassociated', 'intrinsicbiases', 'wefocusonthetrainingdatahere.atpresent', 'therelationshipbetweenthetraining', 'data', 'alongwithassociateddatapractices', 'e.g.', 'datacuration', 'dataselection', 'anddataweighting', '[', 'paulladaetal.2020', 'benderetal.2021', 'rogers2021', ']', 'andtheintrinsicbiasesacquiredbythe', 'foundationmodelremainsunclear', 'futureworkiscriticallyneededtoclarifythisrelationship.since', 'foundationmodelsgenerallyrequiretrainingdataofimmensescale', 'whichposesclearchallenges', 'notonlytoitsdocumentation', '[', 'benderetal.2021', ']', 'butalsocomprehensivescientificexplorationto', '92inadaptation', 'whichinvolveslabelledtask-specificdata', 'biasesinthechoicesofthelabelspace', '[', 'crawford2021', ']', 'andbiasesintheannotatorswholabelthatdata', '[', 'gevaetal.2019', 'sapetal.2019', ']', 'canalsocontributetoextrinsicharms', 'experiencedbyusers']",131
Opportunities and Risks of Foundational Models - Stanford.pdf,"['132', 'centerforresearchonfoundationmodels', 'crfm', 'articulatetherelationshipofdatabiasesandmodelbiases', 'weanticipatenewprotocolsarerequired', 'toaddressthisscale.establishingscalinglawsforbias', 'akintothoseforaccuracymetrics', '[', 'kaplan', 'etal.2020', 'henighanetal.2020', ']', 'mayenablesystematicstudyatsmallerscalestoinformdata', 'practicesatlargerscales', 'model', 'modelingdecisions', 'e.g.', 'trainingobjective', '§4.2', 'train', 'modelarchitecture', '§4.1', 'mod-', 'eling', 'adaptationmethod', '§4.3', 'adaptation', 'influencethebiasesinfoundationmodelsandtheir', 'derivatives', 'therebyaffectingtheexperiencedextrinsicharms.existingworkdemonstratesthe', 'foundationmodelsamplifytrainingdatabiases', 'extendingtrendsseenformachinelearningand', 'deeplearningmodels', '[', 'zhaoetal.2017', 'wangetal.2019d', 'jiaetal.2020', 'hashimotoetal.2018', ']', 'thoughmuchstillremainsunclearaboutwhatandhowmodelpropertiesareresponsibleforthis', 'biasamplification.further', 'giventhatapplyingfoundationmodelsdirectlymaybeinfeasible', 'due', 'totheirscale', 'effortstocompressthesemodelsormakethemmoreefficientalsoappeartoamplify', 'bias', '[', 'hooker', 'et', 'al', '2020', 'renduchintala', 'et', 'al', '2021', ']', 'amplification', 'may', 'also', 'exacerbate', 'feedback', 'loop', 'foundation', 'model', 'modify', 'societal', 'behavior', 'induce', 'sociological', 'change', 'whichmodifiessubsequenttrainingdata', 'feedbackeffectsofthisformtendtoexacerbate', 'inequityinothermlapplications', '[', 'lumandisaac2016', 'ensignetal.2018', 'hashimotoetal.2018', ']', 'beyondtheexplicitdecisionsmadeintrainingandapplyingfoundationmodels', 'communityvalues', '[', 'birhane', 'et', 'al', '2020', ']', 'norms', '§5.6', 'ethics', 'indirectly', 'implicitly', '[', 'liu', 'et', 'al', '2021b', ']', 'shapedecision-makinginbuildingmodels.asaresult', 'measuringbiasesinconjunctionwithwork', 'introducingfoundationmodels', '[', 'e.g.', 'brownetal.2020', ']', 'andinstandardbenchmarks', '[', 'friedmanand', 'nissenbaum1996', '§4.4', 'evaluation', ']', 'aswellasconductinguserstudieswithdiverseusergroups', 'todocumentexperiencedharm', 'arestepstowardsensuringbestpracticesactivelyemphasizethe', 'considerationofbiasandinequity', 'modelers', 'aswithallalgorithmicsystems', 'poorrepresentationanddiversityofstakeholdersand', 'marginalizedcommunitiesindecision-makingbodiesthatdeveloporapplyfoundationmodelsis', 'inherentlyproblematic', 'andmaycontributetogreaterexperiencedharmforthesecommunities.93', 'whiledifficulttodocument', 'existingeffortstodevelopfoundationmodelssuggestthisasapossibil-', 'ity', 'caswelletal', '[', '2021', ']', 'demonstratetheflaweddatahandlingofless-representedlanguagesinthe', 'multilingualdatasetsusedtotrainmultilingualmodelsandhutchinsonetal', '[', '2020', ']', 'showthatmod-', 'elsoftencontainundesirablebiasestowardsdisabledpersons.inbothinstances', 'thesebiasesand', 'harmsmayhavebeennoticedearlierbybetterrepresentationofthesepartiesindeveloperteams', 'sinceend-usersarelikelymorediversethandevelopersandmaynoticetheseconcerns', 'earlier', 'allowingforuserfeedbacktocontributetofoundationmodeldesign', '§2.5', 'interaction', 'animportantdirectionforward', '5.1.4', 'interventionsandrecourse', 'address', 'mitigate', 'andrectifyingtheinequitiesassociatedwithtechnologyrequiresintegrat-', 'ingsocialandtechnicalmethodologies', '[', 'abebeetal.2020', ']', '.forfoundationmodelsspecifically', 'weconsiderbothproactivemethods', 'whichchangehowmodelsaredevelopedanddeployedto', 'prophylactically', 'reduce', 'harm', 'well', 'reactive', 'methods', 'respond', 'harm', 'make', 'changesforthefuture.atitscore', 'theabstractionoffoundationmodelscomplicatesbothaspects', 'knowingifinterventionsatthelevelofthefoundationlevelaresuccessfulinreducingharmrequires', 'downstreamobservationsatthelevelofspecificdeployedapplicationsandrecourseintheevent', '93wenotethatdiversity', 'bothwithrespecttodisciplinarybackgroundsanddemographicidentities', 'isoffundamental', 'importanceinthesehigh-impactdecision-makingsettingsforreasonswellbeyondthepotentialimprovedrecognitionof', 'fairness-relatedharms']",132
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '133', 'ofharmrequiresupstreampropagationofbothfeedbackandaccountabilitytofoundationmodel', 'providers', 'intervention', 'general', 'principles', 'govern', 'intervention', 'technological', 'systems', 'apply', 'thefoundationmodelsetting', 'identifyingwhichsourcesaremostresponsibleforbiasorharm', 'providestheevidencerequiredfortargetedaction.forexample', 'theurgencyofcallsforimproved', 'diversityintheteamsthatdesign', 'produce', 'andcontroltechnology', 'e.g.', 'foundationmodels', 'theirapplications', '[', 'longino1990', 'harding2015', 'nielsenetal.2017', '’', 'connoretal.2019', 'hofstra', 'etal.2020', 'katelletal.2020', ']', 'isfurtherintensifiedifthelackofdiversityisshowntorelatetoharm', '[', 'caswelletal.2021', ']', '.inaddition', 'transparentdocumentation', '[', 'e.g.', 'gebruetal.2018', 'benderand', 'friedman2018', 'mitchelletal.2019', ']', 'andauditing', '[', 'e.g.', 'rajiandbuolamwini2019', ']', 'aresimilarly', 'criticalinprovidingtheimpetusforinterventionandchange', '[', 'burrell2016', 'lipton2018', 'creel2020', 'rajietal.2020', 'wilsonetal.2021', ']', '.thescaleoffoundationmodels', 'aswellasthespecificsoftheir', 'accessibility', 'introducenewchallengesforexistingprotocolsfordocumentationandauditingthat', 'wediscussfurtherin§5.6', 'ethics', 'todate', 'manyoftheinterventionsconsideredforreducingtheinequitableimpactoftechnology', 'includinginthefoundationmodelregime', 'aremethodsfortechnicalmitigationthatcenterthe', 'data', 'toobviatereflectinginequitiesorbiases', 'andmodellingdecisions', 'toavoidamplifyingdata', 'bias', 'involved.ofspecificimportanceinthefoundationmodelregimeisrecognizingthatthese', 'mitigationapproachesmaytargetdifferentstepsinthepipelinesuchasthetrainingdata', '[', 'e.g.', 'lu', 'etal.2020', ']', 'modellingobjectives', '[', 'e.g.', 'zhaoetal.2018', ']', 'andadaptationmethodsandtest-time', 'use', '[', 'e.g.', 'parketal.2018', 'zhaoetal.2019', ']', '.asaresult', 'differentapproachesmaynotonlybe', 'moreorlesseffective', 'butrequireactionfromdifferententities', 'e.g.', 'foundationmodelprovidersvs', 'applicationdevelopers', 'andmoreorlessintensivelyaffecttheexpensivetrainingprocessforthese', 'model', 'e.g.', 'changingtheprocessofcreatingafoundationmodelvs.alteringitposthoc', '.technical', 'interventionofthisformmayalsotargetdifferentgoals', 'someinterventions', 'suchaschanging', 'thetrainingdata', 'aimstoreduceintrinsicbias.onetheotherhand', 'mostworkonmitigationin', 'algorithmic/mlfairnessinsteadconsidersreducingoutcomedisparitiesintermsofmodelbehavior', 'i.e.', 'output', 'downstream', 'systems', 'directly', 'relate', 'extrinsic', 'harm', 'technical', 'mitigationofallformsatpresentisseverelylimited', 'methodsthatmeasureorcombatintrinsic', 'biasarebrittleorineffectual', '[', 'gonenandgoldberg2019', 'ethayarajhetal.2019', 'bommasanietal', '2020', 'zhouetal.2021b', 'antoniakandmimno2021', ']', 'methodsthatmeasureorcombatextrinsic', 'outcomedisparitiesmaynotalignwithstakeholdergoals', '[', 'sahaetal.2020', ']', 'andthereissome', 'evidencetosuggestcertaintypesoftechnicalinterventionmaybesimultaneouslyunsatisfiable', '[', 'corbett-daviesandgoel2018', 'kleinbergetal.2017', ']', 'impossible', '[', 'lechneretal.2021', ']', 'ormayeven', 'exacerbateinequity', '[', 'xuetal.2021', ']', '.inspiteofthisstateofaffairs', 'wecontinuetobelievetechnical', 'methodswillstillplayaninstrumentalroleinaddressingtheharmsthatariseinthefoundation', 'modelregime', 'ingeneral', 'weadvocatefortransparency', 'especiallygiventhattechnicalmitigation', 'methods', 'may', 'able', 'achieve', 'intend', 'goals', 'broadly', 'claim', 'bias', 'bias', 'mitigationmustbemadecarefullytoclearlycommunicatethestatusquotovariousstakeholders', 'withdifferingexpertise', 'e.g.', 'applicationdevelopersbuildingontopoffoundationmodelsand', 'policymakersregulatingthetechnology', '[', 'nissimetal.2020', ']', 'recourse', 'unfortunately', 'proactive', 'intervention', 'unlikely', 'full', 'resolve', 'potential', 'harm', 'inequity', 'may', 'arise', 'due', 'foundation', 'model', 'harm', 'arise', 'currently', 'widely-adopted', 'legally', 'require', 'framework', 'resolve', 'appropriate', 'recourse', 'harm', 'party', 'certain', 'protocols', 'may', 'exist', 'specific', 'applications', 'abstraction', 'foundationmodelsagainintroducesadisconnect', 'harmslikelyarepartiallyattributabletoboth', 'thefoundationmodelprovidersandthedownstreamapplicationdevelopers', 'butallocatingthis']",133
Opportunities and Risks of Foundational Models - Stanford.pdf,"['134', 'centerforresearchonfoundationmodels', 'crfm', 'responsibilitytoeitherpartyremainschallenging.moresimply', 'mechanismsarenotinplaceto', 'evencommunicatetheseharmstofoundationmodelproviders', 'eveniffeedbackorcomplaints', 'areraisedtoapplicationdevelopers', '.asaresult', 'newnormsandstandardsareneededonhow', 'feedbackfromapplicationdevelopersandend-usersshouldreachupstreamtothefoundationmodel', 'providers', 'howtodeterminetheentities', 'e.g.', 'foundationmodelproviders', 'applicationdevelopers', 'responsiblefortheseharms', 'andtherelationshiptolegalresponsibility', '§5.4', 'legality', '.tomake', 'progressonthismatter', 'weencouragefutureworktoconsultthepracticesusedinotherdomains', 'especially', 'similar', 'abstractions', 'multi-entity', 'structure', 'anticipate', 'standardsintroducedwilllikelyneedtobereasonablydynamic', 'sothattheycanbesynchronized', 'withtherapidlychangingstatusquoforthesemodelsandtheirapplications', '5.1.5', 'takeaways', 'machinelearninghasanestablishedtrackrecordofinequitableimpact', 'withmuchoftheburdenof', 'itsharmsbornebymarginalizedcommunities.foundationmodelsintroducenewchallengestothis', 'calculusbut', 'ultimately', 'fortheirsocietalimpacttobeequitable', 'significantresearchandchangeis', 'requiredtounderstandtheharmstheycauseandtomeaningfullyaddressandrectifytheseharms', '1', 'theone-to-manynatureoffoundationmodels', 'i.e.', 'thesamefewfoundationmodelsbeing', 'usedacrossmanyapplications', 'meanstheintrinsicpropertiesoffoundationmodelspervade', 'tomanydownstreamapplications.perniciousbiasesinthesemodelsthereforehaveout-sized', 'effectontheexperiencedharms', '2', 'biasesandharmsinthefoundationmodelregimeoriginatefrommanysources', 'e.g.', 'train', 'andadaptationdata', 'modellingandadaptationdecisions', 'modelerdiversityandcommunity', 'value', '.attributingthesourcesforbiasandharmisfundamentalforquestionsofintervention', 'andresponsibility', 'attributionrequiresnewtechnicalresearchtobedonereliably', '3', 'theinequitiesoffoundationmodelsarenotinevitable', 'butaddressingthemrequiresamulti-', 'prongedapproachcomprisedofbothproactiveintervention', 'e.g.', 'data-centricandmodel-', 'centricchanges', 'andreactiverecourse', 'e.g.', 'mechanismsforfeedbackandaccountability']",134
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '135', '5.2', 'misuse', 'author', 'antoinebosselut', 'shelbygrossman', 'bennewman', 'fig.25', 'thisfigureshowstheeffectfoundationmodelswillhaveonmanipulativeandharmfulcontent', 'generation', 'andtheimplicationsfordetection', 'inthissection', 'weconsidermisuseoffoundationmodels—situationswherepeopleusefoundation', 'modelsastheyareintendedtobeused', 'e.g.', 'togeneratelanguage', 'butwheretheircapabilities', 'areintentionallyleveragedtocauseharmtopopulationsorindividuals.thisdefinitionpositions', 'misuseconcernsbetweenthoseofinequity', 'wheremodelscancauseharmwithoutbadintentions', '§5.1', 'fairness', 'andsecurity', 'wherebadactorsexploitunintentionalabilitiesorvulnerabilitiesin', 'modelstocauseharm', '§4.7', 'security', '.below', 'weoutlinehowfoundationmodelsbothenablenew', 'formsofmisuseandsupportnewtoolsformisusedetectionandmitigation', '5.2.1', 'foundationmodelswillbemisusedforharmfulpurposes', 'advancesinthescale', '§4.2', 'train', 'multimodality', '§4.1', 'model', 'andadaptivity', '§4.3', 'adap-', 'tation', 'ofgenerativefoundationmodelswillallowthemtobemisusedtogeneratehigh-quality', 'cheap', 'personalize', 'content', 'harmful', 'purpose', 'section', 'discuss', 'three', 'dimensionswithinthecontextoftwoexamplesofmaliciousactivity', 'manipulativecontentcreation', 'andharassment', 'contentquality', 'foundationmodelsarecapableofautomaticallygeneratingmuchhigher-quality', 'human-lookingcontentthanprioraimethods.theymayempowerdisinformationactors', 'state', 'forexample', 'createcontenttodeceiveforeignpopulationswithoutbeingtransparentthat', 'content', 'link', 'state', 'currently', 'create', 'content', 'often', 'require', 'hire', 'people', 'whospeakthelanguageofthepopulationbeingtargeted.governmentsmayoutsourcecontent']",135
Opportunities and Risks of Foundational Models - Stanford.pdf,"['136', 'centerforresearchonfoundationmodels', 'crfm', 'productiontonativespeakersinthecountrytheyaretargeting,94,95', 'butthisdecisioncausesreal', 'risk', 'operational', 'security', 'foundation', 'model', 'allow', 'creation', 'content', 'oftenindistinguishablefromcontentcreatedbyhumans', '[', 'krepsetal.2020', 'clarketal.2021', ']', '—and', 'indeeditwillbeabletodothisforawidevarietyoflanguages—enablingbothgoalsofcreating', 'contentthatresonatesandmaintainingoperationalsecurity', 'inadditiontodeceivingforeignpopulations', 'foundationmodels', '’', 'abilitytogeneratehighquality', 'syntheticimages', 'deepfakes', 'ortextmaybeabusedtoharassindividuals.deepfakeshavealready', 'use', 'purpose', 'harassment', 'example', 'rana', 'ayyub', 'indian', 'investigative', 'journalist', 'wastargetedbyahigh-qualitydeepfakethatsuperimposedherfaceontoapornographic', 'video', 'leadinghertoleavepubliclifeformonths.96becausefoundationmodelsareoftenmultimodal', '§4.1', 'model', 'theycouldsimilarlyimpersonatespeech', 'motion', 'orwriting', 'andpotentiallybe', 'misusedtoembarrass', 'intimidate', 'andextortvictims.97', 'costofcontentcreation', 'foundationmodelswillsubstantiallylowerthecostsofcontentcreation', 'thebudgetforone2017influenceoperationthatoriginatedinrussiaandtargetedamericanswas', '$', '12.2million', '[', 'direstaetal.2018', ']', '.morerecently', 'individualsinrussiapaid', '$', '75-', '$', '200perarticleto', 'americanfreelancersaspartofadisinformationcampaign.98foundationmodelswilllowerthese', 'marginalcosts.whilefoundationmodels', 'suchasgpt-3', 'maymakemistakeswhengenerating', 'content', '[', 'buchananetal.2021', ']', 'itwillbemorefeasibletohireasmallnumberofeditorstofixthem', 'thantohirecontentcreatorsdirectly.initialcoststotrainfoundationmodelsaremoresignificant', '§4.5', 'systems', 'buttheseexpensesshouldbemanageableformoststateactors', '[', 'buchananetal', '2021', ']', 'inadditiontomonetarycost', 'foundationmodelsrequirefewertechnicalskillstoachievehigh-', 'qualityresults.currenttools', 'suchasvideoeditingsoftware', 'canenablecrediblephotoorvideo', 'deepfakes', 'butrequireseveralhoursofaskilleduser', '’', 'stimetoyieldqualitycontent.foundation', 'modelslowerthisbarriertouse', 'theirfew-shotadaptationcapabilities', '§4.3', 'adaptation', 'enable', 'newmodesofinteractionforapplicationusers', '§2.5', 'interaction', 'thatwillallowuserstorapidly', 'iterateforcontentcreation', 'personalization', 'foundationmodelswillreduceobstaclestocreatingpersonalizedcontent.for', 'example', 'disinformationfromrussianindividualsthattargetedtheusin2016includedhighly', 'customizedcontent.socialmediapostswerecraftedtopushnarrativesaboutsyria', 'e.g.', 'theu.s', 'shouldgetoutofsyria', 'thatresonatedwithblacklivesmatteractivists', '[', 'direstaetal.2018', ']', 'e.g.', 'suggestingthattheu.s.shouldfocusonissuesfacingtheblackcommunityinamerica', 'andnoton', 'issuesinsyria', '.thesamenarrativeswererepackagedtoresonatewithtexassecessionists', '[', 'diresta', 'etal.2021', ']', '.suchacontentcreationendeavoriscostlyandtimeconsuming.foundationmodels', 'willallowforsimilaractivity', 'butatscaleduetothelowcostofadaptation', '§4.3', 'adaptation', 'inadditiontofoundationmodelsallowinganactortopersonalizecontentfornicheaudiences', 'theyalsoallowanactortopersonalizecontenttotargetasingleindividual—acapabilitythatcan', 'beabusedbyharassers.foundationmodelsthatconditiontheirgenerationsonpersonalattributes', 'orinformationcancreaterealisticpersonalizedcontent', 'whichcouldbemoreembarrassing', 'place', 'victimsinmoredanger,99andleadtomoresuccessfulextortionattempts', '94https', '//www.lawfareblog.com/outsourcing-disinformation', '95https', '//fsi.stanford.edu/content/ira-takedown-20201215', '96https', '//www.huffingtonpost.co.uk/entry/deepfake-porn_uk_5bf2c126e4b0f32bd58ba316', '97https', '//www.wsj.com/articles/fraudsters-use-ai-to-mimic-ceos-voice-in-unusual-cybercrime-case-11567157402', '98https', '//www.nytimes.com/2020/09/02/technology/peacedata-writer-russian-misinformation.html', '99https', '//www.dw.com/en/social-media-uptick-in-honor-crime-in-middle-east/a-56370773']",136
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '137', '5.2.2', 'foundationmodelswillbepowerfuldetectorsofharmfulcontent', 'whilethegenerativecapabilitiesoffoundationmodelswillprovideamplemisuseopportunities', 'thesesameabilitiesmaymakethemstrongdetectorsofharmfulcontent.whilethesecapabilities', 'areequallyrelevantfordetectinghuman-andmodel-generatedcontent', 'wefocusonthedetection', 'ofmodel-generatedcontentinthissection.first', 'weoutlinethechallengesthatcurrentmanual', 'detection', 'approach', 'face', 'discover', 'harmful', 'misuse', 'foundation', 'model', 'proposehowtheinteractiveandmultimodalrepresentationcapabilitiesoffoundationmodelsmay', 'make', 'powerful', 'tool', 'automatic', 'detection', 'harmful', 'content', 'finally', 'discuss', 'risksassociatedwithdeployingautomaticdetectionmodelsinonlinesettingstocombatpotential', 'foundationmodelmisuse', 'rethink', 'human', 'interventions', 'currently', 'malicious', 'practice', 'frequently', 'uncover', 'andonsocialmedia', 'sometimesremoved', 'byhumanssearchingtheinternettouncovercontent', 'origination.100forexample', 'fakesocialmediaprofilescommonlystealprofilephotosfromdating', 'sit', 'whicharediscoverablethroughreverseimagesearches.similarly', 'disinformationwebsites', 'frequentlyuseplagiarizedcontenttomaskdeceptivecontent', '[', 'direstaandgrossman2019', ']', 'iseasilyidentifiedbyconductinginternetphrasesearches.foundationmodelswilllimittheefficacy', 'ofthesedetectionstrategies.already', 'relativelyunsophisticateddisinformationcampaignshave', 'leveragedai-generatedphotos101', 'toremovethepossibilityofdiscoverythroughreverseimage', 'search.toolsforassessingwhetherthesephotosareai-generatedareavailable', 'butfoundation', 'model', 'complicate', 'work', '—', 'text', 'video', 'well', '—', 'challenge', 'manual', 'human', 'discoverytechniques', '[', 'ippolitoetal.2020', 'clarketal.2021', ']', 'foundation', 'model', 'detectors', 'abilities', 'foundation', 'model', 'make', 'stronggeneratorsofcreativecontentmaymakethemstrongdetectorsofmodel-generatedcontent', 'existingworksdemonstratethatfoundationmodelscanbeadaptedtodetectdisinformationfrom', 'textgenerators', '[', 'zellersetal.2019b', ']', '—whichgeneratestatisticaltextualartifacts', '[', 'holtzmanetal', '2020', ']', '—andthattheycanbeusedtoevaluatethetoxicitylevelsoftheirowngenerationsusing', 'promptquestions', '[', 'schicketal.2021', ']', '.below', 'wedescribehowfuturefoundationmodelswillenable', 'morepowerfuldetectionsystemsofmachine-generated', 'harmfulcontent', 'improvementsintheinteractiveandmultimodalinterfacesoffoundationmodelswillprovide', 'newopportunitiestoimprovedetectionoffoundationmodelmisuseforharmfulcontentgeneration', 'currentstatisticaldetectorsmustberetrainedandre-deployedtointegratenewknowledgeabout', 'textual', 'content', 'misuse', 'strategies', '[', 'dinan', 'et', 'al', '2019', ']', 'rapid', 'learn', 'capabilities', 'foundationmodels', '§4.3', 'adaptation', 'mayallowthemtoadaptfromhumanfeedbacktonew', 'misusestrategiesthatthefoundationmodelwasnotinitiallytrainedtorecognize', 'simultaneously', 'themultimodalabilitiesoffoundationmodelswillenablemoreexpressiverepre-', 'sentationofmisuseecosystems.priorworkhasexploredhowmisinformationspreadsmorerapidly', 'acrosssocialnetworksthanauthenticcontent', '[', 'starbirdetal.2018', 'vosoughietal.2018', ']', 'yield', 'recognizablesignatureswhenanalyzedretrospectively.themultimodalcapabilitiesoffoundation', 'modelscouldallowthemtojointlylearnrepresentationsofharmfulcontentanditstypicaldis-', 'seminationsignatureonsocialnetworks.thesejointrepresentationscouldprovidepowerfultools', 'forpredictingwhethercertaintypesofautomatically-generatedcontentareindicativeofmisuse', 'behavior', '100https', '//www.theatlantic.com/ideas/archive/2020/09/future-propaganda-will-be-computer-generated/616400/', '101foramiddleeastcampaignexample', 'seehttps', '//www.thedailybeast.com/right-wing-media-outlets-duped-by-a-', 'middle-east-propaganda-campaign', 'foranexamplefromcuba', 'seehttps', '//raw.githubusercontent.com/stanfordio/publications/main/twitter-cu-202009.pdf']",137
Opportunities and Risks of Foundational Models - Stanford.pdf,"['138', 'centerforresearchonfoundationmodels', 'crfm', 'risk', 'foundation', 'model', 'automatic', 'detectors', 'improvements', 'automatic', 'detection', 'systemsforbothmodel-generatedandhuman-generatedharmfulcontentwillmakethesesystems', 'moreprevalentonline', 'yieldingpotentialnegativeconsequences.anydetectionsystemwillhave', 'falsepositivecaseswherehuman-generatedfaircontentwillbeflaggedasharmful', '[', 'sapetal.2019', 'xuetal.2021', ']', '.therateatwhichalgorithmicfalsepositivesaffectusers', 'orgroupsofusers', 'may', 'causedownstreamharm', '§5.1', 'fairness', '.theadaptivecapabilitiesoffoundationmodelsshould', 'makesystemicfalsepositiveseasiertoaddressasthemodelcanbelocallyeditedtore-classifythose', 'examples', '§4.3', 'adaptation', '.however', 'cornercaseswilllikelynotbeprioritizedandrecoursewill', 'bechallenginginthesesituations', 'morebroadly', 'wide-scaledeploymentofmisusedetectionsystemsmayengenderan', '“', 'armsrace', '”', 'betweenharmfulcontentgeneratorsanddetectors.mostcontentgeneratorsthatusefoundation', 'modelswilllacktheresourcestodevelopthemindividually', 'andwillusesystemsdeployedbylarger', 'entities.whiletermsofusepoliciesshouldoutlineacceptableusesofthesesystems', '§5.6', 'ethics', 'deployersoffoundationmodelswillalsoneedinternaldetectionsystemstoidentifymisuseof', 'theirproducts102', 'andmitigatethem', '§5.4', 'legality', '.however', 'therewillbefewercontrolsfor', 'misuseactorswiththeresourcestodeveloptheirownfoundationmodel-basedcontentgenerators', 'puttingpressureonplatformstocuratethecontentsharedthroughtheirdistributionchannels', 'optimistically', 'contentplatformsencompasssomeofthemostwell-capitalizedfirmsintheworld', 'theirresourcesmayenablethedevelopmentofdetectorsbeyondthecapabilitiesofmostindividual', 'misuseagents.thisresourceadvantagecoulddisincentivizeindividualfoundationmodeldevelop-', 'mentduetothehighcostsofrepeatedlytrainingthesesystemsatscale.however', 'manyinstances', 'offoundationmodelmisusecouldstillbesuccessfulevenwithoutthelargestfoundationmodels', 'topowerthem', 'particularlyasattackersmayleveragetheinteractivecapabilitiesoffoundation', 'modelstorapidlygeneratecontentthatcanevadedetection', '102https', '//www.wired.com/story/ai-fueled-dungeon-game-got-much-darker/']",138
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '139', '5.3', 'environment', 'author', 'peterhenderson', 'laurengillespie', 'danjurafsky', 'fig.26', 'avisualizationofacost-benefitanalysisfordeployingafoundationmodel.thetotalvalueofa', 'modelcanbeapproximatedbyfirstconsideringthenetpositivesocialbenefitsofthemodel', 'aswellasany', 'environmentalbenefits.then', 'wesubtractthenegativeenergycoststotrainanddeploythemodel', 'thesocial', 'costofthecarbonemittedtotrainthemodel', 'andthesecondaryenvironmentaleffects.ifthenetcosts', 'outweighthebenefits', 'thenfoundationmodeldevelopersandlarge-scaledeployersshouldconsiderharm', 'reductionstrategies.thiscouldincludedeployingamoreefficientmodelornotdeployingthemodelatall', 'foundationmodelscanpotentiallyleadtomanysocialandenvironmentalbenefits', 'forexamplein', 'legaldomains', '§3.2', 'law', 'healthcare', '§3.1', 'healthcare', 'oreventacklingclimatechange', '[', 'rolnick', 'etal.2019', ']', '.butbecauseoftheirscale', 'theythemselvescannegativelyimpacttheenvironment', 'throughincreasedcarbonemissionsifmodelcreatorsarenotcareful', '[', 'strubelletal.2019', 'lottick', 'etal.2019', 'schwartzetal.2019', 'lacosteetal.2019', 'caoetal.2020', 'hendersonetal.2020', 'bender', 'etal.2021', 'pattersonetal.2021', 'lannelongueetal.2021', 'parcolletandravanelli2021', ']', '.addressing', 'suchemissionsisanimperative', 'currentforecastsshowthatclimatechangeisoccurringmore', 'rapidlythanpreviouslythought', '[', 'masson-delmotteetal.2021', ']', 'tounderstandwheresuchemissionscanoccurinfoundationmodels', 'weconsidertheirlifecycle', 'first', 'theyaretrainedonvastamountsofdata', 'possiblyforuptomonthsoftimeandoftendistributed', 'acrosshundredstothousandsofgpus.afterwards', 'theymaybeadaptedtonewdomainsorperhaps', 'distilledintosmallermodels.allofthiscanbeconsideredpartofthetrainingregime.modelsused', 'purelyforresearchmaynotmovebeyondthesesteps.aftermodelshavebeenadaptedand/or', 'distil', 'theymightmoveontobedeployedintoproduction.atthispointmanyroundsofinference', 'willrunthroughthemodeluntilanewmodelistrainedandthecyclerepeats', 'eachoneofthesestepshasthepotentialtoutilizelargeamountsofenergyandcancontribute', 'tocarbonemissions.foundationmodelscangeneratelarge', 'one-timeenergycostsandcarbon', 'emissionsduringtheinitialtrainingphase.forexample', 'theamountofemissionsfromtrainingone', 'bert-basemodel', 'undersomeconditions', 'wouldonlybeoffsetby40treesgrownfor10years.103', 'andifdeployedatscale', 'foundationmodelscanrequiresubstantialenergytoservicemillionsof', 'requests104—translatingtolargecarbonemissionsifnonrenewableresourcesareused', '103strubelletal', '[', '2019', ']', 'calculatecarbonemissionsfortrainingbertonanaverageenergygridintheu.s.andweuse', 'https', '//www.epa.gov/energy/greenhouse-gas-equivalencies-calculatortoconvertthattoequivalentemissionsinother', 'domains.wenotethatthisnumbercanvarydependingontheenergygridandotherconsiderations', '[', 'hendersonetal.2020', 'pattersonetal.2021', ']', '104forexample', 'transformersarealreadyusedatscaleforsearchbothatmicrosoftandgoogle.seehttps', '//www.blog.google/', 'products/search/search-language-understanding-bert/andhttps', '//azure.microsoft.com/en-us/blog/microsoft-makes-it-', 'easier-to-build-popular-language-representation-model-bert-at-large-scale/']",139
Opportunities and Risks of Foundational Models - Stanford.pdf,"['140', 'centerforresearchonfoundationmodels', 'crfm', 'therefore', 'theenvironmentalimpactsofcertaindesigndecisionsforbothtraininganddeploying', 'foundation', 'model', 'substantial', 'even', 'seemingly', 'minuscule', 'decisions', 'like', 'reduce', 'number', 'layer', 'model', 'may', 'lead', 'significant', 'environmental', 'cost', 'reductions', 'scale', 'forexample', 'basedoncalculationsfromhendersonetal', '[', '2020', ']', 'aslightlymoreenergyefficient', 'translationmodeldeployedatthescaleofacommercialtranslationservicecouldsavebetween', '78kgco2eqand12,768kgco2eqofcarbonemissionsperdaydependingontheenergygridused', 'thisisroughlyequivalenttothecarbonsequesteredby1to211treesgrownfor10years', 'orthe', 'carbonsequesteredby.35to57.4acresofforestinoneyear.105thusthedesign', 'deployment', 'post-deploymentmonitoringoffoundationmodelsshouldadequatelyreflecttheserisks', 'thereareofcourseuncertaintiesincalculatingtheamountofenergyusedorcarbonemittedby', 'anygivenmodel', '[', 'hendersonetal.2020', 'caoetal.2020', 'pattersonetal.2021', ']', 'andothersourcesof', 'emissionsmaycurrentlybemuchgreaterthanthosegeneratedbyfoundationmodels', '[', 'moraetal', ']', '.butiffoundationmodelscontinuetoscaleandgaininpopularity', 'theymayverywellbecome', 'asignificantcontributortocarbonemissions.ourgoalistoprovideaframeworkforfoundation', 'modeldevelopersandlarge-scaledeployers106toconsiderhowtheycanmitigateanyunnecessary', 'carbonemissionsandkeepthenetsocialimpactofthesemodelspositive.werecommendthat', '1', 'carbonimpactscanandshouldbemitigatedinmanycases.thiscanbeaccomplishedby', 'train', 'model', 'low-carbon', 'intensity', 'regions', 'use', 'efficient', 'model', 'hardware', '§5.3.1', 'environment-mitigation', '2', 'mechanisms', 'mitigation', 'exhaust', 'mitigation', 'longer', 'possible', 'thecostsandbenefitstosocietyshouldbeassessedtodetermineifandwhena', 'largerfoundationmodelshouldbedeployedoverasmaller', 'moreefficient', 'model—withthe', 'understandingthattheup-frontcostsofalargefoundationmodelmaybeamortizedover', 'thelifetimeofthemodel', '§5.3.2', 'environment-costs', '3', 'energy', 'computational', 'andcarboncosts—aswellasanyeffortstakentomitigatenegativeim-', 'pacts—shouldbeclearlyreportedtoinformpolicymakingandresearch', '§5.3.3', 'environment-', 'report', '5.3.1', 'carbonimpactscanandshouldbemitigatedinmanycases', 'thecarbonimpactsoftrainingfoundationmodelsdifferfromtheimpactsofdeployingthemfor', 'inference.modeltraininghasnolatencyrequirements', 'sotrainingcanbemovedacrossenergy', 'gridswithrelativeeaseincloudenvironments.everyenergygridhasitsowncarbonintensity—', 'amount', 'carbon', 'emit', 'kilowatt-hour', 'energy', 'use', 'example', 'québec', 'extremelylowcarbonintensityduetoitsrelianceonhydroelectricity', 'whileestonia', '’', 'senergygrid', 'hasanextremelyhighcarbonintensityduetoitsrelianceonshaleoil', 'thoughthatischanging', 'quickly', '[', 'hendersonetal.2020', ']', '.recentresearchhasevensuggestedthatthetop5', '%', 'ofpolluting', 'powerplantscontributed73', '%', 'ofallelectricity-basedemissions', '[', 'grantetal.2021', ']', '.thus', 'trainingfoundationmodelscanbequiteenergyintensive', 'researchershavedemonstratedthat', 'thecarbonimpactsofthesemodelscanbepartlymitigatedbyselectingenergygridswithminimal', 'carbonemissions', '[', 'hendersonetal.2020', 'lacosteetal.2019', 'pattersonetal.2021', ']', '105sequestrationestimatedviahttps', '//www.epa.gov/energy/greenhouse-gas-equivalencies-calculator', 'butmaybelarger', 'dependingonotherestimationmethods.moreefficientenergygridswillemitlesscarbon', 'resultinginwideestimated', 'rangesofimpacts', '106wefocusonmodeldevelopersandlarge-scaledeployers', 'likethosewhobuildproductionsystemsontopoffoundation', 'model', 'becausetheyaremostabletomakemeaningfulchangestoreduceenergyuseandcarbonemissions.asingle', 'changebytheseactors—likeusingamoreefficientmodel—canscaletomassivecarbonsavings', 'whichwouldotherwise', 'requireamassivecampaigntoreachalldownstreammodelusers']",140
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '141', 'carbonoffsetshavealsobeenproposedasastopgapuntilcarbon-freerenewableelectricityis', 'availableatalldatacenters.thisstrategyinvolvesreducingcarbonemissionsinoneactivityto', 'offsettheemissionsfromanother.butmost—ifnotall—carbonoffsetsareastrictlyworsesolution', 'thannotemittingco', 'inthefirstplace', '[', 'hollandbrancalion2020', ']', '.somecarbonoffsetprograms', '2', 'canevenhaveanegativeimpact.forexample', 'studiesofforestplantingcampaigns', 'oftenasource', 'ofcarbonoffsetting', 'showthattheycandomoreharmthangood.theycanyieldmonocultures', 'useofoneparticularspeciesoftree', 'thatdiminishthebiodiversityoftheregionandreducecarbon', 'storageintheforestsoil', '[', 'heilmayretal.2020', 'hongetal.2020b', ']', '.thiscouldresultinmorecarbon', 'emissionswhenusingcarbonoffsetsthaniftheoriginalcarbonhadneverbeenemittedinthefirst', 'place.therefore', 'whentrainingordeployingafoundationmodel', 'werecommenddesigningforas', 'littlecarbonemissionaspossibleup-front', 'ratherthansimplyrelyingoncarbonoffsetstocancel', 'emissions', 'possible', 'run', 'low-carbon', 'regions', 'mitigation', 'strategies', 'leverage', 'reducingunnecessaryenergyusage.thisincludes', '•', 'usingmoreefficienthardware,107', '•', 'use', 'mixed-precision', 'train', '[', 'micikevicius', 'et', 'al', ']', 'quantization', '[', 'gholami', 'et', 'al', '2021', ']', '•', 'usingmoreefficientarchitectures', 'e.g.', 'usinganevolvedtransformeroveravanillatrans-', 'formerarchitecture', 'orusingsparsemodels', '[', 'soetal.2019', 'pattersonetal.2021', 'mostafa', 'andwang2019', ']', '•', 'distillingmodelsandusingdistilledmodels', 'e.g.', '[', 'sanhetal.2019', ']', '•', 'andutilizingotheroptimizationstrategiesthatwillreduceenergycosts', 'seemorediscussion', 'in§4.5', 'systems', 'maintainersofopensourceprojectsandcloudcomputeshouldstrivetosettheirdefaultsettings', 'tothemostefficientpossible', 'since', '“', 'greendefaults', '”', 'areknowntobethemosteffectivemitigation', 'strategies', 'seediscussionin', '[', 'hendersonetal.2020', ']', '.othermitigationstrategiescanbefound', 'inrecentliterature', '[', 'strubelletal.2019', 'lacosteetal.2019', 'schwartzetal.2019', 'hendersonetal', '2020', ']', '.wealsonotethatreducingandmitigatingenergyusagealsohastheaddedbenefitofmaking', 'modelsmoreaccessibletothosewithlimitedcomputeaccess', 'see§5.6', 'ethicsformorediscussion', 'however', 'whenamodelismainlyusedforinference', 'e.g.', 'deployedinaproductionapplication', 'itoftencannotbemovedtoalesscarbon-intensiveenergygridforlow-latencyapplications.in', 'additiontousingthemitigationstrategiesspecifiedabove', 'inthiscaseitisimportanttoweighthe', 'benefitsoftheproposedfoundationmodelversusamoreenergyefficientalternative.wediscuss', 'thisfurtherinthesubsequentsection', '5.3.2', 'costsandbenefitsshouldbeassessedbeforeusingfoundationmodels', 'aftertakingasmanystepsaspossibletowardsmitigation', 'orwheremitigationisnotpossible', 'isvitaltoassesstherequiredsizeofafoundationmodel—orwhetherafoundationmodelshould', 'beusedatall.thiscost-benefitanalysisshouldconsider', '1', 'isthesocialcostandenvironmentalcostfromdeployingthefoundationmodelgreaterthan', 'thesocialbenefitofthemodel', '?', '2', 'wouldanother', 'computationallysimplerandcheaperapproachachievecomparablesocial', 'benefit', 'e.g.', 'amuchmoreefficientfoundationmodel', 'orperhapssimplebaseline', '?', 'asimplifiedschemeforassessingthistrade-offconsiderstheoverallimpactofamodel𝑀', '107notably', 'californianowregulatescomputerswithinefficientgpusforthisreason', 'requiringthattheystaybelow30-100', 'kwhs/year', 'dependingonthemanufacturingdateandcomputertype.seesections1601-1608ofcalifornia', '’', 'sappliance', 'efficiencyregulations', 'title20']",141
Opportunities and Risks of Foundational Models - Stanford.pdf,"['142', 'centerforresearchonfoundationmodels', 'crfm', '𝑉', '𝑀', '=𝑆', '𝑀', '−𝐶', '𝑀', '−𝐸', '𝑀', '−𝑂', '𝑀', '7', 'figure26representsthisequationandthecostsandbenefitsthatmayentereachvariable.here', '𝑀', 'isthemodeland𝑆', 'isthenetsocialbenefit', 'aswellasenvironmentalbenefit', 'indollars.𝑆', 'canbe', 'increasedbyimprovinghealthcare', 'accesstojustice', 'decreasingpoverty', 'improvingenvironmental', 'monitor', 'aidingecosystemconservationefforts', 'andsoon', '𝐶isthesocialcostofcarbonfromenergyuse.thisrepresentsthefutureharmtosocietyfromthe', 'carbonreleasedasapresent-daymonetaryvalue.theupperboundu.s.environmentalprotection', 'agency', 'epa', 'estimatefrom2017forthesocialcostofcarbonwas', '$', '105', 'in2007u.s.dollars', 'metrictonofco', 'emitted.108', '2', '𝐸', 'istheenergycostofthemodel.forexample', 'inapril2021', 'theaverageu.s.residentialenergy', 'costwasabout', '$', '0.1376perkwh.109addedtothisvariablecouldbethecostsfromincreasedstrain', 'ontheenergygrid.forexample', 'arecentstudysuggestedthatthecostperenergygridinterruption', 'event', 'normalizedbyaveragedemand', 'couldbeashighas', '$', '15.9peraveragekw', '[', 'sullivanetal', ']', '.110', '𝑂', 'isthesocialcostofothersecondorderenvironmentaleffects.thiscouldinclude', '•', 'thecompoundingcarbonimpactsfromincreasedchipdemandandchipproduction', '[', 'gupta', 'etal.2021a', ']', '•', 'otherenvironmentalimpactsofchipmanufacturing', 'likethecreationoftoxicwastesitesin', 'siliconvalley', 'whosehealtheffectsareunequallydistributedtosociallyvulnerablepopula-', 'tions', '[', 'stewartetal.2014', ']', 'orpollutionfrommanufacturingintaiwanthathasbeenlinked', 'tochronichealthproblems', '[', 'tuandlee2009', 'linetal.2016', ']', '•', 'thecompoundingeffectsofclimatechangethatarenotalreadyincludedinthesccmodel', 'forexample', 'theseeffectscouldincludeaccelerateddesertification', '[', 'huangetal.2016', ']', 'rapid', 'ecosystemchangesthatputmanyspeciesatriskofextinction', '[', 'urban2015', ']', 'andincreased', 'carbonemissionsduetomeltingpermafrost', '[', 'schuuretal.2015', ']', '•', 'unnecessarystrainonchipproductioncapacities.recentchipshortageshaveledtowork', 'stoppagesinautomobilemanufacturing.111thereisnoevidencetosuggestthatincreasing', 'demandforml-optimizedchipsledtothisshortage.112', 'butsuchconsiderationsfallinto', 'secondordereffects', 'whereresearchersmightweighwhethertherisks', 'howeverslight', 'contributingtosuchnegativeimpactsareworthusingordeployingalargemodel.113', 'itisimportanttoconsiderinthisanalysisthattheeconomicbenefitsandsocialcostsofcarbon', 'couldbedistributedunequallyacrosscommunities', 'withpoorercommunitiesbeingimpactedmore', 'heavilybyclimatechangeandwealthiercommunitiesbeingbenefitedbyamodel', '[', 'benderetal', '2021', ']', '.114assuch', 'whenconductingtheequation7analysis', 'oneshouldconsiderthebenefitsand', '108seehttps', '//19january2017snapshot.epa.gov/climatechange/social-cost-carbon_.html.butnotethatthesocialcostof', 'carboncanbeacontentiousmetric', '[', 'sternandstiglitz2021', ']', '.byusingafavorablediscountfactor', 'onecanreducecarbon', 'costs.assuch', 'itcanthecalculationofthismetriccanvaryacrossmethodologies', '109https', '//www.eia.gov/electricity/monthly/epm_table_grapher.php', '?', 't=epmt_5_6_a', '110likethesocialcostofcarbon', 'calculationofthesecostscanfluctuateacrossmodelingmethodologies', '111https', '//www.reuters.com/business/autos-transportation/ford-shut-some-n-american-plants-few-weeks-chip-', 'shortage-2021-06-30/', '112thoughrecentreportshavesuggestedthatdemandfordatacenterchipshavesurpassedthegamingsector.see', 'https', '//www.nextplatform.com/2020/08/21/the-local-maxima-ascension-of-datacenter-at-nvidia/', '113likeforothermetricsdescribedpreviously', 'thereisuncertaintyastohowtheseimpactsmightbecalculatedand', 'attributedtomodels', '114seealso', 'https', '//www.un.org/sustainabledevelopment/blog/2016/10/report-inequalities-exacerbate-climate-impacts-', 'on-poor/andhttps', '//blogs.imf.org/2020/12/02/how-artificial-intelligence-could-widen-the-gap-between-rich-and-poor-', 'nations/']",142
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '143', 'fig.27', 'ahypotheticalexampleofamortizedfine-tuningshowingthepointatwhichafoundationmodel', 'inthiscasebertbase', 'willhavelowerenergycoststhanatransformermodeltrainedfromscratch.we', 'estimatetheup-frontenergycostfortrainingbertfromstrubelletal', '[', '2019', ']', 'andcostforfine-tuninga', 'downstreamtaskfromchaudharyetal', '[', '2020', ']', '.wecompareagainstthelinearlyincreasingcostoftraininga', 'transformerfromscratch', 'fromstrubelletal', '[', '2019', ']', '.ifbertisusedforlessthan∼80tasks', 'theup-front', 'energycostsarenotrecovered.afterthatpoint', 'bertismoreenergyefficientthanthemodeltrainedfrom', 'scratch', 'harmstosocietymorebroadlyratherthanforagivenorganizationorcountry.inthiscase𝑉', '𝑀', 'canbeviewedasadistributionandshouldideallybeevenlydistributedacrossthepopulation', 'incaseswherethedistributionishighlyuneven—forexamplewhereallthebenefitsfalltothe', 'modeldesignerwhilealltheharmsfalltopopulationsthatwillneverbenefitfromthemodel—the', 'designershouldspendsubstantiallymoreeffortonmitigationbeforedeployingthemodel', 'thereis', 'ofcourse', 'someuncertaintyinwhichmethodologytousewhenvaluingeachcomponent', 'equation', '7', 'empirical', 'estimate', 'many', 'term', 'range', 'multiple', 'magnitudes', 'depend', 'data', 'source', 'model', 'choice', 'phenomena', 'different', 'mechanismsforevaluatingthesocialcostofcarbon.thekeytakeawayofthiscost-benefitanalysis', 'however', 'isnotthedollarvaluationofeachtermintheequation', 'butrathertheexistenceof', 'relative', 'importance', 'effect', 'goal', 'provide', 'high-level', 'framework', 'beginningtoconsiderthesetrade-offs.futureresearchmaygivemoreguidanceonhowtoquantify', 'eachofthesevalues', 'finally', 'wenotethatthesefactorsshouldalsobeevaluatedoverthelifetimeofthemodel', 'noton', 'aper-runbasis.consideranalternativebaselinemodelthatmustbetrainedfromscratchforevery', 'newtask.thebaselinemaywellrequireanexpensivehyperparametersearchtoachieveequivalent', 'performanceondownstreamtasks.incontrast', 'thefoundationmodelplacesthebruntofthecosts', 'ontheinitialpretrainingprocedure', 'withfine-tuningperhapsbeingmuchsimplerandmoreenergy', 'efficient.overthelifetimeofthefoundationmodel', 'itcouldbemorecarbonefficientthanthe', 'baseline', 'figure27', '.evenmoreefficientadaptationmechanismscouldimprovethisamortization', 'see§4.3', 'adaptation', 'theefficiencyofadaptation', 'however', 'isnotguaranteed.itmaybetruethatsomefoundation', 'modelswillneverbemoreefficientthanaparticularbaseline', 'evenwhenamortizedovermany']",143
Opportunities and Risks of Foundational Models - Stanford.pdf,"['144', 'centerforresearchonfoundationmodels', 'crfm', 'tasks.forexample', 'itcannotbeassumedthatasmallermodelwithfewerparameterswilltrans-', 'latetoenergyefficiencyimprovements.duetoincreasedhyperparametertuningcostsorother', 'optimizations', 'thenumberofparametershasbeenshownnottocorrelatewithenergyefficiency', 'insomecases', '[', 'zhouetal.2020', 'hendersonetal.2020', ']', '.therefore', 'foundationmodeldevelopers', 'shouldrigorouslyassesstheefficiencyoftheirmodelsandadaptationmechanismsbeforebeginning', 'large-scaletrainingefforts', 'theframeworkinthissectionismeanttoguidethereaderinthinkingabouttheenvironmental', 'societal', 'trade-offs', 'train', 'deploy', 'model', 'substantial', 'socialjusticeconsiderationsinvolvedindeployingafoundationmodel', 'discussedin§5.6', 'ethics', '§5.5', 'economics', 'also', 'discuss', 'detail', 'dynamics', 'social', 'welfare', 'algorithm', 'deployment', '5.3.3', 'carbon/energyimpactsshouldbesystematicallyreported', 'acost-benefitanalysiscannotbeconductedunlessresearchersandengineersworkingonfoundation', 'modelsreportthecomputational', 'energy', 'andcarboncostsoftheirmodels.weencouragefoundation', 'modeldevelopers', 'providers', 'andcuratorstoreportthesemetrics', 'aswellaswhatcarbonreduction', 'strategieswereusedinthemakingofthefoundationmodel.see', '[', 'hendersonetal.2020', 'lottick', 'etal.2019', 'lacosteetal.2019', 'schmidtetal.2021', 'anthonyetal.2020', ']', 'forexamplesofacarbon', 'impactstatementandfortoolsthatcanfacilitatethisreporting.forresearchers', 'suchreportingcan', 'occuratpublicationtime', 'butwealsoencourageindustryactorstoadopttransparencymechanisms', 'toreportthesemetricsfortheirdeployedmodels.115', 'thiswillhelpsetpolicyrecommendations', 'withinindustryandacademia', 'aswellashelpdownstreamusersidentifycarbon-friendlyusage', 'patterns.standardizedreportingwillalsoaidindeterminingwhichmodelsareaccessibletothose', 'withlimitedcomputeaccess', 'see§5.6', 'ethicsformorediscussiononaccessibility', 'toencouragemorereportingofenergyandcarbonimpacts', 'wesuggest', 'amongotherstrategies', 'givinggreenbadgesatconferences', 'requiringreportingofrelevantmetricsforsubmissiontocon-', 'ferencevenues', 'lobbyinglarge-scaledeployersoffoundationmodelstoprovidemoretransparency', 'andgenerallyshiftingprofessionalnormsinacademiaandindustrytowardsstandardreportingof', 'thesemetrics', 'seemorediscussiononprofessionalnormsin§5.6', 'ethicsandmorediscussionon', 'reportingmechanismsbyhendersonetal.', '[', '2020', ']', '115asmallsteptowardthishasbeentakenbysomecloudcomputeprovidersthatidentifythemostcarbonfriendly', 'cloudregions.see', 'forexample', 'https', '//cloud.google.com/blog/topics/sustainability/pick-the-google-cloud-region-with-the-', 'lowest-co2']",144
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '145', '5.4', 'legality', 'author', 'neelguha', 'peterhenderson', 'luciazheng', 'markkrass', 'daniele.ho', 'inthissection', 'wedescribehowuslawmayinfluence', 'constrain', 'orfosterthecreationanduse', 'offoundationmodels.116wenotethatthelegallandscapesurroundingalgorithmictoolsremains', 'uncertain.wehighlightissuespertainingto', '1', 'modeltraining', '2', 'liabilityformodelpredictions', '3', 'protectionsformodeloutputs', 'though', 'understand', 'law', 'affect', 'foundation', 'model', 'crucial', 'important', 'recognize', 'law', 'lens', 'evaluate', 'construction', 'maintenance', 'anduseoffoundationmodels.ethicalframeworksarenecessarytounderstandwhere', 'legallypermissibleapplicationsoffoundationmodelsmaystillbeill-advisedfortheharmsthey', 'inflictandarediscussedinmoredepthin§5.6', 'ethicsand§5.1', 'fairness.studyingthepotentialfor', 'misuseandpossiblesecurityconcerns', 'see§5.2', 'misuseand§4.7', 'security', 'iscriticalforpreventing', 'harmfuloutcomesexante', 'asopposedtotheexposttreatmentthatlegalmechanismsoftenprovide', '5.4.1', 'train', 'trainingfoundationmodelswillrequireaccumulatingvastamountsofmulti-modaldata', 'raise', 'questionsarounddatacollectionanddatause', 'first', 'theabilityformodelcreatorstogrowdatasetsviawebscrapingwillbegovernedbythe', 'mannerinwhichcourtswillinterprettermsofserviceprovisionsand', 'notably', 'theu.s.computer', 'fraudandabuseact', 'cfaa', 'whichcriminalizesaccessingaserver', '“', 'withoutauthorization', '”', '[', 'wajert', 'rottman', '2019', ']', 'court', 'conflict', 'question', 'recent', 'case', 'seek', 'clarifythecircumstancesunderwhichwebscrapingmaybebarred.117therestrictivenessofdata', 'accesswouldfundamentallyaffectthediversityofdatapractitionerscanusetotrainfoundation', 'model', '[', 'levendowski2018', ']', 'second', 'muchofthedatacontainedintrainingsetswillbecopyrightedandpotentiallyprotected', 'byintellectualpropertylaw.however', 'copyrightlawrecognizesexceptionswhenindividualsmay', 'bepermittedtousecopyrightedmaterial.118', 'somescholarsbelievethatthelegalpermissibility', 'oftrainingdatasetswilllargelyrestonwhethercourtsinterprettheprocessofmodeltrainingas', '“', 'transformative', '”', 'underfairusedoctrine', '[', 'lemleyandcasey2020', ']', '.thoughthequestionofwhat', 'qualifiesastransformativeishighlycontextdependent', 'thegeneralruleisthattransformative', 'usesarethose', '“', 'thataddsomethingnew', 'withafurtherpurposeordifferentcharacter', 'anddonot', 'substitutefortheoriginaluseofthework', ""''"", '[', 'office2021', ']', '.already', 'therecentlyreleasedgithub', 'copilottoolisbringingtheseargumentstothefore', '[', 'gershgorn2021', ']', 'finally', 'sometrainingdatasetsmayrunafoulofprivacylaws.illinois', 'forinstance', 'enablesindi-', 'vidualstosueforimpropercollectionoruseofbiometricdata', 'e.g.', 'retinaoririsscans', 'fingerprint', 'voiceprints', 'orscansofhandorfacegeometry', '.119foreignprivacylawslikethee.u.', '’', 'sgeneraldata', 'protectionregulation', 'gdpr', '—whichwillaffectamericanmodelcreatorsifdatasetscontain', 'informationfrome.u.citizens—wouldrequiredatasubjectstobeinformedaboutthepurpose', 'data', 'collection', 'issue', 'could', 'arise', 'laws', 'like', 'california', 'consumer', 'protection', 'privacyact', 'ccpa', 'whichprovideindividualswitha', '“', 'righttobeforgotten', '”', 'raisingquestionsas', '116ourperspectiveherecentersonuslawandlegalframeworks.discussionsoftheimplicationsoffoundationmodels', 'withrespecttoothercountriesmayconsequentlytakedifferentperspectives', '117vanburenv.unitedstates,141s.ct.1648', '2021', '118see', 'e.g.', ',17u.s.c§107to112', '119ibmisthedefendantinacurrentclassactionallegingthatibm', '’', 'scollectionanduseofthisdata', 'includingformachine', 'visionpurposes', 'violatesthisstatute.seeclassactioncomplaintat2', 'vancev.int', '’', 'lbus.machinescorp.', 'no.20c577', 'n.d.', 'ill.filedjan.24,2020']",145
Opportunities and Risks of Foundational Models - Stanford.pdf,"['146', 'centerforresearchonfoundationmodels', 'crfm', 'towhethermodelcreatorswillneedto', '“', 'remove', '”', 'trainingdatafrommodels', '[', 'villarongaetal.2018', 'ginartetal.2019', ']', '5.4.2', 'outputliability', 'thoughfoundationmodelsthemselvesaretaskagnostic', 'fine-tunedmodels—ortherepresentations', 'learnedbyfoundationmodelsthemselves—maybeusedfortraditionalpredictiontasks.where', 'task', 'form', 'components', 'larger', 'decision-making', 'systems', 'foundation', 'model', 'thus', 'influence', 'action', 'decisions', 'policies', 'result', 'harm', 'model', 'creators', '—', 'individualsoperatingthem—', 'maybelegallyresponsible', 'embed', 'foundation', 'model', 'physical', 'systems', 'e.g.', 'self-driving', 'cars', 'electric', 'grid', 'man-', 'agement', 'medicaldiagnostics', 'etc', 'mayresultinphysicalharmtoindividuals.here', 'courtswill', 'likelyresolvequestionsofliabilityundertortdoctrine', '[', 'lemleyandcasey2019', 'selbst2020', ']', '.key', 'openquestionsincludetheinterplaybetweentheliabilityofusers', 'foundationmodelproviders', 'andapplicationdevelopers', 'aswellasthestandardscourtswillusetoassesstheriskprofileof', 'foundationmodels.deploymentsinparticularlysensitivedomains', 'e.g.', 'medicine', 'willrequire', 'regulatoryapproval', 'andthedevelopmentofstandardizedprocessestoassesssafety', '[', 'wuetal', '2021g', ']', 'fine-tunedfoundationmodelsthatclassifyindividualsinwaysthatcorrelatewithprotected', 'attribute', 'e.g.', 'race', 'gender', 'mayfacechallengesundercivilrightslaws.scholarshavenotedthat', 'claimsfordisparatetreatmentresultingfromfoundationmodelsmaybebroughtinthecontextof', 'hire', 'house', 'orcreditlending', '[', 'gillisandspiess2019', 'schereretal.2019', ']', '.exactlyhowcourts', 'adjudicate', 'issue', 'far', 'clear', 'scholars', 'note', 'instance', 'court', '’', 'traditionalviewson', '“', 'discrimination', '”', 'wouldactuallypreventmachinelearningpractitionersfrom', 'implementingmanyalgorithmicfairnesstechniques', '[', 'xiang2021', 'hoandxiang2020', ']', '.120', 'u.s.', 'law', 'recognize', 'special', 'privilege', 'limit', 'governmental', 'entities', 'thus', 'use', 'foundationmodelsbygovernmentalentities—atalocal', 'stateorfederallevel—willimplicate', 'specialconsiderations', 'inadditiontoequalprotectionclaims.theuseofmodelsforriskassessment—', 'orinothersettingswhichresultinadeprivationoflife', 'liberty', 'orproperty—willinviteprocedural', 'dueprocessclaims.121whenmodelsareusedbyadministrativeagencies', 'e.g.', 'theenvironmental', 'protectionagency', 'forinstance', 'plaintiffsmayallegethatsuchuseviolatesbasicstandardsofdue', 'process', 'reasonableness/non-arbitrariness', 'andtransparency', '5.4.3', 'legalprotectionsforoutputs', 'modeloutputs—andbyextensionthemodelcreatorsresponsibleforthemodels—mayalsobe', 'affordedcertainlegalprotections.first', 'contentproducedbygenerativemodelsmayimplicate', 'freespeechissues.theextenttowhichcourtswillfindfirstamendmentprotectionsformachine', 'generate', 'content', 'unclear', 'scholars', 'discuss', 'number', 'open', 'question', 'include', 'whether', '“', 'aispeech', '”', 'isprotected', '[', 'massaroetal.2016', ']', 'orifmodeloutputsareineffectthehuman', 'programmer', '’', 'sspeech', '[', 'kajbaf2019', ']', '.othershavenotedthepossibilityofdisclosurerequirements', 'akintosafetydisclosuresforpharmaceuticaldrugsorothersubstances', 'alsoimplicatingspeech', 'doctrine', 'underwhichmodelswouldbeforcedtosharewithlistenersthattheircontentismachine', 'generate', '[', 'lamoandcalo2019', ']', '.theseissuescouldhavewiderangingconsequences', 'affect', 'whetherindividualscanusefoundationmodelstomassproducespeech', 'orwhethermodelcreators', 'couldbeheldliableforcontentgeneratedbyfoundationmodels', '120formoreinformationonhowmodelsmayembedcertainbiases', 'see§5.1', 'fairness', '121proceduraldueprocessrecognizesthatplaintiffsusuallyhavecertainbasicrightsduringanydeliberationthatwill', 'deprivethemoflife', 'liberty', 'orproperty', 'e.g.', 'therighttocross-examineadversewitnesses']",146
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '147', 'second', 'thereisuncertaintyregardingwhomayassertownershipovermodeloutputs.existing', 'copyright', 'law', 'recognize', 'computer', 'program', 'author', 'hence', 'afford', 'copyrightprotectionto', '“', 'work', '”', 'createdbycomputerprograms', '[', 'grimmelmann2015', ']', '.asaresult', 'scholarshaveadvocatedforavarietyofapproaches.somehavearguedthat', 'dependingonthe', 'circumstances', 'boththehumancreatorofaprogramanditshumanusermayhaveviableclaimsto', 'beingthe', '“', 'author', '”', 'oftheprogram', '’', 'soutput', '[', 'ginsburgandbudiardjo2019', ']', 'asmodelsareincreasinglyusedintheprocessof', '“', 'creation', '”', '—fromartisticendeavorstomore', 'mundanesettingslikenewsfilings—disputesovertheownershipofmachinegeneratedcontent', 'willbecomemorecommonplace', 'whileouranalysisaboveonlyskimsthesurfaceofthelegalissuesimplicatedbyfoundation', 'model', 'theresolutionofthesequestionswillbecriticaltotheconstruction', 'use', 'anddeployment', 'offoundationmodels', 'toborrowlarrylessig', '’', 'sphrase', '“', 'codeislaw', '”', '[', 'lessig2000', ']']",147
Opportunities and Risks of Foundational Models - Stanford.pdf,"['148', 'centerforresearchonfoundationmodels', 'crfm', '5.5', 'economics', 'author', 'zanelemunyikwa', 'minalee', 'erikbrynjolfsson', 'foundation', 'model', 'potential', 'substantially', 'improve', 'overall', 'live', 'standards', 'increasingproductivityandinnovation.thesemodelscanbedeployedtosubstituteforhuman', 'labor', 'augmenthumans', 'orhelpinthediscoveryofnewtasksandopportunities', 'whichcanleadto', 'increasedconcentrationofownershipandpower', 'ormoredecentralization.onabroaderlevel', 'resultcanbeeitherincreasedinequalityduetopotentialcentralization', '§5.1', 'fairness', '§5.6', 'ethics', 'ormorebroadlysharedprosperityduetotheeasieradaptationoffoundationmodelsforawide', 'rangeofapplications', '§1', 'introduction', '.theultimateoutcomesonallthesedimensionsarenot', 'dictatedbytechnologyoreconomics', 'butbythechoicesandactionsoftechnologists', 'policymakers', 'managers', 'workers', 'andothermembersofsociety', 'foundationmodelscanbethoughtofaswhateconomistsrefertoasageneral-purposetechnology', '[', 'bresnahanandtrajtenberg1995', ']', '.general-purposetechnologiesrefertotechnologieslikethe', 'steamengineandelectricity', 'whichdrivewavesoftransformationandproductivitygrowthdue', 'totheirpervasiveness', 'improvementovertime', 'andabilitytospawncomplementaryinnovations', 'ahostofproductsandservicesthatrevolvearoundonecoreproduct', '.whilefoundationmodels', 'maynotbepervasiveatthemoment', 'theyseempoisedtobethebasisofwidespreadtechnological', 'innovations', 'andhavethekeyhallmarksofageneral-purposetechnology.asaresult', 'thesemodels', 'arelikelytobeeconomicallyimportant.inconsideringtheimpactoffoundationmodelsonthe', 'economy', 'wewillfocusonthreebroadareasofimpact', 'productivity', 'wageinequality', 'andownership', '5.5.1', 'productivityandinnovation', 'foundationmodelsarelikelytosubstantiallyincreasebothproductivityandinnovation.productiv-', 'itygrowthisoneofthemaincontributingfactorstoboostinglivingstandards', 'asitincreasesthe', 'wealthofnationsandaddressesahostofchallengesfrompovertyandhealthcaretotheenvironment', 'andeducation', 'productivityisdefinedasoutputperunitinput.122onewaytoboostproductivityistoreduce', 'denominator', 'instance', 'enable', 'company', '’', 'advertisements', 'write', 'fewer', 'copywritersorfewerlaborhourspercopywriterlowersthenumberofunitsofinput.productivity', 'canalsobeboostedbyincreasingthenumerator', 'forinstancebyenablingasoftwaredeveloper', 'towritemorecodeinagiventime.ifthegrowthinthenumeratorisgreatenough', 'thiscanlead', 'tomorepeopledevelopingsoftware', 'notfewer', 'evenasproductivityimproves', '[', 'autor2015', ']', '.in', 'many', 'task', 'already', 'observe', 'machine', 'learn', 'systems', 'increase', 'productivity', 'instance', 'anautocompletesystemforclinicaldocumentationreduceskeystrokeburdenofclinical', 'conceptsby67', '%', '[', 'gopinathetal.2020', ']', '.likewise', 'thepotentialforfoundationmodelstoaffect', 'productivityspansalmosteveryindustryandmanyoccupations.consideringlanguagealone', 'analysisofu.s.occupationsusingtheusdepartmentoflabor', '’', 'netdatabaseshowsthatmany', 'occupationsinvolvethetypesoflanguage-relatedworkthatcouldbeaffectedbyfoundationmodels', 'approximately13', '%', 'ofoccupationshaveaprimarytaskthatisrelatedtowriting', 'andthetotalwage', 'billoftheseoccupations', 'annualsalarymultipliedbythenumberofindividualsemployedinthe', 'occupation', 'isover675billiondollars.however', 'thepotentialimpactoffoundationmodelsextends', 'beyondlanguage.theywillalsohaveeffectsondiagnosticimaginginmedicine', 'graphicdesign', '122notethatwhenproperlymeasured', 'productivityisnotjustamatterofcountingunitsproducedorhourswork', 'alsoaccountsforqualitychanges.therefore', 'anincreaseinqualityforagivenamountoflabor', 'suchasmoreinteresting', 'fiction', 'alsocountsasanincreaseinproductivity']",148
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '149', 'music123', 'andmanyothertaskswherepeoplearecreatingsomethingthatissimilartosomething', 'elsethatalreadyexists', '[', 'winkleretal.2019', 'rameshetal.2021', ']', 'perhapsthemostprofound', 'ifstillspeculative', 'effectoffoundationmodelsistheirpotential', 'toenhancecreativityandboosttherateofinnovationitself.forinstance', 'dall·e', '[', 'rameshetal', '2021', ']', 'couldtransformthemarketforillustrationsmuchasinexpensivecamerasrevolutionized', 'photography.ifthesemodelsenablehumanstodevelopnewwaystowritenewsongsandnovels', '§2.5', 'interaction', 'discover', 'variants', 'drug', 'molecules', '§3.1', 'healthcare', 'extend', 'patent', '§3.2', 'law', 'buildinnovativesoftwareapplications', 'ordevelopnewbusinessprocesses', 'thennot', 'onlythelevel', 'ofproductivity', 'buttherateofgrowthofproductivitywouldbeincreased.inthis', 'way', 'foundationmodelshavesomeofthecharacteristicsoftheideasorblueprintsinpaulromer', '’', 'growthmodels', '[', 'romer1990', ']', 'orevenmeta-ideas', 'ideasaboutideas', 'unlikemostother', 'goods', 'arenon-rival', 'thusspeedinggrowth', 'itisworthnotingthatchangesinproductivityarenotalwaysvisibleintheofficialstatistics', 'becausemanyaspectsofinputandoutputaredifficulttomeasure', '[', 'brynjolfssonandcollis2019', ']', 'asaresult', 'thebenefitsandcostsoffoundationmodelswillnotbefullycapturedbytraditional', 'productivitymetrics', 'norbyrelatedmetricslikegrossdomesticproduct', 'gdp', 'orpricelevels', 'averageofcurrentpricesacrosstheentirespectrumofgoodsandservices', '.thisisespeciallytrue', 'forgeneralpurposetechnologieshistorically', 'sincetheyarecatalystsforacascadeofsecondary', 'innovationsthatoftentransformthesetofgoodsandservicesintheeconomy', 'andeventhenature', 'ofproductionandinnovationoveraperiodofyearsorevendecades', '5.5.2', 'wageinequality', 'eveniffoundationmodelsincreaseaverageproductivityorincome', 'thereisnoeconomiclawthat', 'guaranteeseveryonewillbenefit.thisisbecausenotalltaskswillbeaffectedtothesameextent', 'moreimportantly', 'theeffectsoffoundationmodelsonthedemandforlabor', 'andthusemployment', 'andwages', 'canbeeitherpositiveornegative', 'regardlessofproductivitygrowth', '[', 'brynjolfssonand', 'mcafee2011', 'brynjolfssonandmitchell2017', ']', '.whenatechnologysubstitutesforhumanlabor', 'incompletingtasks', 'ittendstoreducedemandfortheworkersdoingthosetasks.thisdepresses', 'employmentandwages.however', 'whenatechnologycomplementslabor', 'orfacilitatesthecreation', 'ofnewopportunitiesortasks', 'ittendstoincreaselabordemand', '[', 'acemogluandrestrepo2019', ']', 'employmentcan', 'andoftendoes', 'goup', 'evenasproductivityincreases.forinstance', 'theinvention', 'oftheairplanecreatedthedemandforanentirelynewoccupation', 'theairlinepilot.inturn', 'developmentofjetengineswascomplementarytohumanpilots', 'furtherincreasingdemandfor', 'them.similarly', 'theeffectsoffoundationmodelsonemployment', 'wag', 'andincomeinequality', 'willdifferdependingonhowtheyareused', 'whiletheindustrialrevolutionmainlytransformedphysicalwork', 'foundationmodelsarelikely', 'totransformtasksinvolvingcognitivework', 'likecontentcreationandcommunication.ingeneral', 'sincefoundationmodelsareintermediaryassetsthatoftenpossessstronggenerativecapabilities', 'weenvisionthattheywillbeabletoaugmenthumansinmanycreativesettings', 'ratherthanreplace', 'humansastherearestillsignificantlimitationsinusingthesemodelsstand-aloneforopen-ended', 'generativetasks', '[', 'seeetal.2019', ']', '.aswedescribein§2.5', 'interaction', 'foundationmodelsmay', 'alsopowersystemsthatuserscanleveragetoco-constructnovelformsofartormoreefficiently', 'prototypenewapplications.fluidhuman-machineandhuman-in-the-loopinteractionwillrequire', 'advance', 'interface', 'design', '§2.5', 'interaction', 'well', 'fundamental', 'improvements', 'interpretability', '§4.11', 'interpretability', 'androbustness', '§4.8', 'robustness', 'ofthesemodels', 'thathumanscanunderstandmodelbehaviorandexpectmodelstoperformwellindiversecontexts', '123https', '//www.landr.com/']",149
Opportunities and Risks of Foundational Models - Stanford.pdf,"['150', 'centerforresearchonfoundationmodels', 'crfm', '5.5.3', 'centralization', 'anotherkeydeterminantoffoundationmodels', '’', 'economicimpactiswhoownsdataandmodels.in', 'particular', 'pushingthefrontieroffoundationmodelshasthusfarprimarilybeenthepurviewof', 'largecorporateentities.asaresult', 'theownershipofdataandmodelsareoftenhighlycentralized', 'leadingtomarketconcentration', '§5.6', 'ethics', '.inturn', 'thiscanleadtosignificantcentralizationof', 'decisionrightsandpower', 'reducingincomeandopportunitiesforthosewhodon', '’', 'thaveownership', 'tocounterbalancethiscentralization', 'therehavebeengrassrootseffortstoopensourceairesearch', 'suchasmasakhane', 'eleutherai', 'andhuggingface', 'orbuildfoundationmodelsthroughdistributed', 'training.however', 'itlikelythatthegapbetweentheprivatemodelsthatindustrycantrainandthe', 'onesthatareopentothecommunitywillremainlargeduetofoundationmodels', '’', 'dependenceon', 'massiveamountofdataandcomputationalresources', '§5.3', 'environment', '.124', '5.5.4', 'otherconsiderations', 'thisshortchapterisnotmeanttobecomprehensiveofalltheeconomiceffectsoffoundation', 'models.inadditiontoaffectingproductivity', 'wageinequality', 'andownership', 'foundationmodels', 'mayalsohavesignificanteffectsonjobqualityandjobsatisfaction.forinstance', 'theymayincrease', 'jobsatisfactionbyautomatingrepetitive', 'uninterestingpartsofwork', 'ordecreasesatisfactionby', 'increasingthepaceofwork', 'therebyinducingmorefrequentburnout.asdiscussedin§5.1', 'fairness', 'and§5.6', 'ethics', 'theycanalsoamplifyandperpetuatebias', 'ofteninunexpectedways', 'orbeused', 'asatoolforreducingit.foundationmodelscanfacilitateglobaltradeandremotework', 'justas', 'earlierusesofmachinetranslationsystemshadsignificanteffectsintheseareas', '[', 'e.g.', 'brynjolfsson', 'etal.2019', ']', '.theremayalsobesignificantenvironmentaleffects', '§5.3', 'environment', 'aswellas', 'unexpectedandunanticipatedeffectsontherateanddirectionofoccupationalchangeandbusiness', 'transformationinaneconomy.morebroadly', 'giventheemergentcapabilitiesoffoundationmodels', 'weshouldexpectnewunknownunknownstoarisethataredifficulttopredict', 'andwhichmay', 'havesubstantialfollow-oneffects.125', 'insummary', 'foundationmodelsarepoisedtobeanimportantgeneral-purposetechnologyofour', 'era.theyhavepotentialtoincreaselivingstandardssubstantially', 'butalsoposerisksofincreasing', 'inequality', 'concentrate', 'power', 'economic', 'implications', 'technologies', 'predetermine', 'butratherdependonhowtechnologists', 'policymakers', 'managers', 'workers', 'otherstakeholdersanswerchallengessuchas', '•', 'howcanweharnessthepotentialoffoundationmodelstoboostproductivity', '?', '•', 'canwedevelopmodelsthatenhancecreativityandboosttherateofinnovation', '?', '•', 'willthebenefitsandcontrolrightsbelimitedtoafeworwidelyshared', '?', 'understandingtheeconomicpotentialofthesesystemsisthefirststeptoguidingthemindirections', 'thatmatchourvalues', '124lambdalabestimatesthatgpt-3trainingcostsover', '$', '4.6m', 'researchanddevelopmentcostsbetween', '$', '11.4mand', '$', '27.6m', 'hardwarerequiredtorungpt-3costsbetween', '$', '100kand', '$', '150kwithoutfactoringinothercosts', 'electricity', 'cool', 'backup', 'etc.', 'andrunningcostsaminimumof', '$', '87kperyear', 'https', '//bdtechtalks.com/2020/09/21/gpt-3-economy-business-model', '125asanexampleofasecondaryeffect', 'considerthattheinventionoftheautomobileinfluencedthedevelopmentand', 'expansionofthesuburbs']",150
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '151', '5.6', 'ethicsofscale', 'author', 'kathleencreel', 'dallascard', 'rosee.wang', 'isabellelevent', 'alextamkin', 'arminw.thomas', 'laurengillespie', 'rishibommasani', 'robreich', 'thewidespreadadoptionoffoundationmodelsposesethical', 'social', 'andpoliticalchallengesin', 'additiontoconcernsaboutincreasedinequity', 'thesubjectof§5.1', 'fairness.inthissection', 'discusssocial', 'political', 'andethicalrisksrelatedtothescaleofapplicationoffoundationmodels', 'ashomogenizationandtheconcentrationofpower', 'thenormsandreleasestrategiesappropriateto', 'addressthem', 'andconcernsaboutthebroaderpoliticaleconomyinwhichfoundationmodelsare', 'developedanddeployed', '5.6.1', 'homogenizationandscale', 'model', 'use', 'across', 'variety', 'domains', 'minimal', 'adaptation', 'strengths', 'weaknesses', 'bias', 'andidiosyncrasiesoftheoriginalmodelwillbeamplified', '§5.1', 'fairness', '.this', 'istrueofthewidespreadadoptionandrelianceonanystandardizedtechnology.similartohowa', 'failureinthemanufacturingofapartusedinmanycarsorairplanescouldhavewidespreadand', 'severeconsequencesacrosssectors', 'abiasorfailureofserviceintrinsictoafoundationmodelcould', 'rippleoutwards.however', 'thecurrentuninterpretability', '§4.11', 'interpretability', 'offoundation', 'modelsandtheirtask-agnostictrainingmakespredicting', 'understand', 'andaddressingthese', 'weaknesseschallenging.if', 'asseemslikely', 'foundationmodelsbecomewidelyadopted', 'foundation', 'modeldevelopersbeargreaterresponsibilitiesofcarethanstandardmodeldevelopers', 'astheir', 'choicesindesignanddeploymenthavewidespreadimplications', '[', 'arendt1987', ']', 'thedefiningfeatureoffoundationmodels—theircapacitytobeusefullyadaptedforamultiplicity', 'oftasks—iswhatmakesthemlikelytobewidelyadoptedforavastrangeofsociallyconsequential', 'tasks.incontrasttothecurrentdistributedandvariedmodelofdecisionmaking', 'employingmany', 'adaptationsofthesamefoundationmodelformultipleautomateddecision-makingtasksmeans', 'thatdecisionsubjectsmayfaceamorehomogeneoussetofjudgmentsrootedintheunderlying', 'foundationmodel', 'algorithmic', 'monoculture', '[', 'kleinberg', 'raghavan', '2021', ']', 'could', 'lead', 'consistent', 'arbitraryrejection', 'mis-classification', 'orill-treatmentofindividualdecisionsubjects', '[', 'gandy2021', ']', 'wewillcallthishomogenization', '[', 'creelandhellman2021', ']', '.forexample', '§4.6.2', 'data-solutions', 'discussesdataqualityissuesthatleadtoundesirablebehavioronsubpopulationsofdata', 'subpopulationscanbeproducedbyanyfilterthatstratifiesthedata', 'includingbysocialgroup', 'see', 'relateddiscussionsin§4.11.1', 'interpretability-behaviorand§4.8.1', 'robustness-advantages', 'untilimprovementsaremadeindataqualitytooling', '§4.6.2', 'data-solutions', 'andtheabilityto', 'identifyslicesofdataonwhichthemodelunder-performs', '[', 'chungetal.2019', 'goeletal.2021', ']', 'foundationmodelmightconsistentlyfailtoprovideaccurateinformationorservicestoasubgroup', 'ofpeople', 'seealso§4.8', 'robustness', 'homogenizationhasthepotentialtoamplifybias', 'tostandardizebias', 'compoundinginjustices', 'ratherthandistributingthem', 'andtoamplifyarbitraryexclusion', '[', 'creelandhellman2021', 'gandy', '2021', ']', '.forexample', 'zhouetal', '[', '2021a', ']', 'havearguedthatbertencodesananglocentricsimilarity', 'metricbydefault', 'onethatcouldbeharmfulifappliedacrosscontextswherefoundationmodels', 'areapplied.theapplicationoffoundationmodelsacrossdomainshasthepotentialtoactasan', 'epistemicallyandculturallyhomogenizingforce', 'spreadingoneimplicitperspective', 'oftenasocially', 'dominantone', 'acrossmultipledomainsofapplication', 'existingtrendsinstandardizationoftrainingcorporaarelikelytobeexacerbatedinfoundation', 'modelsduetothemassivescaleofbothunlabeledandlabeleddataneeded.totheextentthatmodels']",151
Opportunities and Risks of Foundational Models - Stanford.pdf,"['152', 'centerforresearchonfoundationmodels', 'crfm', 'trainonsimilardata', 'theyarelikelytoacquiresimilarpatternsofbehavior', 'bias', '§5.1.3', 'fairness-', 'source', 'anderrors.previoushigh-effortdatacurationandlabelingeffortssuchasimagenethave', 'standardizedtrainingcorpora.indoingso', 'theyhavealsostandardizederrors', 'modelstrainedon', 'imagenetoftenrelyonthesame', '“', 'spuriouscues', '”', '“', 'shortcuts', '”', 'forexampleusingbackground', 'textureslikegreengrasstopredictforegroundobjectclassessuchascows', '[', 'geirhosetal.2020', 'hendrycksetal.2021e', ']', '.despitetheirincreasedrobustnesstomanytypesofdistributionshifts', '§4.8.1', 'robustness-advantages', 'foundationmodelsandotherlargemodelshavebeennoless', 'likelytolearnspuriouscorrelations', '§4.8.2', 'robustness-challenges', 'andarethereforelikelyto', 'learnsimilarerrorsiftrainedonthesamedatasets.similareffectsmayariseduetothechoiceof', 'publiclyavailableunlabeleddata.manyfoundationmodelsaretrainedonunlabeledcorporathat', 'arechosenfortheirconvenienceandaccessibility', 'forexamplepublicinternetdata', '[', 'caswelletal', '2021', ']', 'ratherthantheirquality.however', 'publiclyaccessibledata', 'whetherlabeledorunlabeled', 'isoftenoutweighedbyproprietarydatainthetrainingcorporaofmanyproprietaryfoundation', 'model', 'discuss', '[', 'marr', ']', '§4.6.1', 'data-desiderata', 'therefore', 'research', 'neededontheextenttowhichtrainingonsimilardatahomogenizescorrelationswithinfoundation', 'model', 'extent', 'homogenization', 'might', 'cause', 'uniform', 'failures', 'adapt', 'derivatives', 'model', 'unless', 'constraints', 'apply', 'eliminate', 'behavior', 'adaptation', 'asdiscussedin§4.3.2', 'adaptation-usecases', 'homogenization', 'inevitable', 'model', 'developers', 'intentionally', 'broaden', 'range', 'perspectivesrepresentedintheirdatasets', '§5.1.3', 'fairness-sources', 'moreresearchisneededon', 'thecapacityoffoundationmodelstodeliveradiversityofperspectiveswhenusedforgenerative', 'tasks.forexample', 'shengetal', '[', '2021', ']', 'havedemonstratedthatdialoguesystemsthatadopt', '“', 'personas', '”', 'ofspecificdemographicgroupsbehavedifferentlyonmeasuresofsocialbias.inadditiontochoosing', '“', 'personas', '”', 'withthegoalofavoidingbias', '“', 'personas', '”', 'thatarediversealongavarietyof', 'cognitiveanddemographicaxescouldalsobeusedtogenerateabroaderrangeofcoherentoutputs', 'forgenerativetasks.thereremainmanyopenquestionsabouthowtobalancediversityofoutputs', 'withrelevanceandutilitytoanindividualuser.126', '5.6.2', 'surveillance', 'exclusion', 'andpower', 'akeypremiseoffoundationmodelsisthatmassiveunlabeleddatasetscanbecombinedwithvast', 'computationalresourcestocreateabasisfromwhichnumerousproductscanbederivedfora', 'varietyofapplications.thisparadigmshifthasthepotentialtoaltersocialstructuresandshift', 'power', 'establishingorentrenchingtheinfluenceofmodelcreators', '[', 'zimmerman2020', ']', '.wediscuss', 'threepotentialimplicationsbelow', 'massdatacollectionandsurveillance', 'whereascollectingalabeleddatasettypicallyrequires', 'workingwithdomainexpertsandunderstandingtheproblemswithandlimitationsofsuchdata', 'theneedforexceptionallylargeamountsofdataintrainingfoundationmodelshasencouraged', 'someresearcherstoemphasizequantity', 'ratherthanquality.127', 'thoughpreprocessingcanhelp', 'improvethequalityofthisdata', '[', 'e.g.', 'brownetal.2020', ']', 'thescaleinvolvednecessitatesautomated', 'approach', 'whichmaybebluntorpoorlydocumented', '[', 'dodgeetal.2021', ']', 'althoughthereisanevolvinglandscapeofdataprotectionlegislation', 'e.g.', 'gdprineurope', 'varietyofquestionablepracticescontinuetobeusedinacquiringdata', 'fromopaquepolicies', '[', 'obar', 'andoeldorf-hirsch2020', ']', 'andtheuseof', '“', 'darkpatterns', '”', 'i.e.', 'manipulativeinterfaces', '[', 'narayanan', '126forpossibleapproachestoimplementation', 'seethediscussionsofcontrollablegenerationin', '[', 'keskaretal.2019', ']', '§4.3.2', 'adaptation-usecasesandgeneraldiscussionsin', '[', 'dinanetal.2021', ']', '127forexample', 'dingetal', '[', '2021', ']', 'collected30milliontext-imagepairs', 'chosenottoaddressartefactssuchaswatermarks', 'andwhiteedges', 'despitetheirimpactonmodelquality']",152
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '153', 'etal.2020', ']', 'tooutrightviolationoftermsofservice.indeed', 'thiswasessentiallythestrategytaken', 'byclearviewai—acompanywhichscrapedphotosfromsocialmedia', 'withoutuserconsent', 'andinviolationofplatforms', '’', 'termsofservice', 'forthepurposeofdevelopingfacialclassification', 'software.thecompanywasneverthelessabletosellthistechnologytopolicedepartmentsand', 'otherorganizations', 'inmanycaseswithouttheknowledgeofstatelawmakersordepartmentheads', '[', 'macetal.2021', ']', '.totheextentthattheparadigmoffoundationmodelsincreasesthevalueofbeing', 'firsttohavethelargestpossibledatasetforanyparticulardomain', 'thismayfurtherencourageactors', 'topursueaggressivedatacollection', 'evenwhenthatpursuitislegallyquestionableorcontraryto', 'userexpectations', '[', 'nissenbaum2009', 'zuboff2018', ']', 'theimportanceofdatatofoundationmodelsalsomeansthatorganizationsalreadyengagedin', 'widespreaddatacollectionwillbeinastrongpositiontodevelopsuchmodels', 'andwilllikelyhave', 'incentivetomaintainthisadvantage.totheextentthatderivativeproductscouldthemselvesbe', 'usedtocollectadditionaldata', 'e.g.', 'insurveillanceorhealthdiagnosticapplications', 'developersof', 'foundationmodelsmayseektoensurethattheyobtainownershipofsuchdata.thus', 'eventhough', 'akeyadvantageofthefoundationmodelparadigmistheabilitytogenerateadaptedderivatives', 'thedevelopersoffoundationmodelsmightseektolicensetheirworkinawaythatensuresthat', 'dataflowsbacktothemfromalladaptedderivatives.128', 'concentrationofpower', 'althoughtheabsolutecostofcomputationhasbecomedramatically', 'cheaperovertime', 'thetrainingofthelargestfoundationmodelscurrentlyrequirescomputational', 'resourcesthatputtheirdevelopmentbeyondthereachofallbutafewinstitutionsandorganizations', '§5.3', 'environment', '.thus', 'thequestionofwhohasaccesstotherelevantcomputationalresources', 'anddatawilllikelydeterminewhoisabletoproducecutting-edgefoundationmodelsinthecoming', 'years', 'seealso§5.5.3', 'economics-centralization', 'gpt-3wasatleastpartlyanexperimentinscale', 'showingthatmajorgainscouldbeachievedby', 'scalingupthemodelsize', 'amountofdata', 'andtrainingtime', 'withoutmajormodelinginnovations', 'although', 'extensive', 'ongoing', 'research', 'reduce', 'amount', 'resources', 'require', 'intrainingsuchmodels', 'see§4.2', 'train', 'openai', '’', 'sworksuggeststhattherearestillgains', 'even', 'larger', 'scale', 'efforts', '[', 'kaplan', 'et', 'al', '2020', ']', 'seem', 'plausible', 'organizationsmayseektofollowthispathinotherdomains', 'forexample', 'see', '[', 'lieberetal.2021', ']', 'ifscaledoesturnouttobecriticaltosuccess', 'theorganizationsmostcapableofproducingcompeti-', 'tivefoundationmodelswillbethemostwell-resourced', 'venture-fundedstart-ups', 'already-dominant', 'techgiants', 'andstategovernments.thisraisespotentialconcernsaboutmarketconcentration', 'andmightindicatethekindofincumbentmonopolyoroligopolythatcurrentlyexistsinextreme', 'capital-intensiveindustriessuchasdefenseandsemi-conductormanufacturing', '[', 'carrilandduggan', '2020', ']', 'moreover', 'thiscentralizationofpowerraisesconcernsabouttheabilityofcurrently-marginalized', 'individualsandcommunitiestoparticipateinthedevelopmentofthefoundationmodeldevelop-', 'mentprocess', '[', 'kalluri2020', ']', '.especiallywithintherealmofgovernmentservices', 'theadoptionof', 'foundationmodelscouldfurthertransferdecisionmakingpowerfromgovernmentstocorporate', 'service', 'providers', 'introduce', 'additional', 'barriers', 'due', 'process', 'accountability', '[', 'citron', '2008', ']', '.nevertheless', 'moregrassrootsefforts', 'e.g.', 'masakhane', 'eleutherai', 'huggingface', 'provide', 'encourage', 'alternatives', 'extensive', 'work', 'ways', 'incorporate', 'participatory', 'value-sensitivedesign', '[', 'friedmanandhendry2019', 'prabhakarananddonaldmartin2020', ']', '128asalesssophisticatedexample', 'considerthecreditscoringindustry', 'whichhasbeenabletopositionitselfsuchthat', 'informationflowsbacktocentraldatabrokersaspeopleuseitsproducts', 'asinvettingloanapplications', 'andindividuals', 'havelittlechoicebuttoparticipate', '[', 'lauer2017', ']']",153
Opportunities and Risks of Foundational Models - Stanford.pdf,"['154', 'centerforresearchonfoundationmodels', 'crfm', 'fuelingwidespreadautomateddecision-making', 'recentyearshaveseenadramaticexpan-', 'sionintheuseofautomateddecision-makingsystemsinindustryandgovernment', '[', '’', 'neil2016', 'engstrometal.2020', ']', '.althoughmanyoftheconcernsoversuchautomationarenotspecificto', 'foundationmodels', 'thegenerativeabilitiesofmodelssuchasgpt-3', 'aswellastheimpressive', 'performanceonbenchmarktasks', 'e.g.', 'devlinetal', '[', '2019', ']', 'havethepotentialtopromptaless-than-', 'carefuladoptionofthistechnologyby', 'forexample', 'administrativeagencies', 'manyofwhichlack', 'theexpertisenecessarytounderstandsophisticatedmlsystems', '[', 'caloandcitron2021', ']', '.assuch', 'isespeciallyimportanttocommunicateclearlyabouttherealisticcapabilitiesandlimitationsof', 'foundationmodels', 'mostautomateddecision-makingsystemswillexistaspartsofbroadersociotechnicalsystems', 'inwhichhumansplaykeyroles', '[', 'selbstetal.2018', ']', '.129', 'assuch', 'thereisnoguaranteethateven', 'largeimprovementsinperformanceonstandardizedevaluationswilltranslateintothedesired', 'outcomesintherealworld', 'especiallyifsystemsaredeployedwithoutcarefulconsiderationor', 'ongoingevaluation', '.forexample', 'researchhasshownthatjudgesmayre-imposeracialprejudice', 'ininterpretingtheoutputsofariskassessmentsystem', '[', 'albright2019', ']', 'orotherwiseimposetheir', 'ownbiases', '[', 'stevensonanddoleac2021', ']', '.ongoingevaluationwithproperecologicalvalidity', '[', 'vries', 'etal.2020', ']', 'willbecriticalinthisregard', 'butmaynotstoppotentiallydangerousorcostlysystems', 'frombeingadoptedwithoutadequateevidence', '[', 'ferguson2017', ']', '.researchisongoingonmethods', 'ofrefusal', 'waysforindividualstooptoutofparticipationinfoundationmodelsandtheiradapted', 'derivatives', 'eitherasdataordecisionsubjects', 'withoutrepercussions', '[', 'benjamin2016', ']', 'inshort', 'theexistingproblemswithalgorithmicdecisionmakingwillbeseeninthefunctioning', 'offoundationmodelsoncetheyaredeployed.andtotheextentthatadoptingfoundationmodels', 'acceleratesashiftfromhumantomachinedecisionmaking', 'foundationmodelsaccentuatethecon-', 'cernswithautomation.althoughtherearenotobvioussolutionstothesechallenges', 'itisimportant', 'tomakequestionsabouthowfoundationmodelswillimpactpowerpartoftheconversationabout', 'theircreation', 'tocommunicatewithcivilsocietyorganizations', 'policymakers', 'andcitizensabout', 'thecapabilitiesandlimitationsofsuchsystems', 'andtostriveforbroaderdialogueamongdiverse', 'segmentsofsocietyabouttheadoptionofsuchmodels', '5.6.3', 'norms', 'publicpolicyandformalregulationbylaw', '§5.4', 'legality', 'playanessentialroleincreatingthe', 'infrastructurefortechnologicalinnovationaswellasmitigatingthepotentiallyharmfuleffectsof', 'widelydisseminatedtechnologies.asillustratedbythedecades-longgapbetweenthetuskegee', 'syphilis', 'experiment', 'development', 'research', 'protocols', 'institutions', 'like', 'irb', 'publicpolicytoprotecthumansubjectsandstakeholderstendstolagbehindpublicawarenessand', 'evidenceofharmstothem', '[', 'grady2015', 'stark2012', 'departmentofhealthandwelfare1979', ']', '.asa', 'result', 'societyreliesuponprofessionalnormsforresponsibledevelopmentanddeploymentandthe', 'establishmentofbestpractices', 'normsexistonacontinuumbetweenrecommendationandrequirement.asanascenttechnology', 'thenormsforresponsiblefoundationmodeldevelopmentanddeploymentarenotyetwellestab-', 'lishedateitherstrengthofrecommendation', '[', 'crootof2019', ']', '.inwhatfollowswewilldiscussnorms', 'fordeployedmodels', 'asmodelsforresearchhaveawiderlatitude', 'thosewhowishdevelopersoffoundationmodelstoadoptcertainnormsmightleadbyexample', 'allowingtheirownconductandstatementstorecommendthenorm.asdiscussedin§1.2', 'ecosystem', 'webelievethatuniversitiesandothernonprofitinstitutionshaveanimportantroleinmodeling', 'normsforfoundationmodels.aseducationalinstitutions', 'universitiesareintheuniquepositionto', '129foranextendedstudyofhowhumansinteractwithautomatedjudgements', 'includingdiscussionofbothpositiveand', 'negativeautomationbiases', 'seehidalgo', '[', '2021', ']']",154
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '155', 'encouragethenextgenerationoftheoristsandpractitionerstoconsidertheissuesraisedinthis', 'reportandalsotofosterinterdisciplinaryconversationbetweenresearchersandstudents', '[', 'rogers', '2021', ']', '.universitiesandcollegesmayalsocontributetotheestablishmentofnormsbyauditing', 'existingfoundationmodelsandpublishingtheirfindings', 'institutingethicsreviewboards', '[', 'bernstein', 'etal.2021', ']', 'anddevelopingtheirownfoundationmodels', 'tocreateandadoptnormswillrequireinstitutionalizationinfundingstructures', 'modelreposi-', 'tory', 'releasepractices', 'conferencesubmission', 'andgrantproposalrequirements.130forexample', 'huggingface', '’', 'interface', 'currently', 'encourage', 'post', 'data', 'model', 'card', 'include', 'discussionsofbiasandsocialimpact.131', 'sinceitisnotrequired', 'andperhapssincedataquality', 'workisundervaluedrelativetoitsimportance', '[', 'sambasivanetal.2021', ']', 'fewarefilledout.bias', 'andsocialimpactareincludedinethicsstatementsforconferencesandsomeformsofstandard', 'evaluation', 'asdiscussedin§4.4', 'evaluation', 'butotherwisetreatedasoptionalconsiderationsby', 'someresearchers.thismustchange', 'forsomesociallyconsequentialusecases', 'werecommendlegalstandardsbeestablishedthat', 'require', 'adaptedderivativestoprovablyexhibitcertainproperties', '§5.4', 'legality', '.domainsof', 'specialconcernshouldbedemocraticallydecidedbutarelikelytoincludeallocatinganddistributing', 'governmentservices', 'medicaldiagnosisandmonitoring', 'hire', 'andlending', 'allcontextsinwhich', 'opportunitiesorevenlivesofpeoplerestontheproperfunctioningofanadaptedderivative', 'whatnormsshouldwepromote', 'institutionalize', 'orrequire', '?', 'werecommendafewhere', 'aimprimarilytoencourage', 'dialogueaboutappropriatenormsforthedevelopmentanduseof', 'foundationmodels.priorworkhasoftenfocusedonnormsthatadvocatedocumentation', '[', 'gebru', 'etal.2018', 'benderandfriedman2018', 'mitchelletal.2019', 'dodgeetal.2019', ']', '.becausemanyof', 'thenegativesocialconsequencesthatappearinadownstreamcontextmayinitiallyappeartobe', 'extrinsicorparticulartoausecase', '§5.1', 'fairness', 'documentationandtransparencyareespecially', 'importantforfoundationmodels.currently', 'thosewhoadaptfoundationmodelsthatdocument', 'thebiasesorothernegativefeaturesoftheiradaptedderivativeshavenoautomaticmechanism', 'toreporttheirfindingstothedevelopersofthefoundationmodel.compilingmultiplereportsof', 'relatedproblemsinadaptedderivativesmayallowthemodeldevelopmentteamtodiscoveran', 'intrinsicpropertyofthemodelthatspansmultipleusecases.becausecreatorsofadaptedderivatives', 'oftenrepresentdifferententitiesthanfromfoundationmodeldevelopersorproviders', 'additional', 'reportingstructuresandnormsorregulationwouldbeneededforthistypeoffeedbacktoreach', 'foundationmodeldevelopers.suchfeedbackcouldalsobemadeavailabletothegeneralaudience', 'ofmodelauditors', 'therebymakingauditingandpursuingrecoursemoreaccessible', 'publiccommitmenttonorms', 'standards', 'andcreationofreportingmechanismscouldalsoallow', 'downstreamuserstosubmitfeedbacktofoundationmodelproviders.inordertoenablethis', 'adapt', 'derivativesshouldbeconsistentlylabeledinawaythatallowsimpactedpartiestotraceproblems', 'totheirsource.significanttechnicalandsocialbarriersmayimpedethistracinginpractice', 'suchas', 'privacyconsiderationsandtheproprietarynatureofmanyfoundationmodels', 'butwithoutlabeling', 'itwouldbeimpossible', 'important', 'model', 'developers', 'providers', 'create', 'mechanisms', 'report', 'reportingmechanismscouldbeinformedbysimilarstructuresoncurrentplatforms', 'suchasissue', 'trackingonopensourceprojectsongithub.inparticular', 'thesubmittedissuesshouldbepublicso', 'thatotheruserscanidentifytrendsevenifchangeshavenotyetbeenmadeandsothatdevelopers', 'andproviderscanbeheldaccountableforunaddressedissues.additionalmechanismsareneeded', '130forhelpfuldiscussionofpartialcompliancewith', '“', 'non-compulsoryfairness-consciouspolicy', '”', 'suchasthenormsunder', 'discussionhere', 'seedaietal.', '[', '2021', ']', '131https', '//huggingface.co/docs/datasets/master/']",155
Opportunities and Risks of Foundational Models - Stanford.pdf,"['156', 'centerforresearchonfoundationmodels', 'crfm', 'toescalatetrendsupwardstofoundationmodelproviders.similarsuggestionsregardingtracking', 'issuesintrainingdataarediscussedindinanetal.', '[', '2021', ']', 'and§4.6', 'data', 'holland', 'et', 'al', '[', ']', 'suggest', 'nutrition', 'label', 'helpful', 'model', 'draw', 'label', 'discussionsinconsumerprivacy', '[', 'kelleyetal.2009', ']', '.anutritionlabelincludesbothalistofthe', '“', 'raw', '”', 'ingredientsandthefullnutritionalinformationoftheprocessedfood.sotooamodelcard', '[', 'mitchelletal.2019', ']', 'ornutritionlabelforanadaptedderivativecouldincludebothalistofthe', '“', 'rawmaterials', '”', 'suchastrainingdataandfoundationmodelsused', 'andthefull', '“', 'nutritionalcontent', '”', 'oftheadaptedderivativesuchasitsknowncapacities', 'weaknesses', 'andbiases', 'reportingofthefullpipelineisnecessaryinorderfordatasubjectsandimpactedpartiestotrace', 'harmstotheirsources.however', 'withouttheabilitytoattributeresponsibilityfortheharmtoeither', 'theadaptedderivative', 'thefoundationmodel', 'orboth', 'andwithoutaframeworkforrecourseonce', 'harmhasbeenattributed', 'evenasuccessfultracingofaharmwillbeunlikelytoleadtochangesin', 'themodel', 'seealso§5.1.4', 'fairness-recourse', '.thus', 'significanttechnical', 'policy', 'andlegalwork', 'isneededinordertodevelopframeworksforcommunicatingdata', 'model', 'andderivativecontents', 'tootherexpertsandeventuallytothepublic', 'toattributeresponsibilityforharms', 'andtocreate', 'avenuesforrecourse', '5.6.4', 'releaseandauditing', 'infebruary2019', 'openaiembarkedonanexperiment.byreleasingareduced124mparameter', 'gpt-2', 'sansdatasets', 'theyhopedtobuytime', 'timetotestforbias', 'timetoprepareformisuse', 'timeforsocietytoadapttothepresenceoflargelanguagemodels', '[', 'solaimanetal.2019', ']', '.eight', 'monthslater', 'whenopenaireleasedthefull∼1.5billionparameterversion', 'testinghadexposed', 'somebutbynomeansallofthemodel', '’', 'scapabilitiesandlimitations.whenconsideringsimilar', 'questionstoday', 'thepossibleharmsofrelease', 'centeringprimarilyonmisuse', '§5.2', 'misuse', ',132must', 'beweighedagainstthebenefitoftransparencythatnoclosed-doortestingcanreplicate', 'namely', 'broaderandindependentauditingandaccess', 'audit', 'auditorsprobethelimitationsofcurrentmodelsandsuggestpathstofixingthem', 'well', 'test', 'model', '’', 'adapt', 'derivatives', 'wide', 'variety', 'natural', 'settings', 'policy', 'open', 'access', 'audit', 'allow', 'numerous', 'diverse', 'researchers', 'investigate', 'model', '’', 'sbiases', 'limitations', 'andsecurityvulnerabilities', 'betterinformingacceptableusesofthe', 'modelsandcalibratingappropriatetrust', 'inthem', '[', 'danks2019', 'baier1986', ']', '.133inordertosupport', 'independentauditsoffoundationmodels', 'modeldevelopersorthird-partyintermediariescould', 'hostopenapiaccessforauditors', 'includinggradientaccess', 'andallowaccesstotrainingdata', '[', 'raji', 'andbuolamwini2019', 'rajietal.2020', ']', 'foundationmodelstrainedonproprietarydatainindustryareunlikelytobereleased', 'andthose', 'trainedonprivatedata', 'asinamedicalcontext', 'shouldnotbe.inorderforproprietarymodelsto', 'benefitfromindependentaudits', 'andformodelsubjectstobenefitfromimprovementsprompted', 'byanauditingprocess', 'werecommendthatauditsoccurduringastagedrelease.whilestaged', 'releasemaynotilluminateallpossiblemodelusecases', 'onewaytobroadentherangeofuncovered', 'use', 'case', 'isto', 'enlist', 'aneutral', 'third', 'party', 'decide', 'individuals', 'ororganizations', 'receiveearlyaccessinthestaged-releaseprogram.whenmodeldevelopersdecidewhoshould', 'receive', 'stag', 'access', 'open', 'charge', 'favoritism', 'selective', 'distribution', 'andmanipulatingpublicperceptionoftheirproduct.aneutral', '“', 'stagedreleaseboard', '”', 'orfederal', 'auditors', 'couldprovideabackstopagainstthesefailuremodesandensurethatawiderangeof', '132foranalysisofharmsrelatedtomisuse', 'see', '[', 'rini2017', ']', 'onfakenewsand', '[', 'rini2020', ']', 'ondeepfakes', '133calibratingtrustmayrequireanexplanationcapableofilluminatingfeaturesofthemodelrelevanttotrust', 'suchas', '“', 'discriminatoryuseofasensitivefeature', '”', '[', 'dimanovetal.2020', ']']",156
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '157', 'auditorsandusersareprovidedaccessinordertocapturearangeofdisciplinaryexpertiseand', 'sectorsofsociety.astagedreleaseboardcouldalsomitigateanyperceptionthatauditorswouldbe', 'atriskoflosingtheirearlyaccesstothemodeliftheyshareunflatteringoutputs', 'astheymightbe', 'inastandardstagedreleaseprocess', 'accessandadaptation', 'totheextentthattherearesocialbenefitstofoundationmodels', 'ofmodelsholdsthepotentialtofurtherdistributethem.largelanguagemodelssuchasbertand', 'm-bertarecapableofcross-lingualtransfer', 'which—whenthemodelsareopen-sourced—may', 'allowforadaptationtolanguageswhichotherwisewouldhavetoofewtextsavailable', '[', 'wuand', 'dredze', '2019', 'wang', 'et', 'al', '2020a', ']', 'give', 'number', 'languages', 'currently', 'well', 'serve', 'commercialproviders', 'suchabenefitalonecouldbesubstantial', 'releaseisnotsufficienttodemocratizeaccesstofoundationmodels', 'asthebarrierofcompute', 'powerstillprecludesmanyfrommodifyingorevenloadingfoundationmodels', 'letalonedeveloping', 'theirown.however', 'oneachofthesepointswehaveseensignificantrecenttechnicalimprovement', 'memorytechniquessuchasthezeroredundantoptimizer', 'zero', 'allowresearcherstorunandtrain', 'verylargemodelsonasimplesetup', '[', 'rasleyetal.2020', 'rajbhandarietal.2021', ']', '.techniquessuch', 'asdistillationcouldallowthereleaseofsmaller', 'moretractablemodelsthatrecoupmuchofthe', 'performanceoftheirparentmodelwhilebeingmucheasiertotrain', '[', 'lietal.2020d', ']', '.development', 'oflessenergy-intensivetrainingmethods', 'asdiscussedin§5.3', 'environment', 'couldfurtherspread', 'theabilitytoworkwithreleasedmodels.increasesinefficiencysuchastheco-designofhardware', 'andsoftwareareneededtotrainyetlargermodels', 'asdiscussedin§4.5', 'systems', 'butcouldalsobe', 'usedtolowerthepriceofaccesstocurrentmodels', 'themostpowerfuloftheharms', 'bycontrast', 'arenotobviouslyfueledbyrelease.sophisticated', 'orinstitutionalactorswiththecapacitytoembarkonlarge-scaledisinformation', 'cyberwarfare', 'ortargetedphishingalsoarelikelytohavethecapacitytocreateasimilarmodelifnonewere', 'released.althoughpotentiallysignificant', 'theseharmsshouldnotthereforeweightheavilyona', 'releasecalculus', '[', 'solaimanetal.2019', 'shevlaneanddafoe2020', ']', '.theharmstobeweighedagainst', 'thebenefitsarethosefromlesswell-resourcedactorswhowouldnotbeabletocreatetheirown', 'foundationmodelbutmaybemotivatedtogeneratespamorabuse', 'fakereviews', 'orcheatontests', 'doesthebenefitofreleaseoutweighthepotentialforharmfromactorssophisticatedenoughto', 'useareleasedmodelorapibutnotsophisticatedenoughtocreatetheirown', '?', 'webelievethatthe', 'answerisyes.researchteamswiththeresourcesandconnectionsnecessarytodevelopfoundation', 'modelsarefewinnumber.evencollectively', 'weareunlikelytobenumerousordiverseenoughto', 'imagineallpossiblebeneficialusecasesorallpossibleprobesthatcouldilluminatethecapability', 'surfaceofafoundationmodel', '5.6.5', 'whennottobuild', 'thedevelopmentanddeploymentofpowerfultechnologiesisnotlikegravity', 'anexternalforce', 'thatactsuponus.technologiesreflectasetofchoicesmadebyhumans', 'humanagencyshapesthe', 'technologicalfrontier.itfollowsthattechnologistscanchoosewhennottobuild', 'design', 'ordeploy', 'foundationmodels', '[', 'zimmermann2021', ']', '.thisdecisionneednotbebinary', 'instead', 'onecanrefuse', 'toengageinthedefaultwaybysubvertingembeddedvalues', 'challengingassumptions', 'andshaping', 'researchagendas', '[', 'simpson2007', ']', '.technicalartifacts', 'foundationmodelsincluded', 'areinherently', 'political', 'research', 'socio-political', 'context', 'solely', 'technical', 'one', 'developersandresearchersshouldbecognizantofwhichproblemstheyseektoaddress', 'e.g.', 'toscaleupafoundationmodelversushowtomakeitmorecomputationallyaccessible', 'howthose', 'problemsareformulated', 'andwhotheirsolutionsultimatelyempower', '[', 'rogaway2016', 'winner', '1980', 'passiandbarocas2019', ']', '.weshouldvalueresearchthatseekstomakefoundationmodelsmore']",157
Opportunities and Risks of Foundational Models - Stanford.pdf,"['158', 'centerforresearchonfoundationmodels', 'crfm', 'interpretable', 'accessible', 'sustainable', 'andfair', 'see§4.11', 'interpretability', '§5.3', 'environment', '§5.1', 'fairness', 'byaskingwhennottobuildafoundationmodeloradaptedderivative', 'weareimplicitlyasking', 'notonly', '“', 'whatshouldwebuildornotbuild', '?', '”', 'butalso', '“', 'underwhatconditionsshouldamodel', 'bebuilt', '?', '”', '“', 'whatcriteriaandprinciplesgovernbuilding', '?', '”', 'thefirstquestionstemsfromthe', 'modelview', 'thefollowingquestionsfromtheecosystemview', '§1', 'introduction', 'aninvitationtoconsiderrefusingtobuildisnottantamounttosaying', '“', 'donothing.', '”', 'itisan', 'invitationtomakedeliberateandjudiciouschoicesaboutwhatisworththetime', 'financialresources', 'expertise', 'andenergyusetobuild', 'design', 'anddeploy.ultimately', 'thisisadifficult', 'moralquestion', 'root', 'context', 'value', 'case', 'application', 'adaptive', 'derivatives', 'andalgorithmsandmachinelearningmoregenerally', 'isinappropriate', 'becausethecommunity', 'impactedprotestsorbecausetheadaptivederivativenaivelyexacerbatessystemicissuesthatare', 'betteraddressedwithpublicpolicy', 'additionalfunding', 'orinterdisciplinarycollaborations', '[', 'angwin', 'etal.2016', ']', 'thebelmontreport', 'asappliedtomachinelearninginfloridietal', '[', ']', 'providesonepossible', 'frameworkforthisquestion.drawingfromtheprincipleof', ""''"", 'beneficence', ""''"", '[', 'departmentofhealth', 'andwelfare1979', ']', 'wecanidentifycasestoreconsiderbuildingwhenanadaptivederivativeora', 'researchavenuemightcausemoreharmthangoodorevenprovidenobenefitatall.alternatively', 'theremaybecasesinwhichanadaptivederivativeisbetteratataskonametricofefficiency', 'performance', 'andgeneralization', 'valuesprioritizedinthemachinelearningcommunity', '[', 'birhane', 'etal.2020', ']', 'butanindividual', 'community', 'ororganizationmightchoosetoprioritizeanexisting', 'solutionthathighlightsothervaluessuchashumanconnectionandinterpretability', '[', 'benjamin', ']', '.134indoingso', 'theyexercisetheirautonomy—asexplainedinthebelmontreport', '’', ""''"", 'respect', 'forpersons', ""''"", '—indecidingthatthisisnotanappropriatecontextinwhichtobuild', '[', 'departmentof', 'healthandwelfare1979', ']', 'answeringthequestionofwhennottobuildisamatterofindividualresponsibilityaswellas', 'abroaderprofessionalresponsibility.thedecisionnottobuildsomethingbyoneperson', 'orone', 'team', 'oronecompany', 'invitesthereply', '“', 'butifwedon', '’', 'tbuildthis', 'someoneelsewill', 'andtheymay', 'likelydoitworse.', '”', 'asimpleutilitarianweighingofcomparativeharmsoftheoutcomesofthetwo', 'modelsmissestheimportanceofintegrity.itmattersverymuchwhetherwearetheonesbuilding', 'thebadmodelorwhethersomeoneelseis', '[', 'williams1973', ']', '.individualshavereasonsnottobuild', 'somethingthatgoesagainsttheirvaluesorthattheycannotendorseasrighttobuild', '[', 'korsgaard', '2009', ']', '.however', 'thestructuralenvironmentsocreatedisdifferent.ifevenonecompanydecides', 'tobuildthemosteffectiveversionofanethically-dubiousmodel', 'theyopenthedoorforother', 'companiestoconsidersimilaravenuesofresearch', 'theymakeitcompetitivelydisadvantageous', 'nottopursuetheresearch', '[', 'askelletal.2019', ']', '.whennottobuildisthenacollectivequestionas', 'muchasitisanindividualone', 'requiringthecommunitytoadheretocodesofprofessionalethics', 'andresponsibility', 'intheai/mlcommunitythisinfrastructureisunderdevelopedcomparedtootherfieldssuch', 'asthemedicalfield.althoughprofessionalbodiesliketheassociationforcomputingmachinery', 'acm', 'haveethicsstatements', 'bothindustryandacademialackwidelyusedandacceptedprofes-', 'sionaloaths', 'e.g.', 'thehippocraticoathorthetheobligationoftheengineer', 'regulatorybodies', 'involvedindeploymentandresearch', 'e.g.', 'thefdafordrugs', 'andofficialprotocolsforethics', 'e.g.', 'theirbforresearchinvolvinghumansubjects', '[', 'bernsteinetal.2021', ']', '.theabilityto', 'opt-outcanbeincorporatedintothefoundationmodelecosystematmanystages', 'includingduring', 'dataproduction', 'adaptation', 'anddeployment.asthenormveerstowardscollectinglargerand', '134seealso§4.11.4', 'interpretability-impactsforrelevantdiscussionofimpactsofuninterpretability']",158
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '159', 'largerswathsoftrainingdata', '§4.6', 'data', 'weshouldendeavortomaintaina', ""''"", 'respectforpersons', ""''"", '[', 'departmentofhealthandwelfare1979', ']', 'emphasizingprivacyandconsentaspartofthedata', 'lifecycle.thiswouldrequireinnovationindatamanagementandamoreconcreteunderstand-', 'ing—technicallyandphilosophically—ofinformedconsentonline', 'waysofdocumentingand', 'ensuringthatconsentisrespected', 'andprivacy', 'see§4.6', 'dataforaspecificdatamanagement', 'proposal', '[', 'ohm2014', ']', '.althoughdataandfoundationmodelsarediverseintheirapplications', 'dataparticipantsshouldbeabletoindicatehowthey', 'donotwanttohavetheirdataused.an', 'opt-outconsentmodelfavorsdevelopers', 'asitdoesnotrequirethemtotogetconsentforeachnew', 'unexpectedusecase.importantthenistherighttorevokeconsentgivenvacuouslyforapplications', 'thatarenowbeingpursued', 'butwerenotwhenconsentwasoriginallygiven', '5.6.6', 'conclusion', 'inthissection', 'wehavesurveyedsomeoftheriskstosocietythataccompanythewidespread', 'adoptionoffoundationmodels', 'suchasthehomogenizationofoutcomesandcentralizationof', 'power.developersoffoundationmodelsshouldadoptnormsregardingdevelopment', 'audit', 'releaseoffoundationmodelsinordertoaddresstheserisks', 'aidedbylegislativerequirements', 'individualsshouldbeablerefusetobedataordecisionsubjectsoffoundationsmodelswithout', 'repercussion', 'manyimplicationsoffoundationmodels', '’', 'generativeandinteractivecapacitiesremainunsurveyed', 'here.forexample', '§5.5', 'economicsdiscussesthepotentialgainstoeconomicproductivityfromthe', 'automationofcreativeanddesignwork.however', 'invirtueoftheirgenerativenature', 'foundation', 'modelsmayreplaceworkthatmanypeoplefindmeaningfulandfulfilling', 'suchasgraphicdesign', 'andwriting.wehopethatthescopeofthisreportwillaidothersintheirpursuitofthequestions', 'ofethicsandsocietyunaddressedhere']",159
Opportunities and Risks of Foundational Models - Stanford.pdf,"['160', 'centerforresearchonfoundationmodels', 'crfm', '6', 'conclusion', 'inthisreport', 'wehaveendeavoredtocomprehensivelydiscussmanyofmostcriticalaspectsof', 'foundationmodels', 'rangingfromtheirtechnicalfoundationstotheirsocietalconsequences.inthis', 'way', 'weacknowledgetheunusualapproachtaken', 'wehaveattemptedtoclarifythenatureofa', 'paradigmthatmayonlyhavejustbegun', 'ratherthanwaitingformoretounfoldorthedustto', 'settle.therefore', 'muchstillremainsunclearinspiteofoureffortsandwereiteratethatthisisjust', 'thebeginningofaparadigmshift', 'foundationmodelshaveonlyjustbeguntotransformtheway', 'aisystemsarebuiltanddeployedintheworld.movingforward', 'weviewthisdocumentasserving', 'animportantroleinorientingandframingdialogueonthesemodelsandthisnewparadigmin', 'ai.thatsaid', 'toensuretheresponsibledevelopmentanddeploymentofthesemodelsondurable', 'foundations', 'weenvisioncollaborationbetweendifferentsectors', 'institutions', 'anddisciplinesfrom', 'theonsettobeespeciallycritical', 'acknowledgments', 'would', 'like', 'thank', 'follow', 'people', 'valuable', 'feedback', 'mohit', 'bansal', 'boaz', 'barak', 'yoshuabengio', 'sambowman', 'collinburns', 'nicholascarlini', 'davidchalmers', 'jackclark', 'jeff', 'dean', 'jesse', 'dodge', 'jar', 'dunnmon', 'gabe', 'dupre', 'jason', 'eisner', 'iason', 'gabriel', 'avery', 'hill', 'yacinejernite', 'gabbriellejohnson', 'sarahkreps', 'jaymcclelland', 'preetumnakkiran', 'juliannyarko', 'fernandopereira', 'vinodkumarprabhakaran', 'colinraffel', 'martenvanschijndel', 'ludwigschmidt', 'yoavshoham', 'madalsasingh', 'meghasrivastava', 'jacobsteinhardt', 'emmastrubell', 'qianyang', 'luke', 'zettlemoyer', 'andruiqizhong.inaddition', 'wewouldliketoespeciallythankvanessaparlifor', 'helpingtoorganizethiseffort', 'reference', 'martinabadi', 'paulbarham', 'jianminchen', 'zhifengchen', 'andydavis', 'jeffreydean', 'matthieudevin', 'sanjayghemawat', 'geoffreyirving', 'michaelisard', 'etal.2016.tensorflow', 'asystemforlarge-scalemachinelearning.inproceedingsofthe', '12thusenixsymposiumonoperatingsystemsdesignandimplementation', 'osdi', '.savannah', 'georgia', 'usa', 'jordanabdi', 'ahmedal-hindawi', 'tiffanyng', 'andmarcelapvizcaychipi.2018', 'scopingreviewontheuseofsocially', 'assistiverobottechnologyinelderlycare.bmjopen8,2', 'e018815', 'redietabebe', 'solonbarocas', 'jonkleinberg', 'karenlevy', 'manishraghavan', 'anddavidgrobinson.2020.rolesforcomputing', 'insocialchange.inproceedingsofthe2020conferenceonfairness', 'accountability', 'andtransparency.252–260', 'abubakarabid', 'm.farooqi', 'andj.zou.2021.persistentanti-muslimbiasinlargelanguagemodels.arxivabs/2101.05783', '2021', 'https', '//arxiv.org/abs/2101.05783', 'sergeabiteboul.1997.queryingsemi-structureddata.internationalconferenceondatabasetheory', '1997', 'stevenabney.2007.semisupervisedlearningforcomputationallinguistics', '1sted.', '.chapman', '&', 'hall/crc', 'daronacemoglu.2021.redesigningai.mitpress', 'https', '//books.google.com/books', '?', 'id=hbb6dwaaqbaj', 'daronacemogluandpascualrestrepo.2019.automationandnewtasks', 'howtechnologydisplacesandreinstateslabor', 'journalofeconomicperspectives33,2', '2019', ',3–30', 'accountabilityact.1996.healthinsuranceportabilityandaccountabilityactof1996.publiclaw104', '1996', ',191', 'georgeadam', 'ladislavrampášek', 'zhalehsafikhani', 'petrsmirnov', 'benjaminhaibe-kains', 'andannagoldenberg.2020', 'machinelearningapproachestodrugresponseprediction', 'challengesandrecentprogress.npjprecisiononcology4,1', '2020', ',1–10', 'yossiadi', 'einatkermany', 'yonatanbelinkov', 'oferlavi', 'andyoavgoldberg.2017', 'fine-grainedanalysisofsentence', 'embeddingsusingauxiliarypredictiontasks.ininternationalconferenceonlearningrepresentations', 'steinaerts', 'dietherlambrechts', 'sunitmaity', 'petervanloo', 'bertcoessens', 'frederikdesmet', 'leon-charlestranchevent', 'bartdemoor', 'petermarynen', 'bassemhassan', 'etal.2006', 'geneprioritizationthroughgenomicdatafusion', 'nature', 'biotechnology24,5', '2006', ',537–544', 'sameeragarwal', 'yasutakafurukawa', 'noahsnavely', 'iansimon', 'briancurless', 'stevenmseitz', 'andrichardszeliski.2011', 'buildingromeinaday.commun.acm54,10', '2011', ',105–112', 'sandhiniagarwal', 'gretchenkrueger', 'jackclark', 'alecradford', 'jongwookkim', 'andmilesbrundage.2021.evaluatingclip', 'towardscharacterizationofbroadercapabilitiesanddownstreamimplications.arxivpreprintarxiv:2108.02818', '2021']",160
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '161', 'armenaghajanyan', 'dmytrookhonko', 'mikelewis', 'mandarjoshi', 'huxu', 'gargighosh', 'andlukezettlemoyer.2021', 'htlm', 'hyper-textpre-trainingandpromptingoflanguagemodels.corrabs/2107.06955', '2021', '.arxiv:2107.06955', 'https', '//arxiv.org/abs/2107.06955', 'armenaghajanyan', 'lukezettlemoyer', 'andsonalgupta.2020', 'intrinsicdimensionalityexplainstheeffectivenessof', 'languagemodelfine-tuning.corrabs/2012.13255', '2020', '.arxiv:2012.13255', 'https', '//arxiv.org/abs/2012.13255', 'ashvinagrawal', 'ronychatterjee', 'carlocurino', 'avriliafloratou', 'nehagowdal', 'matteointerlandi', 'alekhjindal', 'kostantinos', 'karanasos', 'subrukrishnan', 'briankroth', 'etal.2019', 'cloudywithhighchanceofdbms', 'a10-yearpredictionfor', 'enterprise-grademl.arxivpreprintarxiv:1909.00084', '2019', 'roxanamagrigoroaieandadrianatapus.2016.developingahealthcarerobotwithpersonalizedbehaviorsandsocial', 'skillsfortheelderly.in201611thacm/ieeeinternationalconferenceonhuman-robotinteraction', 'hri', '.ieee,589–590', 'anuragajay', 'aviralkumar', 'pulkitagrawal', 'sergeylevine', 'andofirnachum.2021.opal', 'offlineprimitivediscoveryfor', 'acceleratingofflinereinforcementlearning.arxivabs/2010.13611', '2021', 'ifeomaajunwa.2019.theparadoxofautomationasanti-biasintervention.cardozol.rev.41', '2019', ',1671', 'hassanakbari', 'linagzheyuan', 'ruiqian', 'wei-hongchuang', 'shih-fuchang', 'yincui', 'andboqinggong.2021', 'vatt', 'transformersformultimodalself-supervisedlearningfromrawvideo', 'audioandtext.arxivpreprintarxiv:2104.11178', '2021', 'guillaumealainandyoshuabengio.2016.understandingintermediatelayersusinglinearclassifierprobes.ininternational', 'conferenceonlearningrepresentations', 'jean-baptistealayrac', 'adriarecasens', 'rosaliaschneider', 'reljaarandjelovic', 'jasonramapuram', 'jeffreydefauw', 'lucas', 'smaira', 'sanderdieleman', 'andandrewzisserman.2020.self-supervisedmultimodalversatilenetworks.neurips2,6', '2020', ',7', 'eaalbadawy', 'asaha', 'andmamazurowski.2018', 'deeplearningforsegmentationofbraintumors', 'impactofcross-', 'institutionaltrainingandtesting.medphys.45', 'alexalbright.2019.ifyougiveajudgeariskscore', 'evidencefromkentuckybaildecisions.', '2019', 'https', '//thelittledataset', 'com/about_files/albright_judge_score.pdf', 'accessed2021-07-18', 'zarqaali', 'johnrobertzibert', 'andsimonfrancisthomsen.2020', 'virtualclinicaltrials', 'perspectivesindermatology', 'dermatology236,4', '2020', ',375–382', 'gordonw.allport.1954.thenatureofprejudice.addison-wesleypublishingcompany', 'https', '//books.google.com/books', '?', 'id=u94xuyrudl4c', 'lailaalrajhi', 'ahmedalamri', 'filipedwanpereira', 'andalexandraicristea.2021.urgencyanalysisoflearners', '’', 'comment', 'anautomatedinterventionprioritymodelformooc.ininternationalconferenceonintelligenttutoringsystems.springer', '148–160', 'sergeialyamkin', 'matthewardi', 'alexandercberg', 'achillebrighton', 'bochen', 'yiranchen', 'hsin-paicheng', 'zichenfan', 'chenfeng', 'bofu', 'etal.2019', 'low-powercomputervision', 'status', 'challenge', 'andopportunities', 'ieeejournalon', 'emergingandselectedtopicsincircuitsandsystems9,2', '2019', ',411–421', 'juliaamann', 'alessandroblasimme', 'effyvayena', 'dietmarfrey', 'andvinceimadai.2020', 'explainabilityforartificial', 'intelligenceinhealthcare', 'amultidisciplinaryperspective.bmcmedicalinformaticsanddecisionmaking20,1', '2020', '1–9', 'americanbarassociation.2004.gideon', '’', 'sbrokenpromise', 'america', '’', 'scontinuingquestforequaljustice.technicalreport', 'americanbarassociation', 'americanbarassociation.2021.nationallawyerpopulationsurvey2021', 'https', '//www.americanbar.org/content/dam/', 'aba/administrative/market_research/2021-national-lawyer-population-survey.pdf', 'saleemaamershi', 'jamesfogarty', 'anddanielweld.2012.regroup', 'interactivemachinelearningforon-demandgroup', 'creationinsocialnetworks.inproceedingsofthesigchiconferenceonhumanfactorsincomputingsystems.acm', 'darioamodei', 'chrisolah', 'jacobsteinhardt', 'paulchristiano', 'johnschulman', 'anddanmané.2016.concreteproblemsin', 'aisafety.arxivpreprintarxiv:1606.06565', 'peteranderson', 'qiwu', 'damienteney', 'jakebruce', 'markjohnson', 'nikosünderhauf', 'ianreid', 'stephengould', 'andanton', 'vandenhengel.2018.vision-and-languagenavigation', 'interpretingvisually-groundednavigationinstructionsinreal', 'environments.incomputervisionandpatternrecognition', 'cvpr', 'jacobandreas.2019', 'measuringcompositionalityinrepresentationlearning', 'internationalconferenceonlearning', 'representations', '2019', 'jacobandreas.2020', 'good-enoughcompositionaldataaugmentation', 'associationforcomputationallinguistics', 'july', '2020', ',7556–7566', 'https', '//doi.org/10.18653/v1/2020.acl-main.676', 'jacobandreas', 'marcusrohrbach', 'trevordarrell', 'anddanklein.2016.neuralmodulenetworks.inproceedingsoftheieee', 'conferenceoncomputervisionandpatternrecognition.39–48', 'marcinandrychowicz', 'filipwolski', 'alexray', 'jonasschneider', 'rachelfong', 'peterwelinder', 'bobmcgrew', 'joshtobin', 'pieterabbeel', 'andwojciechzaremba.2017.hindsightexperiencereplay.arxivpreprintarxiv:1707.01495']",161
Opportunities and Risks of Foundational Models - Stanford.pdf,"['162', 'centerforresearchonfoundationmodels', 'crfm', 'juliaangwin', 'jefflarson', 'suryamattu', 'andlaurenkirchner.2016.machinebias', '’', 'ssoftwareusedacrossthecountry', 'topredictfuturecriminals.andit', '’', 'sbiasedagainstblacks.propublica', 'rohananil', 'vineetgupta', 'tomerkoren', 'kevinregan', 'andyoramsinger.2020.scalablesecondorderoptimizationfor', 'deeplearning.arxivpreprintarxiv:2002.09018', '2020', 'lassef.wolffanthony', 'benjaminkanding', 'andraghavendraselvan.2020.carbontracker', 'trackingandpredictingthe', 'carbonfootprintoftrainingdeeplearningmodels', 'icmlworkshoponchallengesindeployingandmonitoring', 'machinelearningsystems', 'arxiv:2007.03051', 'stanislawantol', 'aishwaryaagrawal', 'jiasenlu', 'margaretmitchell', 'dhruvbatra', 'clawrencezitnick', 'anddeviparikh', '2015.vqa', 'visualquestionanswering.inproceedingsoftheieeeinternationalconferenceoncomputervision.2425–2433', 'mariaantoniakanddavidmimno.2021.badseeds', 'evaluatinglexicalmethodsforbiasmeasurement.inproceedingsof', 'acl2021', 'hannaharendt.1987.collectiveresponsibility.springernetherlands', 'dordrecht,43–50', 'martinarjovsky', 'léonbottou', 'ishaangulrajani', 'anddavidlopez-paz.2019.invariantriskminimization.arxivpreprint', 'arxiv:1907.02893', '2019', 'michaelarmbrust', 'armandofox', 'reangriffith', 'anthonydjoseph', 'randyhkatz', 'andrewkonwinski', 'gunholee', 'davida', 'patterson', 'arielrabkin', 'ionstoica', 'etal.2009.abovetheclouds', 'aberkeleyviewofcloudcomputing.technicalreport', 'technicalreportucb/eecs-2009-28', 'eecsdepartment', 'universityofcalifornia', '....', 'sanjeevarora', 'nadavcohen', 'weihu', 'andyupingluo.2019a', 'implicitregularizationindeepmatrixfactorization.in', 'advancesinneuralinformationprocessingsystems.7411–7422', 'sanjeevarora', 'hrishikeshkhandeparkar', 'mikhailkhodak', 'orestisplevrakis', 'andnikunjsaunshi.2019b', 'atheoretical', 'analysisofcontrastiveunsupervisedrepresentationlearning.arxivpreprintarxiv:1902.09229', '2019', 'sanjeevarora', 'yuanzhili', 'yingyuliang', 'tengyuma', 'andandrejristeski.2016', 'alatentvariablemodelapproachto', 'pmi-basedwordembeddings.transactionsoftheassociationforcomputationallinguistics', 'mikelartetxe', 'sebastianruder', 'anddaniyogatama.2020.onthecross-lingualtransferabilityofmonolingualrepresenta-', 'tions.arxiv:1910.11856', '[', 'cs', ']', 'may2020', 'http', '//arxiv.org/abs/1910.11856', 'euanaashley.2016.towardsprecisionmedicine.naturereviewsgenetics17,9', ',507–522', 'amandaaskell', 'milesbrundage', 'andgillianhadfield.2019', 'theroleofcooperationinresponsibleaidevelopment', 'http', '//arxiv.org/abs/1907.04534', 'davidh.autor.2015.whyaretherestillsomanyjobs', '?', 'thehistoryandfutureofworkplaceautomation.journalof', 'economicperspectives29,3', ',3–30', 'sebastianbach', 'alexanderbinder', 'grégoiremontavon', 'frederickklauschen', 'klaus-robertmüller', 'andwojciechsamek', '2015.onpixel-wiseexplanationsfornon-linearclassifierdecisionsbylayer-wiserelevancepropagation.plosone10,7', 'e0130140', 'claudinebadue', 'rânikguidolini', 'raphaelvivacquacarneiro', 'pedroazevedo', 'viniciusbritocardoso', 'avelinoforechi', 'luanjesus', 'rodrigoberriel', 'thiagomeirelespaixão', 'filipemutz', 'etal.2020.self-drivingcars', 'asurvey.expertsystems', 'withapplications', '2020', ',113816', 'alexeibaevski', 'yuhaozhou', 'abdelrahmanmohamed', 'andmichaelauli.2020.wav2vec2.0', 'aframeworkforself-supervised', 'learningofspeechrepresentations.inadvancesinneuralinformationprocessingsystems', 'h.larochelle', 'm.ranzato', 'r.hadsell', 'm.f.balcan', 'andh.lin', 'eds.', 'vol.33.curranassociates', 'inc.,12449–12460', 'https', '//proceedings.neurips.cc/', 'paper/2020/file/92d1e1eb1cd6f9fba3227870bb6d7f07-paper.pdf', 'dzmitrybahdanau', 'kyunghyuncho', 'andyoshuabengio.2014.neuralmachinetranslationbyjointlylearningtoalignand', 'translate.arxivpreprintarxiv:1409.0473', '2014', 'dzmitrybahdanau', 'felixhill', 'janleike', 'edwardhughes', 's.a.hosseini', 'pushmeetkohli', 'andedwardgrefenstette.2019', 'learningtounderstandgoalspecificationsbymodellingreward.ininternationalconferenceonlearningrepresentations', 'iclr', 'dzmitrybahdanau', 'shikharmurty', 'michaelnoukhovitch', 'thienhuunguyen', 'harmdevries', 'andaaroncourville', 'systematicgeneralization', 'whatisrequiredandcanitbelearned', '?', '.ininternationalconferenceonlearning', 'representations', 'annettebaier.1986.trustandantitrust.ethics96,2', '1986', ',231–260', 'http', '//www.jstor.org/stable/2381376', 'andreabajcsy', 'dylanp.losey', 'm.o', '’', 'malley', 'anda.dragan.2017', 'learningrobotobjectivesfromphysicalhuman', 'interaction.inconferenceonrobotlearning', 'corl', 'bowenbaker', 'i.kanitscheider', 'todormarkov', 'yiwu', 'glennpowell', 'bobmcgrew', 'andigormordatch.2020.emergenttool', 'usefrommulti-agentautocurricula.arxivabs/1909.07528', '2020', 'antonbakhtin', 'laurensvandermaaten', 'justinjohnson', 'lauragustafson', 'androssgirshick.2019.phyre', 'anewbenchmark', 'forphysicalreasoning.advancesinneuralinformationprocessingsystems32', '2019', ',5082–5093', 'jackbandyandnicholasvincent.2021.addressing', ""''"", 'documentationdebt', ""''"", 'inmachinelearningresearch', 'aretrospective', 'datasheetforbookcorpus.arxivpreprintarxiv:2105.05241', '2021']",162
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '163', 'kshitijbansal', 'sarahm.loos', 'markusn.rabe', 'christianszegedy', 'andstewartwilcox.2019.holist', 'anenvironmentfor', 'machinelearningofhigherorderlogictheoremproving.inproceedingsofthe36thinternationalconferenceonmachine', 'learn', 'icml2019,9-15june2019', 'longbeach', 'california', 'usa', 'proceedingsofmachinelearningresearch', 'vol.97', 'kamalikachaudhuriandruslansalakhutdinov', 'eds.', '.pmlr,454–463', 'http', '//proceedings.mlr.press/v97/bansal19a.html', 'yaminibansal', 'galkaplun', 'andboazbarak.2020.forself-supervisedlearning', 'rationalityimpliesgeneralization', 'provably', 'arxivpreprintarxiv:2010.08508', '2020', 'eliasbareinboim', 'juand.correa', 'duliguribeling', 'andthomasicard.2020', 'onpearl', '’', 'shierarchyandthefoundationsof', 'causalinference.technicalreportr-60.causalailab', 'columbiauniversity', 'forthcominginprobabilisticandcausal', 'inference', 'theworksofjudeapearl', 'acmbooks', 'solonbarocas', 'katecrawford', 'aaronshapiro', 'andhannawallach.2017', 'theproblemwithbias', 'allocativeversus', 'representationalharmsinmachinelearning.', 'talkatsigcisconference', 'marcobaroni.2021.ontheproperroleoflinguistically-orienteddeepnetanalysisinlinguistictheorizing.arxivpreprint', 'arxiv:2106.08694', '2021', 'christinebasta', 'martarcosta-jussà', 'andnoecasas.2019.evaluatingtheunderlyinggenderbiasincontextualizedword', 'embeddings.arxivpreprintarxiv:1904.08783', '2019', 'priyambasu', 'tiasasingharoy', 'rakshitnaidu', 'zumrutmuftuoglu', 'sahibsingh', 'andfatemehsadatmireshghallah.2021', 'benchmarkingdifferentialprivacyandfederatedlearningforbertmodels.arxivpreprintarxiv:2106.13973', '2021', 'marybates.2019.healthcarechatbotsareheretohelp.ieeepulse10,3', '2019', ',12–14', 'sarahbatterbury.2012.languagejusticeforsignlanguagepeoples', 'theunconventionontherightsofpersonswith', 'disabilities.languagepolicy11', '082012', 'https', '//doi.org/10.1007/s10993-012-9245-8', 'herbertbay', 'tinnetuytelaars', 'andlucvangool.2006.surf', 'speededuprobustfeatures.ineuropeanconferenceoncomputer', 'vision.springer,404–417', 'danielmbear', 'eliaswang', 'damianmrowca', 'felixjbinder', 'hsiau-yufishtung', 'rtpramod', 'cameronholdaway', 'siruitao', 'kevinsmith', 'lifei-fei', 'etal.2021.physion', 'evaluatingphysicalpredictionfromvisioninhumansandmachines.arxiv', 'preprintarxiv:2106.08261', '2021', 'adamlbeberg', 'daniellensign', 'guhajayachandran', 'sirajkhaliq', 'andvijayspande.2009.folding', 'home', 'lessonsfrom', 'eightyearsofvolunteerdistributedcomputing.in2009ieeeinternationalsymposiumonparallel', '&', 'distributedprocessing', '1–8', 'jthaddeusbeck', 'melissarammage', 'gretchenpjackson', 'anitampreininger', 'irenedankwa-mullan', 'mchristopherroebuck', 'adamtorres', 'helenholtzen', 'sadieecoverdill', 'mpaulwilliamson', 'etal.2020.artificialintelligencetoolforoptimizing', 'eligibilityscreeningforclinicaltrialsinalargecommunitycancercenter.jcoclinicalcancerinformatics4', '2020', ',50–59', 'sarabeery', 'elijahcole', 'andarvigjoka.2020.theiwildcam2020competitiondataset.arxivpreprintarxiv:2004.10340', '2020', 'yonatanbelinkov', 'nadirdurrani', 'fahimdalvi', 'hassansajjad', 'andjamesglass.2017.whatdoneuralmachinetranslation', 'modelslearnaboutmorphology', '?', '.inproceedingsofthe55thannualmeetingoftheassociationforcomputational', 'linguistics', 'volume1', 'longpapers', 'vancouver', 'canada', '.associationforcomputationallinguistics,861–872', 'https', '//doi.org/10.18653/v1/p17-1080', 'kristenbell', 'jennyhong', 'nickmckeown', 'andcatalinvoss.2021', 'thereconapproach', 'anewdirectionformachine', 'learningincriminallaw.berkeleytechnologylawjournal37', '2021', 'izbeltagy', 'matthewepeters', 'andarmancohan.2020', 'longformer', 'thelong-documenttransformer', 'arxivpreprint', 'arxiv:2004.05150', '2020', 'shaiben-david', 'johnblitzer', 'kobycrammer', 'alexkulesza', 'fernandopereira', 'andjenniferwortmanvaughan.2010.a', 'theoryoflearningfromdifferentdomains.machinelearning79,1', '2010', ',151–175', 'kambezhbenam', 'siobhangilchrist', 'andrekleensang', 'anibsatz', 'catherinewillett', 'andqiangzhang.2019.exploring', 'newtechnologiesinbiomedicalresearch.drugdiscoverytoday24,6', '2019', ',1242–1247', 'emilymbender.2011.onachievingandevaluatinglanguage-independenceinnlp.linguisticissuesinlanguagetechnology', '6,3', '2011', ',1–26', 'emilymbenderandbatyafriedman.2018.datastatementsfornaturallanguageprocessing', 'towardmitigatingsystem', 'biasandenablingbetterscience.transactionsoftheassociationforcomputationallinguistics', 'tacl', '6', ',587–604', 'emilym.bender', 'timnitgebru', 'angelinamcmillan-major', 'andshmargaretshmitchell.2021.onthedangersofstochastic', 'parrot', 'canlanguagemodelsbetoobig', '?', '.inproceedingsofthe2021acmconferenceonfairness', 'accountability', 'transparency', 'virtualevent', 'canada', 'facct', '’', '21', '.associationforcomputingmachinery', 'newyork', 'ny', 'usa,610–623', 'https', '//doi.org/10.1145/3442188.3445922', 'emilymbenderandalexanderkoller.2020.climbingtowardsnlu', 'onmeaning', 'form', 'andunderstandingintheageof', 'data.inproceedingsofthe58thannualmeetingoftheassociationforcomputationallinguistics.5185–5198', 'yoshuabengio', 'andrealodi', 'andantoineprouvost.2021.machinelearningforcombinatorialoptimization', 'amethodological', 'tourd', '’', 'horizon.eur.j.oper.res.290,2', '2021', ',405–421', 'https', '//doi.org/10.1016/j.ejor.2020.07.063']",163
Opportunities and Risks of Foundational Models - Stanford.pdf,"['164', 'centerforresearchonfoundationmodels', 'crfm', 'ruhabenjamin.2016.informedrefusal', 'towardajusticebasedbioethics.science', 'technology', '&', 'humanvalues', 'june2016', '967–990', 'ruhabenjamin.2019.raceaftertechnology.politypress', 'tristanbeplerandbonnieberger.2021.learningtheproteinlanguage', 'evolution', 'structure', 'andfunction.cellsystems12', '6', '2021', ',654–669', 'kaustavbera', 'kurtaschalper', 'davidlrimm', 'vamsidharvelcheti', 'andanantmadabhushi.2019.artificialintelligence', 'indigitalpathology—newtoolsfordiagnosisandprecisiononcology.naturereviewsclinicaloncology16,11', '2019', '703–715', 'elikabergelsonanddanielswingley.2012.at6–9months', 'humaninfantsknowthemeaningsofmanycommonnouns', 'proceedingsofthenationalacademyofsciences109,9', '2012', ',3253–3258', 'richardberk', 'hodaheidari', 'shahinjabbari', 'michaelkearns', 'andaaronroth.2021.fairnessincriminaljusticeriskassess-', 'ments', 'thestateoftheart.sociologicalmethods', '&', 'research50,1', '2021', ',3–44', 'https', '//doi.org/10.1177/0049124118782533', 'felixberkenkamp', 'matteoturchetta', 'angelap.schoellig', 'andandreaskrause.2017', 'safemodel-basedreinforcement', 'learningwithstabilityguarantees.inadvancesinneuralinformationprocessingsystems', 'neurips', 'michaels.bernstein', 'margaretlevi', 'davidmagnus', 'betsyrajala', 'debrasatz', 'andcharlawaeiss.2021.esr', 'ethicsand', 'societyreviewofartificialintelligenceresearch', 'http', '//arxiv.org/abs/2106.11521', 'kathryndbettsandkylerjaep.2017.thedawnoffullyautomatedcontractdrafting', 'machinelearningbreathesnewlife', 'intoadecades-oldpromise.dukel.', '&', 'tech.rev.15', ',216', 'urmilbharti', 'deepalibajaj', 'hunarbatra', 'shreyalalit', 'shwetalalit', 'andaayushigangwani.2020.medbot', 'conversational', 'artificialintelligencepoweredchatbotfordeliveringtele-healthaftercovid-19.in20205thinternationalconferenceon', 'communicationandelectronicssystems', 'icces', '.ieee,870–875', 'i.biederman.1972.perceivingreal-worldscenes.science', 'newyork', 'n.y.', '177,4043', 'july1972', ',77–80', 'https', '//doi.org/10', '1126/science.177.4043.77', 'battistabiggio', 'iginocorona', 'davidemaiorca', 'blainenelson', 'nedimšrndić', 'pavellaskov', 'giorgiogiacinto', 'andfabio', 'roli.2013.evasionattacksagainstmachinelearningattesttime.injointeuropeanconferenceonmachinelearningand', 'knowledgediscoveryindatabases.387–402', 'battistabiggio', 'blainenelson', 'andpavellaskov.2012.poisoningattacksagainstsupportvectormachines.ininternational', 'conferenceonmachinelearning', 'icml', '.1467–1474', 'abebabirhane', 'pratyushakalluri', 'dallascard', 'williamagnew', 'ravitdotan', 'andmichellebao.2020.theunderlyingvalues', 'ofmachinelearningresearch.', '2020', 'https', '//drive.google.com/file/d/1tjrm3bf1hxv8iupsiccm1iazitgp-gzj/view', 'christopherm.bishop.2006.patternrecognitionandmachinelearning.springer', 'erdembiyikanddorsasadigh.2018.batchactivepreference-basedlearningofrewardfunctions.inconferenceonrobot', 'learn', 'corl', 'mikołaj', 'bińkowski', 'danica', 'j.', 'sutherland', 'michael', 'arbel', 'arthur', 'gretton', 'demystify', 'mmd', 'gans', 'arxiv:1801.01401', '[', 'stat.ml', ']', 'guyblanc', 'nehagupta', 'gregoryvaliant', 'andpaulvaliant.2019.implicitregularizationfordeepneuralnetworksdrivenby', 'anornstein-uhlenbecklikeprocess.arxivpreprintarxiv:1904.09080', '2019', 'johnblitzer', 'ryanmcdonald', 'andfernandopereira.2006.domainadaptationwithstructuralcorrespondencelearning', 'inempiricalmethodsinnaturallanguageprocessing', 'emnlp', 'sulinblodgett', 'solonbarocas', 'haldauméiii', 'andhannawallach.2020.language', 'technology', 'ispower', 'acriticalsurvey', '“', 'bias', '”', 'innlp.inproceedingsofthe58thannualmeetingoftheassociationforcomputationallinguistics.association', 'forcomputationallinguistics,5454–5476', 'https', '//doi.org/10.18653/v1/2020.acl-main.485', 'sulinblodgett', 'lisagreen', 'andbrendano', '’', 'connor.2016.demographicdialectalvariationinsocialmedia', 'acasestudy', 'ofafrican-americanenglish.inempiricalmethodsinnaturallanguageprocessing', 'emnlp', '.1119–1130', 'sulinblodgett', 'gilsinialopez', 'alexandraolteanu', 'robertsim', 'andhannawallach.2021.stereotypingnorwegiansalmon', 'aninventoryofpitfallsinfairnessbenchmarkdatasets.inproceedingsofthe59thannualmeetingoftheassociationfor', 'computationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing', 'volume1', 'long', 'paper', '.associationforcomputationallinguistics', 'online,1004–1015', 'https', '//doi.org/10.18653/v1/2021.acl-long.81', 'sulinblodgettandbrendano', '’', 'connor.2017', 'racialdisparityinnaturallanguageprocessing', 'acasestudyofsocial', 'mediaafrican-americanenglish.infairness', 'accountability', 'andtransparencyinmachinelearning', 'fat/ml', 'workshop', 'kdd', 'thomasbock.2007.constructionrobotics.autonomousrobots22,3', '2007', ',201–209', 'tolgabolukbasi', 'kai-weichang', 'jamesyzou', 'venkateshsaligrama', 'andadamtkalai.2016', 'manistocomputer', 'programmeraswomanistohomemaker', '?', 'debiasingwordembeddings.inadvancesinneuralinformationprocessing', 'systems', 'd.lee', 'm.sugiyama', 'u.luxburg', 'i.guyon', 'andr.garnett', 'eds.', 'vol.29.curranassociates', 'inc', 'https', '//proceedings.neurips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-paper.pdf']",164
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '165', 'michaeljbommarito', 'danielmartinkatz', 'andericmdetterman.2018.lexnlp', 'naturallanguageprocessingandinformation', 'extractionforlegalandregulatorytexts', 'arxiv:1806.03688', '[', 'cs.cl', ']', 'rishibommasani', 'kellydavis', 'andclairecardie.2020', 'interpretingpretrainedcontextualizedrepresentationsvia', 'reductionstostaticembeddings.inproceedingsofthe58thannualmeetingoftheassociationforcomputationallinguistics', 'associationforcomputationallinguistics', 'online,4758–4781', 'https', '//doi.org/10.18653/v1/2020.acl-main.431', 'rishibommasani', 'stevenwu', 'andxandaschofield.2019', 'towardsprivatesynthetictextgeneration.inneurips2019', 'machinelearningwithguaranteesworkshop', 'paulboniol', 'georgepanagopoulos', 'christosxypolopoulos', 'rajaaelhamdani', 'davidrestrepoamariles', 'andmichalis', 'vazirgiannis.2020.performanceinthecourtroom', 'automatedprocessingandvisualizationofappealcourtdecisionsin', 'france.arxivpreprintarxiv:2006.06251', '2020', 'antoinebosselut', 'omerlevy', 'ariholtzman', 'c.ennis', 'd.fox', 'andyejinchoi.2018', 'simulatingactiondynamicswith', 'neuralprocessnetworks.', 'antoinebosselut', 'hannahrashkin', 'maartensap', 'chaitanyamalaviya', 'a.çelikyilmaz', 'andyejinchoi.2019', 'comet', 'commonsensetransformersforautomaticknowledgegraphconstruction.inacl', 'nickbostromandmilanmcirkovic.2011.globalcatastrophicrisks.oxforduniversitypress', 'léonbottou.2014.frommachinelearningtomachinereasoning.machinelearning94,2', '2014', ',133–149', 'lucasbourtoule', 'varunchandrasekaran', 'christopherachoquette-choo', 'hengruijia', 'adelintravers', 'baiwuzhang', 'david', 'lie', 'andnicolaspapernot.2019.machineunlearning.arxivpreprintarxiv:1912.03817', '2019', 'williamgbowen.2012.the', '“', 'costdisease', '”', 'inhighereducation', 'istechnologytheanswer', '?', 'thetannerlecturesstanford', 'university', '2012', 'samuelr.bowmanandgeorgedahl.2021.whatwillittaketofixbenchmarkinginnaturallanguageunderstanding', '?', '.in', 'proceedingsofthe2021conferenceofthenorthamericanchapteroftheassociationforcomputationallinguistics', 'human', 'languagetechnologies.associationforcomputationallinguistics', 'online,4843–4855', 'https', '//doi.org/10.18653/v1/2021', 'naacl-main.385', 'jamesbradbury', 'royfrostig', 'peterhawkins', 'matthewjamesjohnson', 'chrisleary', 'dougalmaclaurin', 'georgenecula', 'adampaszke', 'jakevanderplas', 'skyewanderman-milne', 'andqiaozhang.2018.jax', 'composabletransformationsof', 'python+numpyprograms', 'http', '//github.com/google/jax', 'jonathanbragg', 'armancohan', 'kylelo', 'andizbeltagy.2021', 'flex', 'unifyingevaluationforfew-shotnlp', 'arxiv', 'abs/2107.07170', '2021', 'gwernbranwen.2020.gpt-3creativefiction.', '2020', 'lukebreitfeller', 'emilyahn', 'davidjurgens', 'andyuliatsvetkov.2019', 'findingmicroaggressionsinthewild', 'acase', 'forlocatingelusivephenomenainsocialmediaposts.inproceedingsofthe2019conferenceonempiricalmethodsin', 'naturallanguageprocessingandthe9thinternationaljointconferenceonnaturallanguageprocessing', 'emnlp-ijcnlp', 'associationforcomputationallinguistics', 'hongkong', 'china,1664–1674', 'https', '//doi.org/10.18653/v1/d19-1176', 'raymondhbrescia', 'waltermccarthy', 'ashleymcdonald', 'kellanpotts', 'andcassandrarivais.2014.embracingdisruption', 'howtechnologicalchangeinthedeliveryoflegalservicescanimproveaccesstojustice.alb.l.rev.78', '2014', ',553', 'timothyf.bresnahanandm.trajtenberg.1995.generalpurposetechnologies', '’', 'enginesofgrowth', '’', '?', 'journalofeconometrics', '65,1', '1995', ',83–108', 'https', '//doi.org/10.1016/0304-4076', '94', '01598-t', 'marilynnb.brewerandwilliamd.crano.2014.researchdesignandissuesofvalidity', '2ed', '.cambridgeuniversitypress', '11–26', 'https', '//doi.org/10.1017/cbo9780511996481.005', 'liamkofibright', 'danielmalinsky', 'andmorganthompson.2016.causallyinterpretingintersectionalitytheory.philosophy', 'ofscience83,1', 'jan.2016', ',60–81', 'https', '//doi.org/10.1086/684173', 'andrewbrock', 'jeffdonahue', 'andkarensimonyan.2018', 'largescalegantrainingforhighfidelitynaturalimage', 'synthesis.ininternationalconferenceonlearningrepresentations', 'mattbrockman.2020.math-gpt_prompts', 'http', '//gptprompts.wikidot.com/logic', 'math', '#', 'toc5', 'uriebronfenbrenner.1977.towardanexperimentalecologyofhumandevelopment.americanpsychologist32', '1977', '513–531', 'r.brooks.2002.fleshandmachines', 'howrobotswillchangeus', 'tomb.brown', 'benjaminmann', 'nickryder', 'melaniesubbiah', 'jaredkaplan', 'prafulladhariwal', 'arvindneelakantan', 'pranav', 'shyam', 'girishsastry', 'amandaaskell', 'sandhiniagarwal', 'arielherbert-voss', 'gretchenkrueger', 'tomhenighan', 'rewon', 'child', 'adityaramesh', 'danielm.ziegler', 'jeffreywu', 'clemenswinter', 'christopherhesse', 'markchen', 'ericsigler', 'mateusz', 'litwin', 'scottgray', 'benjaminchess', 'jackclark', 'christopherberner', 'sammccandlish', 'alecradford', 'ilyasutskever', 'darioamodei.2020.languagemodelsarefew-shotlearners.arxivpreprintarxiv:2005.14165', '2020', 'erikbrynjolfssonandavinashcollis.2019.howshouldwemeasurethedigitaleconomy', '?', 'focusonthevaluecreated', 'justthepricespaid.harvardbusinessreview97,6', '2019', ',140–', 'erikbrynjolfsson', 'xianghui', 'andmengliu.2019.doesmachinetranslationaffectinternationaltrade', '?', 'evidencefroma', 'largedigitalplatform.managementscience65,12', 'dec2019', ',5449–5460', 'https', '//doi.org/10.1287/mnsc.2019.3388']",165
Opportunities and Risks of Foundational Models - Stanford.pdf,"['166', 'centerforresearchonfoundationmodels', 'crfm', 'erikbrynjolfssonandandrewmcafee.2011.raceagainstthemachine', 'erikbrynjolfssonandtommitchell.2017.whatcanmachinelearningdo', '?', 'workforceimplications.science358,6370', '1530–1534', 'sébastienbubeckandmarksellke.2021.auniversallawofrobustnessviaisoperimetry.arxivpreprintarxiv:2105.12806', '2021', 'benbuchanan', 'andrewlohn', 'micahmusser', 'andkaterinasedova.2021.truth', 'lie', 'andautomation', 'howlanguagemodels', 'couldchangedisinformation.centerforsecurityandemergingtechnology', 'https', '//doi.org/10.51593/2021ca003', 'joybuolamwiniandtimnitgebru.2018.gendershades', 'intersectionalaccuracydisparitiesincommercialgenderclassifica-', 'tion.inconferenceonfairness', 'accountabilityandtransparency.77–91', 'christopherburr', 'nellocristianini', 'andjamesladyman.2018.ananalysisoftheinteractionbetweenintelligentsoftware', 'agentsandhumanusers.mindsandmachines28,4', ',735–774', 'jennaburrell.2016.howthemachine', '‘', 'think', '’', 'understandingopacityinmachinelearningalgorithms.bigdata', '&', 'society', '3,1', 'jan.2016', ',205395171562251.', 'https', '//doi.org/10.1177/2053951715622512', 'danielbuschek', 'martinzurn', 'andmalineiband.2021.theimpactofmultipleparallelphrasesuggestionsonemailinput', 'andcompositionbehaviourofnativeandnon-nativeenglishwriters.inproceedingsofthe2021chiconferenceon', 'humanfactorsincomputingsystems', 'jamesecabral', 'abhijeetchavan', 'thomasmclarke', 'andjohngreacen.2012.usingtechnologytoenhanceaccesstojustice', 'harv.jl', '&', 'tech.26', '2012', ',241', 'tianlecai', 'ruiqigao', 'jasondlee', 'andqilei.2021.atheoryoflabelpropagationforsubpopulationshift.arxivpreprint', 'arxiv:2102.11203', '2021', 'aylin', 'caliskan', 'joanna', 'j.', 'bryson', 'arvind', 'narayanan', 'semantics', 'derive', 'automatically', 'language', 'corpora', 'contain', 'human-like', 'bias', 'science', '356', '6334', '183–186', 'https', '//doi.org/10.1126/science.aal4230', 'arxiv', 'https', '//science.sciencemag.org/content/356/6334/183.full.pdf', 'ryancaloanddaniellek.citron.2021.theautomatedadministrativestate', 'acrisisoflegitimacy.emorylawjournal', '40', '2021', '.issue4', 'https', '//scholarlycommons.law.emory.edu/elj/vol70/iss4/1', 'diogomcamacho', 'katherinemcollins', 'ranikpowers', 'jamesccostello', 'andjamesjcollins.2018', 'next-generation', 'machinelearningforbiologicalnetworks.cell173,7', ',1581–1592', 'nickcammarata', 'shancarter', 'gabrielgoh', 'chrisolah', 'michaelpetrov', 'ludwigschubert', 'chelseavoss', 'benegan', 'sweekiatlim.2020.thread', 'circuits.distill', '2020', 'https', '//doi.org/10.23915/distill.00024https', '//distill.pub/2020/circuits', 'nicoladecao', 'wilkeraziz', 'andivantitov.2021.editingfactualknowledgeinlanguagemodels', 'arxiv:2104.08164', '[', 'cs.cl', ']', 'qingqingcao', 'arunabalasubramanian', 'andniranjanbalasubramanian.2020', 'towardsaccurateandreliableenergy', 'measurementofnlpmodels.arxivpreprintarxiv:2010.05248', '2020', 'stevencao', 'nikitakitaev', 'anddanklein.2019.multilingualalignmentofcontextualwordrepresentations.ininternational', 'conferenceonlearningrepresentations', 'yinzhicaoandjunfengyang.2015.towardsmakingsystemsforgetwithmachineunlearning.in2015ieeesymposiumon', 'securityandprivacy.ieee,463–480', 'yangtristacaoandhaldauméiii.2020', 'towardgender-inclusivecoreferenceresolution.inproceedingsofthe58th', 'annualmeetingoftheassociationforcomputationallinguistics.associationforcomputationallinguistics', 'online', '4568–4595', 'https', '//doi.org/10.18653/v1/2020.acl-main.418', 'nicholascarlini.2021.poisoningtheunlabeleddatasetofsemi-supervisedlearning.inusenixsecuritysymposium', 'nicholascarlini', 'changliu', 'úlfarerlingsson', 'jernejkos', 'anddawnsong.2019.thesecretsharer', 'evaluatingandtesting', 'unintendedmemorizationinneuralnetworks.inusenixsecuritysymposium.267–284', 'nicholascarliniandandreasterzis.2021.poisoningandbackdooringcontrastivelearning.arxivpreprintarxiv:2106.09667', '2021', 'nicholascarlini', 'floriantramèr', 'ericwallace', 'matthewjagielski', 'arielherbert-voss', 'katherinelee', 'adamroberts', 'tom', 'brown', 'dawnsong', 'úlfarerlingsson', 'alinaoprea', 'andcolinraffel.2021.extractingtrainingdatafromlargelanguage', 'models.inusenixsecuritysymposium', 'yaircarmon', 'aditiraghunathan', 'ludwigschmidt', 'percyliang', 'andjohnc.duchi.2019', 'unlabeleddataimproves', 'adversarialrobustness.inadvancesinneuralinformationprocessingsystems', 'neurips', 'mathildecaron', 'hugotouvron', 'ishanmisra', 'herv', '’', 'ej', '’', 'egou', 'j.mairal', 'piotrbojanowski', 'andarmandjoulin.2021.emerging', 'propertiesinself-supervisedvisiontransformers.arxivabs/2104.14294', '2021', 'rodrigocarrilandmarkduggan.2020.theimpactofindustryconsolidationongovernmentprocurement', 'evidencefrom', 'departmentofdefensecontracting.journalofpubliceconomics184', '2020', ',104141.', 'https', '//doi.org/10.1016/j.jpubeco', '2020.104141', 'jimmycarter.1978.excerptsfromcarter', '’', 'sspeechtothebarassociation.thenewyorktimes', 'may1978', 'shancarter', 'zanarmstrong', 'ludwigschubert', 'ianjohnson', 'andchrisolah.2019.activationatlas.distill4,3', '2019', 'e15']",166
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '167', 'isaaccaswell', 'juliakreutzer', 'lisawang', 'ahsanwahab', 'daanvanesch', 'nasanbayarulzii-orshikh', 'allahseratapo', 'nishant', 'subramani', 'artemsokolov', 'claytonesikasote', 'monangsetyawan', 'supheakmungkolsarin', 'sokharsamb', 'benoîtsagot', 'clararivera', 'annetterios', 'isabelpapadimitriou', 'salomeyosei', 'pedrojavierortizsuárez', 'iroroorife', 'kelechiogueji', 'rubungoandreniyongabo', 'toanq.nguyen', 'mathiasmüller', 'andrémüller', 'shamsuddeenhassanmuhammad', 'nanda', 'muhammad', 'ayandamnyakeni', 'jamshidbekmirzakhalov', 'tapiwanashematangira', 'colinleong', 'nzelawson', 'sneha', 'kudugunta', 'yacinejernite', 'mathiasjenny', 'orhanfirat', 'bonaventuref.p.dossou', 'sakhiledlamini', 'nisansadesilva', 'sakineçabukballı', 'stellabiderman', 'alessiabattisti', 'ahmedbaruwa', 'ankurbapna', 'pallavibaljekar', 'israelabebe', 'azime', 'ayodeleawokoya', 'duyguataman', 'orevaogheneahia', 'oghenefegoahia', 'swetaagrawal', 'andmofetoluwa', 'adeyemi.2021', 'qualityataglance', 'anauditofweb-crawledmultilingualdatasets', 'arxivabs/2103.12028', '2021', 'https', '//arxiv.org/abs/2103.12028', 'rahmachaabouni', 'robertodessì', 'andeugenekharitonov.2021.cantransformersjumparoundrightinnaturallanguage', '?', 'assessingperformancetransferfromscan.arxivpreprintarxiv:2107.01366', '2021', 'krishnachaitanya', 'ertuncerdil', 'neeravkarani', 'andenderkonukoglu.2020', 'contrastivelearningofglobalandlocal', 'featuresformedicalimagesegmentationwithlimitedannotations.advancesinneuralinformationprocessingsystems33', '2020', 'benjaminchaix', 'jean-emmanuelbibault', 'arthurpienkowski', 'guillaumedelamon', 'arthurguillemassé', 'pierrenectoux', 'andbenoîtbrouard.2019.whenchatbotsmeetpatients', 'one-yearprospectivestudyofconversationsbetweenpatients', 'withbreastcancerandachatbot.jmircancer5,1', '2019', 'e12856', 'iliaschalkidis', 'ionandroutsopoulos', 'andnikolaosaletras.2019.neurallegaljudgmentpredictioninenglish.arxivpreprint', 'arxiv:1906.02059', '2019', 'iliaschalkidis', 'manosfergadiotis', 'prodromosmalakasiotis', 'nikolaosaletras', 'andionandroutsopoulos.2020.legal-bert', 'themuppetsstraightoutoflawschool.arxivpreprintarxiv:2010.02559', '2020', 'robertchallen', 'joshuadenny', 'martinpitt', 'lukegompels', 'tomedwards', 'andkrasimiratsaneva-atanasova.2019.artificial', 'intelligence', 'biasandclinicalsafety.bmjquality', '&', 'safety28,3', '2019', ',231–237', 'mahawagaarachchigepathumchamikara', 'peterbertok', 'ibrahimkhalil', 'dongxiliu', 'andseyitcamtepe.2021.privacy', 'preservingdistributedmachinelearningwithfederatedlearning.computercommunications171', '2021', ',112–125', 'muthukumarchandrasekaranandmin-yenkan.2019', 'whentoreply', '?', 'contextsensitivemodelstopredictinstructor', 'interventionsinmoocforums.arxivpreprintarxiv:1905.10851', '2019', 'eshwarchandrasekharan', 'mattiasamory', 'shagunjhaver', 'huntercharvat', 'amybruckman', 'clifflampe', 'jacobeisenstein', 'ericgilbert.2018.theinternet', '’', 'shiddenrules', 'anempiricalstudyofredditnormviolationsatmicro', 'meso', 'andmacro', 'scales.proc.acmhum.-comput.interact.2', 'cscw', 'article32', 'nov.2018', ',25pages', 'https', '//doi.org/10.1145/3274301', 'angelchang', 'angeladai', 'thomasfunkhouser', 'maciejhalber', 'matthiasniessner', 'manolissavva', 'shuransong', 'andyzeng', 'andyindazhang.2017.matterport3d', 'learningfromrgb-ddatainindoorenvironments.internationalconferenceon', '3dvision', '3dv', 'hongyanchang', 'taduynguyen', 'sasikumarmurakonda', 'ehsankazemi', 'andrezashokri.2020.onadversarialbiasand', 'therobustnessoffairmachinelearning.arxivpreprintarxiv:2006.08669', '2020', 'soravitchangpinyo', 'piyushsharma', 'nanding', 'andradusoricut.2021.conceptual12m', 'pushingweb-scaleimage-text', 'pre-trainingtorecognizelong-tailvisualconcepts.incvpr', 'yatinchaudhary', 'pankajgupta', 'khushbusaxena', 'vivekkulkarni', 'thomasrunkler', 'andhinrichschütze.2020.topicbert', 'forenergyefficientdocumentclassification.arxivpreprintarxiv:2010.16407', '2020', 'annies.chen', 'surajnair', 'andchelseafinn.2021c.learninggeneralizableroboticrewardfunctionsfrom', ""''"", 'in-the-wild', ""''"", 'humanvideos.inrobotics', 'scienceandsystems', 'rss', 'chaofanchen', 'oscarli', 'chaofantao', 'alinajadebarnett', 'jonathansu', 'andcynthiarudin.2018.thislookslikethat', 'deep', 'learningforinterpretableimagerecognition.arxivpreprintarxiv:1806.10574', 'ireneychen', 'shalmalijoshi', 'andmarzyehghassemi.2020b.treatinghealthdisparitieswithartificialintelligence.nature', 'medicine26,1', '2020', ',16–17', 'ireneychen', 'peterszolovits', 'andmarzyehghassemi.2019.canaihelpreducedisparitiesingeneralmedicalandmental', 'healthcare', '?', 'amajournalofethics21,2', '2019', ',167–179', 'liangchen', 'peteredwards', 'johndnelson', 'andtimothyjnorman.2015a', 'anaccesscontrolmodelforprotecting', 'provenancegraphs.in201513thannualconferenceonprivacy', 'securityandtrust', 'pst', '.ieee,125–132', 'lilichen', 'kevinlu', 'aravindrajeswaran', 'kiminlee', 'adityagrover', 'm.laskin', 'p.abbeel', 'a.srinivas', 'andigormordatch', '2021b.decisiontransformer', 'reinforcementlearningviasequencemodeling.arxivabs/2106.01345', '2021', 'mayeechen', 'karangoel', 'nimitssohoni', 'faitpoms', 'kayvonfatahalian', 'andchristopherré.2021a.mandoline', 'model', 'evaluationunderdistributionshift.ininternationalconferenceonmachinelearning.pmlr,1617–1629', 'markchen', 'alecradford', 'rewonchild', 'jeffreywu', 'heewoojun', 'davidluan', 'andilyasutskever.2020d', 'generative', 'pretrainingfrompixels.inproceedingsofthe37thinternationalconferenceonmachinelearning', 'proceedingsofmachine', 'learningresearch', 'vol.119', 'haldauméiiiandaartisingh', 'eds.', '.pmlr,1691–1703', 'http', '//proceedings.mlr.press/v119/']",167
Opportunities and Risks of Foundational Models - Stanford.pdf,"['168', 'centerforresearchonfoundationmodels', 'crfm', 'chen20s.html', 'markchen', 'jerrytworek', 'heewoojun', 'qimingyuan', 'henriquepondedeoliveirapinto', 'jaredkaplan', 'harriedwards', 'yuriburda', 'nicholasjoseph', 'gregbrockman', 'alexray', 'raulpuri', 'gretchenkrueger', 'michaelpetrov', 'heidykhlaaf', 'girishsastry', 'pamelamishkin', 'brookechan', 'scottgray', 'nickryder', 'mikhailpavlov', 'aletheapower', 'lukaszkaiser', 'mohammadbavarian', 'clemenswinter', 'philippetillet', 'felipepetroskisuch', 'davecummings', 'matthiasplappert', 'fotios', 'chantzis', 'elizabethbarnes', 'arielherbert-voss', 'williamhebgenguss', 'alexnichol', 'alexpaino', 'nikolastezak', 'jietang', 'igorbabuschkin', 'suchirbalaji', 'shantanujain', 'williamsaunders', 'christopherhesse', 'andrewn.carr', 'janleike', 'josh', 'achiam', 'vedantmisra', 'evanmorikawa', 'alecradford', 'matthewknight', 'milesbrundage', 'miramurati', 'katiemayer', 'peter', 'welinder', 'bobmcgrew', 'darioamodei', 'sammccandlish', 'ilyasutskever', 'andwojciechzaremba.2021e.evaluatinglarge', 'languagemodelstrainedoncode', 'arxiv:2107.03374', '[', 'cs.lg', ']', 'tingchen', 'simonkornblith', 'mohammadnorouzi', 'andgeoffreyhinton.2020c.asimpleframeworkforcontrastivelearning', 'ofvisualrepresentations.ininternationalconferenceonmachinelearning', 'icml', '.1597–1607', 'tianqichen', 'bingxu', 'chiyuanzhang', 'andcarlosguestrin.2016.trainingdeepnetswithsublinearmemorycost.corr', 'abs/1604.06174', '.arxiv:1604.06174', 'http', '//arxiv.org/abs/1604.06174', 'xinleichen', 'haoqifan', 'rossgirshick', 'andkaiminghe.2020a.improvedbaselineswithmomentumcontrastivelearning', 'arxivpreprintarxiv:2003.04297', '2020', 'xinleichen', 'haofang', 'tsung-yilin', 'ramakrishnavedantam', 'saurabhgupta', 'piotrdollár', 'andclawrencezitnick.2015b', 'microsoftcococaptions', 'datacollectionandevaluationserver.arxivpreprintarxiv:1504.00325', 'xinyunchen', 'changliu', 'boli', 'kimberlylu', 'anddawnsong.2017.targetedbackdoorattacksondeeplearningsystems', 'usingdatapoisoning.arxivpreprintarxiv:1712.05526', 'yunchen', 'friedarong', 'shivamduggal', 'shenlongwang', 'xinchenyan', 'sivabalanmanivasagam', 'shangjiexue', 'ersinyumer', 'andraquelurtasun.2021d.geosim', 'realisticvideosimulationviageometry-awarecompositionforself-driving.in', 'proceedingsoftheieee/cvfconferenceoncomputervisionandpatternrecognition.7230–7240', 'jamescheney', 'laurachiticariu', 'andwang-chiewtan.2009.provenanceindatabases', 'andwhere.nowpublishers', 'inc.', 'ethanachi', 'johnhewitt', 'andchristopherdmanning.2020.findinguniversalgrammaticalrelationsinmultilingual', 'bert.inproceedingsofthe58thannualmeetingoftheassociationforcomputationallinguistics.5564–5577', 'rewonchild', 'scottgray', 'alecradford', 'andilyasutskever.2019.generatinglongsequenceswithsparsetransformers', 'arxivpreprintarxiv:1904.10509', '2019', 'jaemincho', 'jielei', 'haotan', 'andmohitbansal.2021.unifyingvision-and-languagetasksviatextgeneration.ininternational', 'conferenceonmachinelearning', 'icml', 'rochellechoenniandekaterinashutova.2020.cross-neutralising', 'probingforjointencodingoflinguisticinformationin', 'multilingualmodels.arxivpreprintarxiv:2010.12825', '2020', 'alexchohlas-wood', 'joenudell', 'zhiyuanjerrylin', 'juliannyarko', 'andsharadgoel.2020.blindjustice', 'algorithmically', 'maskingraceinchargingdecisions.technicalreport.technicalreport', 'jonathanhchoi.2020.anempiricalstudyofstatutoryinterpretationintaxlaw.nyulrev.95', '2020', ',363', 'noamchomsky.2014.theminimalistprogram.mitpress', 'krzysztofchoromanski', 'valeriilikhosherstov', 'daviddohan', 'xingyousong', 'andreeagane', 'tamassarlos', 'peterhawkins', 'jareddavis', 'afrozmohiuddin', 'lukaszkaiser', 'etal.2020', 'rethinkingattentionwithperformers', 'arxivpreprint', 'arxiv:2009.14794', '2020', 'alexandrachouldechovaandaaronroth.2020.asnapshotofthefrontiersoffairnessinmachinelearning.commun.acm', '63,5', 'april2020', ',82–89', 'https', '//doi.org/10.1145/3376898', 'yinlamchow', 'ofirnachum', 'edgara.duéñez-guzmán', 'andm.ghavamzadeh.2018.alyapunov-basedapproachtosafe', 'reinforcementlearning.inadvancesinneuralinformationprocessingsystems', 'neurips', 'paulchristiano.2016.prosaicaialignment', 'https', '//ai-alignment.com/prosaic-ai-control-b959644d79c2', 'yeounohchung', 'timkraska', 'neoklispolyzotis', 'kihyuntae', 'andsteveneuijongwhang.2019.slicefinder', 'automate', 'dataslicingformodelvalidation.in2019ieee35thinternationalconferenceondataengineering', 'icde', '.ieee,1550–1553', 'cigna.2018', 'cignau.s.lonelinessindex', 'https', '//www.cigna.com/assets/docs/newsroom/loneliness-survey-2018-full-', 'report.pdf', 'daniellekeatscitron.2008.technologicaldueprocess.wash.u.l.rev.1249', '2008', 'https', '//openscholarship.wustl.edu/', 'law_lawreview/vol85/iss6/2/', 'elizabethclark', 'talaugust', 'sofiaserrano', 'nikitahaduong', 'suchingururangan', 'andnoahasmith.2021', 'allthat', '’', '’', 'human', '’', 'isnotgold', 'evaluatinghumanevaluationofgeneratedtext.arxivpreprintarxiv:2107.00061', '2021', 'kevinclark', 'minh-thangluong', 'quocv.le', 'andchristopherd.manning.2020.electra', 'pre-trainingtextencodersas', 'discriminatorsratherthangenerators.arxivabs/2003.10555', '2020', 'peterclark', 'orenetzioni', 'danielkhashabi', 'tusharkhot', 'bhavanadalvimishra', 'kylerichardson', 'ashishsabharwal', 'carissaschoenick', 'oyvindtafjord', 'nikettandon', 'sumithrabhakthavatsalam', 'dirkgroeneveld', 'michalguerquin']",168
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '169', 'michaelschmitz.2019', '’', 'f', '’', '’', '’', 'onthen.y.regentsscienceexams', 'anoverviewofthearistoproject', 'corr', 'abs/1909.01958', '2019', 'http', '//arxiv.org/abs/1909.01958', 'johnd.co-reyes', 'abhishekgupta', 'suvanshsanjeev', 'nickaltieri', 'johndenero', 'pieterabbeel', 'andsergeylevine.2019', 'guidingpolicieswithlanguageviameta-learning.ininternationalconferenceonlearningrepresentations', 'iclr', 'carycoglianeseandlavibendor.2020', 'aiinadjudicationandadministration', 'brooklynlawreview', 'forthcoming', 'universityofpennsylvanialawschool', 'publiclawresearchpaper19-41', '2020', 'elijahcole', 'xuanyang', 'kimberlywilber', 'oisinmacaodha', 'andsergebelongie.2021', 'whendoescontrastivevisual', 'representationlearningwork', '?', 'arxiv:2105.05837', '[', 'cs.cv', ']', 'codycoleman', 'deepaknarayanan', 'danielkang', 'tianzhao', 'jianzhang', 'luiginardi', 'peterbailis', 'kunleolukotun', 'chris', 'ré', 'andmateizaharia.2017', 'dawnbench', 'anend-to-enddeeplearningbenchmarkandcompetition.inneurips', 'workshoponsystemsformachinelearning', 'francisscollinsandharoldvarmus.2015.anewinitiativeonprecisionmedicine.newenglandjournalofmedicine372,9', ',793–795', 'ronancollobertandjasonweston.2008.aunifiedarchitecturefornaturallanguageprocessing', 'deepneuralnetworks', 'withmultitasklearning.ininternationalconferenceonmachinelearning', 'icml', '.160–167', 'cristinacolonnesi', 'geertjanjmstams', 'irenekoster', 'andmarcjnoom.2010.therelationbetweenpointingandlanguage', 'development', 'ameta-analysis.developmentalreview30,4', '2010', ',352–366', 'bernardcomrie.1989.languageuniversalsandlinguistictypology', 'syntaxandmorphology.universityofchicagopress', 'aubreycondor', 'maxlitster', 'andzacharypardos.2021.automaticshortanswergradingwithsbertonout-of-sample', 'questions.inproceedingsofthe14thinternationalconferenceoneducationaldatamining', 'alexisconneau', 'germánkruszewski', 'guillaumelample', 'loïcbarrault', 'andmarcobaroni.2018', 'whatyoucancram', 'intoasingle\\', '$', '&', '#', 'vector', 'probingsentenceembeddingsforlinguisticproperties.inproceedingsofthe56thannual', 'meetingoftheassociationforcomputationallinguistics', 'volume1', 'longpapers', 'melbourne', 'australia', '.associationfor', 'computationallinguistics,2126–2136', 'http', '//aclweb.org/anthology/p18-1198', 'carolmcdonaldconnor.2019.usingtechnologyandassessmenttopersonalizeinstruction', 'preventingreadingproblems', 'preventionscience20,1', '2019', ',89–99', 'erikconser', 'kennedyhahn', 'chandlermwatson', 'andmelaniemitchell.2019.revisitingvisualgrounding.arxivpreprint', 'arxiv:1904.02225', '2019', 'alancooper', 'robertreimann', 'davidcronin', 'andchristophernoessel.2014.aboutface', 'theessentialsofinteractiondesign', 'injohnwiley', '&', 'sons', 'samcorbett-daviesandsharadgoel.2018.themeasureandmismeasureoffairness', 'acriticalreviewoffairmachine', 'learn', 'arxiv:1808.00023', '[', 'cs.cy', ']', 'anthonycorso', 'robertj.moss', 'markkoren', 'r.lee', 'andmykelj.kochenderfer.2020.asurveyofalgorithmsforblack-box', 'safetyvalidation.arxivpreprintarxiv:2005.02979', '2020', 'ajeyacotra.2021', 'thecaseforaligningnarrowlysuperhumanmodels', 'https', '//ai-alignment.com/prosaic-ai-control-', 'b959644d79c2', 'katecrawford.2017.theproblemwithbias.', 'keynoteatneurips', 'katecrawford.2021.atlasofai.yaleuniversitypress', 'kathleencreelanddeborahhellman.2021', 'thealgorithmicleviathan', 'arbitrariness', 'fairness', 'andopportunityin', 'algorithmicdecisionmakingsystems.inproceedingsofthe2021acmconferenceonfairness', 'accountability', 'transparency', 'virtualevent', 'canada', 'facct', '’', '21', '.associationforcomputingmachinery', 'newyork', 'ny', 'usa,816', 'https', '//doi.org/10.1145/3442188.3445942', 'kathleena.creel.2020.transparencyincomplexcomputationalsystems.philosophyofscience87,4', 'oct.2020', ',568–589', 'https', '//doi.org/10.1086/709729', 'kimberlécrenshaw.1989.demarginalizingtheintersectionofraceandsex', 'ablackfeministcritiqueofantidiscrimination', 'doctrine', 'feministtheoryandantiracistpolitics', 'universityofchicagolegalforumvol.1989', 'article8', '1989', 'https', '//chicagounbound.uchicago.edu/cgi/viewcontent.cgi', '?', 'article=1052', '&', 'context=uclf', 'williamcroft.2001.radicalconstructiongrammar', 'syntactictheoryintypologicalperspective.oxforduniversitypresson', 'demand', 'rebeccacrootof.2019.artificialintelligenceresearchneedsresponsiblepublicationnorms.lawfare', 'philippecudré-mauroux', 'hideakikimura', 'k-tlim', 'jennierogers', 'romansimakov', 'emadsoroush', 'pavelvelikhov', 'daniell', 'wang', 'magdalenabalazinska', 'jacekbecla', 'etal.2009.ademonstrationofscidb', 'ascience-orienteddbms.proceedings', 'ofthevldbendowment2,2', '2009', ',1534–1537', 'yuqingcui.2018.applicationofzero-knowledgeproofinresolvingdisputesofprivilegeddocumentsine-discovery', 'harv.jl', '&', 'tech.32', ',633', 'mariano-florentinocuéllar.2019.howtoensureequalaccesstothelawwhenwespeak200differentlanguages.calmatters', 'feb2019', 'https', '//law.stanford.edu/2019/02/05/how-to-ensure-equal-access-to-the-law-when-we-speak-200-different-']",169
Opportunities and Risks of Foundational Models - Stanford.pdf,"['170', 'centerforresearchonfoundationmodels', 'crfm', 'languages/', 'andrewm.daiandquocv.le.2015.semi-supervisedsequencelearning.inadvancesinneuralinformationprocessing', 'systems', 'neurips', 'dengxindaiandlucvangool.2018.darkmodeladaptation', 'semanticimagesegmentationfromdaytimetonighttime', 'in201821stinternationalconferenceonintelligenttransportationsystems', 'itsc', '.3819–3824', 'https', '//doi.org/10.1109/', 'itsc.2018.8569387', 'jessicadai', 'sinafazelpour', 'andzacharylipton.2021.fairmachinelearningunderpartialcompliance.inproceedingsof', 'the2021aaai/acmconferenceonai', 'ethics', 'andsociety.acm', 'https', '//doi.org/10.1145/3461702.3462521', 'zihangdai', 'zhilinyang', 'yimingyang', 'jaimecarbonell', 'quocle', 'andruslansalakhutdinov.2019', 'transformer-xl', 'attentivelanguagemodelsbeyondafixed-lengthcontext.inproceedingsofthe57thannualmeetingoftheassociation', 'forcomputationallinguistics.associationforcomputationallinguistics', 'florence', 'italy,2978–2988', 'https', '//doi.org/10', '18653/v1/p19-1285', 'dimadamen', 'hazeldoughty', 'giovannimariafarinella', 'sanjafidler', 'antoninofurnari', 'evangeloskazakos', 'davide', 'moltisanti', 'jonathanmunro', 'tobyperrett', 'willprice', 'andmichaelwray.2018', 'scalingegocentricvision', 'theepic-', 'kitchensdataset.ineuropeanconferenceoncomputervision', 'eccv', 'alex', 'damian', 'tengyu', 'jason', 'lee', '2021', 'label', 'noise', 'sgd', 'provably', 'prefer', 'flat', 'global', 'minimizers', 'arxiv:2106.06530', '[', 'cs.lg', ']', 'jeanneedaniel', 'williebrink', 'ryaneloff', 'andcharlescopley.2019.towardsautomatinghealthcarequestionansweringin', 'anoisymultilinguallow-resourcesetting.inproceedingsofthe57thannualmeetingoftheassociationforcomputational', 'linguistics.948–953', 'daviddanks.2019.thevalueoftrustworthyai.inproceedingsofthe2019aaai/acmconferenceonai', 'ethics', 'andsociety', 'acm', 'https', '//doi.org/10.1145/3306618.3314228', 'tridao', 'albertgu', 'alexanderratner', 'virginiasmith', 'chrisdesa', 'andchristopherré.2019.akerneltheoryofmodern', 'dataaugmentation.ininternationalconferenceonmachinelearning.pmlr,1528–1537', 'helanadarwin.2017.doinggenderbeyondthebinary', 'avirtualethnography.symbolicinteraction40,3', ',317–334', 'https', '//doi.org/10.1002/symb.316arxiv', 'https', '//onlinelibrary.wiley.com/doi/pdf/10.1002/symb.316', 'sudeepdasari', 'f.ebert', 'stephentian', 'surajnair', 'bernadettebucher', 'k.schmeckpeper', 'siddharthsingh', 'sergeylevine', 'chelseafinn.2019.robonet', 'large-scalemulti-robotlearning.inconferenceonrobotlearning', 'corl', 'haldauméiii.2007.frustratinglyeasydomainadaptation.inassociationforcomputationallinguistics', 'acl', 'thomasdavenportandravikalakota.2019.thepotentialforartificialintelligenceinhealthcare.futurehealthcarejournal', '6,2', '2019', ',94', 'nicoladecao', 'wilkeraziz', 'andivantitov.2021', 'editingfactualknowledgeinlanguagemodels', 'arxivpreprint', 'arxiv:2104.08164', '2021', 'harmdevries', 'dzmitrybahdanau', 'andchristopherd.manning.2020.towardsecologicallyvalidresearchonlanguage', 'userinterfaces.arxivabs/2007.14435', '2020', 'matthewdecampandcharlottalindvall.2020.latentbiasandtheimplementationofartificialintelligenceinmedicine', 'journaloftheamericanmedicalinformaticsassociation27,12', 'june2020', ',2020–2023', 'https', '//doi.org/10.1093/jamia/', 'ocaa094', 'mostafadehghani', 'yitay', 'alexeygritsenko', 'zhezhao', 'neilhoulsby', 'fernandodiaz', 'donaldmetzler', 'andoriolvinyals', '2021.thebenchmarklottery.arxivabs/2107.07002', '2021', 'mauriciodelbracio', 'damienkelly', 'michaelsbrown', 'andpeymanmilanfar.2021.mobilecomputationalphotography', 'tour.arxivpreprintarxiv:2102.09000', '2021', 'dinademner-fushman', 'yassinemrabet', 'andasmabenabacha.2020.consumerhealthinformationandquestionanswering', 'helpingconsumersfindanswerstotheirhealth-relatedinformationneeds.journaloftheamericanmedicalinformatics', 'association27,2', '2020', ',194–201', 'dorottyademszky', 'jingliu', 'zidmancenido', 'juliecohen', 'heatherhill', 'danjurafsky', 'andtatsunorihashimoto.2021', 'measuringconversationaluptake', 'acasestudyonstudent-teacherinteractions.proceedingsofthe59thannualmeeting', 'oftheassociationforcomputationallinguistics', 'acl', '2021', 'jiadeng', 'weidong', 'richardsocher', 'li-jiali', 'kaili', 'andlifei-fei.2009', 'imagenet', 'alarge-scalehierarchicalimage', 'database.incomputervisionandpatternrecognition', 'cvpr', '.248–255', 'educationdepartmentofhealthandwelfare.1979.thebelmontreport', 'timdettmersandlukezettlemoyer.2019.sparsenetworksfromscratch', 'fastertrainingwithoutlosingperformance', 'arxivpreprintarxiv:1907.04840', '2019', 'jacobdevlin', 'ming-weichang', 'kentonlee', 'andkristinatoutanova.2019', 'bert', 'pre-trainingofdeepbidirectional', 'transformersforlanguageunderstanding.inassociationforcomputationallinguistics', 'acl', '.4171–4186', 'bhuwandhingra', 'jeremyr.cole', 'julianmartineisenschlos', 'danielgillick', 'jacobeisenstein', 'andwilliamw.cohen.2021', 'time-awarelanguagemodelsastemporalknowledgebases', 'arxiv:2106.15110', '[', 'cs.cl', ']']",170
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '171', 'mdianaandjjbjosmarescaux.2015.roboticsurgery.journalofbritishsurgery102,2', 'e15–e28', 'gregorymdickinson.2018.acomputationalanalysisoforalargumentinthesupremecourt.cornelljl', '&', 'pub.pol', '’', 'y28', ',449', 'thomasgdietterich.2000.ensemblemethodsinmachinelearning.ininternationalworkshoponmultipleclassifiersystems', 'springer,1–15', 'catherined', '’', 'ignazioandlaurenf.klein.2020.datafeminism.mitpress', 'r.dillmann.2004.teachingandlearningofrobottasksviaobservationofhumanperformance.roboticsauton.syst.47', '2004', ',109–116', 'bottydimanov', 'umangbhatt', 'matejajamnik', 'andadrianweller.2020.youshouldn', '’', 'ttrustme', 'learningmodelswhich', 'concealunfairnessfrommultipleexplanationmethods', '..', 'insafeai', 'aaai', 'emilydinan', 'gavinabercrombie', 'a.steviebergman', 'shannonspruit', 'dirkhovy', 'y-lanboureau', 'andverenarieser', '2021', 'anticipatingsafetyissuesine2econversationalai', 'frameworkandtooling', 'arxivabs/2107.03451', '2021', 'https', '//arxiv.org/abs/2107.03451', 'emilydinan', 'angelafan', 'ledellwu', 'jasonweston', 'douwekiela', 'andadinawilliams.2020.multi-dimensionalgender', 'biasclassification.inproceedingsofthe2020conferenceonempiricalmethodsinnaturallanguageprocessing', 'emnlp', 'associationforcomputationallinguistics', 'online,314–331', 'https', '//doi.org/10.18653/v1/2020.emnlp-main.23', 'emilydinan', 'samuelhumeau', 'bharathchintagunta', 'andj.weston.2019', 'builditbreakitfixitfordialoguesafety', 'robustnessfromadversarialhumanattack.inemnlp/ijcnlp', 'mingding', 'zhuoyiyang', 'wenyihong', 'wendizheng', 'changzhou', 'dayin', 'junyanglin', 'xuzou', 'zhoushao', 'hongxia', 'yang', 'andjietang.2021.cogview', 'masteringtext-to-imagegenerationviatransformers.corrabs/2105.13290', '2021', 'arxiv:2105.13290', 'https', '//arxiv.org/abs/2105.13290', 'yimingding', 'carlosflorensa', 'marianophielipp', 'andp.abbeel.2019.goal-conditionedimitationlearning.inadvancesin', 'neuralinformationprocessingsystems', 'neurips', 'laurent', 'dinh', 'david', 'krueger', 'yoshua', 'bengio', 'nice', 'non-linear', 'independent', 'components', 'estimation', 'arxiv:1410.8516', '[', 'cs.lg', ']', 'renéedirestaandshelbygrossman.2019.potemkinpages', '&', 'personas', 'assessinggruonlineoperations,2014-2019', 'renéediresta', 'shelbygrossman', 'andalexandrasiegel.2021.in-housevs.outsourcedtrolls', 'howdigitalmercenaries', 'shapestateinfluencestrategies.', '2021', 'renéediresta', 'k.shaffer', 'beckyruppel', 'davidsullivan', 'robertc.matney', 'ryanfox', 'jonathanalbright', 'andbenjohnson', '2018.thetactics', '&', 'tropesoftheinternetresearchagency', 'https', '//digitalcommons.unl.edu/cgi/viewcontent.cgi', '?', 'article=', '1003', '&', 'context=senatedocs', 'michaeldiskin', 'alexeybukhtiyarov', 'maxryabinin', 'lucilesaulnier', 'quentinlhoest', 'antonsinitsin', 'dmitrypopov', 'dmitry', 'pyrkin', 'maximkashirin', 'alexanderborzunov', 'etal.2021', 'distributeddeeplearninginopencollaborations', 'arxiv', 'preprintarxiv:2106.10207', '2021', 'lucasdixon', 'johnli', 'jeffreysorensen', 'nithumthain', 'andlucyvasserman.2018.measuringandmitigatingunintendedbias', 'intextclassification.inproceedingsofthe2018aaai/acmconferenceonai', 'ethics', 'andsociety', 'neworleans', 'la', 'usa', 'aies', '’', '18', '.associationforcomputingmachinery', 'newyork', 'ny', 'usa,67–73', 'https', '//doi.org/10.1145/3278721.3278729', 'jessedodge', 'suchingururangan', 'dallascard', 'royschwartz', 'andnoaha.smith.2019', 'showyourwork', 'improve', 'reportingofexperimentalresults', 'arxiv:1909.03004', '[', 'cs.lg', ']', 'jessedodge', 'maartensap', 'anamarasovic', 'williamagnew', 'gabrielilharco', 'dirkgroeneveld', 'andmattgardner.2021', 'documentingtheenglishcolossalcleancrawledcorpus', 'corrabs/2104.08758', '2021', 'arxiv:2104.08758', 'https', '//arxiv.org/abs/2104.08758', 'briandolhansky', 'joannabitton', 'benpflaum', 'jikuolu', 'russhowes', 'menglinwang', 'andcristiancantonferrer.2020.the', 'deepfakedetectionchallengedataset.arxive-prints', '2020', 'arxiv–2006', 'xinlunadong', 'hannanehhajishirzi', 'colinlockard', 'andprashantshiralkar.2020.multi-modalinformationextractionfrom', 'text', 'semi-structured', 'andtabulardataontheweb.inproceedingsofthe26thacmsigkddinternationalconferenceon', 'knowledgediscovery', '&', 'datamining.3543–3544', 'shayandoroudi', 'vincentaleven', 'andemmabrunskill.2017', 'robustevaluationmatrix', 'towardsamoreprincipled', 'offlineexplorationofinstructionalpolicies.inproceedingsofthefourth', 'acmconferenceonlearning', 'scale', 'cambridge', 'massachusetts', 'usa', 'l', '’', '17', '.associationforcomputingmachinery', 'newyork', 'ny', 'usa,3–12', 'https', '//doi.org/10.1145/3051457.3051463', 'finaledoshi-velezandbeenkim.2017', 'towardsarigorousscienceofinterpretablemachinelearning', 'arxivpreprint', 'arxiv:1702.08608', 'alexeydosovitskiy', 'lucasbeyer', 'alexanderkolesnikov', 'dirkweissenborn', 'xiaohuazhai', 'thomasunterthiner', 'mostafa', 'dehghani', 'matthiasminderer', 'georgheigold', 'sylvaingelly', 'etal.2020.animageisworth16x16words', 'transformers', 'forimagerecognitionatscale.ininternationalconferenceonlearningrepresentations']",171
Opportunities and Risks of Foundational Models - Stanford.pdf,"['172', 'centerforresearchonfoundationmodels', 'crfm', 'grahamdove', 'kimhalskov', 'jodiforlizzi', 'andjohnzimmerman.2017', 'uxdesigninnovation', 'challengesforworking', 'withmachinelearningasadesignmaterial.inproceedingsofthe2017chiconferenceonhumanfactorsincomputing', 'systems.acm', 'ancaddraganandsiddharthassrinivasa.2013.formalizingassistiveteleoperation.robotics', 'scienceandsystemsviii', '2013', ',73', 't.dreossi', 'alexandredonzé', 'ands.seshia.2017', 'compositionalfalsificationofcyber-physicalsystemswithmachine', 'learningcomponents.innfm', 'j.drews.2000.drugdiscovery', 'ahistoricalperspective.science2875460', '2000', ',1960–4', 'simons.du', 'weihu', 'shamm.kakade', 'jasond.lee', 'andqilei.2020.few-shotlearningvialearningtherepresentation', 'provably.arxiv', '2020', 'sebastian', 'duerr', 'peter', 'a.', 'gloor', '2021', 'persuasive', 'natural', 'language', 'generation', '–', 'literature', 'arxiv:2101.05786', '[', 'cs.cl', ']', 'emmanueldupoux.2018', 'cognitivescienceintheeraofartificialintelligence', 'aroadmapforreverse-engineeringthe', 'infantlanguage-learner.cognition173', ',43–59', 'miquelduran-frigola', 'eduardopauls', 'oriolguitart-pla', 'martinobertoni', 'víctoralcalde', 'davidamat', 'teresajuan-blanco', 'andpatrickaloy.2020', 'extendingthesmall-moleculesimilarityprincipletoalllevelsofbiologywiththechemical', 'checker.naturebiotechnology38,9', '2020', ',1087–1096', 'cynthiadwork', 'frankmcsherry', 'kobbinissim', 'andadamsmith.2006', 'calibratingnoisetosensitivityinprivatedata', 'analysis.inproceedingsofthe3rdtheoryofcryptographyconference.265–284', 'grégoiredéletang', 'j.grau-moya', 'miljanmartic', 'timgenewein', 'tommcgrath', 'vladimirmikulik', 'm.kunesch', 's.legg', 'pedroa.ortega.2021.causalanalysisofagentbehaviorforaisafety.arxivpreprintarxiv:2103.03938', '2021', 'mahmoudelbattah', 'émilienarnaud', 'maximegignon', 'andgillesdequen.2021.theroleoftextanalyticsinhealthcare', 'reviewofrecentdevelopmentsandapplications', '..', 'inhealthinf.825–832', 'paulelbourne.2011.meaning', 'aslimguidetosemantics.oxforduniversitypress', 'kevinellis', 'catherinewong', 'maxwelli.nye', 'mathiassablé-meyer', 'lucasmorales', 'lukeb.hewitt', 'luccary', 'armando', 'solar-lezama', 'andjoshuab.tenenbaum.2021.dreamcoder', 'bootstrappinginductiveprogramsynthesiswithwake-', 'sleeplibrarylearning.inpldi', '’', '21:42ndacmsigplaninternationalconferenceonprogramminglanguagedesignand', 'implementation', 'virtualevent', 'canada', 'june20-25,20211', 'stephenn.freundanderanyahav', 'eds.', '.acm,835–850', 'https', '//doi.org/10.1145/3453483.3454080', 'gamaleldinfelsayed', 'iangoodfellow', 'andjaschasohl-dickstein.2018.adversarialreprogrammingofneuralnetworks', 'arxivpreprintarxiv:1806.11146', 'erichelsen', 'maratdukhan', 'trevorgale', 'andkarensimonyan.2020.fastsparseconvnets.inproceedingsoftheieee/cvf', 'conferenceoncomputervisionandpatternrecognition', 'cvpr', 'danielcelton.2020.self-explainingaiasanalternativetointerpretableai.ininternationalconferenceonartificialgeneral', 'intelligence.springer,95–106', 'emadelwany', 'davemoore', 'andgauravoberoi.2019.bertgoestolawschool', 'quantifyingthecompetitiveadvantageof', 'accesstolargelegalcorporaincontractunderstanding.arxivpreprintarxiv:1911.00473', '2019', 'douglasc.engelbart.1963', 'aconceptualframeworkfortheaugmentationofman', '’', 'sintellect.incomputer-supported', 'cooperativework', 'abookofreadings', 'davidfreemanengstrom', 'danieleho', 'catherinemsharkey', 'andmariano-florentinocuéllar.2020', 'governmentby', 'algorithm', 'artificialintelligenceinfederaladministrativeagencies.nyuschooloflaw', 'publiclawresearchpaper20-54', '2020', 'danielleensign', 'sorelleafriedler', 'scottneville', 'carlosscheidegger', 'andsureshvenkatasubramanian.2018', 'runaway', 'feedbackloopsinpredictivepolicing.inconferenceonfairness', 'accountabilityandtransparency.pmlr,160–171', 'kawinethayarajh', 'davidduvenaud', 'andgraemehirst.2019.understandingundesirablewordembeddingassociations', 'inproceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics.associationforcomputational', 'linguistics', 'florence', 'italy,1696–1705', 'https', '//doi.org/10.18653/v1/p19-1166', 'kawinethayarajhanddanjurafsky.2020.utilityisintheeyeoftheuser', 'acritiqueofnlpleaderboards.inproceedings', 'ofthe2020conferenceonempiricalmethodsinnaturallanguageprocessing', 'emnlp', '.associationforcomputational', 'linguistics', 'online,4846–4853', 'https', '//doi.org/10.18653/v1/2020.emnlp-main.393', 'allysonettinger.2020.whatbertisnot', 'lessonsfromanewsuiteofpsycholinguisticdiagnosticsforlanguagemodels', 'transactionsoftheassociationforcomputationallinguistics8', '2020', ',34–48', 'https', '//doi.org/10.1162/tacl_a_00298', 'allysonettingerandtallinzen.2016.evaluatingvectorspacemodelsusinghumansemanticprimingresults.inproceedings', 'ofthe1stworkshoponevaluatingvector-spacerepresentationsfornlp.associationforcomputationallinguistics', 'berlin', 'germany,72–77', 'https', '//doi.org/10.18653/v1/w16-2513', 'utkuevci', 'trevorgale', 'jacobmenick', 'pablosamuelcastro', 'anderichelsen.2020.riggingthelottery', 'makingalltickets', 'winners.inproceedingsofthe37thinternationalconferenceonmachinelearning', 'proceedingsofmachinelearning']",172
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '173', 'research', 'vol.119', 'haldauméiiiandaartisingh', 'eds.', '.pmlr,2943–2952', 'tomeveritt', 'garylea', 'andmarcushutter.2018.agisafetyliteraturereview.arxivpreprintarxiv:1805.01109', 'benjamineysenbach', 'shixianggu', 'j.ibarz', 'andsergeylevine.2017', 'leavenotrace', 'learningtoresetforsafeand', 'autonomousreinforcementlearning.arxivpreprintarxiv:1711.06782', 'jerryalanfailsanddanr.olsen.2003', 'adesigntoolforcamera-basedinteraction.inproceedingsoftheconferenceon', 'humanfactorsincomputingsystems.acm', 'linxifan', 'shyamalbuch', 'guanzhiwang', 'ryancao', 'yukezhu', 'juancarlosniebles', 'andlifei-fei.2020', 'rubiksnet', 'learnable3d-shiftforefficientvideoactionrecognition.inproceedingsoftheeuropeanconferenceoncomputervision', 'eccv', 'donaldjfarole', 'jr.andlynnlangston.2010.county-basedandlocalpublicdefenderoffices,2007.technicalreport.u.s', 'departmentofjusticebureauofjusticestatistics', 'sinafazelpouranddaviddanks.2021.algorithmicbias', 'sense', 'source', 'solutions.philosophycompass16,8', 'june2021', 'https', '//doi.org/10.1111/phc3.12760', 'williamfedus', 'barretzoph', 'andnoamshazeer.2021.switchtransformers', 'scalingtotrillionparametermodelswithsimple', 'andefficientsparsity.arxivpreprintarxiv:2101.03961', '2021', 'lifei-fei', 'ashaiyer', 'christofkoch', 'andpietroperona.2007', 'whatdoweperceiveinaglanceofareal-worldscene', '?', 'journalofvision7,1', '2007', ',10–10', 'xinfeng', 'younijiang', 'xuejiaoyang', 'mingdu', 'andxinli.2019.computervisionalgorithmsandhardwareimplementations', 'asurvey.integration69', '2019', ',309–320', 'andrewguthrieferguson.2017.theriseofbigdatapolicing', 'surveillance', 'race', 'andthefutureoflawenforcement.nyu', 'press', 'http', '//www.jstor.org/stable/j.ctt1pwtb27', 'besnikfetahu', 'abhijitanand', 'andavishekanand.2015.howmuchiswikipedialaggingbehindnews', '?', '.inproceedingsof', 'theacmwebscienceconference.1–9', 'anjaliefield', 'sulinblodgett', 'zeerakwaseem', 'andyuliatsvetkov.2021.asurveyofrace', 'racism', 'andanti-racismin', 'nlp.inproceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternational', 'jointconferenceonnaturallanguageprocessing', 'volume1', 'longpapers', '.associationforcomputationallinguistics', 'online,1905–1925', 'https', '//doi.org/10.18653/v1/2021.acl-long.149', 'chelseafinn', 'pieterabbeel', 'andsergeylevine.2017.model-agnosticmeta-learningforfastadaptationofdeepnetworks', 'ininternationalconferenceonmachinelearning', 'icml', 'chelseafinnandsergeylevine.2017', 'deepvisualforesightforplanningrobotmotion.ininternationalconferenceon', 'roboticsandautomation', 'icra', 'c.finn', 's.levine', 'andp.abbeel.2016a', 'guidedcostlearning', 'deepinverseoptimalcontrolviapolicyoptimization.in', 'internationalconferenceonmachinelearning', 'icml', '.49–58', 'chelseafinn', 'xinyutan', 'yanduan', 'trevordarrell', 'sergeylevine', 'andpieterabbeel.2016b.deepspatialautoencodersfor', 'visuomotorlearning.in2016ieeeinternationalconferenceonroboticsandautomation', 'icra', '.ieee,512–519', 'vladfiroiu', 'eseraygün', 'ankitanand', 'zafaraliahmed', 'xavierglorot', 'laurentorseau', 'doinaprecup', 'andshiblmourad', '2021.trainingafirst-ordertheoremproverfromsyntheticdata.thefirstmathematicalreasoningingeneralartificial', 'intelligenceworkshop', 'iclr2021', '2021', 'https', '//mathai-iclr.github.io/papers/papers/mathai_18_paper.pdf', 'jaimef.fisac', 'neilf.lugovoy', 'vicençrúbiesroyo', 's.ghosh', 'andc.tomlin.2019.bridginghamilton-jacobisafetyanalysis', 'andreinforcementlearning.ininternationalconferenceonroboticsandautomation', 'icra', 'adamfisch', 'alontalmor', 'robinjia', 'minjoonseo', 'eunsolchoi', 'anddanqichen.2019.mrqa2019sharedtask', 'evaluate', 'generalizationinreadingcomprehension.inworkshoponmachinereadingforquestionanswering', 'mrqa', 'carlosflorensa', 'yanduan', 'andp.abbeel.2017', 'stochasticneuralnetworksforhierarchicalreinforcementlearning', 'arxivabs/1704.03012', 'lucianofloridi', 'joshcowls', 'monicabeltrametti', 'rajachatila', 'patricechazerand', 'virginiadignum', 'christophluetge', 'robertmadelin', 'ugopagallo', 'francescarossi', 'burkhardschafer', 'peggyvalcke', 'andeffyvayena.2018.ai4people—an', 'ethicalframeworkforagoodaisociety', 'opportunities', 'risk', 'principles', 'andrecommendations.mindsandmachines', '28,4', 'nov.2018', ',689–707', 'https', '//doi.org/10.1007/s11023-018-9482-5', 'ruthc.fongandandreavedaldi.2017.interpretableexplanationsofblackboxesbymeaningfulperturbation.inproceedings', 'oftheieeeinternationalconferenceoncomputervision', 'iccv', 'stanislavfort.2021.adversarialexamplesfortheopenaiclipinitszero-shotclassificationregimeandtheirsemantic', 'generalization', 'https', '//stanislavfort.github.io/2021/01/12/openai_clip_adversarial_examples.html', 's.frank', 'irenefernandezmonsalve', 'robinl.thompson', 'andg.vigliocco.2013.readingtimedataforevaluatingbroad-', 'coveragemodelsofenglishsentenceprocessing.behaviorresearchmethods45', '2013', ',1182–1190', 'mattfredrikson', 'someshjha', 'andthomasristenpart.2015.modelinversionattacksthatexploitconfidenceinformation', 'andbasiccountermeasures.inacmsigsacconferenceoncomputerandcommunicationssecurity']",173
Opportunities and Risks of Foundational Models - Stanford.pdf,"['174', 'centerforresearchonfoundationmodels', 'crfm', 'jonathanb.freeman', 'andrewm.penner', 'aliyasaperstein', 'matthiasscheutz', 'andnaliniambady.2011.lookingthepart', 'socialstatuscuesshaperaceperception.plosone6,9', '092011', ',1–10', 'https', '//doi.org/10.1371/journal.pone.0025107', 'batyafriedmananddavidg.hendry.2019.valuesensitivedesign', 'shapingtechnologywithmoralimagination.themit', 'press', 'batyafriedmanandhelennissenbaum.1996.biasincomputersystems.acmtransactionsoninformationsystems14,3', 'july1996', ',330–347', 'https', '//doi.org/10.1145/230538.230561', 'zackfriedman.2020.studentloandebtstatisticsin2020', 'arecord', '$', '1.6trillion', 'https', '//www.forbes.com/sites/zackfriedman/', '2020/02/03/student-loan-debt-statistics/', '?', 'sh=34191d3281fe', 'justinfu', 'anoopkorattikara', 'sergeylevine', 'andsergioguadarrama.2019.fromlanguagetogoals', 'inversereinforcement', 'learningforvision-basedinstructionfollowing.ininternationalconferenceonlearningrepresentations', 'iclr', 'justinfu', 'avisingh', 'dibyaghosh', 'larryyang', 'andsergeylevine.2018.variationalinversecontrolwithevents', 'ageneral', 'frameworkfordata-drivenrewarddefinition.inadvancesinneuralinformationprocessingsystems', 'neurips', 'richardfutrell', 'ethanwilcox', 'takashimorita', 'pengqian', 'miguelballesteros', 'androgerlevy.2019.neurallanguagemodels', 'aspsycholinguisticsubjects', 'representationsofsyntacticstate.inproceedingsofthe2019conferenceofthenorthamerican', 'chapteroftheassociationforcomputationallinguistics', 'humanlanguagetechnologies', 'volume1', 'longandshortpapers', 'associationforcomputationallinguistics', 'minneapolis', 'minnesota,32–42', 'https', '//doi.org/10.18653/v1/n19-1004', 'iasongabriel.2020.artificialintelligence', 'value', 'andalignment.mindsandmachines30,3', '2020', ',411–437', 'federicoagalatolo', 'mariogcacimino', 'andgigliolavaglini.2021.generatingimagesfromcaptionandviceversavia', 'clip-guidedgenerativelatentspacesearch.arxivpreprintarxiv:2102.01645', '2021', 'trevorgale', 'mateizaharia', 'cliffyoung', 'anderichelsen.2020.sparsegpukernelsfordeeplearning.insc20', 'international', 'conferenceforhighperformancecomputing', 'network', 'storageandanalysis.ieee,1–14', 'juliagalliersandkarenspärckjones.1993', 'evaluatingnaturallanguageprocessingsystems', 'universityofcambridge', 'computerlaboratory', 'https', '//books.google.com/books', '?', 'id=zxklaqaaiaaj', 'chuanggan', 'jeremyschwartz', 'sethalter', 'martinschrimpf', 'jamestraer', 'juliandefreitas', 'jonaskubilius', 'abhishekbhand-', 'waldar', 'nickhaber', 'megumisano', 'kunokim', 'eliaswang', 'damianmrowca', 'michaellingelbach', 'aidancurtis', 'kevin', 'feigelis', 'danielm.bear', 'dangutfreund', 'davidcox', 'jamesj.dicarlo', 'joshmcdermott', 'joshuab.tenenbaum', 'anddaniel', 'l.k.yamins.2020.threedworld', 'aplatformforinteractivemulti-modalphysicalsimulation', 'arxiv:2007.04954', '[', 'cs.cv', ']', 'oscarh.gandy', 'jr.2021.thepanopticsort', 'apoliticaleconomyofpersonalinformation', '2ed.', '.oxforduniversitypress', 'yaroslavganinandvictorlempitsky.2015', 'unsuperviseddomainadaptationbybackpropagation.ininternational', 'conferenceonmachinelearning', 'icml', '.1180–1189', 'leogao', 'stellabiderman', 'sidblack', 'laurencegolding', 'travishoppe', 'charlesfoster', 'jasonphang', 'horacehe', 'anishthite', 'noanabeshima', 'shawnpresser', 'andconnorleahy.2020a.thepile', 'an800gbdatasetofdiversetextforlanguage', 'model', 'arxiv:2101.00027', '[', 'cs.cl', ']', 'ruohangao', 'changanchen', 'ziadal-halab', 'carlschissler', 'andkristengrauman.2020b', 'visualechoes', 'spatialimage', 'representationlearningthroughecholocation.ineccv', 'tianyugao', 'adamfisch', 'anddanqichen.2020c.makingpre-trainedlanguagemodelsbetterfew-shotlearners.corr', 'abs/2012.15723', '2020', '.arxiv:2012.15723', 'https', '//arxiv.org/abs/2012.15723', 'siddhantgargandgouthamramakrishnan.2020.bae', 'bert-basedadversarialexamplesfortextclassification.arxivpreprint', 'arxiv:2004.01970', '2020', 'timnitgebru.2021.raceandgender.intheoxfordhandbookofethicsofai', 'markusdirkdubber', 'frankpasquale', 'sunitdas', 'eds.', '.oxford', 'timnitgebru', 'jamiemorgenstern', 'brianavecchione', 'jenniferwortmanvaughan', 'hannawallach', 'haldauméill', 'andkate', 'crawford.2018.datasheetsfordatasets.arxivpreprintarxiv:1803.09010', 'samuelgehman', 'suchingururangan', 'maartensap', 'yejinchoi', 'andnoaha.smith.2020.realtoxicityprompts', 'evaluate', 'neuraltoxicdegenerationinlanguagemodels.infindingsoftheassociationforcomputationallinguistics', 'emnlp2020', 'associationforcomputationallinguistics', 'online,3356–3369', 'https', '//doi.org/10.18653/v1/2020.findings-emnlp.301', 'sebastiangehrmann', 'tosinadewumi', 'karmanyaaggarwal', 'pawansasankaammanamanchi', 'anuoluwapoaremu', 'an-', 'toinebosselut', 'khyathiraghavichandu', 'miruna-adrianaclinciu', 'dipanjandas', 'kaustubhdhole', 'wanyudu', 'esin', 'durmus', 'ondřejdušek', 'chrischinenyeemezue', 'varungangal', 'cristinagarbacea', 'tatsunorihashimoto', 'yufanghou', 'yacinejernite', 'harshjhamtani', 'yangfengji', 'shailzajolly', 'mihirkale', 'dhruvkumar', 'faisalladhak', 'amanmadaan', 'mounicamaddela', 'khyatimahajan', 'saadmahamood', 'bodhisattwaprasadmajumder', 'pedrohenriquemartins', 'angelina', 'mcmillan-major', 'simonmille', 'emielvanmiltenburg', 'moinnadeem', 'shashinarayan', 'vitalynikolaev', 'andreniy-', 'ongaborubungo', 'salomeyosei', 'ankurparikh', 'lauraperez-beltrachini', 'niranjanrameshrao', 'vikasraunak', 'juandiego', 'rodriguez', 'sashanksanthanam', 'joãosedoc', 'thibaultsellam', 'samirashaikh', 'anastasiashimorina', 'marcoantonio', 'sobrevillacabezudo', 'hendrikstrobelt', 'nishantsubramani', 'weixu', 'diyiyang', 'akhilayerukola', 'andjiaweizhou.2021', 'thegembenchmark', 'naturallanguagegeneration', 'itsevaluationandmetrics.inproceedingsofthe1stworkshopon', 'naturallanguagegeneration', 'evaluation', 'andmetrics', 'gem2021', '.associationforcomputationallinguistics', 'online']",174
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '175', '96–120', 'https', '//doi.org/10.18653/v1/2021.gem-1.10', 'atticusgeiger', 'kylerichardson', 'andchristopherpotts.2020.neuralnaturallanguageinferencemodelspartiallyembed', 'theoriesoflexicalentailmentandnegation.inproceedingsofthethirdblackboxnlpworkshoponanalyzingand', 'interpretingneuralnetworksfornlp.associationforcomputationallinguistics', 'online,163–173', 'https', '//doi.org/10', '18653/v1/2020.blackboxnlp-1.16', 'robertgeirhos', 'jörn-henrikjacobsen', 'claudiomichaelis', 'richardzemel', 'wielandbrendel', 'matthiasbethge', 'andfelixa', 'wichmann.2020.shortcutlearningindeepneuralnetworks.arxivpreprintarxiv:2004.07780', '2020', 'robertgeirhos', 'carlosrmtemme', 'jonasrauber', 'heikohschütt', 'matthiasbethge', 'andfelixawichmann.2018.generali-', 'sationinhumansanddeepneuralnetworks.advancesinneuralinformationprocessingsystems31', ',7538–7550', 'samuelgenheden', 'amolthakkar', 'veronikachadimová', 'jean-louisreymond', 'olaengkvist', 'andesbenbjerrum.2020', 'aizynthfinder', 'afast', 'robustandflexibleopen-sourcesoftwareforretrosyntheticplanning.journalofcheminformatics', '12,1', 'nov.2020', 'https', '//doi.org/10.1186/s13321-020-00472-1', 'davidgershgorn.2021.github', '’', 'sautomaticcodingtoolrestsonuntestedlegalground.https', '//www.theverge.com/', '2021/7/7/22561180/github-copilot-legal-copyright-fair-use-public-code', 'moritzgerstung', 'ellipapaemmanuil', 'inigomartincorena', 'larsbullinger', 'verenaigaidzik', 'peterpaschka', 'michaelheuser', 'felicitasthol', 'niccolobolli', 'peterganly', 'etal.2017.precisiononcologyforacutemyeloidleukemiausingaknowledge', 'bankapproach.naturegenetics49,3', ',332–340', 'morgeva', 'yoavgoldberg', 'andjonathanberant.2019.arewemodelingthetaskortheannotator', '?', 'aninvestigationof', 'annotatorbiasinnaturallanguageunderstandingdatasets.inproceedingsofthe2019conferenceonempiricalmethods', 'innaturallanguageprocessingandthe9thinternationaljointconferenceonnaturallanguageprocessing', 'emnlp-ijcnlp', 'associationforcomputationallinguistics', 'hongkong', 'china,1161–1166', 'https', '//doi.org/10.18653/v1/d19-1107', 'morgeva', 'r.schuster', 'jonathanberant', 'andomerlevy.2020.transformerfeed-forwardlayersarekey-valuememories', 'arxivabs/2012.14913', '2020', 'neginghavamiandletitiaannepeplau.2013', 'anintersectionalanalysisofgenderandethnicstereotypes', 'test', 'threehypotheses', 'psychologyofwomenquarterly37,1', '2013', ',113–127', 'https', '//doi.org/10.1177/0361684312464203', 'arxiv', 'https', '//doi.org/10.1177/0361684312464203', 'amirgholami', 'sehoonkim', 'zhendong', 'zheweiyao', 'michaelwmahoney', 'andkurtkeutzer.2021.asurveyofquantization', 'methodsforefficientneuralnetworkinference.arxivpreprintarxiv:2103.13630', '2021', 'amirataghorbaniandjameszou.2019.datashapley', 'equitablevaluationofdataformachinelearning.ininternational', 'conferenceonmachinelearning.pmlr,2242–2251', 'jamesjgibson.1979.theecologicalapproachtovisualperception.psychologypress', 'taliabgillisandjannlspiess.2019', 'bigdataanddiscrimination', 'theuniversityofchicagolawreview86,2', '2019', '459–488', 'antonioginart', 'melodyy.guan', 'gregoryvaliant', 'andjameszou.2019.makingaiforgetyou', 'datadeletioninmachine', 'learn', 'arxiv:1907.05012', '[', 'cs.lg', ']', 'kathrynt.gines.2011.blackfeminismandintersectionalanalyses.philosophytoday55,9999', '2011', ',275–284', 'https', '//doi.org/10.5840/philtoday201155supplement68', 'janecginsburgandlukealibudiardjo.2019.authorsandmachines.berkeleytech.lj34', '2019', ',343', 'rossgirshick', 'jeffdonahue', 'trevordarrell', 'andjitendramalik.2014.richfeaturehierarchiesforaccurateobjectdetection', 'andsemanticsegmentation.inproceedingsoftheieeeconferenceoncomputervisionandpatternrecognition.580–587', 'xavierglorotandyoshuabengio.2010', 'understandingthedifficultyoftrainingdeepfeedforwardneuralnetworks.in', 'internationalconferenceonartificialintelligenceandstatistics', 'abhinavgoel', 'calebtung', 'yung-hsianglu', 'andgeorgekthiruvathukal.2020b.asurveyofmethodsforlow-powerdeep', 'learningandcomputervision.in2020ieee6thworldforumoninternetofthings', 'wf-iot', '.ieee,1–6', 'karangoel', 'albertgu', 'yixuanli', 'andchristopherré.2020a.modelpatching', 'closingthesubgroupperformancegapwith', 'dataaugmentation.arxivpreprintarxiv:2008.06775', '2020', 'karangoel', 'nazneenrajani', 'jessevig', 'samsontan', 'jasonwu', 'stephanzheng', 'caimingxiong', 'mohitbansal', 'andchristopher', 'ré.2021.robustnessgym', 'unifyingthenlpevaluationlandscape.arxivpreprintarxiv:2101.04840', '2021', 'gabrielgoh', 'nickcammarata', 'chelseavoss', 'shancarter', 'michaelpetrov', 'ludwigschubert', 'alecradford', 'andchrisolah', '2021.multimodalneuronsinartificialneuralnetworks.distill6,3', '2021', 'e30', 'seraphinagoldfarb-tarrant', 'rebeccamarchant', 'ricardomuñozsánchez', 'mugdhapandya', 'andadamlopez.2021.intrinsic', 'biasmetricsdonotcorrelatewithapplicationbias.inproceedingsofthe59thannualmeetingoftheassociationfor', 'computationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing', 'volume1', 'long', 'paper', '.associationforcomputationallinguistics', 'online,1926–1940', 'https', '//doi.org/10.18653/v1/2021.acl-long.150', 'hilagonenandyoavgoldberg.2019', 'lipstickonapig', 'debiasingmethodscoverupsystematicgenderbiasesinword', 'embeddingsbutdonotremovethem.inproceedingsofnaacl2019', 'iangoodfellow', 'yoshuabengio', 'andaaroncourville.2016.deeplearning.mitpress']",175
Opportunities and Risks of Foundational Models - Stanford.pdf,"['176', 'centerforresearchonfoundationmodels', 'crfm', 'ianj.goodfellow', 'jeanpouget-abadie', 'mehdimirza', 'bingxu', 'davidwarde-farley', 'sherjilozair', 'aaroncourville', 'yoshuabengio.2014.generativeadversarialnets.inadvancesinneuralinformationprocessingsystems', 'neurips', 'charlesa.e.goodhart.1984', 'problemsofmonetarymanagement', 'theukexperience', 'inmonetarytheoryandpractice', 'springer,91–121', 'https', '//link.springer.com/chapter/10.1007/978-1-349-17295-5_4', 'm.a.goodrichanda.schultz.2007.human-robotinteraction', 'asurvey.found.trendshum.comput.interact.1', '2007', '203–275', 'divyagopinath', 'monicaagrawal', 'lukemurray', 'stevenhorng', 'davidkarger', 'anddavidsontag.2020.fast', 'structure', 'clinicaldocumentationviacontextualautocomplete.inproceedingsofthe5thmachinelearningforhealthcareconference', 'proceedingsofmachinelearningresearch', 'vol.126', 'finaledoshi-velez', 'jimfackler', 'kenjung', 'davidkale', 'rajesh', 'ranganath', 'byronwallace', 'andjennawiens', 'eds.', '.pmlr,842–870', 'http', '//proceedings.mlr.press/v126/gopinath20a.html', 'mitchellagordon', 'kevinduh', 'andnicholasandrews.2020.compressingbert', 'studyingtheeffectsofweightpruning', 'ontransferlearning.arxivpreprintarxiv:2002.08307', '2020', 'assafgottlieb', 'gideonystein', 'eytanruppin', 'androdedsharan.2011', 'predict', 'amethodforinferringnoveldrug', 'indicationswithapplicationtopersonalizedmedicine.molecularsystemsbiology7,1', '2011', ',496', 'namangoyal', 'jingfeidu', 'myleott', 'girianantharaman', 'andalexisconneau.2021', 'larger-scaletransformersfor', 'multilingualmaskedlanguagemodeling.arxivpreprintarxiv:2105.00572', '2021', 'r.goyal', 's.kahou', 'vincentmichalski', 'joannamaterzynska', 's.westphal', 'heunakim', 'valentinhaenel', 'ingofründ', 'p', 'yianilos', 'moritzmueller-freitag', 'f.hoppe', 'christianthurau', 'i.bax', 'andr.memisevic.2017a.the', '“', 'somethingsomething', '”', 'videodatabaseforlearningandevaluatingvisualcommonsense.2017ieeeinternationalconferenceoncomputer', 'vision', 'iccv', ',5843–5851', 'yashgoyal', 'tejaskhot', 'douglassummers-stay', 'dhruvbatra', 'anddeviparikh.2017b.makingthevinvqamatter', 'elevate', 'theroleofimageunderstandinginvisualquestionanswering.inproceedingsoftheieeeconferenceoncomputervision', 'andpatternrecognition.6904–6913', 'christinegrady.2015.institutionalreviewboards.chest148,5', 'nov.2015', ',1148–1155', 'https', '//doi.org/10.1378/chest.15-0706', 'dongrant', 'davidzelinka', 'andstefaniamitova.2021.reducingco2emissionsbytargetingtheworld', '’', 'shyper-polluting', 'powerplants.environmentalresearchletters', '2021', 'alexgraves', 'gregwayne', 'andivodanihelka.2014.neuralturingmachines.arxivpreprintarxiv:1410.5401', '2014', 'alexgraves', 'gregwayne', 'malcolmreynolds', 'timharley', 'ivodanihelka', 'agnieszkagrabska-barwińska', 'sergiogómez', 'colmenarejo', 'edwardgrefenstette', 'tiagoramalho', 'johnagapiou', 'etal.2016.hybridcomputingusinganeuralnetwork', 'withdynamicexternalmemory.nature538,7626', ',471–476', 'jonathangray', 'kavyasrinet', 'yacinejernite', 'haonanyu', 'zhuoyuanchen', 'demiguo', 'siddharthgoyal', 'clawrencezitnick', 'andarthurszlam.2019.craftassist', 'aframeworkfordialogue-enabledinteractiveagents.arxivpreprintarxiv:1907.08584', '2019', 'anthonyg.greenwald', 'debbiee.mcghee', 'andjordanl.k.schwartz.1998.measuringindividualdifferencesinimplicit', 'cognition', 'theimplicitassociationtest.journalofpersonalityandsocialpsychology74,6', '1998', ',1464.', 'https', '//psycnet', 'apa.org/record/1998-02892-004', 'shaigretz', 'yonatanbilu', 'edocohen-karlik', 'andnoamslonim.2020.theworkweekisthebesttimetostartafamily–a', 'studyofgpt-2basedclaimgeneration.arxivpreprintarxiv:2010.06185', '2020', 'jean-bastiengrill', 'florianstrub', 'florentaltch', '’', 'e', 'c.tallec', 'pierreh.richemond', 'elenabuchatskaya', 'carldoersch', 'b.a', 'pires', 'z.guo', 'm.g.azar', 'bilalpiot', 'k.kavukcuoglu', 'r.munos', 'andmichalvalko.2020.bootstrapyourownlatent', 'newapproachtoself-supervisedlearning.arxivabs/2006.07733', '2020', 'stephengrimm.2021.understanding.inthestanfordencyclopediaofphilosophy', 'summer2021ed.', 'edwardn.zalta', 'ed.', 'metaphysicsresearchlab', 'stanforduniversity', 'jamesgrimmelmann.2015.there', '’', 'snosuchthingasacomputer-authoredwork-andit', '’', 'sagoodthing', 'too.colum.jl', '&', 'arts39', ',403', 'jacobgrinfeld', 'jyotinangalia', 'ejoannabaxter', 'davidcwedge', 'nicosangelopoulos', 'robertcantrill', 'annalgodfrey', 'ellipa-', 'paemmanuil', 'gunesgundem', 'cathymaclean', 'etal.2018.classificationandpersonalizedprognosisinmyeloproliferative', 'neoplasms.newenglandjournalofmedicine379,15', ',1416–1430', 'maurargrossmanandgordonvcormack.2010.technology-assistedreviewine-discoverycanbemoreeffectiveand', 'moreefficientthanexhaustivemanualreview.rich.jl', '&', 'tech.17', '2010', ',1', 'jianguan.2019.artificialintelligenceinhealthcareandmedicine', 'promise', 'ethicalchallengesandgovernance.chinese', 'medicalsciencesjournal34,2', '2019', ',76–83', 'sumitgulwani', 'oleksandrpolozov', 'andrishabhsingh.2017.programsynthesis.found.trendsprogram.lang.4,1-2', '1–119', 'https', '//doi.org/10.1561/2500000010', 'sumitgulwaniandrishabhsingh.2013.automatedfeedbackgenerationforintroductoryprogrammingassignments.in', 'acmsigplanconferenceonprogramminglanguagedesignandimplementation', 'pldi2013', 'acmsigplanconferenceon', 'programminglanguagedesignandimplementation', 'pldi2013', 'ed.', '.15–26', 'https', '//www.microsoft.com/en-us/research/']",176
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '177', 'publication/automated-feedback-generation-for-introductory-programming-assignments/', 'suriyagunasekar', 'jasondlee', 'danielsoudry', 'andnatisrebro.2018.implicitbiasofgradientdescentonlinearconvolutional', 'networks.inadvancesinneuralinformationprocessingsystems.9461–9471', 'suriyagunasekar', 'blakeewoodworth', 'srinadhbhojanapalli', 'behnamneyshabur', 'andnatisrebro.2017.implicitregular-', 'izationinmatrixfactorization.inadvancesinneuralinformationprocessingsystems', 'neurips', '.6151–6159', 'dayaguo', 'shuoren', 'shuailu', 'zhangyinfeng', 'duyutang', 'shujieliu', 'longzhou', 'nanduan', 'alexeysvyatkovskiy', 'shengyufu', 'etal.2020.graphcodebert', 'pre-trainingcoderepresentationswithdataflow.arxivpreprintarxiv:2009.08366', '2020', 'qiguo', 'chinmaykulkarni', 'aniketkittur', 'jeffreyp.bigham', 'andemmabrunskill.2016.questimator', 'generatingknowledge', 'assessmentsforarbitrarytopics.inproceedingsofthetwenty-fifthinternationaljointconferenceonartificialintelligence', 'newyork', 'newyork', 'usa', 'ijcai', '’', '16', '.aaaipress,3726–3732', 'weiguoandaylincaliskan.2021.detectingemergentintersectionalbiases', 'contextualizedwordembeddingscontaina', 'distributionofhuman-likebiases.inproceedingsofthe2021aaai/acmconferenceonai', 'ethics', 'andsociety', 'virtual', 'event', 'usa', 'aies', '’', '21', '.associationforcomputingmachinery', 'newyork', 'ny', 'usa,122–133', 'https', '//doi.org/10.1145/', '3461702.3462536', 'abhinavgupta', 'adithyavairavanmurali', 'dhirajgandhi', 'andlerrelpinto.2018', 'robotlearninginhomes', 'improve', 'generalizationandreducingdatasetbias.inneurips', 'abhishekgupta', 'justinyu', 'tonyzhao', 'vikashkumar', 'aaronrovinsky', 'kelvinxu', 'thomasdevlin', 'andsergeylevine', '2021b.reset-freereinforcementlearningviamulti-tasklearning', 'learningdexterousmanipulationbehaviorswithout', 'humanintervention.arxivpreprintarxiv:2104.11203', '2021', 'uditgupta', 'younggeunkim', 'sylvialee', 'jordantse', 'hsien-hsinslee', 'gu-yeonwei', 'davidbrooks', 'andcarole-jeanwu', '2021a.chasingcarbon', 'theelusiveenvironmentalfootprintofcomputing.in2021ieeeinternationalsymposiumon', 'high-performancecomputerarchitecture', 'hpca', '.ieee,854–867', 'suchingururangan', 'anamarasović', 'swabhaswayamdipta', 'kylelo', 'izbeltagy', 'dougdowney', 'andnoaha.smith.2020', '’', 'tstoppretraining', 'adaptlanguagemodelstodomainsandtasks', 'arxiv:2004.10964', '[', 'cs.cl', ']', 'suchingururangan', 'swabhaswayamdipta', 'omerlevy', 'royschwartz', 'samuelbowman', 'andnoahasmith.2018.annotation', 'artifactsinnaturallanguageinferencedata.inassociationforcomputationallinguistics', 'acl', '.107–112', 'kelvinguu', 'kentonlee', 'zoratung', 'panupongpasupat', 'andming-weichang.2020.realm', 'retrieval-augmentedlanguage', 'modelpre-training.arxivpreprintarxiv:2002.08909', '2020', 'n.haber', 'damianmrowca', 'lifei-fei', 'anddanielyamins.2018.learningtoplaywithintrinsically-motivatedself-aware', 'agents.inneurips', 'danijarhafner', 't.lillicrap', 'ians.fischer', 'rubenvillegas', 'davidrha', 'honglaklee', 'andjamesdavidson.2019.learning', 'latentdynamicsforplanningfrompixels.ininternationalconferenceonmachinelearning', 'icml', 'martinj.haigh.1985.anintroductiontocomputer-aideddesignandmanufacture.blackwellscientificpublications', 'ltd.', 'gbr', 'karenhambardzumyan', 'hrantkhachatrian', 'andjonathanmay.2021.warp', 'word-leveladversarialreprogramming.in', 'proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljoint', 'conferenceonnaturallanguageprocessing', 'volume1', 'longpapers', '.associationforcomputationallinguistics', 'online', '4921–4933', 'https', '//doi.org/10.18653/v1/2021.acl-long.381', 'haraldhammarström', 'robertforkel', 'martinhaspelmath', 'andsebastianbank.2021', 'glottolog4.4', 'leipzig', 'https', '//doi.org/10.5281/zenodo.4761960', 'jessemichaelhan', 'jasonrute', 'yuhuaiwu', 'edwardw.ayers', 'andstanislaspolu.2021', 'proofartifactco-trainingfor', 'theoremprovingwithlanguagemodels.thefirstmathematicalreasoningingeneralartificialintelligenceworkshop', 'iclr2021', '2021', 'https', '//mathai-iclr.github.io/papers/papers/mathai_23_paper.pdf', 'jeffreythancock', 'mornaaman', 'andkarenlevy.2020.ai-mediatedcommunication', 'definition', 'researchagenda', 'ethicalconsiderations.journalofcomputer-mediatedcommunication', '2020', 'd.j.hand.2010.measurementtheoryandpractice', 'theworldthroughquantification.wiley', 'https', '//books.google.com/', 'book', '?', 'id=rap0pwaacaaj', 'alexhanna', 'emilydenton', 'andrewsmart', 'andjamilasmith-loud.2020.towardsacriticalracemethodologyinalgorithmic', 'fairness.inproceedingsofthe2020conferenceonfairness', 'accountability', 'andtransparency.501–512', 'stephenrhanney', 'sophiecastle-clarke', 'jonathangrant', 'susanguthrie', 'chrishenshall', 'jorgemestre-ferrandiz', 'michele', 'pistollato', 'alexandrapollitt', 'jonsussex', 'andstevenwooding.2015.howlongdoesbiomedicalresearchtake', '?', 'study', 'thetimetakenbetweenbiomedicalandhealthresearchanditstranslationintoproducts', 'policy', 'andpractice.health', 'researchpolicyandsystems13,1', ',1–18', 'jeffz.haochen', 'colinwei', 'adriengaidon', 'andtengyuma.2021a.provableguaranteesforself-superviseddeeplearning', 'withspectralcontrastiveloss.corrabs/2106.04156', '2021', '.arxiv:2106.04156', 'https', '//arxiv.org/abs/2106.04156']",177
Opportunities and Risks of Foundational Models - Stanford.pdf,"['178', 'centerforresearchonfoundationmodels', 'crfm', 'jeffzhaochen', 'colinwei', 'jasonlee', 'andtengyuma.2021b.shapematters', 'understandingtheimplicitbiasofthenoise', 'covariance.inconferenceonlearningtheory.pmlr,2315–2357', 'alberthaque', 'michelleguo', 'alexandrealahi', 'serenayeung', 'zelunluo', 'alisharege', 'jeffreyjopling', 'lancedowning', 'williambeninati', 'amitsingh', 'etal.2017.towardsvision-basedsmarthospitals', 'asystemfortrackingandmonitoring', 'handhygienecompliance.inmachinelearningforhealthcareconference.pmlr,75–87', 'alberthaque', 'arnoldmilstein', 'andlifei-fei.2020.illuminatingthedarkspacesofhealthcarewithambientintelligence', 'nature585,7824', '2020', ',193–202', 'sandraharding.2015.objectivityanddiversity.universityofchicagopress', 'https', '//doi.org/doi:10.7208/9780226241531', 'stefanharrer', 'pratikshah', 'bhavnaantony', 'andjianyinghu.2019.artificialintelligenceforclinicaltrialdesign.trendsin', 'pharmacologicalsciences40,8', '2019', ',577–591', 'tatsunorihashimoto', 'meghasrivastava', 'hongseoknamkoong', 'andpercyliang.2018.fairnesswithoutdemographicsin', 'repeatedlossminimization.ininternationalconferenceonmachinelearning.pmlr,1929–1938', 'kaiminghe', 'haoqifan', 'yuxinwu', 'sainingxie', 'androssgirshick.2019.momentumcontrastforunsupervisedvisual', 'representationlearning.arxivpreprintarxiv:1911.05722', '2019', 'kaiminghe', 'haoqifan', 'yuxinwu', 'sainingxie', 'androssb.girshick.2020.momentumcontrastforunsupervisedvisual', 'representationlearning.2020ieee/cvfconferenceoncomputervisionandpatternrecognition', 'cvpr', '2020', ',9726–9735', 'kaiminghe', 'xiangyuzhang', 'shaoqingren', 'andjiansun.2016a.deepresiduallearningforimagerecognition.inproceedings', 'oftheieeeconferenceoncomputervisionandpatternrecognition.770–778', 'kaiminghe', 'xiangyuzhang', 'shaoqingren', 'andjiansun.2016b', 'deepresiduallearningforimagerecognition.in', 'computervisionandpatternrecognition', 'cvpr', 'allisonhegel', 'marinashah', 'genevievepeaslee', 'brendanroof', 'andemadelwany.2021', 'thelawoflargedocuments', 'understandingthestructureoflegalcontractsusingvisualcues.arxivpreprintarxiv:2107.08128', '2021', 'fabiancabaheilbron', 'victorescorcia', 'bernardghanem', 'andjuancarlosniebles.2015.activitynet', 'alarge-scalevideo', 'benchmarkforhumanactivityunderstanding.inproceedingsoftheieeeconferenceoncomputervisionandpattern', 'recognition.961–970', 'robertheilmayr', 'cristianecheverría', 'andericflambin.2020.impactsofchileanforestsubsidiesonforestcover', 'carbon', 'andbiodiversity.naturesustainability3,9', '2020', ',701–709', 'christinaheinze-demlandnicolaimeinshausen.2017.conditionalvariancepenaltiesanddomainshiftrobustness.arxiv', 'preprintarxiv:1710.11469', 'kylehelfrich', 'devinwillmott', 'andqiangye.2018.orthogonalrecurrentneuralnetworkswithscaledcayleytransform.in', 'internationalconferenceonmachinelearning.pmlr,1969–1978', 'josephmhellersteinandmichaelstonebraker.2005.readingsindatabasesystems.mitpress', 'deborahhellman.2020.measuringalgorithmicfairness.va.l.rev.106', '2020', ',811', 'deborahhellman.2021.bigdataandcompoundinginjustice.journalofmoralphilosophy', 'forthcoming', 'virginiapublic', 'lawandlegaltheoryresearchpaper2021-27', '2021', 'mikaelhenaff', 'jasonweston', 'arthurszlam', 'antoinebordes', 'andyannlecun.2016.trackingtheworldstatewithrecurrent', 'entitynetworks.arxivpreprintarxiv:1612.03969', 'olivierjhénaff', 'skandakoppula', 'jean-baptistealayrac', 'aaronvandenoord', 'oriolvinyals', 'andjoãocarreira.2021', 'efficientvisualpretrainingwithcontrastivedetection.iccv', '2021', 'peterhenderson', 'jieruhu', 'joshuaromoff', 'emmabrunskill', 'danjurafsky', 'andjoellepineau.2020.towardsthesystematic', 'reportingoftheenergyandcarbonfootprintsofmachinelearning.journalofmachinelearningresearch21,248', '2020', '1–43', 'peterhenderson', 'koustuvsinha', 'nicolasangelard-gontier', 'nanrosemaryke', 'genevievefried', 'ryanlowe', 'andjoelle', 'pineau.2017.ethicalchallengesindata-drivendialoguesystems.inaaai/acmaiethicsandsocietyconference', 'danhendrycks', 'collinburns', 'stevenbasart', 'andyzou', 'mantasmazeika', 'dawnsong', 'andjacobsteinhardt.2021a.measuring', 'massivemultitasklanguageunderstanding.ininternationalconferenceonlearningrepresentations', 'iclr', 'danhendrycks', 'collinburns', 'stevenbasart', 'andyzou', 'mantasmazeika', 'dawnsong', 'andjacobsteinhardt.2021b', 'measuringmassivemultitasklanguageunderstanding.ininternationalconferenceonlearningrepresentations', 'https', '//openreview.net/forum', '?', 'id=d7kbjmi3gmq', 'danhendrycks', 'collinburns', 'anyachen', 'andspencerball.2021c.cuad', 'anexpert-annotatednlpdatasetforlegalcontract', 'review.arxivpreprintarxiv:2103.06268', '2021', 'danhendrycks', 'nicholascarlini', 'johnschulman', 'tomdietterich', 'andjacobsteinhardt.2021d.unsolvedproblemsinml', 'safety.arxivpreprint', '2021', 'danhendrycksandthomasdietterich.2019', 'benchmarkingneuralnetworkrobustnesstocommoncorruptionsand', 'perturbations.ininternationalconferenceonlearningrepresentations', 'iclr', 'danhendrycks', 'kiminlee', 'andmantasmazeika.2019a.usingpre-trainingcanimprovemodelrobustnessanduncertainty', 'ininternationalconferenceonmachinelearning', 'icml']",178
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '179', 'danhendrycks', 'xiaoyuanliu', 'ericwallace', 'adamdziedzic', 'rishabhkrishnan', 'anddawnsong.2020.pretrainedtrans-', 'formersimproveout-of-distributionrobustness.arxivpreprintarxiv:2004.06100', '2020', 'danhendrycks', 'mantasmazeika', 'sauravkadavath', 'anddawnsong.2019b.usingself-supervisedlearningcanimprove', 'modelrobustnessanduncertainty.inadvancesinneuralinformationprocessingsystems', 'neurips', 'danhendrycks', 'kevinzhao', 'stevenbasart', 'jacobsteinhardt', 'anddawnsong.2021e', 'naturaladversarialexamples', 'arxiv:1907.07174', '[', 'cs.lg', ']', 'tomhenighan', 'jaredkaplan', 'morkatz', 'markchen', 'christopherhesse', 'jacobjackson', 'heewoojun', 't.brown', 'prafulla', 'dhariwal', 'scottgray', 'chrishallacy', 'benjaminmann', 'alecradford', 'adityaramesh', 'nickryder', 'danielm.ziegler', 'john', 'schulman', 'darioamodei', 'andsammccandlish.2020', 'scalinglawsforautoregressivegenerativemodeling', 'arxiv', 'abs/2010.14701', '2020', 'https', '//arxiv.org/abs/2010.14701', 'sylvial.herbert', 'jasonj.choi', 'suvanshqazi', 'marsalisgibson', 'k.sreenath', 'andc.tomlin.2021', 'scalablelearningof', 'safetyguaranteesforautonomoussystemsusinghamilton-jacobireachability.arxivpreprintarxiv:2101.05916', '2021', 'maguireherriman', 'elanameer', 'royrosin', 'vivianlee', 'vindellwashington', 'andkevingvolpp.2020.askedandanswered', 'buildingachatbottoaddresscovid-19-relatedconcerns.nejmcatalystinnovationsincaredelivery', '2020', 'j.hestness', 'sharannarang', 'newshaardalani', 'g.diamos', 'heewoojun', 'hassankianinejad', 'md.mostofaalipatwary', 'yang', 'andyanqizhou.2017.deeplearningscalingispredictable', 'empirically.arxivabs/1712.00409', 'johnhewittandpercyliang.2019', 'designingandinterpretingprobeswithcontroltasks.inproceedingsofthe2019', 'conferenceonempiricalmethodsinnaturallanguageprocessingandthe9thinternationaljointconferenceonnatural', 'languageprocessing', 'emnlp-ijcnlp', '.associationforcomputationallinguistics', 'hongkong', 'china', 'https', '//www', 'aclweb.org/anthology/d19-1275', 'johnhewittandchristopherd.manning.2019.astructuralprobeforfindingsyntaxinwordrepresentations.innorth', 'americanchapteroftheassociationforcomputationallinguistics', 'humanlanguagetechnologies', 'naacl', 'minneapolis', 'usa', '.associationforcomputationallinguistics', 'hidalgo.2021.howhumansjudgemachines.themitpress', 'cambridge', 'massachusetts', 'brianhie', 'ellendzhong', 'bonnieberger', 'andbryanbryson.2021.learningthelanguageofviralevolutionandescape', 'science371,6526', '2021', ',284–288', 'geoffreyhinton', 'oriolvinyals', 'andjeffdean.2015', 'distillingtheknowledgeinaneuralnetwork', 'arxivpreprint', 'arxiv:1503.02531', 'geoffreyehinton', 'simonosindero', 'andyee-whyeteh.2006', 'afastlearningalgorithmfordeepbeliefnets', 'neural', 'computation18,7', '2006', ',1527–1554', 'danielehoandalicexiang.2020.affirmativealgorithms', 'thelegalgroundsforfairnessasawareness.u.chi.l.rev', 'online', '2020', ',134', 'jonathanho', 'ajayjain', 'andp.abbeel.2020.denoisingdiffusionprobabilisticmodels.arxivabs/2006.11239', '2020', 'sepphochreiterandjürgenschmidhuber.1997.longshort-termmemory.neuralcomputation9,8', '1997', ',1735–1780', 'bashofstra', 'vivekv.kulkarni', 'sebastianmunoz-najargalvez', 'bryanhe', 'danjurafsky', 'anddaniela.mcfarland.2020.the', 'diversity–innovationparadoxinscience.proceedingsofthenationalacademyofsciences117,17', 'april2020', ',9284–9291', 'https', '//doi.org/10.1073/pnas.1915378117', 'fredhohman', 'minsukkahng', 'robertpienta', 'andduenhorngchau.2018.visualanalyticsindeeplearning', 'aninterrogative', 'surveyforthenextfrontiers.ieeetransactionsonvisualizationandcomputergraphics25,8', ',2674–2693', 'fredhohman', 'kanitwongsuphasawat', 'marybethkery', 'andkayurpatel.2020.understandingandvisualizingdataiteration', 'inmachinelearning.inproceedingsofthe2020chiconferenceonhumanfactorsincomputingsystems.1–13', 'karend.hollandpedroh.s.brancalion.2020.treeplantingisnotasimplesolution.science368,6491', 'may2020', ',580–581', 'https', '//doi.org/10.1126/science.aba8232zscc:0000092publisher', 'americanassociationfortheadvancementofscience', 'section', 'perspective', 'sarahholland', 'ahmedhosny', 'sarahnewman', 'joshuajoseph', 'andkasiachmielinski.2018.thedatasetnutritionlabel', 'frameworktodrivehigherdataqualitystandards', 'arxiv:1805.03677', '[', 'cs.db', ']', 'norahollenstein', 'mariustroendle', 'cezhang', 'andnicolaslanger.2020.zuco2.0', 'adatasetofphysiologicalrecordings', 'duringnaturalreadingandannotation.inproceedingsofthe12thlanguageresourcesandevaluationconference', 'europeanlanguageresourcesassociation', 'marseille', 'france,138–146', 'ariholtzman', 'janbuys', 'maxwellforbes', 'andyejinchoi.2020', 'thecuriouscaseofneuraltextdegeneration.in', 'internationalconferenceonlearningrepresentations', 'iclr', 'nilsholzenberger', 'andrewblair-stanek', 'andbenjaminvandurme.2020', 'adatasetforstatutoryreasoningintaxlaw', 'entailmentandquestionanswering.arxivpreprintarxiv:2005.05257', '2020', 'andreasholzinger', 'georglangs', 'helmutdenk', 'kurtzatloukal', 'andheimomüller.2019.causabilityandexplainability', 'ofartificialintelligenceinmedicine.wileyinterdisciplinaryreviews', 'dataminingandknowledgediscovery9,4', '2019', 'e1312']",179
Opportunities and Risks of Foundational Models - Stanford.pdf,"['180', 'centerforresearchonfoundationmodels', 'crfm', 'spurthiambahombaiah', 'taochen', 'mingyangzhang', 'michaelbendersky', 'andmarcnajork.2021.dynamiclanguage', 'modelsforcontinuouslyevolvingcontent.corrabs/2106.06297', '2021', '.arxiv:2106.06297', 'https', '//arxiv.org/abs/2106', '06297', 'joeyhong', 'daviddohan', 'rishabhsingh', 'charlessutton', 'andmanzilzaheer.2021.latentprogrammer', 'discretelatent', 'codesforprogramsynthesis.ininternationalconferenceinmachinelearning', 'icml', 'jasonihongandjamesalanday.2004.anarchitectureforprivacy-sensitiveubiquitouscomputing.inproceedingsofthe', '2ndinternationalconferenceonmobilesystems', 'applications', 'andservices.177–189', 'luhongandscottepage.2004.groupsofdiverseproblemsolverscanoutperformgroupsofhigh-abilityproblemsolvers', 'science101,46', '2004', 'sanghyunhong', 'yiğitcankaya', 'ionuţ-vladmodoranu', 'andtudordumitraş.2020a.apanda', '?', '’', 'sasloth', 'slowdown', 'attacksonadaptivemulti-exitneuralnetworkinference.arxivpreprintarxiv:2010.02432', '2020', 'songbaihong', 'guodongyin', 'shilongpiao', 'raydybzinski', 'nancong', 'xiangyili', 'kaiwang', 'joseppeñuelas', 'huizeng', 'andanpingchen.2020b.divergentresponsesofsoilorganiccarbontoafforestation.naturesustainability3,9', '2020', '694–700', 'sarahooker.2020.thehardwarelottery.arxivpreprintarxiv:2009.06489', '2020', 'sarahooker', 'nyallengmoorosi', 'gregoryclark', 'samybengio', 'andemilyl.denton.2020.characterisingbiasincompressed', 'models.arxivabs/2010.03058', '2020', 'https', '//arxiv.org/abs/2010.03058', 'erichorvitz.1999.principlesofmixed-initiativeuserinterfaces.inproceedingsofthesigchiconferenceonhumanfactors', 'incomputingsystems.acm', 'neilhoulsby', 'andreigiurgiu', 'stanislawjastrzebski', 'brunamorrone', 'quentindelaroussilhe', 'andreagesmundo', 'mona', 'attariyan', 'andsylvaingelly.2019.parameter-efficienttransferlearningfornlp.inproceedingsofthe36thinternational', 'conferenceonmachinelearning', 'proceedingsofmachinelearningresearch', 'vol.97', 'kamalikachaudhuriandruslan', 'salakhutdinov', 'eds.', '.pmlr,2790–2799', 'http', '//proceedings.mlr.press/v97/houlsby19a.html', 'dirkhovyandanderssøgaard.2015.taggingperformancecorrelateswithage.inassociationforcomputationallinguistics', 'acl', '.483–488', 'jeremyhowardandsebastianruder.2018.universallanguagemodelfine-tuningfortextclassification.inassociationfor', 'computationallinguistics', 'acl', 'edwardj.hu', 'yelongshen', 'phillipwallis', 'zeyuanallen-zhu', 'yuanzhili', 'sheanwang', 'andweizhuchen.2021', 'lora', 'low-rankadaptationoflargelanguagemodels.corrabs/2106.09685', '2021', '.arxiv:2106.09685', 'https', '//arxiv.org/abs/', '2106.09685', 'junjiehu', 'sebastianruder', 'adityasiddhant', 'grahamneubig', 'orhanfirat', 'andmelvinjohnson.2020.xtreme', 'amassively', 'multilingualmulti-taskbenchmarkforevaluatingcross-lingualgeneralization.arxivpreprintarxiv:2003.11080', '2020', 'danielhuang', 'prafulladhariwal', 'dawnsong', 'andilyasutskever.2018.gamepad', 'alearningenvironmentfortheorem', 'proving.corrabs/1806.00608', '.arxiv:1806.00608', 'http', '//arxiv.org/abs/1806.00608', 'jianpinghuang', 'haipengyu', 'xiaodanguan', 'guoyinwang', 'andruixiaguo.2016.accelerateddrylandexpansionunder', 'climatechange.natureclimatechange6,2', 'feb.2016', ',166–171', 'https', '//doi.org/10.1038/nclimate2837zscc:0001034', 'bandiera_abtest', 'acg_type', 'natureresearchjournalsnumber:2primary_atype', 'researchpublisher', 'naturepublishing', 'groupsubject_term', 'developingworld', 'projectionandpredictionsubject_term_id', 'developing-world', 'projection-and-', 'prediction', 'kexinhuang', 'tianfanfu', 'wenhaogao', 'yuezhao', 'yusufroohani', 'jureleskovec', 'connorwcoley', 'caoxiao', 'jimengsun', 'andmarinkazitnik.2021a.therapeuticsdatacommons', 'machinelearningdatasetsandtasksfortherapeutics.arxiv', 'preprintarxiv:2102.09548', '2021', 'yanpinghuang', 'youlongcheng', 'ankurbapna', 'orhanfirat', 'dehaochen', 'miachen', 'hyoukjoonglee', 'jiquanngiam', 'quocvle', 'yonghuiwu', 'etal.2019', 'gpipe', 'efficienttrainingofgiantneuralnetworksusingpipelineparallelism', 'advancesinneuralinformationprocessingsystems32', '2019', ',103–112', 'zihanhuang', 'charleslow', 'mengqiuteng', 'hongyizhang', 'danieleho', 'markskrass', 'andmatthiasgrabmair.2021b', 'context-awarelegalcitationrecommendationusingdeeplearning.arxivpreprintarxiv:2106.10776', '2021', 'zhichenghuang', 'zhaoyangzeng', 'yupanhuang', 'beiliu', 'dongmeifu', 'andjianlongfu.2021c', 'seeingoutofthebox', 'end-to-endpre-trainingforvision-languagerepresentationlearning.inproceedingsoftheieee/cvfconferenceon', 'computervisionandpatternrecognition.12976–12985', 'evanhubinger', 'chrisvanmerwijk', 'vladimirmikulik', 'joarskalse', 'andscottgarrabrant.2019', 'risksfromlearned', 'optimizationinadvancedmachinelearningsystems.arxivabs/1906.01820', '2019', 'drewhudsonandchristopherdmanning.2019a', 'learningbyabstraction', 'theneuralstatemachine.inadvancesin', 'neuralinformationprocessingsystems.5903–5916', 'drewahudsonandchristopherdmanning.2018', 'compositionalattentionnetworksformachinereasoning', 'internationalconferenceonlearningrepresentations', 'iclr', 'internationalconferenceonlearningrepresentations', 'iclr']",180
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '181', 'drewahudsonandchristopherdmanning.2019b.gqa', 'anewdatasetforreal-worldvisualreasoningandcompositional', 'questionanswering.inproceedingsoftheieee/cvfconferenceoncomputervisionandpatternrecognition.6700–6709', 'drewahudsonandc.lawrencezitnick.2021.generativeadversarialtransformers.proceedingsofthe38thinternational', 'conferenceonmachinelearning', 'icml2021', '2021', 'jamesphughes', 'stephenrees', 'sbarrettkalindjian', 'andkarenlphilpott.2011.principlesofearlydrugdiscovery.british', 'journalofpharmacology162,6', '2011', ',1239–1249', 'benhutchinson', 'vinodkumarprabhakaran', 'emilydenton', 'kelliewebster', 'yuzhong', 'andstephendenuyl.2020.social', 'biasesinnlpmodelsasbarriersforpersonswithdisabilities.inproceedingsofthe58thannualmeetingoftheassociation', 'forcomputationallinguistics.associationforcomputationallinguistics', 'online,5491–5501', 'https', '//doi.org/10.18653/', 'v1/2020.acl-main.487', 'jenad.hwang', 'chandrabhagavatula', 'ronanlebras', 'jeffda', 'keisukesakaguchi', 'antoinebosselut', 'andyejinchoi.2021', 'comet-atomic2020', 'onsymbolicandneuralcommonsenseknowledgegraphs.inaaai', 'jeminhwangbo', 'joonholee', 'alexeydosovitskiy', 'dariobellicoso', 'vassiliostsounis', 'vladlenkoltun', 'andmarcohutter', '2019.learningagileanddynamicmotorskillsforleggedrobots.sciencerobotics4,26', '2019', 'janetshibleyhyde', 'rebeccas.bigler', 'daphnajoel', 'charlottechuckytate', 'andsarim.vananders.2019.thefutureofsex', 'andgenderinpsychology', 'fivechallengestothegenderbinary.americanpsychologist74', '2019', ',171–193', 'h.iida', 'dungthai', 'varunmanjunatha', 'andmohitiyyer.2021', 'tabbie', 'pretrainedrepresentationsoftabulardata.in', 'naacl', 'robertikedaandjenniferwidom.2010.panda', 'asystemforprovenanceanddata.', '2010', 'danielaionescuetal.2020', 'deeplearningalgorithmsandbighealthcaredatainclinicalnaturallanguageprocessing', 'linguisticandphilosophicalinvestigations19', '2020', ',86–92', 'daphneippolito', 'danielduckworth', 'chriscallison-burch', 'andd.eck.2020.automaticdetectionofgeneratedtextis', 'easiestwhenhumansarefooled.inacl', 'robertl.loganiv', 'ivanabalazevic', 'ericwallace', 'fabiopetroni', 'sameersingh', 'andsebastianriedel.2021', 'cut', 'downonpromptsandparameters', 'simplefew-shotlearningwithlanguagemodels', 'corrabs/2106.13353', '2021', 'arxiv:2106.13353', 'https', '//arxiv.org/abs/2106.13353', 'rayjackendoff.2011.whatisthehumanlanguagefaculty', '?', 'twoviews.language87,3', '2011', ',586–624', 'http', '//www.jstor', 'org/stable/23011656', 'simonjackman.2008', 'measurement', 'oxfordhandbooks', 'https', '//www.oxfordhandbooks.com/view/10.1093/oxfordhb/', '9780199286546.001.0001/oxfordhb-9780199286546-e-6', 'abigailz.jacobsandhannawallach.2021', 'measurementandfairness.inproceedingsofthe2021acmconferenceon', 'fairness', 'accountability', 'andtransparency', 'virtualevent', 'canada', 'facct', '’', '21', '.associationforcomputingmachinery', 'newyork', 'ny', 'usa,375–385', 'https', '//doi.org/10.1145/3442188.3445901', 'alonjacoviandyoavgoldberg.2020.towardsfaithfullyinterpretablenlpsystems', 'howshouldwedefineandevaluate', 'faithfulness', '?', 'arxivpreprintarxiv:2004.03685', '2020', 'alonjacovi', 'anamarasović', 'timmiller', 'andyoavgoldberg.2021.formalizingtrustinartificialintelligence', 'prerequisites', 'causesandgoalsofhumantrustinai.inproceedingsofthe2021acmconferenceonfairness', 'accountability', 'transparency.624–635', 'andrewjaegle', 'sebastianborgeaud', 'jean-baptistealayrac', 'carldoersch', 'catalinionescu', 'davidding', 'skandakoppula', 'danielzoran', 'andrewbrock', 'evanshelhamer', 'etal.2021a.perceiverio', 'ageneralarchitectureforstructuredinputs', '&', 'outputs.arxivpreprintarxiv:2107.14795', '2021', 'andrewjaegle', 'felixgimeno', 'andrewbrock', 'andrewzisserman', 'oriolvinyals', 'andjoãocarreira.2021b.perceiver', 'general', 'perceptionwithiterativeattention.ininternationalconferenceonmachinelearning', 'icml', 'm.jamnik.2001.mathematicalreasoningwithdiagrams', 'michaeljanner', 'qiyangli', 'andsergeylevine.2021.reinforcementlearningasonebigsequencemodelingproblem.arxiv', 'abs/2106.02039', '2021', 'theomvjanssenandbarbarahpartee.1997.compositionality.inhandbookoflogicandlanguage.elsevier,417–473', 'karoljaroch', 'alinajaroch', 'andbarbarabojko.2018.cellculturesindrugdiscoveryanddevelopment', 'theneedofreliable', 'invitro-invivoextrapolationforpharmacodynamicsandpharmacokineticsassessment.journalofpharmaceuticaland', 'biomedicalanalysis147', ',297–312', 'shervinjavdani', 'hennyadmoni', 'stefaniapellegrinelli', 'siddharthassrinivasa', 'andjandrewbagnell.2018.sharedautonomy', 'viahindsightoptimizationforteleoperationandteaming', 'internationaljournalofroboticsresearch', 'ijrr', '37', '717–742', 'siddhantmjayakumar', 'razvanpascanu', 'jackwrae', 'simonosindero', 'anderichelsen.2021.top-kast', 'top-kalways', 'sparsetraining.arxivpreprintarxiv:2106.03517', '2021', 'nealjean', 'marshallburke', 'michaelxie', 'wmatthewdavis', 'davidblobell', 'andstefanoermon.2016.combiningsatellite', 'imageryandmachinelearningtopredictpoverty.science353,6301', ',790–794']",181
Opportunities and Risks of Foundational Models - Stanford.pdf,"['182', 'centerforresearchonfoundationmodels', 'crfm', 'emilyjensen', 'meghandale', 'patrickjdonnelly', 'cathlynstone', 'seankelly', 'amandagodley', 'andsidneykd', '’', 'mello.2020', 'towardautomatedfeedbackonteacherdiscoursetoenhanceteacherlearning.inproceedingsofthe2020chiconference', 'onhumanfactorsincomputingsystems.1–13', 'sooyeonjeong', 'kristopherdossantos', 'suzannegraca', 'briannao', '’', 'connell', 'laurelanderson', 'nicolestenquist', 'katie', 'fitzpatrick', 'honeygoodenough', 'deirdrelogan', 'peterweinstock', 'etal.2015.designingasociallyassistiverobotfor', 'pediatriccare.inproceedingsofthe14thinternationalconferenceoninteractiondesignandchildren.387–390', 'yji', 'zzhou', 'hliu', 'andrvdavuluri.2021.dnabert', 'pre-trainedbidirectionalencoderrepresentationsfromtransformers', 'modelfordna-languageingenome.bioinformatics', '2021', 'shengyujia', 'taomeng', 'jieyuzhao', 'andkai-weichang.2020', 'mitigatinggenderbiasamplificationindistributionby', 'posteriorregularization.inproceedingsofthe58thannualmeetingoftheassociationforcomputationallinguistics', 'associationforcomputationallinguistics', 'online,2936–2942', 'https', '//doi.org/10.18653/v1/2020.acl-main.264', 'zhihaojia', 'jamesthomas', 'todwarszawski', 'mingyugao', 'mateizaharia', 'andalexaiken.2019a', 'optimizingdnn', 'computationwithrelaxedgraphsubstitutions.sysml2019', '2019', 'zhihaojia', 'mateizaharia', 'andalexaiken.2019b.beyonddataandmodelparallelismfordeepneuralnetworks.sysml', '2019', '2019', 'zhengbaojiang', 'frankf.xu', 'junaraki', 'andgrahamneubig.2020.howcanweknowwhatlanguagemodelsknow', '?', 'transactionsoftheassociationforcomputationallinguistics8', '2020', ',423–438', 'https', '//doi.org/10.1162/tacl_a_00324', 'dijin', 'zhijingjin', 'joeytianyizhou', 'andpeterszolovits.2020.isbertreallyrobust', '?', 'astrongbaselinefornaturallanguage', 'attackontextclassificationandentailment.inproceedingsoftheaaaiconferenceonartificialintelligence', 'vol.34', '8018–8025', 'qiaojin', 'zhengyuan', 'guangzhixiong', 'qianlanyu', 'chuanqitan', 'moshachen', 'songfanghuang', 'xiaozhongliu', 'andsheng', 'yu.2021.biomedicalquestionanswering', 'acomprehensivereview.arxivpreprintarxiv:2102.05281', '2021', 'wengongjin', 'reginabarzilay', 'andtommijaakkola.2018', 'junctiontreevariationalautoencoderformoleculargraph', 'generation.ininternationalconferenceonmachinelearning.pmlr,2323–2332', 'eunseojoandtimnitgebru.2020.lessonsfromarchives', 'strategiesforcollectingsocioculturaldatainmachinelearning', 'inproceedingsofthe2020conferenceonfairness', 'accountability', 'andtransparency.306–316', 'gabbriellem.johnson.2020', 'algorithmicbias', 'ontheimplicitbiasesofsocialtechnology', 'synthese', 'june2020', 'https', '//doi.org/10.1007/s11229-020-02696-y', 'jeffjohnson', 'matthijsdouze', 'andhervéjégou.2019.billion-scalesimilaritysearchwithgpus.ieeetransactionsonbig', 'data', '2019', 'justinjohnson', 'bharathhariharan', 'laurensvandermaaten', 'lifei-fei', 'clawrencezitnick', 'androssgirshick.2017.clevr', 'adiagnosticdatasetforcompositionallanguageandelementaryvisualreasoning.inproceedingsoftheieeeconference', 'oncomputervisionandpatternrecognition.2901–2910', 'pratikjoshi', 'sebastinsanty', 'amarbudhiraja', 'kalikabali', 'andmonojitchoudhury.2020.thestateandfateoflinguistic', 'diversityandinclusioninthenlpworld.inproceedingsofthe58thannualmeetingoftheassociationforcomputational', 'linguistics.6282–6293', 'normanpjouppi', 'cliffyoung', 'nishantpatil', 'davidpatterson', 'gauravagrawal', 'raminderbajwa', 'sarahbates', 'sureshbhatia', 'nanboden', 'alborchers', 'etal.2017.in-datacenterperformanceanalysisofatensorprocessingunit.inproceedingsof', 'the44thannualinternationalsymposiumoncomputerarchitecture.1–12', 'kyled.julianandmykelj.kochenderfer.2019.guaranteeingsafetyforneuralnetwork-basedaircraftcollisionavoidance', 'systems.2019ieee/aiaa38thdigitalavionicssystemsconference', 'dasc', 'sep2019', 'https', '//doi.org/10.1109/dasc43569', '2019.9081748', 'johnjumper', 'richardevans', 'alexanderpritzel', 'timgreen', 'michaelfigurnov', 'kathryntunyasuvunakool', 'olafronneberger', 'russbates', 'augustinžídek', 'alexbridgland', 'etal.2020.highaccuracyproteinstructurepredictionusingdeeplearning', 'fourteenthcriticalassessmentoftechniquesforproteinstructureprediction', 'abstractbook', '22', '2020', ',24', 'd.jurafskyandj.h.martin.2009.speechandlanguageprocessing', 'anintroductiontonaturallanguageprocessing', 'compu-', 'tationallinguistics', 'andspeechrecognition.pearsonprenticehall', 'https', '//books.google.gr/books', '?', 'id=fzmj5unk8aqc', 'davidjurgens', 'libbyhemphill', 'andeshwarchandrasekharan.2019.ajustandcomprehensivestrategyforusingnlp', 'toaddressonlineabuse.inproceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics', 'associationforcomputationallinguistics', 'florence', 'italy,3658–3666', 'https', '//doi.org/10.18653/v1/p19-1357', 'arturkadurin', 'sergeynikolenko', 'kuzmakhrabrov', 'alexaliper', 'andalexzhavoronkov.2017', 'drugan', 'anadvanced', 'generativeadversarialautoencodermodelfordenovogenerationofnewmoleculeswithdesiredmolecularpropertiesin', 'silico.molecularpharmaceutics14,9', ',3098–3104', 'lesliekaelbling.1993.learningtoachievegoals.ininternationaljointconferenceonartificialintelligence', 'ijcai', 'lukaszkaiser', 'aidanngomez', 'noamshazeer', 'ashishvaswani', 'nikiparmar', 'llionjones', 'andjakobuszkoreit.2017.one', 'modeltolearnthemall.arxivpreprintarxiv:1706.05137']",182
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '183', 'hildakajbaf.2019.thefirstamendmentandmoderntechnology', 'thefreespeechclauseandchatbotspeech.hastings', 'const.lq47', '2019', ',337', 'dmitrykalashnikov', 'jacobvarley', 'yevgenchebotar', 'benjaminswanson', 'ricojonschkowski', 'chelseafinn', 'sergeylevine', 'andkarolhausman.2021.mt-opt', 'continuousmulti-taskroboticreinforcementlearningatscale.arxivpreprint', 'arxiv:2104.08212', '2021', 'pratyushakalluri.2020.don', '’', 'taskifartificialintelligenceisgoodorfair', 'askhowitshiftspower.nature583,169', '2020', 'https', '//doi.org/10.1038/d41586-020-02003-2', 'danielkang', 'deeptiraghavan', 'peterbailis', 'andmateizaharia.2020.modelassertionsformonitoringandimprovingml', 'models.arxivpreprintarxiv:2003.01668', '2020', 'jaredkaplan', 'sammccandlish', 'tomhenighan', 'tomb.brown', 'benjaminchess', 'rewonchild', 'scottgray', 'alecradford', 'jeffreywu', 'anddarioamodei.2020.scalinglawsforneurallanguagemodels.arxivabs/2001.08361', '2020', 'https', '//arxiv.org/abs/2001.08361', 'siddharthkaramcheti', 'dorsasadigh', 'andpercyliang.2020.learningadaptivelanguageinterfacesthroughdecomposition', 'inemnlpworkshopforinteractiveandexecutablesemanticparsing', 'intex-sempar', 'siddharthkaramcheti', 'edwardc.williams', 'diliparumugam', 'minarhee', 'nakulgopalan', 'lawsonl.s.wong', 'andstefanie', 'tellex.2017', 'ataleoftwodraggns', 'ahybridapproachforinterpretingaction-orientedandgoal-oriented', 'instructions.infirstworkshoponlanguagegroundingforrobotics', 'acl', 'siddharthkaramcheti', 'albertj.zhai', 'dylanp.losey', 'anddorsasadigh.2021.learningvisuallyguidedlatentactionsfor', 'assistiveteleoperation.inlearningfordynamicsandcontrol', 'holdenkarnofsky.2016', 'potentialrisksfromadvancedartificialintelligence', 'thephilanthropicopportunity', 'open', 'philanthropyproject6', 'vladimirkarpukhin', 'barlasoguz', 'sewonmin', 'patricklewis', 'ledellwu', 'sergeyedunov', 'danqichen', 'andwen-tau', 'yih.2020', 'densepassageretrievalforopen-domainquestionanswering.inproceedingsofthe2020conferenceon', 'empiricalmethodsinnaturallanguageprocessing', 'emnlp', '.associationforcomputationallinguistics', 'online,6769–6781', 'https', '//doi.org/10.18653/v1/2020.emnlp-main.550', 'terokarras', 'samulilaine', 'miikaaittala', 'jannehellsten', 'jaakkolehtinen', 'andtimoaila.2020.analyzingandimproving', 'theimagequalityofstylegan.inproceedingsoftheieee/cvfconferenceoncomputervisionandpatternrecognition', '8110–8119', 'norakassner', 'philippdufter', 'andhinrichschütze.2021.multilinguallama', 'investigatingknowledgeinmultilingual', 'pretrainedlanguagemodels.ineacl', 'hirokatsukataoka', 'kazushigeokayasu', 'asatomatsumoto', 'eisukeyamagata', 'ryosukeyamada', 'nakamasainoue', 'akio', 'nakamura', 'andyutakasatoh.2020', 'pre-trainingwithoutnaturalimages.inproceedingsoftheasianconferenceon', 'computervision', 'michaelkatell', 'megyoung', 'dharmadailey', 'berneaseherman', 'vivianguetler', 'aarontam', 'corinnebintz', 'daniellaraz', 'p.m.krafft.2020.towardsituatedinterventionsforalgorithmicequity.inproceedingsofthe2020conferenceonfairness', 'accountability', 'andtransparency.acm', 'https', '//doi.org/10.1145/3351095.3372874', 'danielmartinkatz', 'michaeljbommarito', 'andjoshblackman.2017.ageneralapproachforpredictingthebehaviorofthe', 'supremecourtoftheunitedstates.plosone12,4', 'e0174698', 'amitkaushal', 'russaltman', 'andcurtlanglotz.2020.geographicdistributionofuscohortsusedtotraindeeplearning', 'algorithms.jama324,12', '2020', ',1212–1213', 'matthewkay', 'cynthiamatuszek', 'andseana.munson.2015.unequalrepresentationandgenderstereotypesinimage', 'searchresultsforoccupations.inproceedingsofthe33rdannualacmconferenceonhumanfactorsincomputingsystems', 'seoul', 'republicofkorea', 'chi', '’', '15', '.acm', 'newyork', 'ny', 'usa,3819–3828', 'https', '//doi.org/10.1145/2702123.2702520', 'willkay', 'joaocarreira', 'karensimonyan', 'brianzhang', 'chloehillier', 'sudheendravijayanarasimhan', 'fabioviola', 'tim', 'green', 'trevorback', 'paulnatsev', 'etal.2017.thekineticshumanactionvideodataset.arxivpreprintarxiv:1705.06950', 'alexanderke', 'williamellsworth', 'oishibanerjee', 'andrewyng', 'andpranavrajpurkar.2021.chextransfer', 'performance', 'andparameterefficiencyofimagenetmodelsforchestx-rayinterpretation.inproceedingsoftheconferenceonhealth', 'inference', 'andlearning.116–124', 'seanpkeehan', 'gigiacuckler', 'johnapoisal', 'andreamsisko', 'sheiladsmith', 'andrewjmadison', 'kathrynerennie', 'jacquelineafiore', 'andjameschardesty.2020.nationalhealthexpenditureprojections,2019–28', 'expectedrebound', 'inpricesdrivesrisingspendinggrowth', 'nationalhealthexpenditureprojectionsfortheperiod2019–2028', 'health', 'affairs39,4', '2020', ',704–714', 'patrickgagekelley', 'joannabresee', 'lorriefaithcranor', 'androbertwreeder.2009', ""''"", 'nutritionlabel', ""''"", 'forprivacy.in', 'proceedingsofthe5thsymposiumonusableprivacyandsecurity.1–12', 'tomkenter', 'melvinwevers', 'pimhuijnen', 'andmaartenderijke.2015.adhocmonitoringofvocabularyshiftsovertime', 'inproceedingsofthe24thacminternationalonconferenceoninformationandknowledgemanagement.1191–1200']",183
Opportunities and Risks of Foundational Models - Stanford.pdf,"['184', 'centerforresearchonfoundationmodels', 'crfm', 'zacharykenton', 'tomeveritt', 'lauraweidinger', 'iasongabriel', 'vladimirmikulik', 'andgeoffreyirving.2021.alignmentof', 'languageagents.arxivabs/2103.14659', '2021', 'clarkkerr.2001.theusesoftheuniversity.harvarduniversitypress', 'nitishshirishkeskar', 'bryanmccann', 'lavrvarshney', 'caimingxiong', 'andrichardsocher.2019', 'ctrl', 'aconditional', 'transformerlanguagemodelforcontrollablegeneration.arxivpreprintarxiv:1909.05858', '2019', 'oskeyes.2018.themisgenderingmachines.proceedingsoftheacmonhuman-computerinteraction2', 'cscw', 'nov.2018', '1–22', 'https', '//doi.org/10.1145/3274357', 'urvashi', 'khandelwal', 'omer', 'levy', 'dan', 'jurafsky', 'luke', 'zettlemoyer', 'mike', 'lewis', '2020', 'generalization', 'memorization', 'nearestneighborlanguagemodels.ininternationalconferenceonlearningrepresentations', 'https', '//openreview.net/forum', '?', 'id=hklbjcekvh', 'danielkhashabi', 'gabrielstanovsky', 'jonathanbragg', 'nicholaslourie', 'jungokasai', 'yejinchoi', 'noahasmith', 'anddaniels', 'weld.2021.genie', 'aleaderboardforhuman-in-the-loopevaluationoftextgeneration.arxivpreprintarxiv:2101.06561', '2021', 'omarkhattab', 'christopherpotts', 'andmateizaharia.2020', 'relevance-guidedsupervisionforopenqawithcolbert', '2020', '.arxiv', 'https', '//arxiv.org/abs/2007.00814', 'o.khattabandm.zaharia.2020.colbert', 'efficientandeffectivepassagesearchviacontextualizedlateinteractionover', 'bert.proceedingsofthe43rdinternationalacmsigirconferenceonresearchanddevelopmentininformationretrieval', '2020', 'behrokhkhoshnevis.2004.automatedconstructionbycontourcrafting—relatedroboticsandinformationtechnologies', 'automationinconstruction13,1', '2004', ',5–19', 'douwekiela', 'maxbartolo', 'yixinnie', 'divyanshkaushik', 'atticusgeiger', 'zhengxuanwu', 'bertievidgen', 'grushaprasad', 'amanpreet', 'singh', 'pratik', 'ringshia', 'et', 'al', '2021', 'dynabench', 'rethink', 'benchmarking', 'nlp', 'arxiv', 'preprint', 'arxiv:2104.14337', '2021', 'najoungkimandtallinzen.2020.cogs', 'acompositionalgeneralizationchallengebasedonsemanticinterpretation.in', 'proceedingsofthe2020conferenceonempiricalmethodsinnaturallanguageprocessing', 'emnlp', '.9087–9105', 'seohyunkim', 'jinmanzhao', 'yuchitian', 'andsatishchandra.2021b.codepredictionbyfeedingtreestotransformers.in', '2021ieee/acm43rdinternationalconferenceonsoftwareengineering', 'icse', '.ieee,150–162', 'wonjaekim', 'bokyungson', 'andildookim.2021a.vilt', 'vision-and-languagetransformerwithoutconvolutionorregion', 'supervision.ininternationalconferenceonmachinelearning', 'icml', 'diederikp.kingmaandprafulladhariwal.2018.glow', 'generativeflowwithinvertible1x1convolutions.inneurips', 'diederikp.kingmaandm.welling.2014.auto-encodingvariationalbayes.corrabs/1312.6114', '2014', 'darrellgkirchandkatepetelle.2017.addressingthephysicianshortage', 'theperilofignoringdemography.jama317,19', ',1947–1948', 'jameskirkpatrick', 'razvanpascanu', 'neilrabinowitz', 'joelveness', 'guillaumedesjardins', 'andreiarusu', 'kieranmilan', 'johnquan', 'tiagoramalho', 'agnieszkagrabska-barwinska', 'etal.2017.overcomingcatastrophicforgettinginneural', 'networks.proceedingsofthenationalacademyofsciences114,13', ',3521–3526', 'nikitakitaev', 'łukaszkaiser', 'andanselmlevskaya.2020.reformer', 'theefficienttransformer.arxivpreprintarxiv:2001.04451', '2020', 'predragklasnjaandwandapratt.2012.healthcareinthepocket', 'mappingthespaceofmobile-phonehealthinterventions', 'journalofbiomedicalinformatics45,1', '2012', ',184–198', 'jonkleinberg', 'sendhilmullainathan', 'andmanishraghavan.2017.inherenttrade-offsinthefairdeterminationofrisk', 'scores.ininnovationsintheoreticalcomputerscience', 'itcs', 'jon', 'kleinberg', 'manish', 'raghavan', '2021', 'algorithmic', 'monoculture', 'social', 'welfare', 'proceed-', 'ings', 'national', 'academy', 'sciences', '118', '22', '2021', 'https', '//doi.org/10.1073/pnas.2018340118', 'arxiv', 'https', '//www.pnas.org/content/118/22/e2018340118.full.pdf', 'a.s.klyubin', 'd.polani', 'andchrystopherl.nehaniv.2005.empowerment', 'auniversalagent-centricmeasureofcontrol', '2005ieeecongressonevolutionarycomputation1', '2005', ',128–135vol.1', 'robertpkocher.2021.reducingadministrativewasteintheushealthcaresystem.jama325,5', '2021', ',427–428', 'kennethr.koedingerandjohnr.anderson.1990', 'abstractplanningandperceptualchunks', 'elementsofexpertisein', 'geometry.cognitivescience14,4', '1990', ',511–550', 'https', '//doi.org/10.1016/0364-0213', '90', '90008-k', 'allisonkoenecke', 'andrewnam', 'emilylake', 'joenudell', 'minniequartey', 'zionmengesha', 'connortoups', 'johnrrickford', 'danjurafsky', 'andsharadgoel.2020.racialdisparitiesinautomatedspeechrecognition.proceedingsofthenational', 'academyofsciences117,14', '2020', ',7684–7689', 'pangweikohandpercyliang.2017', 'understandingblack-boxpredictionsviainfluencefunctions.ininternational', 'conferenceonmachinelearning', 'icml', 'pangweikoh', 'shiorisagawa', 'henrikmarklund', 'sangmichaelxie', 'marvinzhang', 'akshaybalsubramani', 'weihuahu', 'michihiroyasunaga', 'richardlanasphillips', 'irenagao', 'tonylee', 'etiennedavid', 'ianstavness', 'weiguo', 'bertona']",184
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '185', 'earnshaw', 'imrans.haque', 'sarabeery', 'jureleskovec', 'anshulkundaje', 'emmapierson', 'sergeylevine', 'chelseafinn', 'andpercyliang.2021.wilds', 'abenchmarkofin-the-wilddistributionshifts.ininternationalconferenceonmachine', 'learn', 'icml', 'erickolve', 'roozbehmottaghi', 'danielgordon', 'yukezhu', 'abhinavgupta', 'andalifarhadi.2017a.ai2-thor', 'aninteractive', '3denvironmentforvisualai.arxivpreprintarxiv:1712.05474', 'erickolve', 'r.mottaghi', 'winsonhan', 'elivanderbilt', 'lucaweihs', 'alvaroherrasti', 'danielgordon', 'yukezhu', 'abhinav', 'gupta', 'andalifarhadi.2017b.ai2-thor', 'aninteractive3denvironmentforvisualai.arxivabs/1712.05474', 'junkong', 'leeadcooper', 'fushengwang', 'davidagutman', 'jingjinggao', 'candacechisolm', 'ashishsharma', 'tonypan', 'erwingvanmeir', 'tahsinmkurc', 'etal.2011.integrative', 'multimodalanalysisofglioblastomausingtcgamolecular', 'data', 'pathologyimages', 'andclinicaloutcomes.ieeetransactionsonbiomedicalengineering58,12', '2011', ',3469–3474', 'dianemkorngiebelandseandmooney.2021', 'consideringthepossibilitiesandpitfallsofgenerativepre-trained', 'transformer3', 'gpt-3', 'inhealthcaredelivery.npjdigitalmedicine4,1', '2021', ',1–3', 'christinekorsgaard.2009.self-constitution', 'agency', 'identity', 'andintegrity.oxforduniversitypress', 'oxfordnewyork', 'sekrepsanddlkriner.2020', 'modeluncertainty', 'politicalcontestation', 'andpublictrustinscience', 'evidencefromthe', 'covid-19pandemic.scienceadvances6,43', '2020', 'eabd4563', 'sarahkreps', 'r.milesmccain', 'andmilesbrundage.2020.allthenewsthat', '’', 'sfittofabricate', 'ai-generatedtextasatool', 'ofmediamisinformation.journalofexperimentalpoliticalscience', '2020', ',1–14', 'https', '//doi.org/10.1017/xps.2020.37', 'kundankrishna', 'sopankhosla', 'jeffreypbigham', 'andzacharyclipton.2020.generatingsoapnotesfromdoctor-patient', 'conversations.arxivpreprintarxiv:2005.01795', '2020', 'kalpeshkrishna', 'gauravsinghtomar', 'ankurpparikh', 'nicolaspapernot', 'andmohitiyyer.2019.thievesonsesamestreet', 'modelextractionofbert-basedapis.arxivpreprintarxiv:1910.12366', '2019', 'ranjaykrishna', 'yukezhu', 'olivergroth', 'justinjohnson', 'kenjihata', 'joshuakravitz', 'stephaniechen', 'yanniskalantidi', 'li-jiali', 'davida.shamma', 'michaels.bernstein', 'andfei-feili.2017.visualgenome', 'connectinglanguageandvision', 'usingcrowdsourceddenseimageannotations.internationaljournalofcomputervision123', ',32–73', 'alexkrizhevsky', 'geoffreyhinton', 'etal.2009.learningmultiplelayersoffeaturesfromtinyimages.', '2009', 'alexkrizhevsky', 'ilyasutskever', 'andgeoffreyehinton.2012', 'imagenetclassificationwithdeepconvolutionalneural', 'networks.advancesinneuralinformationprocessingsystems25', '2012', ',1097–1105', 'harlanmkrumholz', 'sharonfterry', 'andjoannewaldstreicher.2016.dataacquisition', 'curation', 'anduseforacontinuously', 'learninghealthsystem.jama316,16', ',1669–1670', 'rohithkuditipudi', 'xiangwang', 'holdenlee', 'yizhang', 'zhiyuanli', 'weihu', 'sanjeevarora', 'androngge.2019.explaining', 'landscapeconnectivityoflow-costsolutionsformultilayernets.arxivpreprintarxiv:1906.06247', '2019', 'takukudoandjohnrichardson.2018', 'sentencepiece', 'asimpleandlanguageindependentsubwordtokenizerand', 'detokenizerforneuraltextprocessing.inemnlp', 'ananyakumar', 'tengyuma', 'andpercyliang.2020a', 'understandingself-trainingforgradualdomainadaptation.in', 'internationalconferenceonmachinelearning', 'icml', 'aviralkumar', 'aurickzhou', 'georgetucker', 'andsergeylevine.2020b.conservativeq-learningforofflinereinforcement', 'learning.', '2020', 'https', '//arxiv.org/abs/2006.04779', 'keitakurita', 'nidhivyas', 'ayushpareek', 'alanwblack', 'andyuliatsvetkov.2019.measuringbiasincontextualizedword', 'representations.arxivpreprintarxiv:1906.07337', '2019', 'alexandrelacoste', 'alexandraluccioni', 'victorschmidt', 'andthomasdandres.2019.quantifyingthecarbonemissionsof', 'machinelearning.arxivpreprintarxiv:1910.09700', '2019', 'irolaina', 'christianrupprecht', 'vasileiosbelagiannis', 'federicotombari', 'andnassirnavab.2016.deeperdepthprediction', 'withfullyconvolutionalresidualnetworks.in2016fourthinternationalconferenceon3dvision', '3dv', '.ieee,239–248', 'brendenlakeandmarcobaroni.2018.generalizationwithoutsystematicity', 'onthecompositionalskillsofsequence-to-', 'sequencerecurrentnetworks.ininternationalconferenceonmachinelearning.pmlr,2873–2882', 'brendenmlake', 'ruslansalakhutdinov', 'andjoshuabtenenbaum.2015.human-levelconceptlearningthroughprobabilistic', 'programinduction.science350,6266', ',1332–1338', 'brendenmlake', 'tomerdullman', 'joshuabtenenbaum', 'andsamueljgershman.2017.buildingmachinesthatlearnand', 'thinklikepeople.behavioralandbrainsciences40', 'georgelakoffandrafaelnúñez.2000.wheremathematicscomesfrom', 'howtheembodiedmindbringsmathematicsinto', 'being.basicbooks', 'newyork', 'http', '//perso.unifr.ch/rafael.nunez/welcome.html', 'samuellalmuanawma', 'jamalhussain', 'andlalrinfelachhakchhuak.2020.applicationsofmachinelearningandartificial', 'intelligenceforcovid-19', 'sars-cov-2', 'pandemic', 'areview.chaos', 'solitons', '&', 'fractals', '2020', ',110059', 'madelinelamoandryancalo.2019.regulatingbotspeech.uclal.rev.66', '2019', ',988', 'guillaumelample', 'alexandresablayrolles', 'marc', '’', 'aurelioranzato', 'ludovicdenoyer', 'andh.jégou.2019.largememory', 'layerswithproductkeys.inneurips']",185
Opportunities and Risks of Foundational Models - Stanford.pdf,"['186', 'centerforresearchonfoundationmodels', 'crfm', 'zhenzhonglan', 'mingdachen', 'sebastiangoodman', 'kevingimpel', 'piyushsharma', 'andradusoricut.2019.albert', 'alite', 'bertforself-supervisedlearningoflanguagerepresentations.arxive-prints', '2019', 'arxiv–1909', 'gertrglanckriet', 'tijldebie', 'nellocristianini', 'michaelijordan', 'andwilliamstaffordnoble.2004.astatisticalframework', 'forgenomicdatafusion.bioinformatics20,16', '2004', ',2626–2635', 'saschalange', 'thomasgabel', 'andmartinriedmiller.2012.batchreinforcementlearning.inreinforcementlearning.springer', '45–73', 'lynnlangstonanddonaldjfarole', 'jr.2010.statepublicdefenderprograms,2007.technicalreport.u.s.departmentof', 'justicebureauofjusticestatistics', 'loïclannelongue', 'jasongrealey', 'andmichaelinouye.2021', 'greenalgorithms', 'quantifyingthecarbonfootprintof', 'computation.advancedscience', '2021', ',2100707', 'sebastianlapuschkin', 'stephanwäldchen', 'alexanderbinder', 'grégoiremontavon', 'wojciechsamek', 'andklaus-robertmüller', '2019.unmaskingcleverhanspredictorsandassessingwhatmachinesreallylearn.naturecommunications10,1', '2019', '1–8', 'jill', 'h.', 'larkin', 'herbert', 'a.', 'simon', '1987', 'diagram', 'sometimes', 'worth', 'ten', 'thousand', 'word', 'cognitive', 'science', '11', '1', '1987', '65–100', 'https', '//doi.org/10.1111/j.1551-6708.1987.tb00863.x', 'arxiv', 'https', '//onlinelibrary.wiley.com/doi/pdf/10.1111/j.1551-6708.1987.tb00863.x', 'joshlauer.2017.creditworthy', 'ahistoryofconsumersurveillanceandfinancialidentityinamerica.columbiauniversity', 'press', 'http', '//www.jstor.org/stable/10.7312/laue16808', 'benjaminlaufer.2020.feedbackeffectsinrepeat-usecriminalriskassessments', 'arxiv:2011.14075', '[', 'cs.cy', ']', 'annelauscher', 'vinitravishankar', 'ivanvulić', 'andgoranglavaš.2020.fromzerotohero', 'onthelimitationsofzero-shot', 'languagetransferwithmultilingualtransformers.inproceedingsofthe2020conferenceonempiricalmethodsinnatural', 'languageprocessing', 'emnlp', '.4483–4499', 'adamlavertuandrussbaltman.2019', 'redmed', 'extendingdruglexiconsforsocialmediaapplications', 'journalof', 'biomedicalinformatics99', '2019', ',103307', 'angelikilazaridou', 'adhigunakuncoro', 'elenagribovskaya', 'devangagrawal', 'adamliska', 'tayfunterzi', 'maigimenez', 'cypriendemassond', '’', 'autume', 'sebastianruder', 'daniyogatama', 'etal.2021.pitfallsofstaticlanguagemodelling.arxiv', 'preprintarxiv:2102.01951', '2021', 'tevenlescaoandalexanderrush.2021.howmanydatapointsisapromptworth', '?', '.inproceedingsofthe2021conferenceof', 'thenorthamericanchapteroftheassociationforcomputationallinguistics', 'humanlanguagetechnologies.association', 'forcomputationallinguistics', 'online,2627–2636', 'https', '//doi.org/10.18653/v1/2021.naacl-main.208', 'toscalechner', 'shaiben-david', 'sushantagarwal', 'andnivasiniananthakrishnan.2021', 'impossibilityresultsforfair', 'representations.arxivabs/2107.03483', '2021', 'yannlecun', 'yoshuabengio', 'andgeoffreyhinton.2015.deeplearning.nature521,7553', 'yannlecun', 'johnsdenker', 'andsaraasolla.1990.optimalbraindamage.inadvancesinneuralinformationprocessing', 'systems.598–605', 'jinhyuklee', 'wonjinyoon', 'sungdongkim', 'donghyeonkim', 'sunkyukim', 'chanhoso', 'andjaewookang.2020d.biobert', 'pre-trainedbiomedicallanguagerepresentationmodelforbiomedicaltextmining.bioinformatics36,4', '2020', ',1234–1240', 'jasondlee', 'qilei', 'nikunjsaunshi', 'andjiachengzhuo.2020a', 'predictingwhatyoualreadyknowhelps', 'provable', 'self-supervisedlearning.arxivpreprintarxiv:2008.01064', '2020', 'jieh-shengleeandjiehhsiang.2019.patentbert', 'patentclassificationwithfine-tuningapre-trainedbertmodel.arxiv', 'preprintarxiv:1906.02124', '2019', 'katherinelee', 'daphneippolito', 'andrewnystrom', 'chiyuanzhang', 'douglaseck', 'chriscallison-burch', 'andnicholascarlini', '2021.deduplicatingtrainingdatamakeslanguagemodelsbetter', 'arxiv:2107.06499', '[', 'cs.cl', ']', 'michellealee', 'matthewtan', 'yukezhu', 'andjeannettebohg.2020b.detect', 'reject', 'correct', 'crossmodalcompensationof', 'corruptedsensors.arxivpreprintarxiv:2012.00201', '2020', 'michellealee', 'brentyi', 'robertomartín-martín', 'silviosavarese', 'andjeannettebohg.2020c.multimodalsensorfusionwith', 'differentiablefilters.inproceedingsoftheieee/rsjinternationalconferenceonintelligentrobotsandsystems', 'iros', 'minkyunglee', 'danielkusbit', 'ansonkahng', 'jitaekim', 'xinranyuan', 'allissachan', 'danielsee', 'riteshnoothigattu', 'siheon', 'lee', 'alexandrospsomas', 'andarield.procaccia.2019.webuildai', 'participatoryframeworkforalgorithmicgovernance', 'cscw', '2019', 'yongjaelee', 'joydeepghosh', 'andk.grauman.2012', 'discoveringimportantpeopleandobjectsforegocentricvideo', 'summarization.2012ieeeconferenceoncomputervisionandpatternrecognition', '2012', ',1346–1353', 'jameslee-thorp', 'joshuaainslie', 'ilyaeckstein', 'andsantiagoontanon.2021.fnet', 'mixingtokenswithfouriertransforms', 'arxivpreprintarxiv:2105.03824', '2021', 'normanlefsteinandrobertlspagenberg.2009.justicedenied', 'america', '’', 'scontinuingneglectofourconstitutionalright', 'tocounsel', 'technicalreport.nationalrighttocounselcommittee', 'theconstitutionproject', 'nationallegalaid', '&', 'defenderassociation']",186
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '187', 'legalservicescorporation.2017.thejusticegap', 'measuringtheunmetcivillegalneedsoflow-incomeamericans.technical', 'report.preparedbynorcattheuniversityofchicagoforlegalservicescorporation', 'washington', 'dc', 'j.leike', 'davidkrueger', 'tomeveritt', 'miljanmartic', 'vishalmaini', 'ands.legg.2018.scalableagentalignmentviareward', 'model', 'aresearchdirection.arxivabs/1811.07871', 'spyrettaleivaditi', 'julienrossi', 'andevangeloskanoulas.2020.abenchmarkforleasecontractreview.arxivpreprint', 'arxiv:2010.10386', '2020', 'markalemleyandbryancasey.2019.remediesforrobots.theuniversityofchicagolawreview86,5', '2019', ',1311–1396', 'markalemleyandbryancasey.2020.fairlearning.tex.l.rev.99', '2020', ',743', 'dmitrylepikhin', 'hyoukjoonglee', 'yuanzhongxu', 'dehaochen', 'orhanfirat', 'yanpinghuang', 'maximkrikun', 'noamshazeer', 'andzhifengchen.2020.gshard', 'scalinggiantmodelswithconditionalcomputationandautomaticsharding.arxiv', 'preprintarxiv:2006.16668', '2020', 'lawrencelessig.2000.codeislaw.https', '//www.harvardmagazine.com/2000/01/code-is-law-html', 'brian', 'lester', 'rami', 'al-rfou', 'noah', 'constant', '2021', 'power', 'scale', 'parameter-efficient', 'prompt', 'tune', 'arxiv:2104.08691', '[', 'cs.cl', ']', 'amandalevendowski.2018', 'howcopyrightlawcanfixartificialintelligence', '’', 'simplicitbiasproblem', 'wash.l.rev.93', ',579', 'sergeylevine', 'p.pastor', 'a.krizhevsky', 'anddeirdrequillen.2018.learninghand-eyecoordinationforroboticgrasping', 'withdeeplearningandlarge-scaledatacollection.theinternationaljournalofroboticsresearch37', ',421–436', 'yoavlevine', 'noamwies', 'orsharir', 'hofitbata', 'andamnonshashua.2020.limitstodepthefficienciesofself-attention', 'arxive-prints', '2020', 'arxiv–2006', 'rogerlevy.2008.expectation-basedsyntacticcomprehension.cognition106,3', '2008', ',1126–1177', 'https', '//doi.org/10.1016/', 'j.cognition.2007.05.006', 'mikelewis', 'yinhanliu', 'namangoyal', 'marjanghazvininejad', 'abdelrahmanmohamed', 'omerlevy', 'vesstoyanov', 'andluke', 'zettlemoyer.2020a.bart', 'denoisingsequence-to-sequencepre-trainingfornaturallanguagegeneration', 'translation', 'andcomprehension.inassociationforcomputationallinguistics', 'acl', 'patricklewis', 'ethanperez', 'aleksandrapiktus', 'fabiopetroni', 'vladimirkarpukhin', 'namangoyal', 'heinrichküttler', 'mike', 'lewis', 'wen-tauyih', 'timrocktäschel', 'sebastianriedel', 'anddouwekiela.2020b', 'retrieval-augmentedgeneration', 'forknowledge-intensivenlptasks.inadvancesinneuralinformationprocessingsystems', 'h.larochelle', 'm.ranzato', 'r.hadsell', 'm.f.balcan', 'andh.lin', 'eds.', 'vol.33.curranassociates', 'inc.,9459–9474', 'https', '//proceedings.neurips.cc/', 'paper/2020/file/6b493230205f780e1bc26945df7481e5-paper.pdf', 'ireneli', 'michihiroyasunaga', 'muhammedyavuznuzumlalı', 'cesarcaraballo', 'shiwanimahajan', 'harlankrumholz', 'dragomirradev.2019a.aneuraltopic-attentionmodelformedicaltermabbreviationdisambiguation.machinelearning', 'forhealth', 'ml4h', '2019', 'jiweili', 'xinleichen', 'eduardhovy', 'anddanjurafsky.2015.visualizingandunderstandingneuralmodelsinnlp.arxiv', 'preprintarxiv:1506.01066', 'jialuli', 'esindurmus', 'andclairecardie.2020a.exploringtheroleofargumentstructureinonlinedebatepersuasion', 'inproceedingsofthe2020conferenceonempiricalmethodsinnaturallanguageprocessing', 'emnlp', '.associationfor', 'computationallinguistics', 'online,8905–8912', 'https', '//doi.org/10.18653/v1/2020.emnlp-main.716', 'shenli', 'yanlizhao', 'rohanvarma', 'omkarsalpekar', 'pieternoordhuis', 'tengli', 'adampaszke', 'jeffsmith', 'brianvaughan', 'pritamdamania', 'etal.2020e.pytorchdistributed', 'experiencesonacceleratingdataparalleltraining.arxivpreprint', 'arxiv:2006.15704', '2020', 'wendali', 'leiyu', 'yuhuaiwu', 'andlawrencec.paulson.2021b', 'isarstep', 'abenchmarkforhigh-levelmathematical', 'reasoning.ininternationalconferenceonlearningrepresentations', 'https', '//openreview.net/forum', '?', 'id=pzj6fzu6wkj', 'xuezixiangli', 'quyu', 'andhengyin.2021a.palmtree', 'learninganassemblylanguagemodelforinstructionembedding', 'corrabs/2103.03809', '2021', '.arxiv:2103.03809', 'https', '//arxiv.org/abs/2103.03809', 'xianglisaliandpercyliang.2021', 'prefix-tuning', 'optimizingcontinuouspromptsforgeneration', 'arxivpreprint', 'arxiv:2101.00190', '2021', 'yunzhuli', 'torulin', 'kexinyi', 'danielbear', 'daniell.k.yamins', 'jiajunwu', 'joshuab.tenenbaum', 'andantoniotorralba', '2020b.visualgroundingoflearnedphysicalmodels.inicml', 'yikuanli', 'shishirrao', 'joserobertoayalasolares', 'abdelaalihassaine', 'remaramakrishnan', 'dextercanoy', 'yajiezhu', 'kazemrahimi', 'andgholamrezasalimi-khorshidi.2020c.behrt', 'transformerforelectronichealthrecords.scientific', 'reports10,1', '2020', ',1–12', 'yunzhuli', 'jun-yanzhu', 'russtedrake', 'andantoniotorralba.2019b.connectingtouchandvisionviacross-modalprediction', 'inproceedingsoftheieee/cvfconferenceoncomputervisionandpatternrecognition.10609–10618', 'zhuohanli', 'ericwallace', 'shengshen', 'kevinlin', 'kurtkeutzer', 'danklein', 'andjosephegonzalez.2020d.trainlarge', 'compress', 'rethinkingmodelsizeforefficienttrainingandinferenceoftransformers.arxivpreprintarxiv:2002.11794', '2020']",187
Opportunities and Risks of Foundational Models - Stanford.pdf,"['188', 'centerforresearchonfoundationmodels', 'crfm', 'jindřichlibovicky', 'rudolfrosa', 'andalexanderfraser.2019.howlanguage-neutralismultilingualbert', '?', 'arxivpreprint', 'arxiv:1911.03310', '2019', 'opherlieber', 'orsharir', 'baraklenz', 'andyoavshoham.2021', 'jurassic-1', 'technicaldetailsandevaluation', 'whitepaper', 'ai21labs', 'chu-chenglin', 'aaronjaech', 'xinli', 'mattgormley', 'andjasoneisner.2021.limitationsofautoregressivemodelsandtheir', 'alternatives.inproceedingsofthe2021conferenceofthenorthamericanchapteroftheassociationforcomputational', 'linguistics', 'humanlanguagetechnologies', 'naacl-hlt', '.online,5147–5173', 'http', '//cs.jhu.edu/~jason/papers/', '#', 'lin-et-al-', '2021-naacl', 'ro-tinglin', 'davidcchristiani', 'ichirokawachi', 'ta-chienchan', 'po-huangchiang', 'andchang-chuanchan.2016.increased', 'riskofrespiratorymortalityassociatedwiththehigh-techmanufacturingindustry', 'a26-yearstudy.internationaljournal', 'ofenvironmentalresearchandpublichealth13,6', ',557', 'tsung-yilin', 'michaelmaire', 'sergebelongie', 'jameshays', 'pietroperona', 'devaramanan', 'piotrdollár', 'andclawrence', 'zitnick.2014.microsoftcoco', 'commonobjectsincontext.ineuropeanconferenceoncomputervision.springer,740–755', 'pantelislinardatos', 'vasilispapastefanopoulos', 'andsotiriskotsiantis.2021.explainableai', 'areviewofmachinelearning', 'interpretabilitymethods.entropy23,1', '2021', ',18', 'lindal.lindsey.2015', 'thesociologyofgendertheoreticalperspectivesandfeministframeworks', 'routledge', 'https', '//www.routledge.com/gender-sociological-perspectives/lindsey/p/book/9781138103696', 'wangle', 'edwardgrefenstette', 'karlmoritzhermann', 'tomáškočisky', 'andrewsenior', 'fuminwang', 'andphilblunsom', '2016.latentpredictornetworksforcodegeneration.arxivpreprintarxiv:1603.06744', 'tallinzen.2020.howcanweaccelerateprogresstowardshuman-likelinguisticgeneralization', '?', '.inproceedingsofthe', '58thannualmeetingoftheassociationforcomputationallinguistics.associationforcomputationallinguistics', 'online', '5210–5217', 'https', '//doi.org/10.18653/v1/2020.acl-main.465', 'tallinzenandmarcobaroni.2021.syntacticstructurefromdeeplearning.annualreviewoflinguistics7', '2021', ',195–212', 'tallinzen', 'emmanueldupoux', 'andyoavgoldberg.2016', 'assessingtheabilityoflstmstolearnsyntax-sensitive', 'dependencies.transactionsoftheassociationforcomputationallinguistics', 'tacl', '4', 'marcolippi', 'przemysławpałka', 'giuseppecontissa', 'francescalagioia', 'hans-wolfgangmicklitz', 'giovannisartor', 'andpaolo', 'torroni.2019.claudette', 'anautomateddetectorofpotentiallyunfairclausesinonlinetermsofservice.artificial', 'intelligenceandlaw27,2', '2019', ',117–139', 'zacharyc.lipton.2018', 'themythosofmodelinterpretability', 'commun.acm', '61,10', 'sept.2018', ',36–43', 'https', '//doi.org/10.1145/3233231', 'zacharyc.liptonandjacobsteinhardt.2019', 'troublingtrendsinmachinelearningscholarship', 'somemlpapers', 'sufferfromflawsthatcouldmisleadthepublicandstymiefutureresearch.queue17,1', 'feb.2019', ',45–77', 'https', '//doi.org/10.1145/3317287.3328534', 'andyt.liu', 'shuwenyang', 'po-hanchi', 'po-chunhsu', 'andhungyilee.2020d', 'mockingjay', 'unsupervisedspeech', 'representationlearningwithdeepbidirectionaltransformerencoders.icassp2020-2020ieeeinternationalconference', 'onacoustics', 'speechandsignalprocessing', 'icassp', '2020', ',6419–6423', 'fenglinliu', 'shenge', 'andxianwu.2021a', 'competence-basedmultimodalcurriculumlearningformedicalreport', 'generation.inacl', 'jiachangliu', 'dinghanshen', 'yizhezhang', 'billdolan', 'lawrencecarin', 'andweizhuchen.2021d', 'whatmakesgood', 'in-contextexamplesforgpt-3', '?', '.inarxiv', 'nelsonf.liu', 'tonylee', 'robinjia', 'andpercyliang.2021b', 'cansmallandsyntheticbenchmarksdrivemodeling', 'innovation', '?', 'aretrospectivestudyofquestionansweringmodelingapproaches.arxivabs/2102.01065', '2021', 'https', '//arxiv.org/abs/2102.01065', 'ruishanliu', 'shemrarizzo', 'samuelwhipple', 'navdeeppal', 'arturolopezpineda', 'michaellu', 'brandonarnieri', 'yinglu', 'williamcapra', 'ryancopping', 'etal.2021c.evaluatingeligibilitycriteriaofoncologytrialsusingreal-worlddataandai', 'nature592,7855', '2021', ',629–633', 'weijieliu', 'pengzhou', 'zhezhao', 'zhiruowang', 'qiju', 'haotangdeng', 'andp.wang.2020e.k-bert', 'enablinglanguage', 'representationwithknowledgegraph.arxivabs/1909.07606', '2020', 'xueboliu', 'longyuewang', 'derekfwong', 'liangding', 'lidiaschao', 'andzhaopengtu.2020c.understandingandimproving', 'encoderlayerfusioninsequence-to-sequencelearning.arxivpreprintarxiv:2012.14768', '2020', 'xiaoliu', 'yananzheng', 'zhengxiaodu', 'mingding', 'yujieqian', 'zhilinyang', 'andjietang.2021e.gptunderstands', 'corrabs/2103.10385', '2021', '.arxiv:2103.10385', 'https', '//arxiv.org/abs/2103.10385', 'yeliu', 'shaikachowdhury', 'chenweizhang', 'corneliacaragea', 'andphilipsyu.2020a.interpretablemulti-stepreasoning', 'withknowledgeextractiononcomplexhealthcarequestionanswering.arxivpreprintarxiv:2008.02434', '2020', 'yinhanliu', 'jiataogu', 'namangoyal', 'xianli', 'sergeyedunov', 'marjanghazvininejad', 'mikelewis', 'andlukezettlemoyer', '2020b.multilingualdenoisingpre-trainingforneuralmachinetranslation.transactionsoftheassociationforcomputa-', 'tionallinguistics8', '2020', ',726–742', 'https', '//doi.org/10.1162/tacl_a_00343']",188
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '189', 'yuxuanliu', 'abhishekgupta', 'pieterabbeel', 'andsergeylevine.2018', 'imitationfromobservation', 'learningtoimitate', 'behaviorsfromrawvideoviacontexttranslation.in2018ieeeinternationalconferenceonroboticsandautomation', 'icra', '.ieee,1118–1125', 'yinhanliu', 'myleott', 'namangoyal', 'jingfeidu', 'mandarjoshi', 'danqichen', 'omerlevy', 'mikelewis', 'lukezettlemoyer', 'veselinstoyanov.2019.roberta', 'arobustlyoptimizedbertpretrainingapproach.arxivpreprintarxiv:1907.11692', '2019', 'janeloevinger.1957.objectivetestsasinstrumentsofpsychologicaltheory.psychologicalreports3,3', '1957', ',635–694', 'https', '//doi.org/10.2466/pr0.1957.3.3.635arxiv', 'https', '//doi.org/10.2466/pr0.1957.3.3.635', 'lajanugenlogeswaran', 'ming-weichang', 'kentonlee', 'kristinatoutanova', 'jacobdevlin', 'andhonglaklee.2019.zero-shot', 'entitylinkingbyreadingentitydescriptions.inarxiv:1906.07348v1', 'helenlongino.1990.scienceassocialknowledge', 'valuesandobjectivityinscientificinquiry.princetonuniversitypress', 'princeton', 'lianelongpre', 'esindurmus', 'andclairecardie.2019.persuasionoftheundecided', 'languagevs.thelistener.inproceedings', 'ofthe6thworkshoponargumentmining.associationforcomputationallinguistics', 'florence', 'italy,167–176', 'https', '//doi.org/10.18653/v1/w19-4519', 'kadanlottick', 'silviasusai', 'sorellea.friedler', 'andjonathanp.wilson.2019', 'energyusagereports', 'environmental', 'awarenessaspartofalgorithmicaccountability.workshopontacklingclimatechangewithmachinelearningatneurips', '2019', '2019', 'davidglowe.1992.robustmodel-basedmotiontrackingthroughtheintegrationofsearchandestimation.international', 'journalofcomputervision8,2', '1992', ',113–122', 'davidglowe.19991999.objectrecognitionfromlocalscale-invariantfeatures.ininternationalconferenceoncomputer', 'vision', 'iccv', 'proceedingsoftheseventhieeeinternationalconferenceoncomputervision', 'vol.2.1150–1157', 'davidglowe.2004.distinctiveimagefeaturesfromscale-invariantkeypoints.internationaljournalofcomputervision60', '2', '2004', ',91–110', 'jiasenlu', 'dhruvbatra', 'deviparikh', 'andstefanlee.2019a.vilbert', 'pretrainingtask-agnosticvisiolinguisticrepresenta-', 'tionsforvision-and-languagetasks.inneurips', 'kevinlu', 'adityagrover', 'pieterabbeel', 'andigormordatch.2021a', 'pretrainedtransformersasuniversalcomputation', 'engines.corrabs/2103.05247', '2021', '.arxiv:2103.05247', 'https', '//arxiv.org/abs/2103.05247', 'kaijilu', 'piotrmardziel', 'fangjingwu', 'preetamamancharla', 'andanupamdatta.2020', 'genderbiasinneuralnatural', 'languageprocessing', 'inlogic', 'language', 'andsecurity', 'essaysdedicatedtoandrescedrovontheoccasionofhis65th', 'birthday', 'viveknigam', 'tajanabankirigin', 'carolyntalcott', 'joshuaguttman', 'stepankuznetsov', 'boonthauloo', 'mitsuhirookada', 'eds.', '.springerinternationalpublishing', 'cham,189–202', 'https', '//doi.org/10.1007/978-3-030-62077-6_14', 'lulu', 'pengzhanjin', 'andgeorgeemkarniadakis.2019b.deeponet', 'learningnonlinearoperatorsforidentifyingdifferential', 'equationsbasedontheuniversalapproximationtheoremofoperators.arxivpreprintarxiv:1910.03193', '2019', 'shuailu', 'dayaguo', 'shuoren', 'junjiehuang', 'alexeysvyatkovskiy', 'ambrosioblanco', 'colinb.clement', 'dawndrain', 'daxin', 'jiang', 'duyutang', 'geli', 'lidongzhou', 'linjunshou', 'longzhou', 'micheletufano', 'minggong', 'mingzhou', 'nanduan', 'neel', 'sundaresan', 'shaokundeng', 'shengyufu', 'andshujieliu.2021b.codexglue', 'amachinelearningbenchmarkdataset', 'forcodeunderstandingandgeneration.corrabs/2102.04664', '2021', '.arxiv:2102.04664', 'https', '//arxiv.org/abs/2102.04664', 'kristianlumandwilliamisaac.2016.topredictandserve', '?', 'significance13,5', ',14–19', 'scottmlundbergandsu-inlee.2017', 'aunifiedapproachtointerpretingmodelpredictions.inproceedingsofthe31st', 'internationalconferenceonneuralinformationprocessingsystems.4768–4777', 'huaishaoluo', 'leiji', 'botianshi', 'haoyanghuang', 'nanduan', 'tianruili', 'jasonli', 'taroonbharti', 'andmingzhou.2020', 'univl', 'aunifiedvideoandlanguagepre-trainingmodelformultimodalunderstandingandgeneration.arxivpreprint', 'arxiv:2002.06353', '2020', 'coreylynchandpierresermanet.2020.groundinglanguageinplay.arxivpreprintarxiv:2005.07648', '2020', 'coreylynchandpierresermanet.2021.languageconditionedimitationlearningoverunstructureddata.', '2021', 'kallelyytinenandyoungjinyoo.2002.ubiquitouscomputing.commun.acm45,12', '2002', ',63–96', 'm2m-100.2020.m2m-100', 'aimodelthattranslates100languageswithoutrelyingonenglish.https', '//about.fb.com/', 'news/2020/10/first-multilingual-machine-translation-model/', 'edwardma.2019.nlpaugmentation.https', '//github.com/makcedward/nlpaug', 'jianzhuma', 'samsonhfong', 'yunanluo', 'christopherjbakkenist', 'johnpaulshen', 'soufianemourragui', 'lodewykfawessels', 'marchafner', 'rodedsharan', 'jianpeng', 'etal.2021b.few-shotlearningcreatespredictivemodelsofdrugresponsethat', 'translatefromhigh-throughputscreenstoindividualpatients.naturecancer2,2', '2021', ',233–244', 'zhiyima', 'kawinethayarajh', 'tristanthrush', 'somyajain', 'ledellwu', 'robinjia', 'christopherpotts', 'adinawilliams', 'douwekiela.2021a', 'dynaboard', 'anevaluation-as-a-serviceplatformforholisticnext-generationbenchmarking', 'arxivabs/2106.06052', '2021', 'https', '//arxiv.org/abs/2106.06052']",189
Opportunities and Risks of Foundational Models - Stanford.pdf,"['190', 'centerforresearchonfoundationmodels', 'crfm', 'ryanmac', 'carolinehaskins', 'briannasacks', 'andloganmcdonald.2021.surveillancenation.buzzfeednews', '9april2021', 'https', '//www.buzzfeednews.com/article/ryanmac/clearview-ai-local-police-facial-recognitionaccessed2021-07-18', 'j.macglashan', 'monicababes-vroman', 'm.desjardins', 'm.littman', 's.muresan', 's.squire', 'stefanietellex', 'diliparumugam', 'andleiyang.2015.groundingenglishcommandstorewardfunctions.inrobotics', 'scienceandsystems', 'rss', 'aleksandermadry', 'aleksandarmakelov', 'ludwigschmidt', 'dimitristsipras', 'andadrianvladu.2018.towardsdeeplearning', 'modelsresistanttoadversarialattacks.ininternationalconferenceonlearningrepresentations', 'iclr', 'jeffreymahler', 'jackyliang', 'sherdilniyaz', 'michaellaskey', 'r.doan', 'xinyuliu', 'j.a.ojea', 'andkengoldberg.2017.dex-net', '2.0', 'deeplearningtoplanrobustgraspswithsyntheticpointcloudsandanalyticgraspmetrics.arxivabs/1703.09312', 'alimalik', 'mikewu', 'vrindavasavada', 'jinpengsong', 'madisoncoots', 'johnmitchell', 'noahgoodman', 'andchrispiech.2021', 'generativegrading', 'nearhuman-levelaccuracyforautomatedfeedbackonrichlystructuredproblems.inproceedings', 'ofthe14thinternationalconferenceoneducationaldatamining', 'vittoriocaggianonamangoyalsiddharthgoyalmyleottbenjaminlefaudeuxvitaliyliptchinskymikerabbatsam', 'sheifferanjalisridharminxumandeepbaines', 'shrutibhosale.2021.fairscale', 'ageneralpurposemodularpytorch', 'libraryforhighperformanceandlargescaletraining.https', '//github.com/facebookresearch/fairscale', 'travismandel', 'yun-enliu', 'sergeylevine', 'emmabrunskill', 'andzoranpopovic.2014.offlinepolicyevaluationacrossrep-', 'resentationswithapplicationstoeducationalgames.inproceedingsofthe2014internationalconferenceonautonomous', 'agentsandmulti-agentsystems', 'paris', 'france', 'aamas', '’', '14', '.internationalfoundationforautonomousagentsand', 'multiagentsystems', 'richland', 'sc,1077–1084', 'ajaymandlekar', 'jonathanbooher', 'maxspero', 'alberttung', 'anchitgupta', 'yukezhu', 'animeshgarg', 'silviosavarese', 'andli', 'fei-fei.2019.scalingrobotsupervisiontohundredsofhourswithroboturk', 'roboticmanipulationdatasetthrough', 'humanreasoninganddexterity.ininternationalconferenceonintelligentrobotsandsystems', 'iros', 'christopherdmanning', 'kevinclark', 'johnhewitt', 'urvashikhandelwal', 'andomerlevy.2020.emergentlinguisticstructure', 'inartificialneuralnetworkstrainedbyself-supervision', 'proceedingsofthenationalacademyofsciences117', '2020', '30046–30054', 'manolissavva', 'abhishekkadian', 'oleksandrmaksymets', 'yilizhao', 'erikwijmans', 'bhavanajain', 'julianstraub', 'jialiu', 'vladlenkoltun', 'jitendramalik', 'deviparikh', 'anddhruvbatra.2019.habitat', 'aplatformforembodiedairesearch.in', 'proceedingsoftheieee/cvfinternationalconferenceoncomputervision', 'iccv', 'marketline.2021.legalservicesintheunitedstates', 'https', '//www.marketresearch.com/marketline-v3883/legal-services-', 'united-states-14193556/', 'bernardmarr.2017.reallybigdataatwalmart', 'real-timeinsightsfromtheir40+petabytedatacloud.https', '//www.forbes', 'com/sites/bernardmarr/2017/01/23/really-big-data-at-walmart-real-time-insights-from-their-40-petabyte-data-cloud', 'davidmarr.1982.vision', 'acomputationalinvestigationintothehumanrepresentationandprocessingofvisualinformation', 'w.h.freeman', 'sanfrancisco', 'robertomartin-martin', 'mihirpatel', 'hamidrezatofighi', 'abhijeetshenoi', 'junyounggwak', 'ericfrankel', 'amirsadeghian', 'andsilviosavarese.2021.jrdb', 'adatasetandbenchmarkofegocentricrobotvisualperceptionofhumansinbuilt', 'environments.ieeetransactionsonpatternanalysisandmachineintelligence', 'tpami', '2021', 'nicolemartinez-martin', 'zelunluo', 'amitkaushal', 'ehsanadeli', 'alberthaque', 'saraskelly', 'sarahwieten', 'mildredkcho', 'davidmagnus', 'lifei-fei', 'etal.2020', 'ethicalissuesinusingambientintelligenceinhealth-caresettings', 'thelancet', 'digitalhealth', '2020', 'rebeccamarvinandtallinzen.2018', 'targetedsyntacticevaluationoflanguagemodels.inproceedingsofthe2018', 'conferenceonempiricalmethodsinnaturallanguageprocessing.associationforcomputationallinguistics', 'brussels', 'belgium,1192–1202', 'https', '//doi.org/10.18653/v1/d18-1151', 'tonimmassaro', 'helennorton', 'andmargotekaminski.2016.siri-ously2.0', 'whatartificialintelligencerevealsaboutthe', 'firstamendment.minn.l.rev.101', ',2481', 'v.masson-delmotte', 'p.zhai', 'a.pirani', 's.l.connors', 'c.p/', '‘', 'ean', 's.berger', 'n.caud', 'y.chen', 'l.goldfarb', 'm.i.gomis', 'huang', 'k.leitzell', 'e.lonnoy', 'j.b.r.matthews', 't.k.maycock', 't.waterfield', 'o.yelekci', 'r.yu', 'andb.zhou', 'eds.', '.2021', 'ipcc,2021', 'climatechange2021', 'thephysicalsciencebasis.contributionofworkinggroupitothesixthassessment', 'reportoftheintergovernmentalpanelonclimatechange.', '2021', 'danielmasur.2018.datalicensing—tipsandtactics.corporatecomplianceinsights', 'petermattson', 'christinecheng', 'codycoleman', 'gregdiamos', 'pauliusmicikevicius', 'davidpatterson', 'hanlintang', 'gu-yeon', 'wei', 'peterbailis', 'victorbittorf', 'etal.2020.mlperftrainingbenchmark.inthirdconferenceonmachinelearningand', 'systems', 'chandlermay', 'alexwang', 'shikhabordia', 'samuelr.bowman', 'andrachelrudinger.2019.onmeasuringsocialbiasesin', 'sentenceencoders.inproceedingsofthe2019conferenceofthenorthamericanchapteroftheassociationforcomputational', 'linguistics', 'humanlanguagetechnologies', 'volume1', 'longandshortpapers', '.associationforcomputationallinguistics', 'minneapolis', 'minnesota,622–628', 'https', '//doi.org/10.18653/v1/n19-1063']",190
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '191', 'jsmccarley', 'rishavchakravarti', 'andavirupsil.2019.structuredpruningofabert-basedquestionansweringmodel', 'arxivpreprintarxiv:1910.06360', '2019', 'jameslmcclellandanddaviderumelhart.1981.aninteractiveactivationmodelofcontexteffectsinletterperception', 'i.', 'anaccountofbasicfindings.psychologicalreview88,5', '1981', ',375', 'michaelmccloskeyandnealj.cohen.1989.catastrophicinterferenceinconnectionistnetworks', 'thesequentiallearning', 'problem', 'psychologyoflearningandmotivation', 'vol.24.academicpress,109–165', 'https', '//doi.org/10.1016/s0079-', '7421', '08', '60536-8', 'jamiemckenzie.2003.pedagogydoesmatter', 'theeducationaltechnologyjournal13,1', '2003', 'warwickmckibbin', 'roshenfernando', 'etal.2020.theeconomicimpactofcovid-19.economicsinthetimeofcovid-19', '45,10.1162', '2020', 'hbrendanmcmahan', 'danielramage', 'kunaltalwar', 'andlizhang.2018.learningdifferentiallyprivaterecurrentlanguage', 'models.ininternationalconferenceonlearningrepresentations', 'williammerrill', 'yoavgoldberg', 'royschwartz', 'andnoahasmith.2021.provablelimitationsofacquiringmeaningfrom', 'ungroundedform', 'whatwillfuturelanguagemodelsunderstand', '?', 'arxivpreprintarxiv:2104.10809', '2021', 'robertkmerton.1979.thenormativestructureofscience.thesociologyofscience', 'theoreticalandempiricalinvestigations', '1979', ',267–278', 'samuelmessick.1987.validity.etsresearchreportseries1987,2', '1987', 'i–208', 'https', '//onlinelibrary.wiley.com/doi/abs/10', '1002/j.2330-8516.1987.tb00244.x', 'samuelmessick.1988.theonceandfutureissuesofvalidity', 'assessingthemeaningandconsequencesofmeasurement', 'etsresearchreportseries', '1988', 'https', '//onlinelibrary.wiley.com/doi/abs/10.1002/j.2330-8516.1986.tb00185.x', 'pauliusmicikevicius', 'sharannarang', 'jonahalben', 'gregorydiamos', 'erichelsen', 'davidgarcia', 'borisginsburg', 'michael', 'houston', 'oleksiikuchaiev', 'ganeshvenkatesh', 'etal.2017', 'mixedprecisiontraining', 'arxivpreprintarxiv:1710.03740', 'tomasmikolov', 'kaichen', 'gregcorrado', 'andjeffreydean.2013.efficientestimationofwordrepresentationsinvector', 'space.arxivpreprintarxiv:1301.3781', '2013', 'tomasmikolov', 'martinkarafiát', 'lukasburget', 'jancernocký', 'andsanjeevkhudanpur.2010.recurrentneuralnetwork', 'basedlanguagemodel.proceedingsofthe11thannualconferenceoftheinternationalspeechcommunicationassociation', 'interspeech20102,1045–1048', 'silviamilano', 'mariarosariataddeo', 'andlucianofloridi.2020.recommendersystemsandtheirethicalchallenges.ai', '&', 'society35,4', '2020', ',957–967', 'alexandermiller', 'adamfisch', 'jessedodge', 'amir-hosseinkarimi', 'antoinebordes', 'andjasonweston.2016', 'key-value', 'memorynetworksfordirectlyreadingdocuments.inproceedingsofthe2016conferenceonempiricalmethodsinnatural', 'languageprocessing.1400–1409', 'g.a.miller', 'galantere.', 'andk.h.pribram.1960.plansandthestructureofbehavior.holt', 'newyork', 'johnmiller', 'rohantaori', 'aditiraghunathan', 'shiorisagawa', 'pangweikoh', 'vaishaalshankar', 'percyliang', 'yaircarmon', 'ludwigschmidt.2021.accuracyontheline', 'onthestrongcorrelationbetweenout-of-distributionandin-distribution', 'generalization.ininternationalconferenceonmachinelearning', 'icml', 'smithamilli', 'lucabelli', 'andmoritzhardt.2021.fromoptimizingengagementtomeasuringvalue.inproceedingsofthe', '2021acmconferenceonfairness', 'accountability', 'andtransparency', 'virtualevent', 'canada', 'facct', '’', '21', '.associationfor', 'computingmachinery', 'newyork', 'ny', 'usa,714–722', 'https', '//doi.org/10.1145/3442188.3445933', 'sewonmin', 'mikelewis', 'hannanehhajishirzi', 'andlukezettlemoyer.2021.noisychannellanguagemodelpromptingfor', 'few-shottextclassification', 'arxiv:2108.04106', '[', 'cs.cl', ']', 'dipendramisra', 'johnlangford', 'andyoavartzi.2017b', 'mappinginstructionsandvisualobservationstoactionswith', 'reinforcementlearning.arxivpreprintarxiv:1704.08795', 'ishanmisra', 'abhinavgupta', 'andmartialhebert.2017a', 'fromredwinetoredtomato', 'compositionwithcontext.in', 'proceedingsoftheieeeconferenceoncomputervisionandpatternrecognition.1792–1801', 'margaretmitchell', 'simonewu', 'andrewzaldivar', 'parkerbarnes', 'lucyvasserman', 'benhutchinson', 'elenaspitzer', 'in-', 'ioluwadeborahraji', 'andtimnitgebru.2019', 'modelcardsformodelreporting', 'proceedingsoftheconferenceon', 'fairness', 'accountability', 'andtransparency', 'jan2019', 'https', '//doi.org/10.1145/3287560.3287596', 'yasuhidemiura', 'yuhaozhang', 'emilybaotsai', 'curtisplanglotz', 'anddanjurafsky.2021.improvingfactualcompleteness', 'andconsistencyofimage-to-textradiologyreportgeneration.naacl', '2021', 'pieromolino', 'yaroslavdudin', 'andsaisumanthmiryala.2019.ludwig', 'atype-baseddeclarativedeeplearningtoolbox', 'arxivpreprintarxiv:1909.07930', '2019', 'camilomora', 'randilrollins', 'katietaladay', 'michaelbkantar', 'masonkchock', 'mioshimada', 'anderikcfranklin.2018', 'bitcoinemissionsalonecouldpushglobalwarmingabove2c.natureclimatechange8,11', ',931–933', 'hansmoravec.1988.mindchildren', 'thefutureofrobotandhumanintelligence.harvarduniversitypress']",191
Opportunities and Risks of Foundational Models - Stanford.pdf,"['192', 'centerforresearchonfoundationmodels', 'crfm', 'heshammostafaandxinwang.2019', 'parameterefficienttrainingofdeepconvolutionalneuralnetworksbydynamic', 'sparsereparameterization.ininternationalconferenceonmachinelearning.pmlr,4646–4655', 'http', '//proceedings.mlr', 'press/v97/mostafa19a.htmlzscc:0000081issn:2640-3498', 'husseinmozannaranddavidsontag.2020', 'consistentestimatorsforlearningtodefertoanexpert.ininternational', 'conferenceonmachinelearning.pmlr,7076–7087', 'jessemuandjacobandreas.2020.compositionalexplanationsofneurons.arxivpreprintarxiv:2006.14032', '2020', 'dheevatsamudigere', 'yuchenhao', 'jianyuhuang', 'andrewtulloch', 'srinivassridharan', 'xingliu', 'mustafaozdal', 'jade', 'nie', 'jongsoopark', 'liangluo', 'etal.2021', 'high-performance', 'distributedtrainingoflarge-scaledeeplearning', 'recommendationmodels.arxivpreprintarxiv:2104.05158', '2021', 'brada.myers', 'scotte.hudson', 'andrandypausch.2000.past', 'presentandfutureofuserinterfacesoftwaretools.inacm', 'transactionsoncomputerhumaninteraction.acm', 'moinnadeem', 'annabethke', 'andsivareddy.2021.stereoset', 'measuringstereotypicalbiasinpretrainedlanguagemodels', 'inproceedingsofacl2021', 'vaishnavhnagarajan', 'andersandreassen', 'andbehnamneyshabur.2020', 'understandingthefailuremodesofout-of-', 'distributiongeneralization.arxivpreprintarxiv:2010.15775', '2020', 'arshanagrani', 'shanyang', 'anuragarnab', 'arenjansen', 'cordeliaschmid', 'andchensun.2021.attentionbottlenecksfor', 'multimodalfusion.arxivpreprintarxiv:2107.00135', '2021', 'ashvinnair', 'vitchyrh.pong', 'murtazadalal', 'shikharbahl', 'stevenlin', 'andsergeylevine.2018', 'visualreinforcement', 'learningwithimaginedgoals.inneurips', 'v.nairandg.e.hinton.2010.rectifiedlinearunitsimproverestrictedboltzmannmachines.ininternationalconferenceon', 'machinelearning', 'icml', '.807–814', 'preetumnakkiran', 'galkaplun', 'yaminibansal', 'tristanyang', 'boazbarak', 'andilyasutskever.2019.deepdoubledescent', 'wherebiggermodelsandmoredatahurt.arxivpreprintarxiv:1912.02292', '2019', 'nikitanangia', 'claravania', 'rasikabhalerao', 'andsamuelr.bowman.2020.crows-pairs', 'achallengedatasetformeasuring', 'socialbiasesinmaskedlanguagemodels.inproceedingsofthe2020conferenceonempiricalmethodsinnaturallanguage', 'process', 'emnlp', '.associationforcomputationallinguistics', 'online,1953–1967', 'https', '//doi.org/10.18653/v1/2020', 'emnlp-main.154', 'arvindnarayanan', 'aruneshmathur', 'marshinichetty', 'andmihirkshirsagar.2020.darkpatterns', 'past', 'present', 'andfuture', 'commun.acm63,9', 'aug.2020', ',42–47', 'https', '//doi.org/10.1145/3397884', 'deepaknarayanan', 'aaronharlap', 'amarphanishayee', 'vivekseshadri', 'nikhilrdevanur', 'gregoryrganger', 'phillipb', 'gibbons', 'andmateizaharia.2019.pipedream', 'generalizedpipelineparallelismfordnntraining.inproceedingsofthe', '27thacmsymposiumonoperatingsystemsprinciples.1–15', 'deepaknarayanan', 'amarphanishayee', 'kaiyushi', 'xiechen', 'andmateizaharia.2021a.memory-efficientpipeline-parallel', 'dnntraining.ininternationalconferenceonmachinelearning.pmlr,7937–7947', 'deepaknarayanan', 'keshavsanthanam', 'amarphanishayee', 'andmateizaharia.2018.acceleratingdeeplearningworkloads', 'throughefficientmulti-modelexecution.inneuripsworkshoponsystemsformachinelearning.20', 'deepaknarayanan', 'mohammadshoeybi', 'jaredcasper', 'patricklegresley', 'mostofapatwary', 'vijayanandkorthikanti', 'dmitrivainbrand', 'prethvikashinkunti', 'juliebernauer', 'bryancatanzaro', 'etal.2021b.efficientlarge-scalelanguage', 'modeltrainingongpuclusters.arxivpreprintarxiv:2104.04473', '2021', 'jenniferc.nash.2008.re-thinkingintersectionality.feministreview89,1', 'june2008', ',1–15', 'https', '//doi.org/10.1057/fr.2008.4', 'miladnasr', 'rezashokri', 'andamirhoumansadr.2018', 'machinelearningwithmembershipprivacyusingadversarial', 'regularization.inproceedingsofthe2018acmsigsacconferenceoncomputerandcommunicationssecurity', 'toronto', 'canada', 'ccs', '’', '18', '.associationforcomputingmachinery', 'newyork', 'ny', 'usa,634–646', 'https', '//doi.org/10.1145/3243734', '3243855', 'wilhelminanekoto', 'vukosimarivate', 'tshinondiwamatsila', 'timiefasubaa', 'taiwofagbohungbe', 'solomonoluwole', 'akinola', 'shamsuddeenhassanmuhammad', 'salomonkabongokabenamualu', 'salomeyosei', 'freshiasackey', 'etal.2020', 'participatoryresearchforlow-resourcedmachinetranslation', 'acasestudyinafricanlanguages.inemnlp', 'find', 'andrewy.ngandstuartrussell.2000', 'algorithmsforinversereinforcementlearning.ininternationalconferenceon', 'machinelearning', 'elhadjimamadounguer', 'allalo', 'cheikhmbambadione', 'sileyeoba', 'andmoussalo.2020.sencorpus', 'afrench-wolof', 'parallelcorpus.inproceedingsofthe12thlanguageresourcesandevaluationconference.2803–2811', 'anhnguyen', 'alexeydosovitskiy', 'jasonyosinski', 'thomasbrox', 'andjeffclune.2016.synthesizingthepreferredinputsfor', 'neuronsinneuralnetworksviadeepgeneratornetworks.advancesinneuralinformationprocessingsystems29', '3387–3395', 'yizhaoni', 'stephaniekennebeck', 'judithwdexheimer', 'constancemmcaneney', 'huaxiutang', 'toddlingren', 'qili', 'haijunzhai', 'andimresolti.2015.automatedclinicaltrialeligibilityprescreening', 'increasingtheefficiencyofpatient', 'identificationforclinicaltrialsintheemergencydepartment.journaloftheamericanmedicalinformaticsassociation22']",192
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '193', '1', ',166–178', 'allennie', 'ashleyzehnder', 'rodneylpage', 'yuhuizhang', 'arturolopezpineda', 'manuelarivas', 'carlosdbustamante', 'jameszou.2018.deeptag', 'inferringdiagnosesfromveterinaryclinicalnotes.npjdigitalmedicine1,1', ',1–8', 'mathiaswullumnielsen', 'sharlaalegria', 'lovebörjeson', 'henryetzkowitz', 'hollyj.falk-krzesinski', 'aparnajoshi', 'erin', 'leahey', 'laurelsmith-doerr', 'anitawilliamswoolley', 'andlondaschiebinger.2017.opinion', 'genderdiversityleadsto', 'betterscience.proceedingsofthenationalacademyofsciences114,8', 'feb.2017', ',1740–1742', 'https', '//doi.org/10.1073/', 'pnas.1700616114', 'helennissenbaum.2004.privacyascontextualintegrity.wash.l.rev.79', '2004', ',119', 'helennissenbaum.2009.privacyincontext', 'technology', 'policy', 'andtheintegrityofsociallife.stanforduniversitypress', 'malvinanissim', 'rikvannoord', 'androbvandergoot.2020.fairisbetterthansensational', 'manistodoctoraswomanis', 'todoctor.computationallinguistics46,2', 'june2020', ',487–497', 'https', '//doi.org/10.1162/coli_a_00379', 'safiyaumojanoble.2018.algorithmsofoppression.newyorkuniversitypress', 'shimonynof.1999.handbookofindustrialrobotics.johnwiley', '&', 'sons', 'sebastiannordhoffandharaldhammarström.2011.glottolog/langdoc', 'definingdialects', 'languages', 'andlanguagefamilies', 'ascollectionsofresources.infirstinternationalworkshoponlinkedscience2011-inconjunctionwiththeinternational', 'semanticwebconference', 'iswc2011', 'deboranozza', 'federicobianchi', 'anddirkhovy.2021.honest', 'measuringhurtfulsentencecompletioninlanguage', 'models.inproceedingsofthe2021conferenceofthenorthamericanchapteroftheassociationforcomputational', 'linguistics', 'humanlanguagetechnologies.associationforcomputationallinguistics', 'online,2398–2406', 'https', '//doi.org/10.18653/v1/2021.naacl-main.191', 'marthacravennussbaum.2010.notforprofit', 'whydemocracyneedsthehumanities.princetonuniversitypress', 'nvidia.2021.nvidiacollectivecommunicationlibrary', 'nccl', '.https', '//developer.nvidia.com/nccl', 'juliannyarkoandsarathsanga.2020.astatisticaltestforlegalinterpretation', 'theoryandapplications.availableat', 'ssrn3737292', '2020', 'lukeoakden-rayner', 'jareddunnmon', 'gustavocarneiro', 'andchristopherré.2019.hiddenstratificationcausesclinically', 'meaningfulfailuresinmachinelearningformedicalimaging.arxive-prints', 'art.arxivpreprintarxiv:1909.12475', '2019', 'douglaswoard', 'fabriziosebastiani', 'andjyothikvinjumur.2018', 'jointlyminimizingtheexpectedcostsofreviewfor', 'responsivenessandprivilegeine-discovery.acmtransactionsoninformationsystems', 'tois', '37,1', ',1–35', 'jonathana.obarandanneoeldorf-hirsch.2020', 'thebiggestlieontheinternet', 'ignoringtheprivacypoliciesand', 'termsofservicepoliciesofsocialnetworkingservices', 'information', 'communication', '&', 'society23,1', '2020', ',128–147', 'https', '//doi.org/10.1080/1369118x.2018.1486870', 'cailino', '’', 'connor', 'liamkofibright', 'andjustinp.bruner.2019', 'theemergenceofintersectionaldisadvantage', 'social', 'epistemology33,1', 'jan.2019', ',23–41', 'https', '//doi.org/10.1080/02691728.2018.1555870', 'u.s.copyrightoffice.2021.moreinformationonfairuse.https', '//www.copyright.gov/fair-use/more-info.html', 'paulohm.2014.changingtherules', 'generalprinciplesfordatauseandanalysis.cambridgeuniversitypress,96–111', 'chrisolah', 'nickcammarata', 'ludwigschubert', 'gabrielgoh', 'michaelpetrov', 'andshancarter.2020.zoomin', 'anintroduction', 'tocircuits.distill5,3', '2020', 'e00024–001', 'thiagodiasoliva', 'dennysmarceloantonialli', 'andalessandragomes.2021.fightinghatespeech', 'silencingdragqueens', '?', 'artificialintelligenceincontentmoderationandriskstolgbtqvoicesonline.sexuality', '&', 'culture25,2', '2021', ',700–732', 's.omohundro.2008.thebasicaidrives.inagi', 'cathyo', '’', 'neil.2016', 'weaponsofmathdestruction', 'howbigdataincreasesinequalityandthreatensdemocracy', 'crown', 'publishinggroup', 'usa', 'openai', 'i.akkaya', 'marcinandrychowicz', 'maciekchociej', 'mateuszlitwin', 'bobmcgrew', 'arthurpetron', 'alexpaino', 'matthiasplappert', 'glennpowell', 'raphaelribas', 'jonasschneider', 'n.tezak', 'jerrytworek', 'p.welinder', 'lilianweng', 'qimingyuan', 'wojciechzaremba', 'andleizhang.2019.solvingrubik', '’', 'scubewitharobothand.arxivabs/1910.07113', '2019', 'yonatanoren', 'shiorisagawa', 'tatsunorihashimoto', 'andpercyliang.2019.distributionallyrobustlanguagemodeling.in', 'empiricalmethodsinnaturallanguageprocessing', 'emnlp', 'laurelorr', 'meganleszczynski', 'simranarora', 'senwu', 'neelguha', 'xiaoling', 'andchrisré.2020.bootleg', 'chasingthetail', 'withself-supervisednamedentitydisambiguation.inarxiv', 'malteostendorff', 'elliottash', 'terryruas', 'belagipp', 'julianmoreno-schneider', 'andgeorgrehm.2021.evaluatingdocument', 'representationsforcontent-basedlegalliteraturerecommendations.arxivpreprintarxiv:2104.13841', '2021', 'davidouyang', 'bryanhe', 'amirataghorbani', 'nealyuan', 'josephebinger', 'curtisplanglotz', 'paulaheidenreich', 'roberta', 'harrington', 'davidhliang', 'euanaashley', 'etal.2020.video-basedaiforbeat-to-beatassessmentofcardiacfunction', 'nature580,7802', '2020', ',252–256', 'isabelpapadimitriou', 'ethanachi', 'richardfutrell', 'andkylemahowald.2021.deepsubjecthood', 'higher-ordergrammatical', 'featuresinmultilingualbert.inproceedingsofthe16thconferenceoftheeuropeanchapteroftheassociationfor']",193
Opportunities and Risks of Foundational Models - Stanford.pdf,"['194', 'centerforresearchonfoundationmodels', 'crfm', 'computationallinguistics', 'mainvolume.2522–2532', 'isabelpapadimitriouanddanjurafsky.2020.learningmusichelpsyouread', 'usingtransfertostudylinguisticstructurein', 'languagemodels.arxivpreprintarxiv:2004.14601', '2020', 'denispaperno', 'germankruszewski', 'angelikilazaridou', 'quanngocpham', 'raffaellabernardi', 'sandropezzelle', 'marco', 'baroni', 'gemmaboleda', 'andraquelfernandez.2016.thelambadadataset', 'wordpredictionrequiringabroaddiscourse', 'context.inassociationforcomputationallinguistics', 'acl', 'nicolaspapernot', 'patrickmcdaniel', 'iangoodfellow', 'someshjha', 'z.berkaycelik', 'andananthramswami.2017.practical', 'black-boxattacksagainstdeeplearningsystemsusingadversarialexamples.inproceedingsoftheacmasiaconference', 'oncomputerandcommunicationssecurity', 'titouanparcolletandmircoravanelli.2021.theenergyandcarbonfootprintoftrainingend-to-endspeechrecognizers', '2021', 'c.l.paris', 'w.r.swartout', 'andw.c.mann.2013.naturallanguagegenerationinartificialintelligenceandcomputational', 'linguistics.springerus', 'https', '//books.google.gr/books', '?', 'id=4vbibwaaqbaj', 'germani.parisi', 'ronaldkemker', 'josel.part', 'christopherkanan', 'andstefanwermter.2019.continuallifelonglearning', 'withneuralnetworks', 'areview.neuralnetworks113', '2019', ',54–71', 'https', '//doi.org/10.1016/j.neunet.2019.01.012', 'joonsukpark', 'sallyklingel', 'clairecardie', 'marynewhart', 'cynthiafarina', 'andjoan-josepvallbé.2012', 'facilitative', 'moderationforonlineparticipationinerulemaking.inproceedingsofthe13thannualinternationalconferenceondigital', 'governmentresearch.173–182', 'jihopark', 'jaminshin', 'andpascalefung.2018.reducinggenderbiasinabusivelanguagedetection.inproceedingsof', 'the2018conferenceonempiricalmethodsinnaturallanguageprocessing.associationforcomputationallinguistics', 'brussels', 'belgium,2799–2804', 'https', '//doi.org/10.18653/v1/d18-1302', 'taesungpark', 'ming-yuliu', 'ting-chunwang', 'andjun-yanzhu.2019.gaugan', 'semanticimagesynthesiswithspatially', 'adaptivenormalization.inacmsiggraph2019real-timelive', '1–1', 'andrewparker.2003.intheblinkofaneye', 'howvisionsparkedthebigbangofevolution.', '2003', 'samirpassiandsolonbarocas.2019', 'problemformulationandfairness.inproceedingsoftheconferenceonfairness', 'accountability', 'andtransparency.acm', 'https', '//doi.org/10.1145/3287560.3287567', 'adampaszke', 'samgross', 'franciscomassa', 'adamlerer', 'jamesbradbury', 'gregorychanan', 'trevorkilleen', 'zeminglin', 'nataliagimelshein', 'lucaantiga', 'albandesmaison', 'andreasköpf', 'edwardyang', 'zachdevito', 'martinraison', 'alykhan', 'tejani', 'sasankchilamkurthy', 'benoitsteiner', 'lufang', 'junjiebai', 'andsoumithchintala.2019.pytorch', 'animperative', 'style', 'high-performancedeeplearninglibrary.inadvancesinneuralinformationprocessingsystems', 'neurips', 'orpatashnik', 'zongzewu', 'elishechtman', 'danielcohen-or', 'anddanilischinski.2021.styleclip', 'text-drivenmanipulation', 'ofstyleganimagery.arxive-prints', '2021', 'arxiv–2103', 'deepakpathak', 'pulkitagrawal', 'alexeia.efros', 'andtrevordarrell.2017.curiosity-drivenexplorationbyself-supervised', 'prediction.2017ieeeconferenceoncomputervisionandpatternrecognitionworkshops', 'cvprw', ',488–489', 'davidpatterson', 'josephgonzalez', 'quocle', 'chenliang', 'lluis-miquelmunguia', 'danielrothchild', 'davidso', 'maudtexier', 'andjeffdean.2021.carbonemissionsandlargeneuralnetworktraining.arxivpreprintarxiv:2104.10350', '2021', 'amandalynnepaullada', 'inioluwadeborahraji', 'emilym.bender', 'emilyl.denton', 'andalexhanna.2020.dataandits', 'dis', 'content', 'asurveyofdatasetdevelopmentanduseinmachinelearningresearch', 'arxivabs/2012.05345', '2020', 'https', '//arxiv.org/abs/2012.05345', 'judeapearl.2000.causality', 'model', 'reasoningandinference.vol.29.springer', 'dinglanpeng', 'shuxinzheng', 'yataoli', 'guolinke', 'dihe', 'andtie-yanliu.2021.howcouldneuralnetworksunderstand', 'program', '?', 'corrabs/2105.04297', '2021', '.arxiv:2105.04297', 'https', '//arxiv.org/abs/2105.04297', 'xingchaopeng', 'qinxunbai', 'xidexia', 'zijunhuang', 'katesaenko', 'andbowang.2019.momentmatchingformulti-source', 'domainadaptation.ininternationalconferenceoncomputervision', 'iccv', 'xuebinpeng', 'erwincoumans', 'tingnanzhang', 'tsang-weiedwardlee', 'jietan', 'andsergeylevine.2020.learningagile', 'roboticlocomotionskillsbyimitatinganimals.inrobotics', 'scienceandsystems', 'https', '//doi.org/10.15607/rss.2020.xvi', '064', 'andrew', 'm.', 'penner', 'aliya', 'saperstein', '2008', 'social', 'status', 'shape', 'race', 'proceed', 'national', 'academy', 'sciences', '105', '50', '2008', '19628–19630', 'https', '//doi.org/10.1073/pnas.0805762105', 'arxiv', 'https', '//www.pnas.org/content/105/50/19628.full.pdf', 'andrewm.pennerandaliyasaperstein.2013', 'engenderingracialperceptions', 'anintersectionalanalysisofhow', 'social', 'status', 'shape', 'race', 'gender', '&', 'society', '27', '3', '2013', '319–344', 'https', '//doi.org/10.1177/0891243213480262', 'arxiv', 'https', '//doi.org/10.1177/0891243213480262', 'andrewm.pennerandaliyasaperstein.2015.disentanglingtheeffectsofracialself-identificationandclassificationby', 'others', 'thecaseofarrest.demography52,3', ',1017–1024', 'https', '//link.springer.com/article/10.1007/s13524-015-', '0394-1']",194
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '195', 'jeffreypennington', 'richardsocher', 'andchristopherdmanning.2014.glove', 'globalvectorsforwordrepresentation.in', 'empiricalmethodsinnaturallanguageprocessing', 'emnlp', '.1532–1543', 'bethanypercha.2021', 'modernclinicaltextmining', 'aguideandreview', 'annualreviewofbiomedicaldatascience4', '2021', 'ethanperez', 'douwekiela', 'andkyunghyuncho.2021', 'truefew-shotlearningwithlanguagemodels', 'arxivpreprint', 'arxiv:2105.11447', '2021', 'matthewe.peters', 'markneumann', 'mohitiyyer', 'mattgardner', 'christopherclark', 'kentonlee', 'andlukezettlemoyer.2018', 'deepcontextualizedwordrepresentations.innorthamericanassociationforcomputationallinguistics', 'naacl', 'matthewe.peters', 'markneumann', 'ivrobertllogan', 'royschwartz', 'v.joshi', 'sameersingh', 'andnoaha.smith.2019', 'knowledgeenhancedcontextualwordrepresentations.inemnlp/ijcnlp', 'fabiopetroni', 'timrocktäschel', 'patricklewis', 'a.bakhtin', 'yuxiangwu', 'alexanderh.miller', 'ands.riedel.2019.language', 'modelsasknowledgebases', '?', '.inemnlp', 'chrispiechandlisaeinstein.2020', 'avisionofaiforjoyfuleducation', 'scientificamerican', 'feb2020', 'https', '//blogs', 'scientificamerican.com/observations/a-vision-of-ai-for-joyful-education/', 'tiagopimentel', 'josefvalvoda', 'rowanhallmaudslay', 'ranzmigrod', 'adinawilliams', 'andryancotterell.2020.information-', 'theoreticprobingforlinguisticstructure.inproceedingsofthe58thannualmeetingoftheassociationforcomputational', 'linguistics.associationforcomputationallinguistics', 'online,4609–4622', 'https', '//www.aclweb.org/anthology/2020.acl-', 'main.420', 'joellepineau', 'philippevincent-lamarre', 'koustuvsinha', 'vincentlarivière', 'alinabeygelzimer', 'florenced', '’', 'alchébuc', 'emily', 'fox', 'andhugolarochelle.2020.improvingreproducibilityinmachinelearningresearch', 'areportfromtheneurips', '2019reproducibilityprogram', 'arxiv:2003.12206', '[', 'cs.lg', ']', 'lerrelpintoandabhinavgupta.2016.supersizingself-supervision', 'learningtograspfrom50ktriesand700robothours', 'inieeeinternationalconferenceonroboticsandautomation', 'icra', '.ieee,3406–3413', 'telmopires', 'evaschlinger', 'anddangarrette.2019', 'howmultilingualismultilingualbert', '?', '.inproceedingsofthe57th', 'annualmeetingoftheassociationforcomputationallinguistics.4996–5001', 'ninapoerner', 'ulliwaltinger', 'andhinrichschutze.2020', 'e-bert', 'efficient-yet-effectiveentityembeddingsforbert', 'arxiv:1911.03681v2', '2020', 'adampoliak', 'jasonnaradowsky', 'aparajitahaldar', 'rachelrudinger', 'andbenjaminvandurme.2018.hypothesisonly', 'baselinesinnaturallanguageinference.inproceedingsoftheseventhjointconferenceonlexicalandcomputational', 'semantics.associationforcomputationallinguistics', 'neworleans', 'louisiana,180–191', 'https', '//doi.org/10.18653/v1/s18-', '2023', 'antoniopolino', 'razvanpascanu', 'anddanalistarh.2018', 'modelcompressionviadistillationandquantization', 'arxiv', 'preprintarxiv:1802.05668', 'stanislas', 'polu', 'ilya', 'sutskever', '2020', 'generative', 'language', 'model', 'automate', 'theorem', 'prove', 'corr', 'abs/2009.03393', '2020', '.arxiv:2009.03393', 'https', '//arxiv.org/abs/2009.03393', 'edoardomariaponti', 'heleno', '’', 'horan', 'yevgeniberzak', 'ivanvulić', 'roireichart', 'thierrypoibeau', 'ekaterinashutova', 'andannakorhonen.2019', 'modelinglanguagevariationanduniversals', 'asurveyontypologicallinguisticsfor', 'naturallanguageprocessing.computationallinguistics45,3', '092019', ',559–601', 'https', '//doi.org/10.1162/coli_a_00357', 'arxiv', 'https', '//direct.mit.edu/coli/article-pdf/45/3/559/1847397/coli_a_00357.pdf', 'ryanpoplin', 'avinashvvaradarajan', 'katyblumer', 'yunliu', 'michaelvmcconnell', 'gregscorrado', 'lilypeng', 'anddaler', 'webster.2018', 'predictionofcardiovascularriskfactorsfromretinalfundusphotographsviadeeplearning', 'nature', 'biomedicalengineering2,3', ',158–164', 'vinodkumarprabhakaranandjr.donaldmartin.2020.participatorymachinelearningusingcommunity-basedsystem', 'dynamics.healthhumrights', '2020', 'grushaprasad', 'martenvanschijndel', 'andtallinzen.2019', 'usingprimingtouncovertheorganizationofsyntactic', 'representationsinneurallanguagemodels.inproceedingsofthe23rdconferenceoncomputationalnaturallanguage', 'learn', 'conll', '.associationforcomputationallinguistics', 'hongkong', 'china,66–76', 'https', '//doi.org/10.18653/v1/k19-', '1007', 'doinaprecup', 'r.sutton', 'andsatindersingh.2000.eligibilitytracesforoff-policypolicyevaluation.inicml', 'gilpress.2021.andrewnglaunchesacampaignfordata-centricai.https', '//www.forbes.com/sites/gilpress/2021/06/16/', 'andrew-ng-launches-a-campaign-for-data-centric-ai/', '?', 'sh=44865f6a74f5', 'georgelpriestandbenjaminklein.1984.theselectionofdisputesforlitigation.thejournaloflegalstudies13,1', '1984', '1–55', 'pytorch.2021.pytorchjit.https', '//pytorch.org/docs/stable/jit.html', 'guanghuiqinandjasoneisner.2021.learninghowtoask', 'queryinglmswithmixturesofsoftprompts.inproceedings', 'ofthe2021conferenceofthenorthamericanchapteroftheassociationforcomputationallinguistics', 'humanlanguage', 'technologies', 'naacl-hlt', '.online,5203–5212', 'http', '//cs.jhu.edu/~jason/papers/', '#', 'qin-eisner-2021']",195
Opportunities and Risks of Foundational Models - Stanford.pdf,"['196', 'centerforresearchonfoundationmodels', 'crfm', 'marcqueudot', 'ériccharton', 'andmarie-jeanmeurs.2020', 'improvingaccesstojusticewithlegalchatbots', 'stats3,3', '2020', ',356–375', 'joaquinquiñonero-candela', 'masashisugiyama', 'antonschwaighofer', 'andneild.lawrence.2009.whentrainingandtest', 'setsaredifferent', 'characterizinglearningtransfer.indatasetshiftinmachinelearning.3–28', 'markusn.rabe', 'dennislee', 'kshitijbansal', 'andchristianszegedy.2021', 'mathematicalreasoningviaself-supervised', 'skip-treetraining.iclr', '2021', 'https', '//openreview.net/forum', '?', 'id=ymqany0cmey', 'alecradford', 'jongwookkim', 'chrishallacy', 'adityaramesh', 'gabrielgoh', 'sandhiniagarwal', 'girishsastry', 'amandaaskell', 'pamelamishkin', 'jackclark', 'etal.2021.learningtransferablevisualmodelsfromnaturallanguagesupervision.arxiv', 'preprintarxiv:2103.00020', '2021', 'alecradfordandkarthiknarasimhan.2018.improvinglanguageunderstandingbygenerativepre-training', 'alecradford', 'karthiknarasimhan', 'timsalimans', 'andilyasutskever.2018.improvinglanguageunderstandingbygenerative', 'pre-training.technicalreport.openai', 'alecradford', 'jeffreywu', 'rewonchild', 'davidluan', 'darioamodei', 'andilyasutskever.2019', 'languagemodelsare', 'unsupervisedmultitasklearners.openaiblog1,8', '2019', 'kiraradinsky.2015.datamonopolistslikegooglearethreateningtheeconomy.harvardbusinessreview2', 'evaniradiya-dixitandfloriantramèr.2021', 'datapoisoningwon', '’', 'tsaveyoufromfacialrecognition', 'arxivpreprint', 'arxiv:2106.14851', '2021', 'colinraffel', 'noamshazeer', 'adamroberts', 'katherinelee', 'sharannarang', 'michaelmatena', 'yanqizhou', 'weili', 'andpeterj', 'liu.2019.exploringthelimitsoftransferlearningwithaunifiedtext-to-texttransformer.arxivpreprintarxiv:1910.10683', '2019', 'maithraraghu', 'benpoole', 'jonkleinberg', 'suryaganguli', 'andjaschasohl-dickstein.2017.ontheexpressivepowerofdeep', 'neuralnetworks.ininternationalconferenceonmachinelearning.pmlr,2847–2854', 'maithraraghu', 'chiyuanzhang', 'jonkleinberg', 'andsamybengio.2019.transfusion', 'understandingtransferlearning', 'formedicalimaging.inadvancesinneuralinformationprocessingsystems', 'h.wallach', 'h.larochelle', 'a.beygelzimer', 'f.d', '’', 'alchébuc', 'e.fox', 'andr.garnett', 'eds.', 'vol.32.curranassociates', 'inc', 'https', '//proceedings.neurips.cc/paper/2019/', 'file/eb1e78328c46506b46a4ac4a1e378b91-paper.pdf', 'samyamrajbhandari', 'jeffrasley', 'olatunjiruwase', 'andyuxionghe.2020.zero', 'memoryoptimizationstowardtraining', 'trillionparametermodels.insc20', 'internationalconferenceforhighperformancecomputing', 'network', 'storageand', 'analysis.ieee,1–16', 'samyamrajbhandari', 'olatunjiruwase', 'jeffrasley', 'shadensmith', 'andyuxionghe.2021.zero-infinity', 'breakingthegpu', 'memorywallforextremescaledeeplearning', 'arxiv:2104.07857', '[', 'cs.dc', ']', 'inioluwadeborahrajiandjoybuolamwini.2019', 'actionableauditing', 'investigatingtheimpactofpubliclynaming', 'biasedperformanceresultsofcommercialaiproducts.inproceedingsofthe2019aaai/acmconferenceonai', 'ethics', 'andsociety', 'honolulu', 'hi', 'usa', 'aies', '’', '19', '.associationforcomputingmachinery', 'newyork', 'ny', 'usa,429–435', 'https', '//doi.org/10.1145/3306618.3314244', 'inioluwadeborahraji', 'andrewsmart', 'rebeccan.white', 'margaretmitchell', 'timnitgebru', 'benhutchinson', 'jamila', 'smith-loud', 'danieltheron', 'andparkerbarnes.2020', 'closingtheaiaccountabilitygap.inproceedingsofthe2020', 'conferenceonfairness', 'accountability', 'andtransparency.acm', 'https', '//doi.org/10.1145/3351095.3372873', 'alvinrajkomar', 'eyaloren', 'kaichen', 'andrewmdai', 'nissanhajaj', 'michaelahardt', 'peterjliu', 'xiaobingliu', 'jakemarcus', 'mimisun', 'etal.2018', 'scalableandaccuratedeeplearningwithelectronichealthrecords', 'npjdigitalmedicine1,1', ',1–10', 'pranavrajpurkar', 'robinjia', 'andpercyliang.2018.knowwhatyoudon', '’', 'tknow', 'unanswerablequestionsforsquad.in', 'proceedingsofthe56thannualmeetingoftheassociationforcomputationallinguistics', 'volume2', 'shortpapers', '.784–789', 'pranavrajpurkar', 'jianzhang', 'konstantinlopyrev', 'andpercyliang.2016', 'squad:100,000+questionsformachine', 'comprehensionoftext.inempiricalmethodsinnaturallanguageprocessing', 'emnlp', 'adityaramesh', 'mikhailpavlov', 'gabrielgoh', 'scottgray', 'chelseavoss', 'alecradford', 'markchen', 'andilyasutskever.2021', 'zero-shottext-to-imagegeneration', 'arxiv:2102.12092', '[', 'cs.cv', ']', 'bharathramsundar', 'stevenm.kearnes', 'patrickriley', 'dalewebster', 'davide.konerding', 'andvijays.pande.2015.massively', 'multitasknetworksfordrugdiscovery.corrabs/1502.02072', '.arxiv:1502.02072', 'http', '//arxiv.org/abs/1502.02072', 'jeffrasley', 'samyamrajbhandari', 'olatunjiruwase', 'andyuxionghe.2020', 'deepspeed', 'systemoptimizationsenable', 'trainingdeeplearningmodelswithover100billionparameters.inproceedingsofthe26thacmsigkddinternational', 'conferenceonknowledgediscovery', '&', 'datamining.3505–3506', 'lailarasmy', 'yangxiang', 'ziqianxie', 'cuitao', 'anddeguizhi.2021.med-bert', 'pretrainedcontextualizedembeddingson', 'large-scalestructuredelectronichealthrecordsfordiseaseprediction.npjdigitalmedicine4,1', '2021', ',1–13', 'r.ratcliff.1990.connectionistmodelsofrecognitionmemory', 'constraintsimposedbylearningandforgettingfunctions', 'psychologicalreview972', '1990', ',285–308']",196
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '197', 'alexanderratner', 'stephenh.bach', 'henryehrenberg', 'jasonfries', 'senwu', 'andchristopherré.2017', 'snorkel', 'rapid', 'trainingdatacreationwithweaksupervision.proceedingsofthevldbendowment', 'pvldb', 'geraldkrayandjeffreyslubbers.2014.agovernmentsuccessstory', 'howdataanalysisbythesocialsecurityappeals', 'council', 'withapushfromtheadministrativeconferenceoftheunitedstates', 'istransformingsocialsecuritydisability', 'adjudication.geo.wash.l.rev.83', '2014', ',1575', 'christopherré', 'fengniu', 'pallavigudipati', 'andcharlessrisuwananukorn.2019.overton', 'adatasystemformonitoring', 'andimprovingmachine-learnedproducts.arxivpreprintarxiv:1909.05372', '2019', 'richardmreandaliciasolow-niederman.2019.developingartificiallyintelligentjustice.stan.tech.l.rev.22', '2019', ',242', 'benjaminrecht', 'rebeccaroelofs', 'ludwigschmidt', 'andvaishaalshankar.2019', 'doimagenetclassifiersgeneralizeto', 'imagenet', '?', '.ininternationalconferenceonmachinelearning', 'icml', 'coloradoj.reed', 'xiangyuyue', 'aninrusimha', 'saynaebrahimi', 'vivekvijaykumar', 'richardmao', 'boli', 'shanghang', 'zhang', 'devinguillory', 'seanmetzger', 'kurtkeutzer', 'andtrevordarrell.2021', 'self-supervisedpretrainingimproves', 'self-supervisedpretraining', 'arxiv:2103.12718', '[', 'cs.cv', ']', 'robreich', 'mehransahami', 'andjeremym.weinstein.2021.systemerror', 'wherebigtechwentwrongandhowwecan', 'reboot.harper', 'https', '//books.google.com/books', '?', 'id=mu0qeaaaqbaj', 'theodorosrekatsinas', 'xuchu', 'ihabf.ilyas', 'andchristopherré.2017a.holoclean', 'holisticdatarepairswithprobabilistic', 'inference.proceedingsofthevldbendowment', 'pvldb', 'theodorosrekatsinas', 'manasjoglekar', 'hectorgarcia-molina', 'adityaparameswaran', 'andchristopherré.2017b.slimfast', 'guaranteedresultsfordatafusionandsourcereliability.inproceedingsofthe2017acminternationalconferenceon', 'managementofdata.1399–1414', 'hongyuren', 'hanjundai', 'zihangdai', 'mengjiaoyang', 'jureleskovec', 'daleschuurmans', 'andbodai.2021.combiner', 'full', 'attentiontransformerwithsparsecomputationcost.arxivpreprintarxiv:2107.05768', '2021', 'hongyuren', 'weihuahu', 'andjureleskovec.2020.query2box', 'reasoningoverknowledgegraphsinvectorspaceusing', 'boxembeddings.ininternationalconferenceonlearningrepresentations', 'iclr', 'hongyurenandjureleskovec.2020.betaembeddingsformulti-hoplogicalreasoninginknowledgegraphs.inneurips', 'adithyarenduchintala', 'denisediaz', 'kennethheafield', 'xianli', 'andmonadiab.2021.genderbiasamplificationduring', 'speed-qualityoptimizationinneuralmachinetranslation.inproceedingsofthe59thannualmeetingoftheassociation', 'forcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing', 'volume2', 'short', 'paper', '.associationforcomputationallinguistics', 'online,99–109', 'https', '//doi.org/10.18653/v1/2021.acl-short.15', 'lariareynoldsandkylemcdonell.2021.promptprogrammingforlargelanguagemodels', 'beyondthefew-shotparadigm', 'inextendedabstract', 'proceedingsofthesigchiconferenceonhumanfactorsincomputingsystems.acm', 'deborahlrhode.2004.accesstojustice.oxforduniversitypress', 'deborahlrhode.2014.accesstojustice', 'aroadmapforreform.fordhamurb.lj41', '2014', ',1227', 'dianarhotenandcraigcalhoun.2011.knowledgematters', 'thepublicmissionoftheresearchuniversity.columbiauniversity', 'press', 'marcotulioribeiro', 'tongshuangwu', 'carlosguestrin', 'andsameersingh.2020.beyondaccuracy', 'behavioraltestingof', 'nlpmodelswithchecklist.arxivpreprintarxiv:2005.04118', '2020', 'ricardotribeiro', 'ruitatomarinho', 'andjmiguelsanches.2012.classificationandstagingofchronicliverdiseasefrom', 'multimodaldata.ieeetransactionsonbiomedicalengineering60,5', '2012', ',1336–1344', 'douglasrice', 'jessehrhodes', 'andtatishenteta.2019', 'racialbiasinlegallanguage', 'research', '&', 'politics6,2', '2019', '2053168019848930', 'c.richards', 'w.p.bouman', 'andm.j.barker.2017.genderqueerandnon-binarygenders.palgravemacmillanuk', 'https', '//books.google.com/books', '?', 'id=qfjddwaaqbaj', 'johnrrickford', 'fayemcnair-knox', 'etal.1994.addressee-andtopic-influencedstyleshift', 'aquantitativesociolinguistic', 'study.sociolinguisticperspectivesonregister', '1994', ',235–276', 'reginarini.2017.fakenewsandpartisanepistemology.kennedyinstituteofethicsjournal27', 's2', ',43–64', 'https', '//doi.org/10.1353/ken.2017.0025', 'reginarini.2020.deepfakesandtheepistemicbackstop.philosopher', '’', 'simprint20,24', '2020', ',1–16', 'alexanderrives', 'joshuameier', 'tomsercu', 'siddharthgoyal', 'zeminglin', 'jasonliu', 'demiguo', 'myleott', 'c.lawrencezitnick', 'jerryma', 'androbfergus.2021.biologicalstructureandfunctionemergefromscalingunsupervisedlearningto250million', 'proteinsequences.proceedingsofthenationalacademyofsciences118,15', '2021', 'https', '//doi.org/10.1073/pnas.2016239118', 'arxiv', 'https', '//www.pnas.org/content/118/15/e2016239118.full.pdf', 'adamroberts', 'colinraffel', 'andnoamshazeer.2020', 'howmuchknowledgecanyoupackintotheparametersofa', 'languagemodel', '?', '.inproceedingsofthe2020conferenceonempiricalmethodsinnaturallanguageprocessing', 'emnlp', '5418–5426', 'philliprogaway.2016.themoralcharacterofcryptographicwork.,48pages', 'annarogers.2020.peerreviewinnlp', 'resourcepapers', 'https', '//hackingsemantics.xyz/2020/reviewing-data/']",197
Opportunities and Risks of Foundational Models - Stanford.pdf,"['198', 'centerforresearchonfoundationmodels', 'crfm', 'annarogers.2021.changingtheworldbychangingthedata.arxivabs/2105.13947', '2021', 'https', '//arxiv.org/abs/2105.13947', 'annarogers', 'olgakovaleva', 'andannarumshisky.2020.aprimerinbertology', 'whatweknowabouthowbertworks', 'transactionsoftheassociationforcomputationallinguistics', 'tacl', '8', '2020', ',842–866', 'davidrolnick', 'priyaldonti', 'lynnhkaack', 'kellykochanski', 'alexandrelacoste', 'krissankaran', 'andrewslavinross', 'nikolamilojevic-dupont', 'natashajaques', 'annawaldman-brown', 'etal.2019.tacklingclimatechangewithmachine', 'learning.arxivpreprintarxiv:1906.05433', '2019', 'paulmromer.1990.endogenoustechnologicalchange.journalofpoliticaleconomy98,5', 'part2', '1990', 's71–s102', 'friedarong.2021.extrapolatingtounnaturallanguageprocessingwithgpt-3', '’', 'sin-contextlearning', 'thegood', 'thebad', 'andthemysterious', 'http', '//ai.stanford.edu/blog/in-context-learning/', 'stéphaneross', 'geoffreygordon', 'andandrewbagnell.2011.areductionofimitationlearningandstructuredpredictionto', 'no-regretonlinelearning.inartificialintelligenceandstatistics', 'aistats', 'edwardrostenandtomdrummond.2006.machinelearningforhigh-speedcornerdetection.ineuropeanconferenceon', 'computervision.springer,430–443', 'danielrothchild', 'alextamkin', 'julieyu', 'ujvalmisra', 'andjosephe.gonzalez.2021', 'c5t5', 'controllablegenerationof', 'organicmoleculeswithtransformers.arxivpreprint', '2021', 'baptisterozière', 'marie-annelachaux', 'marcszafraniec', 'andguillaumelample.2021.dobf', 'adeobfuscationpre-training', 'objectiveforprogramminglanguages.corrabs/2102.07492', '2021', '.arxiv:2102.07492', 'https', '//arxiv.org/abs/2102.07492', 'sebastianruderandbarbaraplank.2018.strongbaselinesforneuralsemi-supervisedlearningunderdomainshift.in', 'proceedingsofthe56thannualmeetingoftheassociationforcomputationallinguistics', 'volume1', 'longpapers', 'melbourne', 'australia', '.associationforcomputationallinguistics,1044–1054', 'http', '//aclweb.org/anthology/p18-1096', 'cynthiarudin.2019.stopexplainingblackboxmachinelearningmodelsforhighstakesdecisionsanduseinterpretable', 'modelsinstead.naturemachineintelligence1,5', '2019', ',206–215', 'camiloruiz', 'marinkazitnik', 'andjureleskovec.2020.identificationofdiseasetreatmentmechanismsthroughthemultiscale', 'interactome.naturecommunications', '2020', 'olgarussakovsky', 'jiadeng', 'haosu', 'jonathankrause', 'sanjeevsatheesh', 'seanma', 'zhihenghuang', 'andrejkarpathy', 'aditya', 'khosla', 'michaelbernstein', 'etal.2015.imagenetlargescalevisualrecognitionchallenge.internationaljournalofcomputer', 'vision115,3', ',211–252', 'stuartj.russellandpeternorvig.2020.artificialintelligence', 'amodernapproach', '4thedition', '.pearson', 'http', '//aima.cs', 'berkeley.edu/', 'maxryabininandantongusev.2020.towardscrowdsourcedtrainingoflargeneuralnetworksusingdecentralized', 'mixture-of-experts.arxivpreprintarxiv:2002.04013', '2020', 'christopherré.2021.theroadtosoftware2.0ordata-centricai.https', '//hazyresearch.stanford.edu/data-centric-ai', 'fereshtehsadeghiandsergeylevine.2017', 'cad2rl', 'realsingle-imageflightwithoutasinglerealimage', 'arxiv', 'abs/1611.04201', 'jennyrsaffran', 'richardnaslin', 'andelissalnewport.1996.statisticallearningby8-month-oldinfants.science274,5294', '1996', ',1926–1928', 'shiorisagawa', 'pangweikoh', 'tatsunorib.hashimoto', 'andpercyliang.2020a.distributionallyrobustneuralnetworks', 'forgroupshifts', 'ontheimportanceofregularizationforworst-casegeneralization.ininternationalconferenceon', 'learningrepresentations', 'iclr', 'shiorisagawa', 'aditiraghunathan', 'pangweikoh', 'andpercyliang.2020b.aninvestigationofwhyoverparameterization', 'exacerbatesspuriouscorrelations.ininternationalconferenceonmachinelearning', 'icml', 'debjanisaha', 'candiceschumann', 'duncanc.mcelfresh', 'johnp.dickerson', 'michellel.mazurek', 'andmichaelcarltschantz', '2020', 'humancomprehensionoffairnessinmachinelearning.inproceedingsoftheaaai/acmconferenceonai', 'ethics', 'andsociety', 'newyork', 'ny', 'usa', 'aies', '’', '20', '.associationforcomputingmachinery', 'newyork', 'ny', 'usa,152', 'https', '//doi.org/10.1145/3375627.3375819', 'hassansajjad', 'fahimdalvi', 'nadirdurrani', 'andpreslavnakov.2020', 'ontheeffectofdroppinglayersofpre-trained', 'transformermodels.arxivpreprintarxiv:2004.03844', '2020', 'christophsalge', 'c.glackin', 'andd.polani.2013.empowerment-anintroduction.arxivabs/1310.1863', '2013', 'nithyasambasivan', 'shivanikapania', 'hannahhighfill', 'dianaakrong', 'praveenparitosh', 'andloramaroyo.2021.', '“', 'everyone', 'wantstodothemodelwork', 'notthedatawork', '”', 'datacascadesinhigh-stakesai.inproceedingsofthe2021chi', 'conferenceonhumanfactorsincomputingsystems.1–15', 'victorsanh', 'lysandredebut', 'julienchaumond', 'andthomaswolf.2019.distilbert', 'adistilledversionofbert', 'smaller', 'faster', 'cheaperandlighter.arxivpreprintarxiv:1910.01108', '2019', 'gilliansankoff.2018', 'languagechangeacrossthelifespan', 'annualreviewoflinguistics4,1', ',297–316', 'https', '//doi.org/10.1146/annurev-linguistics-011817-045438arxiv', 'https', '//doi.org/10.1146/annurev-linguistics-011817-045438', 'lindsaysanneman', 'christopherfourie', 'andjulieshah.2020', 'thestateofindustrialrobotics', 'emergingtechnologies', 'challenge', 'andkeyresearchdirections', 'https', '//www.therobotreport.com/wp-content/uploads/2021/01/2020-research-']",198
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '199', 'brief-sanneman-fourie-shah.pdf', 'keshavsanthanam', 'siddharthkrishna', 'ryotatomioka', 'andrewfitzgibbon', 'andtimharris.2021.distir', 'anintermediate', 'representationforoptimizingdistributedneuralnetworks.inproceedingsofthe1stworkshoponmachinelearningand', 'systems.15–23', 'adamsantoro', 'sergeybartunov', 'matthewbotvinick', 'daanwierstra', 'andtimothyp.lillicrap.2016.meta-learningwith', 'memory-augmentedneuralnetworks.inicml.1842–1850', 'http', '//proceedings.mlr.press/v48/santoro16.html', 'shibanisanturkar', 'dimitristsipras', 'andaleksandermadry.2020.breeds', 'benchmarksforsubpopulationshift.arxiv', '2020', 'maartensap', 'dallascard', 'saadiagabriel', 'yejinchoi', 'andnoaha.smith.2019', 'theriskofracialbiasinhatespeech', 'detection.inproceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics.associationfor', 'computationallinguistics', 'florence', 'italy,1668–1678', 'https', '//doi.org/10.18653/v1/p19-1163', 'aliyasapersteinandandrewm.penner.2012.racialfluidityandinequalityintheunitedstates.amer.j.sociology118,3', '2012', ',676–727', 'https', '//doi.org/10.1086/667722arxiv', 'https', '//doi.org/10.1086/667722', 'aliyasaperstein', 'andrewm.penner', 'andryanlight.2013', 'racialformationinperspective', 'connectingindividuals', 'institutions', 'andpowerrelations.annualreviewofsociology39,1', '2013', ',359–378', 'https', '//doi.org/10.1146/annurev-', 'soc-071312-145639arxiv', 'https', '//doi.org/10.1146/annurev-soc-071312-145639', 'n.saunshi', 's.malladi', 'ands.arora.2020a.amathematicalexplorationofwhylanguagemodelshelpsolvedownstream', 'tasks.arxivpreprintarxiv:2010.03648', '2020', 'nikunjsaunshi', 'sadhikamalladi', 'andsanjeevarora.2020b.amathematicalexplorationofwhylanguagemodelshelp', 'solvedownstreamtasks.arxivpreprintarxiv:2010.03648', '2020', 'jaromirsavelka', 'vernrwalker', 'matthiasgrabmair', 'andkevindashley.2017.sentenceboundarydetectioninadjudicatory', 'decisionsintheunitedstates.traitementautomatiquedeslangues58', ',21', 'manolissavva', 'abhishekkadian', 'oleksandrmaksymets', 'yilizhao', 'erikwijmans', 'bhavanajain', 'julianstraub', 'jialiu', 'vladlenkoltun', 'jitendramalik', 'etal.2019.habitat', 'aplatformforembodiedairesearch.in2019ieee/cvfinternational', 'conferenceoncomputervision', 'iccv', '.ieeecomputersociety,9338–9346', 'francoscarselli', 'marcogori', 'ahchungtsoi', 'markushagenbuchner', 'andgabrielemonfardini.2008.thegraphneural', 'networkmodel.ieeetransactionsonneuralnetworks20,1', '2008', ',61–80', 'tomschaul', 'danhorgan', 'k.gregor', 'andd.silver.2015.universalvaluefunctionapproximators.ininternationalconference', 'onmachinelearning', 'icml', 'monicaschenone', 'vladodančík', 'bridgetkwagner', 'andpaulaclemons.2013.targetidentificationandmechanismof', 'actioninchemicalbiologyanddrugdiscovery.naturechemicalbiology9,4', '2013', ',232–240', 'matthewuscherer', 'allangking', 'andmarkojmrkonich.2019.applyingoldrulestonewtools', 'employmentdiscrimina-', 'tionlawintheageofalgorithms.sclrev.71', '2019', ',449', 'timoschickandhinrichschütze.2021a.exploitingcloze-questionsforfew-shottextclassificationandnaturallanguage', 'inference.inproceedingsofthe16thconferenceoftheeuropeanchapteroftheassociationforcomputationallinguistics', 'mainvolume.associationforcomputationallinguistics', 'online,255–269', 'https', '//aclanthology.org/2021.eacl-main.20', 'timoschickandhinrichschütze.2021b', '’', 'snotjustsizethatmatters', 'smalllanguagemodelsarealsofew-shot', 'learners.inproceedingsofthe2021conferenceofthenorthamericanchapteroftheassociationforcomputational', 'linguistics', 'humanlanguagetechnologies.associationforcomputationallinguistics', 'online,2339–2352', 'https', '//doi.org/10.18653/v1/2021.naacl-main.185', 'timoschick', 'sahanaudupa', 'andh.schutze.2021.self-diagnosisandself-debiasing', 'aproposalforreducingcorpus-based', 'biasinnlp.arxivabs/2103.00453', '2021', 'londaschiebinger.2013.machinetranslation', 'analyzinggender.', '2013', 'http', '//genderedinnovations.stanford.edu/case-', 'studies/nlp.html', '#', 'tabs-2', 'londaschiebinger.2014.scientificresearchmusttakegenderintoaccount.nature507,7490', '2014', ',9', 'k.schmeckpeper', 'olehrybkin', 'kostasdaniilidis', 'sergeylevine', 'andchelseafinn.2020.reinforcementlearningwith', 'videos', 'combiningofflineobservationswithinteraction.arxivabs/2011.06507', '2020', 'jürgenschmidhuber.1987.evolutionaryprinciplesinself-referentiallearning', 'oronlearninghowtolearn', 'themeta-meta-', '...', 'hook.ph.d.dissertation.technischeuniversitätmünchen', 'j.schmidhuber.2019.reinforcementlearningupsidedown', '’', 'tpredictrewards-justmapthemtoactions.arxiv', 'abs/1912.02875', '2019', 'ludwigschmidt', 'shibanisanturkar', 'dimitristsipras', 'kunaltalwar', 'andaleksandermadry.2018', 'adversariallyrobust', 'generalizationrequiresmoredata.inadvancesinneuralinformationprocessingsystems', 'neurips', '.5014–5026', 'victorschmidt', 'kamalgoyal', 'adityajoshi', 'borisfeld', 'liamconell', 'nikolaslaskaris', 'dougblank', 'jonathanwilson', 'sorellefriedler', 'andsashaluccioni.2021.codecarbon', 'estimateandtrackcarbonemissionsfrommachinelearning', 'computing.https', '//github.com/mlco2/codecarbon.', '2021', 'https', '//doi.org/10.5281/zenodo.4658424', 'gisbertschneider.2018.automatingdrugdiscovery.naturereviewsdrugdiscovery17,2', ',97–113']",199
Opportunities and Risks of Foundational Models - Stanford.pdf,"['200', 'centerforresearchonfoundationmodels', 'crfm', 'joelm.schumm.2012.nationalindigentdefensereform', 'thesolutionismultifaceted.technicalreport.nationalassociation', 'ofcriminaldefenselawyers', 'americanbarassociation', 'm.schusterandkaisukenakajima.2012.japaneseandkoreanvoicesearch.2012ieeeinternationalconferenceonacoustics', 'speechandsignalprocessing', 'icassp', '2012', ',5149–5152', 'roeischuster', 'congzhengsong', 'erantromer', 'andvitalyshmatikov.2021.youautocompleteme', 'poisoningvulnerabilities', 'inneuralcodecompletion.in30th', '{', 'usenix', '}', 'securitysymposium', '{', 'usenix', '}', 'security21', 'e.a.g.schuur', 'a.d.mcguire', 'c.schädel', 'g.grosse', 'j.w.harden', 'd.j.hayes', 'g.hugelius', 'c.d.koven', 'p.kuhry', 'd.m', 'lawrence', 's.m.natali', 'd.olefeldt', 'v.e.romanovsky', 'k.schaefer', 'm.r.turetsky', 'c.c.treat', 'andj.e.vonk.2015.climate', 'changeandthepermafrostcarbonfeedback.nature520,7546', 'april2015', ',171–179', 'https', '//doi.org/10.1038/nature14338', 'zscc', 'nocitationdata', '[', 's0', ']', 'bandiera_abtest', 'acg_type', 'natureresearchjournalsnumber:7546primary_atype', 'review', 'publisher', 'naturepublishinggroupsubject_term', 'biogeochemistry', 'climatesciences', 'earthandenvironmentalsciences', 'subject_term_id', 'biogeochemistry', 'climate-sciences', 'earth-and-environmental-sciences', 'royschwartz', 'jessedodge', 'noahasmith', 'andorenetzioni.2019.greenai.arxivpreprintarxiv:1907.10597', '2019', 'maxschwarzer', 'nitarshanrajkumar', 'michaelnoukhovitch', 'ankeshanand', 'laurentcharlin', 'devonhjelm', 'philipbach-', 'man', 'andaaronc.courville.2021', 'pretrainingrepresentationsfordata-efficientreinforcementlearning', 'arxiv', 'abs/2106.04799', '2021', 'abigailsee', 'aneeshpappu', 'rohunsaxena', 'akhilayerukola', 'andchristopherd.manning.2019.domassivelypretrained', 'languagemodelsmakebetterstorytellers', '?', '.inproceedingsofthe23rdconferenceoncomputationalnaturallanguage', 'learn', 'conll', '.associationforcomputationallinguistics', 'hongkong', 'china,843–861', 'https', '//doi.org/10.18653/v1/', 'k19-1079', 'marwinh.s.segler', 'mikepreuss', 'andmarkp.waller.2018.planningchemicalsyntheseswithdeepneuralnetworksand', 'symbolicai.nat.555,7698', ',604–610', 'https', '//doi.org/10.1038/nature25978', 'andrewdselbst.2020.negligenceandai', '’', 'shumanusers.bulrev.100', '2020', ',1315', 'andrewd.selbst', 'danahboyd', 'sorellefriedler', 'sureshvenkatasubramanian', 'andjanetvertesi.2018', 'fairnessand', 'abstractioninsociotechnicalsystems.inproceeedingsoftheconferenceonfairness', 'accountability', 'andtransparency', 'selene.2021.selenesupercomputer.https', '//www.top500.org/system/179842/', 'ramprasaathrselvaraju', 'karandesai', 'justinjohnson', 'andnikhilnaik.2021.castingyourmodel', 'learningtolocalize', 'improvesself-supervisedrepresentations.inproceedingsoftheieee/cvfconferenceoncomputervisionandpattern', 'recognition.11058–11067', 'andreww.senior', 'richardevans', 'johnjumper', 'jameskirkpatrick', 'laurentsifre', 'timgreen', 'chongliqin', 'augustinzídek', 'alexanderw.r.nelson', 'alexbridgland', 'hugopenedones', 'stigpetersen', 'karensimonyan', 'stevecrossan', 'pushmeet', 'kohli', 'davidt.jones', 'davidsilver', 'koraykavukcuoglu', 'anddemishassabis.2020.improvedproteinstructureprediction', 'usingpotentialsfromdeeplearning.nat.577,7792', '2020', ',706–710', 'https', '//doi.org/10.1038/s41586-019-1923-7', 'ricosennrich', 'b.haddow', 'andalexandrabirch.2016', 'neuralmachinetranslationofrarewordswithsubwordunits', 'arxivabs/1508.07909', 'pierresermanet', 'coreylynch', 'yevgenchebotar', 'jasminehsu', 'ericjang', 'stefanschaal', 'sergeylevine', 'andgooglebrain', '2018.time-contrastivenetworks', 'self-supervisedlearningfromvideo.in2018ieeeinternationalconferenceonrobotics', 'andautomation', 'icra', '.ieee,1134–1141', 'alishafahi', 'parsasaadatpanah', 'chenzhu', 'aminghiasi', 'christophstuder', 'davidjacobs', 'andtomgoldstein.2019.adver-', 'sariallyrobusttransferlearning.arxivpreprintarxiv:1905.08232', '2019', 'nealashah', 'jessicajue', 'andtimkmackey.2020.surgicaldatarecordingtechnology', 'asolutiontoaddressmedicalerrors', '?', 'annalsofsurgery271,3', '2020', ',431–433', 'danilojimenezrezendshakirmohamed.2015.variationalinformationmaximisationforintrinsicallymotivatedreinforce-', 'mentlearning.innips', 'c.shannon.1948.amathematicaltheoryofcommunication.bellsyst.tech.j.27', '1948', ',379–423', 'linshao', 'tokimigimatsu', 'q.zhang', 'karenyang', 'andjeannettebohg.2020', 'concept2robot', 'learningmanipulation', 'conceptsfrominstructionsandhumandemonstrations.inrobotics', 'scienceandsystems', 'rss', 'pratyushasharma', 'l.mohan', 'lerrelpinto', 'anda.gupta.2018', 'multipleinteractionsmadeeasy', 'mime', 'largescale', 'demonstrationsdataforimitation.inconferenceonrobotlearning', 'corl', 'noamshazeer', 'youlongcheng', 'nikiparmar', 'dustintran', 'ashishvaswani', 'penpornkoanantakool', 'peterhawkins', 'hy-', 'oukjoonglee', 'mingshenghong', 'cliffyoung', 'etal.2018.mesh-tensorflow', 'deeplearningforsupercomputers.advances', 'inneuralinformationprocessingsystems31', ',10414–10423', 'noamshazeer', 'azaliamirhoseini', 'krzysztofmaziarz', 'andydavis', 'quocle', 'geoffreyhinton', 'andjeffdean.2017.outra-', 'geouslylargeneuralnetworks', 'thesparsely-gatedmixture-of-expertslayer.arxivpreprintarxiv:1701.06538', 'noamshazeerandmitchellstern.2018.adafactor', 'adaptivelearningrateswithsublinearmemorycost.ininternational', 'conferenceonmachinelearning.pmlr,4596–4604']",200
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '201', 'bokuishen', 'feixia', 'chengshuli', 'robertomartın-martın', 'linxifan', 'guanzhiwang', 'claudiad', '’', 'arpino', 'shyamalbuch', 'sanjanasrivastava', 'lyneptchapmi', 'kentvainio', 'lifei-fei', 'andsilviosavarese.2021a.igibson', 'asimulationenvironment', 'forinteractivetasksinlargerealisticscenes.internationalconferenceonintelligentrobotsandsystems', 'iros', '2021', 'haichenshen', 'lequnchen', 'yuchenjin', 'liangyuzhao', 'bingyukong', 'matthaiphilipose', 'arvindkrishnamurthy', 'andravi', 'sundaram.2019.nexus', 'agpuclusterengineforacceleratingdnn-basedvideoanalysis.inproceedingsofthe27th', 'acmsymposiumonoperatingsystemsprinciples.322–337', 'jiatracyshen', 'michiharuyamashita', 'ethanprihar', 'neilheffernan', 'xintaowu', 'anddongwonlee.2021b.mathbert', 'pre-trainedlanguagemodelforgeneralnlptasksinmathematicseducation', 'arxiv:2106.07340', '[', 'cs.cl', ']', 'emilysheng', 'josharnold', 'zhouyu', 'kai-weichang', 'andnanyunpeng.2021.revealingpersonabiasesindialoguesystems', 'arxiv:2104.08728', '[', 'cs.cl', ']', 'emilysheng', 'kai-weichang', 'premkumarnatarajan', 'andnanyunpeng.2019.thewomanworkedasababysitter', 'onbiases', 'inlanguagegeneration.inproceedingsofthe2019conferenceonempiricalmethodsinnaturallanguageprocessingand', 'the9thinternationaljointconferenceonnaturallanguageprocessing', 'emnlp-ijcnlp', '.associationforcomputational', 'linguistics', 'hongkong', 'china,3407–3412', 'https', '//doi.org/10.18653/v1/d19-1339', 'tobyshevlaneandallandafoe.2020.theoffense-defensebalanceofscientificknowledge', 'doespublishingairesearch', 'reducemisuse', '?', '.inproceedingsofthe2020aaai/acmconferenceonai', 'ethics', 'andsociety', 'aies', '’', '20', 'http', '//arxiv.org/', 'abs/2001.00463', 'taylorshin', 'yasamanrazeghi', 'robertl.loganiv', 'ericwallace', 'andsameersingh.2020.autoprompt', 'elicitingknowledge', 'fromlanguagemodelswithautomaticallygeneratedprompts.inproceedingsofthe2020conferenceonempirical', 'methodsinnaturallanguageprocessing', 'emnlp', '.associationforcomputationallinguistics', 'online,4222–4235', 'https', '//doi.org/10.18653/v1/2020.emnlp-main.346', 'benshneiderman.1997.directmanipulationvs.interfaceagents.ininteractions.acm', 'mohammadshoeybi', 'mostofapatwary', 'raulpuri', 'patricklegresley', 'jaredcasper', 'andbryancatanzaro.2019.megatron-lm', 'trainingmulti-billionparameterlanguagemodelsusingmodelparallelism', 'http', '//arxiv.org/abs/1909.08053', 'cite', 'arxiv:1909.08053', 'rezashokri', 'marcostronati', 'congzhengsong', 'andvitalyshmatikov.2017.membershipinferenceattacksagainstmachine', 'learningmodels.inieeesymposiumonsecurityandprivacy.3–18', 'connorshortenandtaghimkhoshgoftaar.2019.asurveyonimagedataaugmentationfordeeplearning.journalofbig', 'data6,1', '2019', ',1–48', 'williamhshrank', 'teresalrogstad', 'andnatashaparekh.2019.wasteintheushealthcaresystem', 'estimatedcostsand', 'potentialforsavings.jama322,15', '2019', ',1501–1509', 'mohitshridhar', 'jessethomason', 'danielgordon', 'yonatanbisk', 'winsonhan', 'roozbehmottaghi', 'lukezettlemoyer', 'dieterfox.2020.alfred', 'abenchmarkforinterpretinggroundedinstructionsforeverydaytasks.incomputervision', 'andpatternrecognition', 'cvpr', 'avantishrikumar', 'peytongreenside', 'andanshulkundaje.2017', 'learningimportantfeaturesthroughpropagating', 'activationdifferences.ininternationalconferenceonmachinelearning', 'icml', 'iliashumailov', 'yirenzhao', 'danielbates', 'nicolaspapernot', 'robertmullins', 'androssanderson.2020.spongeexamples', 'energy-latencyattacksonneuralnetworks.arxivpreprintarxiv:2006.03463', '2020', 'davidsilver', 'ajahuang', 'chrisj.maddison', 'arthurguez', 'laurentsifre', 'georgevandendriessche', 'julianschrittwieser', 'ioannisantonoglou', 'vedavyaspanneershelvam', 'marclanctot', 'sanderdieleman', 'dominikgrewe', 'johnnham', 'nal', 'kalchbrenner', 'ilyasutskever', 'timothyp.lillicrap', 'madeleineleach', 'koraykavukcuoglu', 'thoregraepel', 'anddemis', 'hassabis.2016.masteringthegameofgowithdeepneuralnetworksandtreesearch.nat.529,7587', ',484–489', 'https', '//doi.org/10.1038/nature16961', 'karensimonyan', 'andreavedaldi', 'andandrewzisserman.2013.deepinsideconvolutionalnetworks', 'visualisingimage', 'classificationmodelsandsaliencymaps.arxivpreprintarxiv:1312.6034', '2013', 'ksimonyananda.zisserman.2015.verydeepconvolutionalnetworksforlarge-scaleimagerecognition.ininternational', 'conferenceonlearningrepresentations', 'iclr', 'audrasimpson.2007.onethnographicrefusal', 'indigeneity', '’', 'voice', '’', 'colonialcitizenship.junctures', 'dec.2007', 'avisingh', 'larryyang', 'kristianhartikainen', 'chelseafinn', 'andsergeylevine.2019.end-to-endroboticreinforcement', 'learningwithoutrewardengineering.inrobotics', 'scienceandsystems', 'rss', 'satindersingh', 'andrewgbarto', 'andnuttapongchentanez.2005.intrinsicallymotivatedreinforcementlearning.technical', 'report.massachusettsunivamherstdeptofcomputerscience', 'antonsinitsin', 'vsevolodplokhotnyuk', 'dmitrypyrkin', 'sergeipopov', 'andartembabenko.2020.editableneuralnetworks', 'ininternationalconferenceonlearningrepresentations', 'https', '//openreview.net/forum', '?', 'id=hjedxaetvs', 'vincentsitzmann', 'michaelzollhöfer', 'andgordonwetzstein.2019.scenerepresentationnetworks', 'continuous3d-structure-', 'awareneuralscenerepresentations.arxivpreprintarxiv:1906.01618', '2019']",201
Opportunities and Risks of Foundational Models - Stanford.pdf,"['202', 'centerforresearchonfoundationmodels', 'crfm', 'cestellesmith', 'bowenyu', 'anjalisrivastava', 'aaronhalfaker', 'lorenterveen', 'andhaiyizhu.2020.keepingcommunityin', 'theloop', 'understandingwikipediastakeholdervaluesformachinelearning-basedsystems.inproceedingsofthe2020', 'chiconferenceonhumanfactorsincomputingsystems.1–14', 'laurasmith', 'nikitadhawan', 'marvinzhang', 'p.abbeel', 'andsergeylevine.2019.avid', 'learningmulti-stagetasksvia', 'pixel-leveltranslationofhumanvideos.arxivabs/1912.04443', '2019', 'jakesnell', 'kevinswersky', 'andrichardszemel.2017', 'prototypicalnetworksforfew-shotlearning', 'arxivpreprint', 'arxiv:1703.05175', 'davidso', 'quocle', 'andchenliang.2019.theevolvedtransformer.inproceedingsofthe36thinternationalconferenceon', 'machinelearning', 'proceedingsofmachinelearningresearch', 'vol.97', 'kamalikachaudhuriandruslansalakhutdinov', 'eds.', '.pmlr,5877–5886', 'http', '//proceedings.mlr.press/v97/so19a.html', 'natesoares', 'benjafallenstein', 'stuartarmstrong', 'andeliezeryudkowsky.2015.corrigibility.inworkshopsatthetwenty-', 'ninthaaaiconferenceonartificialintelligence', 'j.sohl-dickstein', 'erica.weiss', 'nirumaheswaranathan', 'ands.ganguli.2015', 'deepunsupervisedlearningusing', 'nonequilibriumthermodynamics.arxivabs/1503.03585', 'irenesolaiman', 'milesbrundage', 'jackclark', 'amandaaskell', 'arielherbert-voss', 'jeffwu', 'alecradford', 'gretchenkrueger', 'jongwookkim', 'sarahkreps', 'milesmccain', 'alexnewhouse', 'jasonblazakis', 'krismcguffie', 'andjasminewang.2019', 'releasestrategiesandthesocialimpactsoflanguagemodels.technicalreport.openai', 'http', '//arxiv.org/abs/1908.09203', 'irenesolaimanandchristydennison.2021.processforadaptinglanguagemodelstosociety', 'palm', 'withvalues-targeted', 'datasets.arxivpreprintarxiv:2106.10328', '2021', 'miriamsolomon.2006.normsofepistemicdiversity.episteme3,1', '2006', ',23–36', 'hamidsoltanian-zadeh.2019.multimodalanalysisinbiomedicine.inbigdatainmultimodalmedicalimaging.chapman', 'andhall/crc,193–203', 'congzhengsong', 'thomasristenpart', 'andvitalyshmatikov.2017.machinelearningmodelsthatremembertoomuch.in', 'proceedingsofthe2017acmsigsacconferenceoncomputerandcommunicationssecurity', 'dallas', 'texas', 'usa', 'ccs', '’', '17', '.associationforcomputingmachinery', 'newyork', 'ny', 'usa,587–601', 'https', '//doi.org/10.1145/3133956.3134077', 'congzhengsongandvitalyshmatikov.2019.overlearningrevealssensitiveattributes.arxivpreprintarxiv:1905.11742', '2019', 'yangsongands.ermon.2019.generativemodelingbyestimatinggradientsofthedatadistribution.arxivabs/1907.05600', '2019', 'danielsoudry', 'eladhoffer', 'morshpigelnacson', 'suriyagunasekar', 'andnathansrebro.2018.theimplicitbiasofgradient', 'descentonseparabledata.journalofmachinelearningresearch', 'jmlr', '19,1', ',2822–2878', 'stevenj.spencer', 'christinelogel', 'andpaulg.davies.2016', 'stereotypethreat', 'annualreviewofpsychology67', '415–437', 'kattaspiel', 'christopherfrauenberger', 'oskeyes', 'andgeraldinefitzpatrick.2019.agencyofautisticchildrenintechnology', 'research—acriticalliteraturereview', 'acmtransactionsoncomputer-humaninteraction26,6', 'dec.2019', ',1–40', 'https', '//doi.org/10.1145/3344919', 'peterspirtes', 'clarknglymour', 'andrichardscheines.2001.causation', 'prediction', 'andsearch', '2nded.', '.mitpress', 'josttobiasspringenberg', 'alexeydosovitskiy', 'thomasbrox', 'andmartinriedmiller.2014.strivingforsimplicity', 'theall', 'convolutionalnet.arxivpreprintarxiv:1412.6806', '2014', 'meghasrivastavaandnoahgoodman.2021.questiongenerationforadaptiveeducation.inassociationforcomputational', 'linguistics', 'acl', 'r.srivastava', 'pranavshyam', 'filipewallmutz', 'wojciechjaśkowski', 'andj.schmidhuber.2019', 'trainingagentsusing', 'upside-downreinforcementlearning.arxivabs/1912.02877', '2019', 'sanjanasrivastava', 'chengshuli', 'michaellingelbach', 'robertomartín-martín', 'feixia', 'kentvainio', 'zhenglian', 'cem', 'gokmen', 'shyamalbuch', 'ckarenliu', 'etal.2021.behavior', 'benchmarkforeverydayhouseholdactivitiesinvirtual', 'interactive', 'andecologicalenvironments.arxivpreprintarxiv:2108.03332', '2021', 'katestarbird', 'ahmerarif', 'tomwilson', 'katherinevankoevering', 'katyayefimova', 'anddanielscarnecchia.2018.ecosystem', 'orecho-system', '?', 'exploringcontentsharingacrossalternativemediadomains.proceedingsoftheinternationalaaai', 'conferenceonwebandsocialmedia12,1', 'jun.2018', 'https', '//ojs.aaai.org/index.php/icwsm/article/view/15009', 'laurastark.2012.behindcloseddoors', 'irbsandthemakingofmedicalresearch.universityofchicagopress', 'danielsteel', 'sinafazelpour', 'kinleygillette', 'biancacrewe', 'andmichaelburgess.2018.multiplediversityconceptsand', 'theirethical-epistemicimplications.europeanjournalforphilosophyofscience8,3', ',761–780', 'ethansteinberg', 'kenjung', 'jasonafries', 'conorkcorbin', 'stephenrpfohl', 'andnigamhshah.2021.languagemodelsare', 'aneffectiverepresentationlearningtechniqueforelectronichealthrecorddata.journalofbiomedicalinformatics113', '2021', ',103637', 'nicholassternandjosephestiglitz.2021.thesocialcostofcarbon', 'risk', 'distribution', 'marketfailures', 'analternativeapproach', 'technicalreport.nationalbureauofeconomicresearch']",202
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '203', 'megant.stevensonandjenniferl.doleac.2021', 'algorithmicriskassessmentinthehandsofhumans', 'ssrn', '2021', 'https', '//doi.org/10.2139/ssrn.3489440', 'iriststewart', 'christophermbacon', 'andwilliamdburke.2014.theunevendistributionofenvironmentalburdensand', 'benefitsinsiliconvalley', '’', 'sbackyard.appliedgeography55', '2014', ',266–277', 'nisanstiennon', 'longouyang', 'jeffwu', 'danielm.ziegler', 'ryanj.lowe', 'chelseavoss', 'alecradford', 'darioamodei', 'paulchristiano.2020.learningtosummarizefromhumanfeedback.arxivabs/2009.01325', '2020', 'jonathanmstokes', 'kevinyang', 'kyleswanson', 'wengongjin', 'andrescubillos-ruiz', 'ninamdonghia', 'craigrmacnair', 'shawnfrench', 'lindseyacarfrae', 'zoharbloom-ackermann', 'etal.2020.adeeplearningapproachtoantibioticdiscovery', 'cell180,4', '2020', ',688–702', 'michaelstonebrakerandihabf.ilyas.2018.dataintegration', 'thecurrentstatusandthewayforward.ieeecomputer', 'societytechnicalcommitteeondataengineering', 'michaelstonebrakerandarielweisberg.2013.thevoltdbmainmemorydbms.ieeedataeng.bull.36,2', '2013', ',21–27', 'marilynstrathern.1997', '‘', 'improvingratings', '’', 'auditinthebritishuniversitysystem', 'europeanreview5,3', '1997', ',305–', '321.', 'https', '//www.cambridge.org/core/journals/european-review/article/abs/improving-ratings-audit-in-the-british-', 'university-system/fc2ee640c0c44e3db87c29fb666e9aab', 'yolandestrengers', 'lizhenqu', 'qiongkaixu', 'andjarrodknibbe.2020', 'adhere', 'steer', 'andqueering', 'treatmentof', 'genderinnaturallanguagegeneration.inproceedingsofthe2020chiconferenceonhumanfactorsincomputing', 'systems.acm', 'https', '//doi.org/10.1145/3313831.3376315', 'emmastrubell', 'ananyaganesh', 'andandrewmccallum.2019.energyandpolicyconsiderationsfordeeplearninginnlp', 'arxivpreprintarxiv:1906.02243', '2019', 'masashisugiyama', 'matthiaskrauledat', 'andklaus-robertmuller.2007.covariateshiftadaptationbyimportanceweighted', 'crossvalidation.journalofmachinelearningresearch', 'jmlr', '8', '2007', ',985–1005', 'sainbayarsukhbaatar', 'jasonweston', 'robfergus', 'etal.2015.end-to-endmemorynetworks.inadvancesinneuralinformation', 'processingsystems.2440–2448', 'michaelsullivan', 'joshschellenberg', 'andmarshallblundell.2015.updatedvalueofservicereliabilityestimatesforelectric', 'utilitycustomersintheunitedstates', 'technicalreportlbnl–6941e,1172643.lbnl–6941e,1172643pages', 'https', '//doi.org/10.2172/1172643zscc:0000086', 'chensun', 'austinmyers', 'carlvondrick', 'kevinmurphy', 'andcordeliaschmid.2019a.videobert', 'ajointmodelforvideoand', 'languagerepresentationlearning.inproceedingsoftheieee/cvfinternationalconferenceoncomputervision.7464–7473', 'peisun', 'henrikkretzschmar', 'xerxesdotiwalla', 'aurelienchouard', 'vijaysaipatnaik', 'paultsui', 'jamesguo', 'yinzhou', 'yuning', 'chai', 'benjamincaine', 'vijayvasudevan', 'weihan', 'jiquanngiam', 'hangzhao', 'alekseitimofeev', 'scottettinger', 'maxim', 'krivokon', 'amygao', 'adityajoshi', 'shengzhao', 'shuyangcheng', 'yuzhang', 'jonathonshlens', 'zhifengchen', 'anddragomir', 'anguelov.2020a.scalabilityinperceptionforautonomousdriving', 'waymoopendataset', 'arxiv:1912.04838', '[', 'cs.cv', ']', 'tianxiangsun', 'yunfanshao', 'xipengqiu', 'qipengguo', 'yaruhu', 'xuanjinghuang', 'andzhengzhang.2020b', 'colake', 'contextualizedlanguageandknowledgeembedding.arxivpreprintarxiv:2010.00309', '2020', 'yusun', 'erictzeng', 'trevordarrell', 'andalexeia.efros.2019b.unsuperviseddomainadaptationthroughself-supervision', 'arxiv:1909.11825', '[', 'cs.lg', ']', 'mukundsundararajan', 'ankurtaly', 'andqiqiyan.2017.axiomaticattributionfordeepnetworks.ininternationalconference', 'onmachinelearning', 'icml', '.3319–3328', 'floodsung', 'yongxinyang', 'lizhang', 'taoxiang', 'philiphstorr', 'andtimothymhospedales.2018.learningtocompare', 'relationnetworkforfew-shotlearning.inproceedingsoftheieeeconferenceoncomputervisionandpatternrecognition', '1199–1208', 'harrysurden.2020.theethicsofartificialintelligenceinlaw', 'basicquestions.forthcomingchapterinoxfordhandbookof', 'ethicsofai', '2020', ',19–29', 'abhijitsuresh', 'jenniferjacobs', 'vivianlai', 'chenhaotan', 'wayneward', 'jameshmartin', 'andtamarasumner.2021.using', 'transformerstoprovideteacherswithpersonalizedfeedbackontheirclassroomdiscourse', 'thetalkmovesapplication', 'arxivpreprintarxiv:2105.07949', '2021', 'annamalaisuresh', 'rudendhran', 'andsvimal.2020.deepneuralnetworksformultimodalimagingandbiomedicalapplications', 'igiglobal', 'alexeysvyatkovskiy', 'shaokundeng', 'shengyufu', 'andneelsundaresan.2020.intellicodecompose', 'codegenerationusing', 'transformer.inproceedingsofthe28thacmjointmeetingoneuropeansoftwareengineeringconferenceandsymposium', 'onthefoundationsofsoftwareengineering.1433–1443', 'latanyasweeney.2013', 'discriminationinonlineaddelivery', 'queue11,3', 'article10', 'march2013', ',20pages', 'https', '//doi.org/10.1145/2460276.2460278', 'stephenjswensen', 'garyskaplan', 'greggsmeyer', 'eugenecnelson', 'gordonchunt', 'davidbpryor', 'jediweissberg', 'jenniferdaley', 'garyryates', 'andmarkrchassin.2011.controllinghealthcarecostsbyremovingwaste', 'whatamerican', 'doctorscandonow.bmjquality', '&', 'safety20,6', '2011', ',534–537']",203
Opportunities and Risks of Foundational Models - Stanford.pdf,"['204', 'centerforresearchonfoundationmodels', 'crfm', 'christianszegedy', 'weiliu', 'yangqingjia', 'pierresermanet', 'scottreed', 'dragomiranguelov', 'dumitruerhan', 'vincent', 'vanhoucke', 'andandrewrabinovich.2015.goingdeeperwithconvolutions.inproceedingsoftheieeeconferenceon', 'computervisionandpatternrecognition.1–9', 'christianszegedy', 'wojciechzaremba', 'ilyasutskever', 'joanbruna', 'dumitruerhan', 'iangoodfellow', 'androbfergus.2014', 'intriguingpropertiesofneuralnetworks.ininternationalconferenceonlearningrepresentations', 'iclr', 'andrewszot', 'alexclegg', 'ericundersander', 'erikwijmans', 'yilizhao', 'johnturner', 'noahmaestre', 'mustafamukadam', 'devendrachaplot', 'oleksandrmaksymets', 'aarongokaslan', 'vladimirvondrus', 'sameerdharur', 'franziskameier', 'wojciech', 'galuba', 'angelchang', 'zsoltkira', 'vladlenkoltun', 'jitendramalik', 'manolissavva', 'anddhruvbatra.2021.habitat2.0', 'traininghomeassistantstorearrangetheirhabitat', 'arxiv:2106.14405', '[', 'cs.lg', ']', 'alextamkin', 'vincentliu', 'rongfeilu', 'danielfein', 'colinschultz', 'andnoahgoodman.2021a.dabs', 'adomain-agnostic', 'benchmarkforself-supervisedlearning.', '2021', 'a.tamkin', 'mikewu', 'andnoahd.goodman.2021b.viewmakernetworks', 'learningviewsforunsupervisedrepresentation', 'learning.arxivabs/2010.07432', '2021', 'haotanandmohitbansal.2020.vokenization', 'improvinglanguageunderstandingviacontextualized', 'visually-grounded', 'supervision.inproceedingsofthe2020conferenceonempiricalmethodsinnaturallanguageprocessing', 'emnlp', '2066–2080', 'haohaotanandmohitbansal.2019.lxmert', 'learningcross-modalityencoderrepresentationsfromtransformers.in', 'empiricalmethodsinnaturallanguageprocessing', 'emnlp', 'mingxingtanandquocvle.2021', 'efficientnetv2', 'smallermodelsandfastertraining', 'arxivpreprintarxiv:2104.00298', '2021', 'rohantaori', 'achaldave', 'vaishaalshankar', 'nicholascarlini', 'benjaminrecht', 'andludwigschmidt.2020', 'measure', 'robustnesstonaturaldistributionshiftsinimageclassification.arxivpreprintarxiv:2007.00644', '2020', 'rachaeltatman.2017.genderanddialectbiasinyoutube', '’', 'sautomaticcaptions.inworkshoponethicsinnaturallangauge', 'process', 'vol.1.53–59', 'nicholasptatonetti', 'pyepatrick', 'roxanadaneshjou', 'andrussbaltman.2012.data-drivenpredictionofdrugeffectsand', 'interactions.sciencetranslationalmedicine4,125', '2012', ',125ra31–125ra31', 'yitay', 'mostafadehghani', 'darabahri', 'anddonaldmetzler.2020', 'efficienttransformers', 'asurvey', 'arxivpreprint', 'arxiv:2009.06732', '2020', 'yitay', 'vinhqtran', 'sebastianruder', 'jaigupta', 'hyungwonchung', 'darabahri', 'zhenqin', 'simonbaumgartner', 'congyu', 'anddonaldmetzler.2021.charformer', 'fastcharactertransformersviagradient-basedsubwordtokenization.arxiv', 'preprintarxiv:2106.12672', '2021', 'jessicataylor', 'eliezeryudkowsky', 'patricklavictoire', 'andandrewcritch.2016.alignmentforadvancedmachinelearning', 'systems.inethicsofartificialintelligence', 'iantenney', 'dipanjandas', 'andelliepavlick.2019.bertrediscoverstheclassicalnlppipeline.arxiv', '2019', 'thehaiadaptiveagentsgroup.2021', 'whenartificialagentslie', 'defame', 'anddefraud', 'whoistoblame', '?', 'https', '//hai.stanford.edu/news/when-artificial-agents-lie-defame-and-defraud-who-blame', 'arminwthomas', 'haukerheekeren', 'klaus-robertmüller', 'andwojciechsamek.2019', 'analyzingneuroimagingdata', 'throughrecurrentdeeplearningmodels.frontiersinneuroscience13', '2019', ',1321.', 'https', '//doi.org/10.3389/fnins.2019.01321', 'charlesthorpe', 'martialhhebert', 'takeokanade', 'andstevenashafer.1988.visionandnavigationforthecarnegie-mellon', 'navlab.ieeetransactionsonpatternanalysisandmachineintelligence10,3', '1988', ',362–373', 'simonthorpe', 'denisfize', 'andcatherinemarlot.1996.speedofprocessinginthehumanvisualsystem.nature381,6582', 'june1996', ',520–522', 'https', '//doi.org/10.1038/381520a0', 'sebastianthrun.1998.lifelonglearningalgorithms.learningtolearn', '1998', ',181–209', 's.thrunandtommichaelmitchell.1995.lifelongrobotlearning.roboticsauton.syst.15', '1995', ',25–46', 'yonglongtian', 'chensun', 'benpoole', 'dilipkrishnan', 'cordeliaschmid', 'andphillipisola.2020a.whatmakesforgoodviews', 'forcontrastivelearning.arxivpreprintarxiv:2005.10243', '2020', 'yuandongtian', 'lantaoyu', 'xinleichen', 'andsuryaganguli.2020b.understandingself-supervisedlearningwithdualdeep', 'networks.arxivpreprintarxiv:2010.00578', '2020', 'elizabethchikatippett', 'charlottealexander', 'andlkarlbranting.2021', 'doeslawyeringmatter', '?', 'predictingjudicial', 'decisionsfromlegalbriefs', 'andwhatthatmeansforaccesstojustice.texaslawreview', 'forthcoming', '2021', 'ilyatolstikhin', 'neilhoulsby', 'alexanderkolesnikov', 'lucasbeyer', 'xiaohuazhai', 'thomasunterthiner', 'jessicayung', 'daniel', 'keysers', 'jakobuszkoreit', 'mariolucic', 'andalexeydosovitskiy.2021.mlp-mixer', 'anall-mlparchitectureforvision', 'arxiv:2105.01601', '[', 'cs.cv', ']', 'nenadtomasev', 'kevinr.mckee', 'jackiekay', 'andshakirmohamed.2021.fairnessforunobservedcharacteristics', 'insights', 'fromtechnologicalimpactsonqueercommunities.arxiv:2102.04257', '2021', 'https', '//doi.org/10.1145/3461702.3462540', 'christophertosh', 'akshaykrishnamurthy', 'anddanielhsu.2020.contrastiveestimationrevealstopicposteriorinformation', 'tolinearmodels.arxiv:2003.02234', '2020']",204
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '205', 'christophertosh', 'akshaykrishnamurthy', 'anddanielhsu.2021.contrastivelearning', 'multi-viewredundancy', 'andlinear', 'models.inalgorithmiclearningtheory.pmlr,1179–1206', 'floriantramèranddanboneh.2021', 'differentiallyprivatelearningneedsbetterfeatures', 'ormuchmoredata', '.in', 'internationalconferenceonlearningrepresentations', 'floriantramèr', 'fanzhang', 'arijuels', 'michaelk.reiter', 'andthomasristenpart.2016.stealingmachinelearningmodelsvia', 'predictionapis.inusenixsecurity', 'nileshtripuraneni', 'michaelijordan', 'andchijin.2020.onthetheoryoftransferlearning', 'theimportanceoftaskdiversity', 'arxivpreprintarxiv:2006.11650', '2020', 'megan', 'l.', 'truax', 'impact', 'teacher', 'language', 'growth', 'mindset', 'feedback', 'write', 'motiva-', 'tion', 'literacy', 'research', 'instruction', '57', '2', '135–157', 'https', '//doi.org/10.1080/19388071.2017.1340529', 'arxiv', 'https', '//doi.org/10.1080/19388071.2017.1340529', 'tomertsaban', 'juliakvarga', 'orlyavraham', 'zivbenaharon', 'alisakhramushin', 'andoraschueler-furman.2021.harnessing', 'proteinfoldingneuralnetworksforpeptide-proteindocking.biorxiv', '2021', 'yao-hunghuberttsai', 'yuewu', 'ruslansalakhutdinov', 'andlouis-philippemorency.2020.self-supervisedlearningfroma', 'multi-viewperspective.arxivpreprintarxiv:2006.05576', '2020', 'mariatsimpoukelli', 'jacobmenick', 'serkancabi', 'smeslami', 'oriolvinyals', 'andfelixhill.2021', 'multimodalfew-shot', 'learningwithfrozenlanguagemodels.arxivpreprintarxiv:2106.13884', '2021', 'masatoshitsuchiya.2018.performanceimpactcausedbyhiddenbiasoftrainingdataforrecognizingtextualentailment', 'inproceedingsoftheeleventhinternationalconferenceonlanguageresourcesandevaluation', 'lrec2018', '.european', 'languageresourcesassociation', 'elra', 'miyazaki', 'japan', 'https', '//aclanthology.org/l18-1239', 'lifutu', 'garimalalwani', 'spandanagella', 'andhehe.2020', 'anempiricalstudyonrobustnesstospuriouscorrelations', 'usingpre-trainedlanguagemodels.transactionsoftheassociationforcomputationallinguistics8', '2020', ',621–633', 'wenlingtuandyujunglee.2009', 'ineffectiveenvironmentallawsinregulatingelectronicmanufacturingpollution', 'examiningwaterpollutiondisputesintaiwan.in2009ieeeinternationalsymposiumonsustainablesystemsand', 'technology.ieee,1–6', 'josephturian', 'levratinov', 'andyoshuabengio.2010.wordrepresentations', 'asimpleandgeneralmethodforsemi-supervised', 'learning.inassociationforcomputationallinguistics', 'acl', '.384–394', 'alanmturing.1950.computingmachineryandintelligence.mind49', '1950', ',433–460', 'turing-nlg.2020.turing-nlg', 'a17-billion-parameterlanguagemodelbymicrosoft.https', '//www.microsoft.com/en-', 'us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft//', 'barbaratverskyandjeffreymzacks.2013.eventperception.oxfordhandbookofcognitivepsychology', '2013', ',83–94', 'jonathanuesato', 'jean-baptistealayrac', 'po-senhuang', 'robertstanforth', 'alhusseinfawzi', 'andpushmeetkohli.2019.are', 'labelsrequiredforimprovingadversarialrobustness', '?', '.inadvancesinneuralinformationprocessingsystems', 'neurips', 'shimonullman.1979', 'theinterpretationofstructurefrommotion', 'proceedingsoftheroyalsocietyoflondon.seriesb', 'biologicalsciences203,1153', '1979', ',405–426', 'unitednationsgeneralassembly.2015', 'transformingourworld', 'the2030agendaforsustainabledevelopment', 'https', '//www.refworld.org/docid/57b6e3e44.html', 'josefurbanandjanjakubuv.2020.firstneuralconjecturingdatasetsandexperiments.inintelligentcomputermathematics', '-13thinternationalconference', 'cicm2020', 'bertinoro', 'italy', 'july26-31,2020', 'proceed', 'lecturenotesincomputerscience', 'vol.12236', 'christophbenzmüllerandbrucer.miller', 'eds.', '.springer,315–323', 'https', '//doi.org/10.1007/978-3-030-53518-', '6_24', 'markc.urban.2015', 'acceleratingextinctionriskfromclimatechange', 'science348,6234', 'may2015', ',571–573', 'https', '//doi.org/10.1126/science.aaa4984', 'zscc:0000959publisher', 'americanassociationfortheadvancementofscience', 'section', 'report', 'aäronvandenoord', 's.dieleman', 'h.zen', 'k.simonyan', 'oriolvinyals', 'a.graves', 'nalkalchbrenner', 'a.senior', 'andk', 'kavukcuoglu.2016.wavenet', 'agenerativemodelforrawaudio.inssw', 'aäronvandenoord', 'yazheli', 'andoriolvinyals.2018.representationlearningwithcontrastivepredictivecoding.arxiv', 'abs/1807.03748', 'aäronvandenoord', 'oriolvinyals', 'andk.kavukcuoglu.2017.neuraldiscreterepresentationlearning.innips', 'michaelvanhartskamp', 'sergioconsoli', 'wimverhaegh', 'milanpetkovic', 'andanjavandestolpe.2019.artificialintelligence', 'inclinicalhealthcareapplications', 'viewpoint.interactivejournalofmedicalresearch8,2', 'apr2019', 'e12100', 'https', '//doi.org/10.2196/12100', 'martenvanschijndelandtallinzen.2018.aneuralmodelofadaptationinreading.inproceedingsofthe2018conference', 'onempiricalmethodsinnaturallanguageprocessing.associationforcomputationallinguistics', 'brussels', 'belgium', '4704–4710', 'https', '//doi.org/10.18653/v1/d18-1499']",205
Opportunities and Risks of Foundational Models - Stanford.pdf,"['206', 'centerforresearchonfoundationmodels', 'crfm', 'manasivartak', 'hariharsubramanyam', 'wei-enlee', 'srinidhiviswanathan', 'saadiyahhusnoo', 'samuelmadden', 'andmatei', 'zaharia.2016.modeldb', 'asystemformachinelearningmodelmanagement.inproceedingsoftheworkshoponhuman-', 'in-the-loopdataanalytics.1–3', 'ashishvaswani', 'noamshazeer', 'nikiparmar', 'jakobuszkoreit', 'llionjones', 'aidanngomez', 'lukaszkaiser', 'andillia', 'polosukhin.2017.attentionisallyouneed.arxivpreprintarxiv:1706.03762', 'saraveldhoen', 'dieuwkehupkes', 'andwillemzuidema.2016', 'diagnosticclassifiers', 'revealinghowneuralnetworks', 'processhierarchicalstructure.inpre-proceedingsoftheworkshoponcognitivecomputation', 'integratingneuraland', 'symbolicapproaches', 'coco', 'nips2016', 'petarveličković', 'guillemcucurull', 'arantxacasanova', 'adrianaromero', 'pietroliò', 'andyoshuabengio.2017', 'graph', 'attentionnetworks.arxive-prints', 'arxiv–1710', 'patverga', 'haitiansun', 'liviobaldinisoares', 'andwilliamwcohen.2020.factsasexperts', 'adaptableandinterpretable', 'neuralmemoryoversymbolicknowledge.arxivpreprintarxiv:2007.00849', '2020', 'vikasverma', 'thangluong', 'kenjikawaguchi', 'hieupham', 'andquocle.2021.towardsdomain-agnosticcontrastivelearning', 'ininternationalconferenceonmachinelearning.pmlr,10530–10541', 'lucasnunesvieira', 'minakoo', '’', 'hagan', 'andcarolo', '’', 'sullivan.2020.understandingthesocietalimpactsofmachinetranslation', 'acriticalreviewoftheliteratureonmedicalandlegalusecases.information', 'communication', '&', 'society', '2020', ',1–18', 'jessevig', 'sebastiangehrmann', 'yonatanbelinkov', 'sharonqian', 'danielnevo', 'simassakenis', 'jasonhuang', 'yaronsinger', 'andstuartshieber.2020.causalmediationanalysisforinterpretingneuralnlp', 'thecaseofgenderbias.arxivpreprint', 'arxiv:2004.12265', '2020', 'eduardfoschvillaronga', 'peterkieseberg', 'andtiffanyli.2018.humansforget', 'machinesremember', 'artificialintelligence', 'andtherighttobeforgotten.computerlaw', '&', 'securityreview34,2', ',304–313', 'anttivirtanen', 'jennakanerva', 'ramiilo', 'jouniluoma', 'juhaniluotolahti', 'tapiosalakoski', 'filipginter', 'andsampopyysalo', '2019.multilingualisnotenough', 'bertforfinnish.arxivpreprintarxiv:1912.07076', '2019', 'robvoigt', 'nicholaspcamp', 'vinodkumarprabhakaran', 'williamlhamilton', 'rebeccachetey', 'camillamgriffiths', 'david', 'jurgens', 'danjurafsky', 'andjenniferleberhardt.2017.languagefrompolicebodycamerafootageshowsracialdisparities', 'inofficerrespect.proceedingsofthenationalacademyofsciences114,25', ',6521–6526', 'robvoigt', 'davidjurgens', 'vinodkumarprabhakaran', 'danjurafsky', 'andyuliatsvetkov.2018', 'rtgender', 'acorpusfor', 'studyingdifferentialresponsestogender.inproceedingsoftheeleventhinternationalconferenceonlanguageresources', 'andevaluation', 'lrec2018', '.europeanlanguageresourcesassociation', 'elra', 'miyazaki', 'japan', 'https', '//aclanthology', 'org/l18-1445', 'elenavoitaandivantitov.2020.information-theoreticprobingwithminimumdescriptionlength.arxiv:2003.12298', '[', 'cs.cl', ']', 'andrewvoldandjackgconrad.2021.usingtransformerstoimproveanswerretrievalforlegalquestions.', '2021', 'soroushvosoughi', 'debroy', 'andsinanaral.2018', 'thespreadoftrueandfalsenewsonline', 'science359,6380', '1146–1151', 'https', '//doi.org/10.1126/science.aap9559arxiv', 'https', '//science.sciencemag.org/content/359/6380/1146.full.pdf', 'harmd.vries', 'dzmitrybahdanau', 'andchristopherd.manning.2020.towardsecologicallyvalidresearchonlanguage', 'userinterfaces.arxivpreprintarxiv:2007.14435', '2020', 'lyndseywajertandgaberottman.2019.scrapingpublicwebsiteslikelydoesn', '’', 'tviolatethecomputerfraudandabuse', 'act', 'courtholds.https', '//www.rcfp.org/scraping-not-violation-cfaa/', 'ericwallace', 'shifeng', 'nikhilkandpal', 'mattgardner', 'andsameersingh.2019.universaladversarialtriggersforattacking', 'andanalyzingnlp.inempiricalmethodsinnaturallanguageprocessing', 'wpatrickwaltersandreginabarzilay.2020.applicationsofdeeplearninginmoleculegenerationandmolecularproperty', 'prediction.accountsofchemicalresearch54,2', '2020', ',263–270', 'alexwang', 'yadapruksachatkun', 'nikitanangia', 'amanpreetsingh', 'julianmichael', 'felixhill', 'omerlevy', 'andsamuelr', 'bowman.2019a.superglue', 'astickierbenchmarkforgeneral-purposelanguageunderstandingsystems.inadvances', 'inneuralinformationprocessingsystems', 'neurips', 'alexwang', 'amapreetsingh', 'julianmichael', 'felixhill', 'omerlevy', 'andsamuelrbowman.2019b', 'glue', 'amulti-', 'taskbenchmarkandanalysisplatformfornaturallanguageunderstanding.ininternationalconferenceonlearning', 'representations', 'iclr', 'benwangandarankomatsuzaki.2021.gpt-j-6b', 'a6billionparameterautoregressivelanguagemodel.https', '//github', 'com/kingoflolz/mesh-transformer-jax', 'haojiewang', 'jidongzhai', 'mingyugao', 'zixuanma', 'shizhitang', 'liyanzheng', 'yuanzhili', 'kaiyuanrong', 'yuanyongchen', 'andzhihaojia.2021c.pet', 'optimizingtensorprogramswithpartiallyequivalenttransformationsandautomated', 'corrections.in15thusenixsymposiumonoperatingsystemsdesignandimplementation', 'osdi21', '.37–54', 'lijunwang', 'wanliouyang', 'xiaogangwang', 'andhuchuanlu.2015b.visualtrackingwithfullyconvolutionalnetworks.in', 'proceedingsoftheieeeinternationalconferenceoncomputervision.3119–3127', 'mingzhewangandjiadeng.2020', 'learningtoprovetheoremsbylearningtogeneratetheorems.inadvancesin', 'neuralinformationprocessingsystems33', 'annualconferenceonneuralinformationprocessingsystems2020', 'neurips2020']",206
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '207', 'december6-12,2020', 'virtual', 'hugolarochelle', 'marc', '’', 'aurelioranzato', 'raiahadsell', 'maria-florinabalcan', 'andhsuan-tien', 'lin', 'eds.', 'https', '//proceedings.neurips.cc/paper/2020/hash/d2a27e83d429f0dcae6b937cf440aeb1-abstract.html', 'sinongwang', 'belindazli', 'madiankhabsa', 'hanfang', 'andhaoma.2020c.linformer', 'self-attentionwithlinearcomplexity', 'arxivpreprintarxiv:2006.04768', '2020', 'tongzhouwangandphillipisola.2020.understandingcontrastiverepresentationlearningthroughalignmentanduniformity', 'onthehypersphere.ininternationalconferenceonmachinelearning.pmlr,9929–9939', 'tianluwang', 'jieyuzhao', 'markyatskar', 'kai-weichang', 'andvicenteordonez.2019d.balanceddatasetsarenotenough', 'estimatingandmitigatinggenderbiasindeepimagerepresentations.inproceedingsoftheieee/cvfinternational', 'conferenceoncomputervision.5310–5319', 'wenhuiwang', 'senyang', 'xiangzhang', 'andjingli.2014.drugrepositioningbyintegratingtargetinformationthrougha', 'heterogeneousnetworkmodel.bioinformatics30,20', '2014', ',2923–2930', 'xiaolongwang', 'davidfouhey', 'andabhinavgupta.2015a', 'designingdeepnetworksforsurfacenormalestimation.in', 'proceedingsoftheieeeconferenceoncomputervisionandpatternrecognition.539–547', 'xiaozhiwang', 'tianyugao', 'zhaochengzhu', 'zhengyanzhang', 'zhiyuanliu', 'juanzili', 'andjiantang.2021a.kepler', 'unifiedmodelforknowledgeembeddingandpre-trainedlanguagerepresentation.transactionsoftheassociationfor', 'computationallinguistics9', '2021', ',176–194', 'xuefengwang', 'ericpxing', 'anddanieljschaid.2015c.kernelmethodsforlarge-scalegenomicdataanalysis.briefingsin', 'bioinformatics16,2', ',183–192', 'yuwang', 'jinchaoli', 'tristannaumann', 'chenyanxiong', 'haocheng', 'roberttinn', 'cliffwong', 'naotousuyama', 'richard', 'rogahn', 'zhihongshen', 'etal.2021b.domain-specificpretrainingforverticalsearch', 'casestudyonbiomedicalliterature', 'inacmsigkddconferenceonknowledgediscoveryanddatamining', 'kdd', 'zihanwang', 'karthikeyank', 'stephenmayhew', 'anddanroth.2020a', 'extendingmultilingualberttolow-resource', 'languages.arxiv:2004.13640', '[', 'cs', ']', 'apr2020', 'http', '//arxiv.org/abs/2004.13640', 'zihanwang', 'kkarthikeyan', 'stephenmayhew', 'anddanroth.2020b', 'extendingmultilingualberttolow-resource', 'languages.inproceedingsofthe2020conferenceonempiricalmethodsinnaturallanguageprocessing', 'findings.2649–', '2656', 'ziruiwang', 'zacharyclipton', 'andyuliatsvetkov.2020d.onnegativeinterferenceinmultilinguallanguagemodels.in', 'proceedingsofthe2020conferenceonempiricalmethodsinnaturallanguageprocessing', 'emnlp', '.4438–4450', 'zihengwang', 'jeremywohlwend', 'andtaolei.2019c', 'structuredpruningoflargelanguagemodels', 'arxivpreprint', 'arxiv:1910.04732', '2019', 'zeerakwaseem', 'thomasdavidson', 'danawarmsley', 'andingmarweber.2017', 'understandingabuse', 'atypologyof', 'abusivelanguagedetectionsubtasks.inproceedingsofthefirstworkshoponabusivelanguageonline.associationfor', 'computationallinguistics', 'vancouver', 'bc', 'canada,78–84', 'https', '//doi.org/10.18653/v1/w17-3012', 'kwashington', 'dsbrowitt', 'kmurata', 'dmonroe', 'andtheames.1995', 'kbert.knowledgebasedestimationofmaterial', 'releasetransients.technicalreport.sandianationallabs.', 'albuquerque', 'nm', 'unitedstates', 'colinwei', 'shamkakade', 'andtengyuma.2020a.theimplicitandexplicitregularizationeffectsofdropout.ininternational', 'conferenceonmachinelearning', 'colinwei', 'kendrickshen', 'yiningchen', 'andtengyuma.2020b.theoreticalanalysisofself-trainingwithdeepnetworkson', 'unlabeleddata.arxivpreprintarxiv:2010.03622', '2020', 'colinwei', 'sangmichaelxie', 'andtengyuma.2021.whydopretrainedlanguagemodelshelpindownstreamtasks', '?', 'analysisofheadandprompttuning', 'arxiv:2106.09226', '[', 'cs.lg', ']', 'kenweiner.2018.canaicreatetrueart', '?', 'scientificamerican', 'laurelwestbrookandaliyasaperstein.2015', 'newcategoriesarenotenough', 'rethinkingthemeasurementofsex', 'andgenderinsocialsurveys', 'gender', '&', 'society', '29,4', ',534–560', 'https', '//doi.org/10.1177/0891243215584758', 'arxiv', 'https', '//doi.org/10.1177/0891243215584758', 'hanneswestermann', 'vernrwalker', 'kevindashley', 'andkarimbenyekhlef.2019.usingfactorstopredictandanalyze', 'landlord-tenantdecisionstoincreaseaccesstojustice.inproceedingsoftheseventeenthinternationalconferenceon', 'artificialintelligenceandlaw.133–142', 'jasonweston', 'sumitchopra', 'andantoinebordes.2014.memorynetworks.arxivpreprintarxiv:1410.3916', '2014', 'michellewhirl-carrillo', 'ellenmmcdonagh', 'jmhebert', 'ligong', 'ksangkuhl', 'cfthorn', 'russbaltman', 'andterieklein', '2012', 'pharmacogenomicsknowledgeforpersonalizedmedicine', 'clinicalpharmacology', '&', 'therapeutics92,4', '2012', '414–417', 'jennawiens', 'suchisaria', 'marksendak', 'marzyehghassemi', 'vincentxliu', 'finaledoshi-velez', 'kennethjung', 'katherine', 'heller', 'davidkale', 'mohammedsaeed', 'etal.2019.donoharm', 'aroadmapforresponsiblemachinelearningforhealth', 'care.naturemedicine25,9', '2019', ',1337–1340', 'bernardwilliams.1973.inutilitarianism', 'forandagainst', 'j.c.smartandbernardwilliams', 'eds', '.cambridgeuniversity', 'press,82–118']",207
Opportunities and Risks of Foundational Models - Stanford.pdf,"['208', 'centerforresearchonfoundationmodels', 'crfm', 'monnicat.williams.2020.psychologycannotaffordtoignorethemanyharmscausedbymicroaggressions.perspectives', 'onpsychologicalscience15,1', '2020', ',38–43', 'angelicawillis', 'glenndavis', 'sherryruan', 'lakshmimanoharan', 'jameslanday', 'andemmabrunskill.2019.keyphrase', 'extractionforgeneratingeducationalquestion-answerpairs.inproceedingsofthesixth', '2019', 'acmconferenceon', 'learn', 'scale', 'chicago', 'il', 'usa', 'l', '’', '19', '.associationforcomputingmachinery', 'newyork', 'ny', 'usa', 'article20', '10pages', 'https', '//doi.org/10.1145/3330430.3333636', 'benjamin', 'wilson', 'judy', 'hoffman', 'jamie', 'morgenstern', '2019', 'predictive', 'inequity', 'object', 'detection', '2019', 'https', '//arxiv.org/pdf/1902.11097.pdf', 'christowilson', 'avijitghosh', 'shanjiang', 'alanmislove', 'lewisbaker', 'janelleszary', 'kellytrindel', 'andfridapolli.2021', 'buildingandauditingfairalgorithms', 'acasestudyincandidatescreening.inproceedingsoftheconferenceonfairness', 'accountability', 'andtransparency', 'facct2021', '.virtualevent', 'canada', 'juliak.winkler', 'christinefink', 'ferdinandtoberer', 'alexanderenk', 'teresadeinlein', 'rainerhofmann-wellenhof', 'luc', 'thomas', 'aimilioslallas', 'andreasblum', 'wilhelmstolz', 'andholgera.haenssle.2019.associationbetweensurgicalskin', 'markingsindermoscopicimagesanddiagnosticperformanceofadeeplearningconvolutionalneuralnetworkfor', 'melanomarecognition.jamadermatology155,10', '102019', ',1135–1141', 'https', '//doi.org/10.1001/jamadermatol.2019.1735', 'arxiv', 'https', '//jamanetwork.com/journals/jamadermatology/articlepdf/2740808/jamadermatology_winkler_2019_oi_190038.pdf', 'langdonwinner.1980.doartifactshavepolitics', '?', 'daedalus109,1', '1980', ',121–136', 'http', '//www.jstor.org/stable/20024652', 'publisher', 'themitpress', 'l.wittgenstein.1953.philosophicalinvestigations.blackwell', 'oxford', 'thomaswolf', 'julienchaumond', 'lysandredebut', 'victorsanh', 'clementdelangue', 'anthonymoi', 'pierriccistac', 'morgan', 'funtowicz', 'joedavison', 'samshleifer', 'etal.2020', 'transformers', 'state-of-the-artnaturallanguageprocessing.in', 'proceedingsofthe2020conferenceonempiricalmethodsinnaturallanguageprocessing', 'systemdemonstrations.38–45', 'davidhwolpertandwilliamgmacready.1997.nofreelunchtheoremsforoptimization.ieeetransactionsonevolutionary', 'computation1,1', '1997', ',67–82', 'ericwongandj.zicokolter.2020.learningperturbationsetsforrobustmachinelearning.arxiv', '2020', 'blakewoodworth', 'suriyagunasekar', 'jasondlee', 'edwardmoroshko', 'pedrosavarese', 'itaygolan', 'danielsoudry', 'nathansrebro.2020.kernelandrichregimesinoverparametrizedmodels.arxivpreprintarxiv:2002.09277', '2020', 'beverlyparkwoolf', 'h.chadlane', 'vinayk.chaudhri', 'andjanetl.kolodner.2013.aigrandchallengesforeducation.ai', 'magazine34,4', 'dec.2013', ',66–84', 'https', '//doi.org/10.1609/aimag.v34i4.2490', 'olivierjwouters', 'martinmckee', 'andjeroenluyten.2020', 'estimatedresearchanddevelopmentinvestmentneededto', 'bringanewmedicinetomarket,2009-2018.jama323,9', '2020', ',844–853', 'bohanwu', 'surajnair', 'robertomartín-martín', 'lifei-fei', 'andchelseafinn.2021d', 'greedyhierarchicalvariational', 'autoencodersforlarge-scalevideoprediction.arxivpreprintarxiv:2103.04174', '2021', 'ericwu', 'kevinwu', 'roxanadaneshjou', 'davidouyang', 'danieleho', 'andjameszou.2021g.howmedicalaidevicesare', 'evaluate', 'limitationsandrecommendationsfromananalysisoffdaapprovals.naturemedicine27,4', '2021', ',582–584', 'kevinewu', 'kathryneyost', 'howardychang', 'andjameszou.2021h.babelenablescross-modalitytranslationbetween', 'multiomicprofilesatsingle-cellresolution.proceedingsofthenationalacademyofsciences118,15', '2021', 'mikewu', 'chrispiech', 'noahgoodman', 'andchelseafinn.2021e.prototransformer', 'ameta-learningapproachtoproviding', 'studentfeedback.arxiv', '2021', 'shijiewuandmarkdredze.2019.beto', 'bentz', 'becas', 'thesurprisingcross-lingualeffectivenessofbert.inproceedingsof', 'the2019conferenceonempiricalmethodsinnaturallanguageprocessingandthe9thinternationaljointconferenceon', 'naturallanguageprocessing', 'emnlp-ijcnlp', '.associationforcomputationallinguistics', 'hongkong', 'china,833–844', 'https', '//doi.org/10.18653/v1/d19-1077', 'yuhuaiwu', 'albertjiang', 'jimmyba', 'androgergrosse.2021a.int', 'aninequalitybenchmarkforevaluatinggeneralization', 'intheoremproving.', '2021', 'https', '//openreview.net/forum', '?', 'id=o6lpudownqm', 'yuhuaiwu', 'markusn.rabe', 'wendali', 'jimmyba', 'rogerb.grosse', 'andchristianszegedy.2021f.lime', 'learninginductive', 'biasforprimitivesofmathematicalreasoning.', '2021', 'zacharywu', 'kadinaejohnston', 'francesharnold', 'andkevinkyang.2021b.proteinsequencedesignwithdeepgenerative', 'models.currentopinioninchemicalbiology65', '2021', ',18–27', 'zhengxuanwu', 'nelsonfliu', 'andchristopherpotts.2021c.identifyingthelimitsofcross-domainknowledgetransfer', 'forpretrainedmodels.arxivpreprintarxiv:2104.08410', '2021', 'zhirongwu', 'yuanjunxiong', 'stellax.yu', 'anddahualin.2018.unsupervisedfeaturelearningvianon-parametricinstance', 'discrimination.2018ieee/cvfconferenceoncomputervisionandpatternrecognition', ',3733–3742', 'alicexiang.2021.reconcilinglegalandtechnicalapproachestoalgorithmicbias.tennesseelawreview88,3', '2021', 'kaixiao', 'loganengstrom', 'andrewilyas', 'andaleksandermadry.2020.noiseorsignal', 'theroleofimagebackgroundsin', 'objectrecognition.arxivpreprintarxiv:2006.09994', '2020']",208
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '209', 'tetexiao', 'xiaolongwang', 'alexeia.efros', 'andtrevordarrell.2021', 'whatshouldnotbecontrastiveincontrastive', 'learn', 'arxiv:2008.05659', '[', 'cs.cv', ']', 'michaelxie', 'nealjean', 'marshallburke', 'davidlobell', 'andstefanoermon.2016.transferlearningfromdeepfeaturesfor', 'remotesensingandpovertymapping.inassociationfortheadvancementofartificialintelligence', 'aaai', 'qizhexie', 'minh-thangluong', 'eduardhovy', 'andquocv.le.2020.self-trainingwithnoisystudentimprovesimagenet', 'classification.arxiv', '2020', 'sangmichaelxie', 'ananyakumar', 'robertjones', 'fereshtekhani', 'tengyuma', 'andpercyliang.2021a.in-n-out', 'pre-training', 'andself-trainingusingauxiliaryinformationforout-of-distributionrobustness.ininternationalconferenceonlearning', 'representations', 'iclr', 'sangmichaelxie', 'tengyuma', 'andpercyliang.2021b.composedfine-tuning', 'freezingpre-traineddenoisingautoencoders', 'forimprovedgeneralization.internationalconferenceonmachinelearning', 'icml', '2021', 'caimingxiong', 'stephenmerity', 'andrichardsocher.2016', 'dynamicmemorynetworksforvisualandtextualquestion', 'answering.ininternationalconferenceonmachinelearning.2397–2406', 'albertxu', 'eshaanpathak', 'ericwallace', 'suchingururangan', 'maartensap', 'anddanklein.2021', 'detoxifyinglanguage', 'modelsrisksmarginalizingminorityvoices.inproceedingsofthe2021conferenceofthenorthamericanchapterofthe', 'associationforcomputationallinguistics', 'humanlanguagetechnologies.associationforcomputationallinguistics', 'online,2390–2397', 'https', '//doi.org/10.18653/v1/2021.naacl-main.190', 'huijuanxuandkatesaenko.2016.ask', 'attendandanswer', 'exploringquestion-guidedspatialattentionforvisualquestion', 'answering.ineuropeanconferenceoncomputervision.springer,451–466', 'jianxu', 'sunkyukim', 'minsong', 'minbyuljeong', 'donghyeonkim', 'jaewookang', 'justinfrousseau', 'xinli', 'weijiaxu', 'vetlei', 'torvik', 'etal.2020.buildingapubmedknowledgegraph.scientificdata7,1', '2020', ',1–15', 'jiaxu', 'pengweiyang', 'shangxue', 'bhuvansharma', 'martasanchez-martin', 'fangwang', 'kirkabeaty', 'elinordehan', 'andbaiju', 'parikh.2019.translatingcancergenomicsintoprecisionmedicinewithartificialintelligence', 'applications', 'challenge', 'andfutureperspectives.humangenetics138,2', '2019', ',109–124', 'lintingxue', 'adityabarua', 'noahconstant', 'ramial-rfou', 'sharannarang', 'mihirkale', 'adamroberts', 'andcolinraffel.2021', 'byt5', 'towardsatoken-freefuturewithpre-trainedbyte-to-bytemodels.arxivpreprintarxiv:2105.13626', '2021', 'lintingxue', 'noahconstant', 'adamroberts', 'mihirkale', 'ramial-rfou', 'adityasiddhant', 'adityabarua', 'andcolinraffel', '2020.mt5', 'amassivelymultilingualpre-trainedtext-to-texttransformer.arxivpreprintarxiv:2010.11934', '2020', 'eugeneyang', 'seanmacavaney', 'daviddlewis', 'andophirfrieder.2021', 'goldilocks', 'just-righttuningofbertfor', 'technology-assistedreview.arxivpreprintarxiv:2105.01044', '2021', 'mengjiaoyangandofirnachum.2021', 'representationmatters', 'offlinepretrainingforsequentialdecisionmaking.in', 'icml', 'qianyang', 'aaronsteinfeld', 'carolynprose', ',andjohnzimmerman.2020.re-examiningwhether', 'andhowhuman-ai', 'interactionisuniquelydifficulttodesign.inproceedingsofthe2020chiconferenceonhumanfactorsincomputing', 'systems', 'qianyang', 'jinasuh', 'nan-chenchen', 'andgonzaloramos.2018.groundinginteractivemachinelearningtooldesignin', 'hownon-expertsactuallybuildmodels.indis', '’', '18', 'proceedingsofthe2018designinginteractivesystemsconference', 'acm', 'qianyang', 'johnzimmerman', 'aaronsteinfeld', 'andanthonytomasic.2016.planningadaptivemobileexperienceswhen', 'wireframing.inproceedingsofthe2016acmconferenceondesigninginteractivesystems.acm', 'zhilinyang', 'zihangdai', 'yimingyang', 'j.carbonell', 'r.salakhutdinov', 'andquocv.le.2019.xlnet', 'generalizedautoregres-', 'sivepretrainingforlanguageunderstanding.inneurips', 'michihiroyasunagaandpercyliang.2020.graph-based', 'self-supervisedprogramrepairfromdiagnosticfeedback.in', 'internationalconferenceonmachinelearning', 'icml', 'michihiroyasunagaandpercyliang.2021.break-it-fix-it', 'unsupervisedlearningforprogramrepair.ininternational', 'conferenceonmachinelearning', 'icml', 'michihiroyasunaga', 'hongyuren', 'antoinebosselut', 'percyliang', 'andjureleskovec.2021', 'qa-gnn', 'reasoningwith', 'languagemodelsandknowledgegraphsforquestionanswering.arxivpreprintarxiv:2104.06378', '2021', 'nanyangye', 'kaicanli', 'lanqinghong', 'haoyuebai', 'yitingchen', 'fengweizhou', 'andzhenguoli.2021', 'ood-bench', 'benchmarkingandunderstandingout-of-distributiongeneralizationdatasetsandalgorithms', 'kexinyi', 'chuanggan', 'yunzhuli', 'pushmeetkohli', 'jiajunwu', 'antoniotorralba', 'andjoshuabtenenbaum.2019.clevrer', 'collisioneventsforvideorepresentationandreasoning.arxivpreprintarxiv:1910.01442', '2019', 'pengchengyin', 'grahamneubig', 'wentauyih', 'andsebastianriedel.2020.tabert', 'pretrainingforjointunderstandingof', 'textualandtabulardata.inacl', 'daniyogatama', 'cypriendemassond', '’', 'autume', 'jeromeconnor', 'tomaskocisky', 'mikechrzanowski', 'lingpengkong', 'angeliki', 'lazaridou', 'wangle', 'leiyu', 'chrisdyer', 'etal.2019.learningandevaluatinggenerallinguisticintelligence.arxiv', 'preprintarxiv:1901.11373', '2019']",209
Opportunities and Risks of Foundational Models - Stanford.pdf,"['210', 'centerforresearchonfoundationmodels', 'crfm', 'narukiyoshikawa', 'ryuichikubo', 'andkazukiz.yamamoto.2021.twitterintegrationofchemistrysoftwaretools.journal', 'ofcheminformatics13,1', 'july2021', 'https', '//doi.org/10.1186/s13321-021-00527-x', 'jiaxuanyou', 'bowenliu', 'rexying', 'vijaypande', 'andjureleskovec.2018.graphconvolutionalpolicynetworkforgoal-', 'directedmoleculargraphgeneration.inproceedingsofthe32ndinternationalconferenceonneuralinformationprocessing', 'systems.curranassociatesinc.', 'redhook', 'ny', 'usa,6412–6422', 'chao', 'yu', 'jiming', 'liu', 'shamim', 'nemati', '2019', 'reinforcement', 'learn', 'healthcare', 'survey', 'arxiv', 'preprint', 'arxiv:1908.08796', '2019', 'donghanyu', 'chenguangzhu', 'yimingyang', 'andmichaelzeng.2020c.jaket', 'jointpre-trainingofknowledgegraphand', 'languageunderstanding.arxivpreprintarxiv:2010.00796', '2020', 'fisheryu', 'haofengchen', 'xinwang', 'wenqixian', 'yingyingchen', 'fangchenliu', 'vashishtmadhavan', 'andtrevordarrell', '2020a.bdd100k', 'adiversedrivingdatasetforheterogeneousmultitasklearning.inieee/cvfconferenceoncomputer', 'visionandpatternrecognition', 'cvpr', 'kun-hsingyu', 'andrewlbeam', 'andisaacskohane.2018.artificialintelligenceinhealthcare.naturebiomedicalengineering', '2,10', ',719–731', 'tianheyu', 'garrettthomas', 'lantaoyu', 'stefanoermon', 'jameszou', 'sergeylevine', 'chelseafinn', 'andtengyuma.2020b', 'mopo', 'model-basedofflinepolicyoptimization.arxivpreprintarxiv:2005.13239', '2020', 'eliezeryudkowsky.2016.theaialignmentproblem', 'whyitishard', 'andwheretostart.symbolicsystemsdistinguished', 'speaker', 'eliezeryudkowskyetal.2008.artificialintelligenceasapositiveandnegativefactoringlobalrisk.globalcatastrophicrisks', '1,303', '2008', ',184', 'jeffreymzacks', 'barbaratversky', 'andgowriiyer.2001.perceiving', 'remember', 'andcommunicatingstructureinevents', 'journalofexperimentalpsychology', 'general130,1', '2001', ',29', 'mateizaharia', 'mosharafchowdhury', 'tathagatadas', 'ankurdave', 'justinma', 'murphymccauly', 'michaeljfranklin', 'scott', 'shenker', 'andionstoica.2012.resilientdistributeddatasets', 'afault-tolerantabstractionforin-memoryclustercomputing', 'in9th', '{', 'usenix', '}', 'symposiumonnetworkedsystemsdesignandimplementation', '{', 'nsdi', '}', '12', '.15–28', 'manzilzaheer', 'guruguruganesh', 'kumaravinavadubey', 'joshuaainslie', 'chrisalberti', 'santiagoontanon', 'philippham', 'anirudhravula', 'qifanwang', 'liyang', 'etal.2020.bigbird', 'transformersforlongersequences', '..', 'inneurips', 'eladbenzaken', 'shauliravfogel', 'andyoavgoldberg.2021.bitfit', 'simpleparameter-efficientfine-tuningfortransformer-', 'basedmaskedlanguage-models.corrabs/2106.10199', '2021', '.arxiv:2106.10199', 'https', '//arxiv.org/abs/2106.10199', 'amirr.zamir', 'alexandersax', 'williamb.shen', 'leonidasj.guibas', 'jitendramalik', 'andsilviosavarese.2018.taskonomy', 'disentanglingtasktransferlearning.inieeeconferenceoncomputervisionandpatternrecognition', 'cvpr', '.ieee', 'jakubzavrel', 'walterdaelemans', 'andjornveenstra.1997', 'resolvingppattachmentambiguitieswithmemory-based', 'learning.inconll97', 'computationalnaturallanguagelearning', 'matthewdzeilerandrobfergus.2014.visualizingandunderstandingconvolutionalnetworks.ineuropeanconferenceon', 'computervision.springer,818–833', 'rowanzellers', 'yonatanbisk', 'alifarhadi', 'andyejinchoi.2019a.fromrecognitiontocognition', 'visualcommonsense', 'reasoning.intheieeeconferenceoncomputervisionandpatternrecognition', 'cvpr', 'rowanzellers', 'ariholtzman', 'matthewpeters', 'roozbehmottaghi', 'aniruddhakembhavi', 'alifarhadi', 'andyejinchoi.2021a', 'piglet', 'languagegroundingthroughneuro-symbolicinteractionina3dworld', 'arxivpreprintarxiv:2106.00188', '2021', 'rowanzellers', 'ariholtzman', 'hannahrashkin', 'yonatanbisk', 'alifarhadi', 'franziskaroesner', 'andyejinchoi.2019b', 'defendingagainstneuralfakenews.inadvancesinneuralinformationprocessingsystems', 'neurips', '.9054–9065', 'rowanzellers', 'ximinglu', 'jackhessel', 'youngjaeyu', 'jaesungpark', 'jizecao', 'alifarhadi', 'andyejinchoi.2021b.merlot', 'multimodalneuralscriptknowledgemodels.arxivpreprintarxiv:2106.02636', '2021', 'haoranzhang', 'amyxlu', 'mohamedabdalla', 'matthewmcdermott', 'andmarzyehghassemi.2020b', 'hurtfulwords', 'quantifyingbiasesinclinicalcontextualwordembeddings.inproceedingsoftheacmconferenceonhealth', 'inference', 'andlearning.110–120', 't.zhangandt.hashimoto.2020', 'ontheinductivebiasofmaskedlanguagemodeling', 'fromstatisticaltosyntactic', 'dependencies.inassociationforcomputationallinguistics', 'acl', 'tianyizhangandtatsunorihashimoto.2021.ontheinductivebiasofmaskedlanguagemodeling', 'fromstatisticalto', 'syntacticdependencies.arxivpreprintarxiv:2104.05694', '2021', 'yuhaozhang', 'hangjiang', 'yasuhidemiura', 'christopherdmanning', 'andcurtisplanglotz.2020a.contrastivelearningof', 'medicalvisualrepresentationsfrompairedimagesandtext.arxivpreprintarxiv:2010.00747', '2020', 'yuhuizhang', 'allennie', 'ashleyzehnder', 'rodneylpage', 'andjameszou.2019b.vettag', 'improvingautomatedveterinary', 'diagnosiscodingvialarge-scalelanguagemodeling.npjdigitalmedicine2,1', '2019', ',1–8', 'yianzhang', 'alexwarstadt', 'haau-singli', 'andsamuelrbowman.2021.whendoyouneedbillionsofwordsofpretraining', 'data', '?', '.inproceedingsofthe59thannualmeetingoftheassociationforcomputationallinguistics']",210
Opportunities and Risks of Foundational Models - Stanford.pdf,"['ontheopportunitiesandrisksoffoundationmodels', '211', 'zhengyanzhang', 'xuhan', 'zhiyuanliu', 'xinjiang', 'maosongsun', 'andqunliu.2019a', 'ernie', 'enhancedlanguage', 'representationwithinformativeentities.inacl', 'zhoutongzhang', 'qiujiali', 'zhengjiahuang', 'jiajunwu', 'joshuabtenenbaum', 'andwilliamtfreeman.2017.shapeand', 'materialfromsound.', 'jieyuzhao', 'tianluwang', 'markyatskar', 'ryancotterell', 'vicenteordonez', 'andkai-weichang.2019', 'genderbiasin', 'contextualizedwordembeddings.inproceedingsofthe2019conferenceofthenorthamericanchapteroftheassociationfor', 'computationallinguistics', 'humanlanguagetechnologies', 'volume1', 'longandshortpapers', '.associationforcomputational', 'linguistics', 'minneapolis', 'minnesota,629–634', 'https', '//doi.org/10.18653/v1/n19-1064', 'jieyuzhao', 'tianluwang', 'markyatskar', 'vicenteordonez', 'andkai-weichang.2017.menalsolikeshopping', 'reduce', 'genderbiasamplificationusingcorpus-levelconstraints.inproceedingsofthe2017conferenceonempiricalmethods', 'innaturallanguageprocessing.associationforcomputationallinguistics', 'copenhagen', 'denmark,2979–2989', 'https', '//doi.org/10.18653/v1/d17-1323', 'jieyuzhao', 'yichaozhou', 'zeyuli', 'weiwang', 'andkai-weichang.2018.learninggender-neutralwordembeddings.in', 'proceedingsofthe2018conferenceonempiricalmethodsinnaturallanguageprocessing.associationforcomputational', 'linguistics', 'brussels', 'belgium,4847–4853', 'https', '//doi.org/10.18653/v1/d18-1521', 'mengjiezhao', 'taolin', 'feimi', 'martinjaggi', 'andhinrichschütze.2020b.maskingasanefficientalternativetofinetuningfor', 'pretrainedlanguagemodels.inproceedingsofthe2020conferenceonempiricalmethodsinnaturallanguageprocessing', 'emnlp', '.associationforcomputationallinguistics', 'online,2226–2241', 'https', '//doi.org/10.18653/v1/2020.emnlp-', 'main.174', 'qingyuzhao', 'ehsanadeli', 'andkilianmpohl.2020a.trainingconfounder-freedeeplearningmodelsformedicalapplications', 'naturecommunications11,1', '2020', ',1–9', 'tonyzzhao', 'ericwallace', 'shifeng', 'danklein', 'andsameersingh.2021', 'calibratebeforeuse', 'improvingfew-shot', 'performanceoflanguagemodels.arxivpreprintarxiv:2102.09690', '2021', 'luciazheng', 'neelguha', 'brandonranderson', 'peterhenderson', 'anddanieleho.2021.whendoespretraininghelp', '?', 'assessingself-supervisedlearningforlawandthecaseholddataset.arxivpreprintarxiv:2104.08671', 'haoxizhong', 'chaojunxiao', 'cunchaotu', 'tianyangzhang', 'zhiyuanliu', 'andmaosongsun.2020.howdoesnlpbenefit', 'legalsystem', 'asummaryoflegalartificialintelligence.arxivpreprintarxiv:2004.12158', '2020', 'jinpengzhou', 'yuhuaiwu', 'colinli', 'androgergrosse.2021c.refactor', 'learningtoextracttheoremsfromproofs.the', 'firstmathematicalreasoningingeneralartificialintelligenceworkshop', 'iclr2021', '2021', 'https', '//mathai-iclr.github.io/', 'papers/papers/mathai_22_paper.pdf', 'kaitlynzhou', 'kawinethayarajh', 'anddanjurafsky.2021a.frequency-baseddistortionsincontextualizedwordembeddings', 'arxivabs/2104.08465', '2021', 'https', '//arxiv.org/abs/2104.08465', 'sharonzhou', 'mitchelllgordon', 'ranjaykrishna', 'austinnarcomey', 'lifei-fei', 'andmichaelsbernstein.2019.hype', 'benchmarkforhumaneyeperceptualevaluationofgenerativemodels.neurips', '2019', 'xiyouzhou', 'zhiyuchen', 'xiaoyongjin', 'andwilliamyangwang.2020.hulk', 'anenergyefficiencybenchmarkplatformfor', 'responsiblenaturallanguageprocessing.arxivpreprintarxiv:2002.05829', '2020', 'xuhuizhou', 'maartensap', 'swabhaswayamdipta', 'yejinchoi', 'andnoahsmith.2021b', 'challengesinautomatedde-', 'bias', 'toxic', 'language', 'detection', 'proceed', '16th', 'conference', 'european', 'chapter', 'asso-', 'ciationforcomputationallinguistics', 'mainvolume.associationforcomputationallinguistics', 'online,3143–3155', 'https', '//aclanthology.org/2021.eacl-main.274', 'yirenzhou', 'seyed-mohsenmoosavi-dezfooli', 'ngai-mancheung', 'andpascalfrossard.2018.adaptivequantizationfor', 'deepneuralnetworks.inthirty-secondaaaiconferenceonartificialintelligence', 'chenzhu', 'ankitsinghrawat', 'manzilzaheer', 'srinadhbhojanapalli', 'daliangli', 'felixyu', 'andsanjivkumar.2020.modifying', 'memoriesintransformermodels', 'arxiv:2012.00363', '[', 'cs.cl', ']', 'mingzhu', 'amanahuja', 'weiwei', 'andchandankreddy.2019', 'ahierarchicalattentionretrievalmodelforhealthcare', 'questionanswering.intheworldwidewebconference.2472–2482', 'briand.ziebart', 'andrewl.maas', 'j.andrewbagnell', 'andanindk.dey.2008.maximumentropyinversereinforcement', 'learning.inassociationfortheadvancementofartificialintelligence', 'aaai', 'annettezimmerman.2020.ifyoucandothingswithwords', 'youcandothingswithalgorithms', 'https', '//dailynous', 'com/2020/07/30/philosophers-gpt-3/', '#', 'zimmermann', 'annettezimmermann.2021.stopbuildingbadai.bostonreview', 'july2021', 'https', '//bostonreview.net/science-nature/', 'annette-zimmermann-stop-building-bad-ai', 'rolandszimmermann', 'yashsharma', 'steffenschneider', 'matthiasbethge', 'andwielandbrendel.2021.contrastivelearning', 'invertsthedatageneratingprocess.arxivpreprintarxiv:2102.08850', '2021', 'luisamzintgraf', 'tacoscohen', 'tameemadel', 'andmaxwelling.2017.visualizingdeepneuralnetworkdecisions', 'prediction', 'differenceanalysis.arxivpreprintarxiv:1702.04595', 'shoshanazuboff.2018.theageofsurveillancecapitalism', 'thefightforahumanfutureatthenewfrontierofpower']",211
Opportunities and Risks of Foundational Models - Stanford.pdf,"['212', 'centerforresearchonfoundationmodels', 'crfm', 'danielzügner', 'tobiaskirschstein', 'michelecatasta', 'jureleskovec', 'andstephangünnemann.2021', 'language-agnostic', 'representationlearningofsourcecodefromstructureandcontext.arxivpreprintarxiv:2103.11318', '2021']",212
